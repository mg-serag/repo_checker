[
  {
    "instance_id": "apache__pulsar-24402",
    "pr_id": 24402,
    "issue_id": 24389,
    "repo": "apache/pulsar",
    "problem_statement": "Potential resource leak in LoadSimulationController\n### Search before reporting\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\n`org.apache.pulsar.testclient.LoadSimulationController#read`  BufferedReader scriptReader\n\n![Image](https://github.com/user-attachments/assets/1fd31562-a628-4432-9119-1bde6c28ffc9)\n\nIf any exception is thrown from within the while loop, ` scriptReader.close(); `statement will be skipped\n\n### Solution\n\nuse  `try-with-resources` statement\n\n### Alternatives\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 89,
    "test_files_count": 1,
    "non_test_files_count": 4,
    "pr_changed_files": [
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/AutoClusterFailover.java",
      "pulsar-functions/runtime/src/main/java/org/apache/pulsar/functions/runtime/RuntimeUtils.java",
      "pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/FunctionActioner.java",
      "pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/rest/api/ComponentImpl.java",
      "pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java"
    ],
    "pr_changed_test_files": [
      "pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java"
    ],
    "base_commit": "0f9ea181b084907ec8cb3d25535f7c6e3d2ffdc2",
    "head_commit": "0ea0c8e108c94721877aa10b2aa7752eed0e4337",
    "repo_url": "https://github.com/apache/pulsar/pull/24402",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24402",
    "dockerfile": "",
    "pr_merged_at": "2025-06-10T16:50:12.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/AutoClusterFailover.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/AutoClusterFailover.java\nindex 68b781e67d29c..844d1e2d25349 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/AutoClusterFailover.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/AutoClusterFailover.java\n@@ -128,9 +128,9 @@ boolean probeAvailable(String url) {\n         try {\n             resolver.updateServiceUrl(url);\n             InetSocketAddress endpoint = resolver.resolveHost();\n-            Socket socket = new Socket();\n-            socket.connect(new InetSocketAddress(endpoint.getHostName(), endpoint.getPort()), TIMEOUT);\n-            socket.close();\n+            try (Socket socket = new Socket()) {\n+                socket.connect(new InetSocketAddress(endpoint.getHostName(), endpoint.getPort()), TIMEOUT);\n+            }\n             return true;\n         } catch (Exception e) {\n             log.warn(\"Failed to probe available, url: {}\", url, e);\n\ndiff --git a/pulsar-functions/runtime/src/main/java/org/apache/pulsar/functions/runtime/RuntimeUtils.java b/pulsar-functions/runtime/src/main/java/org/apache/pulsar/functions/runtime/RuntimeUtils.java\nindex 49a5dd40fa271..ae58fc40e2b65 100644\n--- a/pulsar-functions/runtime/src/main/java/org/apache/pulsar/functions/runtime/RuntimeUtils.java\n+++ b/pulsar-functions/runtime/src/main/java/org/apache/pulsar/functions/runtime/RuntimeUtils.java\n@@ -540,17 +540,17 @@ public static String genFunctionLogFolder(String logDirectory, InstanceConfig in\n     }\n \n     public static String getPrometheusMetrics(int metricsPort) throws IOException {\n-        StringBuilder result = new StringBuilder();\n         URL url = new URL(String.format(\"http://%s:%s\", InetAddress.getLocalHost().getHostAddress(), metricsPort));\n         HttpURLConnection conn = (HttpURLConnection) url.openConnection();\n         conn.setRequestMethod(\"GET\");\n-        BufferedReader rd = new BufferedReader(new InputStreamReader(conn.getInputStream()));\n-        String line;\n-        while ((line = rd.readLine()) != null) {\n-            result.append(line + System.lineSeparator());\n+        try (BufferedReader rd = new BufferedReader(new InputStreamReader(conn.getInputStream()))) {\n+            StringBuilder result = new StringBuilder();\n+            String line;\n+            while ((line = rd.readLine()) != null) {\n+                result.append(line + System.lineSeparator());\n+            }\n+            return result.toString();\n         }\n-        rd.close();\n-        return result.toString();\n     }\n \n     /**\n\ndiff --git a/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/FunctionActioner.java b/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/FunctionActioner.java\nindex 389051fce4217..4bdd120e215d2 100644\n--- a/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/FunctionActioner.java\n+++ b/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/FunctionActioner.java\n@@ -266,13 +266,11 @@ private void downloadFile(File pkgFile, boolean isPkgUrlProvided, FunctionMetaDa\n         } else if (downloadFromPackageManagementService) {\n             getPulsarAdmin().packages().download(pkgLocationPath, tempPkgFile.getPath());\n         } else {\n-            FileOutputStream tempPkgFos = new FileOutputStream(tempPkgFile);\n-            WorkerUtils.downloadFromBookkeeper(\n-                    dlogNamespace,\n-                    tempPkgFos,\n-                    pkgLocationPath);\n-            if (tempPkgFos != null) {\n-                tempPkgFos.close();\n+            try (FileOutputStream tempPkgFos = new FileOutputStream(tempPkgFile)) {\n+                WorkerUtils.downloadFromBookkeeper(\n+                        dlogNamespace,\n+                        tempPkgFos,\n+                        pkgLocationPath);\n             }\n         }\n \n\ndiff --git a/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/rest/api/ComponentImpl.java b/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/rest/api/ComponentImpl.java\nindex ba87713d3c13e..4058ebb667c06 100644\n--- a/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/rest/api/ComponentImpl.java\n+++ b/pulsar-functions/worker/src/main/java/org/apache/pulsar/functions/worker/rest/api/ComponentImpl.java\n@@ -1283,8 +1283,9 @@ public void uploadFunction(final InputStream uploadedInputStream, final String p\n             if (worker().getWorkerConfig().isFunctionsWorkerEnablePackageManagement()) {\n                 File tempFile = createPkgTempFile();\n                 tempFile.deleteOnExit();\n-                FileOutputStream out = new FileOutputStream(tempFile);\n-                IOUtils.copy(uploadedInputStream, out);\n+                try (FileOutputStream out = new FileOutputStream(tempFile)) {\n+                    IOUtils.copy(uploadedInputStream, out);\n+                }\n                 PackageMetadata metadata = PackageMetadata.builder().createTime(System.currentTimeMillis()).build();\n                 worker().getBrokerAdmin().packages().upload(metadata, path, tempFile.getAbsolutePath());\n             } else {\n",
    "test_patch": "diff --git a/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java b/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java\nindex 2ba3eac171bf6..26f8cae012ffd 100644\n--- a/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java\n+++ b/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/LoadSimulationController.java\n@@ -638,14 +638,13 @@ private void read(final String[] args) {\n                     final List<String> commandArguments = arguments.commandArguments;\n                     checkAppArgs(commandArguments.size() - 1, 1);\n                     final String scriptName = commandArguments.get(1);\n-                    final BufferedReader scriptReader = new BufferedReader(\n-                            new InputStreamReader(new FileInputStream(Paths.get(scriptName).toFile())));\n-                    String line = scriptReader.readLine();\n-                    while (line != null) {\n-                        read(line.split(\"\\\\s+\"));\n-                        line = scriptReader.readLine();\n+                    try (BufferedReader scriptReader = new BufferedReader(\n+                            new InputStreamReader(new FileInputStream(Paths.get(scriptName).toFile())))) {\n+                        String line;\n+                        while ((line = scriptReader.readLine()) != null) {\n+                            read(line.split(\"\\\\s+\"));\n+                        }\n                     }\n-                    scriptReader.close();\n                     break;\n                 case \"copy\":\n                     handleCopy(arguments);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24330",
    "pr_id": 24330,
    "issue_id": 24329,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ManagedLedgerTest.testDoNotGetOffloadPoliciesMultipleTimesWhenTrimLedgers\n### Search before reporting\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/15161846788/job/42630332032#step:11:10816\n\n### Exception stacktrace\n\n```text\nError:  Tests run: 126, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 103.667 s <<< FAILURE! - in org.apache.bookkeeper.mledger.impl.ManagedLedgerTest\n  Error:  org.apache.bookkeeper.mledger.impl.ManagedLedgerTest.testDoNotGetOffloadPoliciesMultipleTimesWhenTrimLedgers  Time elapsed: 0.052 s  <<< FAILURE!\n  java.lang.AssertionError: expected [10] but found [11]\n  \tat org.testng.Assert.fail(Assert.java:110)\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerTest.testDoNotGetOffloadPoliciesMultipleTimesWhenTrimLedgers(ManagedLedgerTest.java:3872)\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n```\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 274,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java"
    ],
    "base_commit": "66624713da79061dee455f0a1fd82b5fa8e9ff4b",
    "head_commit": "1783055edd740aef0f9ea060ab2b4d24099ac0ec",
    "repo_url": "https://github.com/apache/pulsar/pull/24330",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24330",
    "dockerfile": "",
    "pr_merged_at": "2025-05-22T04:29:05.000Z",
    "patch": "",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\nindex 9074e8f985c78..e0b76ca2a5a58 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\n@@ -3869,7 +3869,7 @@ public void testDoNotGetOffloadPoliciesMultipleTimesWhenTrimLedgers() throws Exc\n         for (int i = 0; i < entries; i++) {\n             ledger.addEntry(data);\n         }\n-        assertEquals(ledger.ledgers.size(), 10);\n+        Awaitility.await().untilAsserted(() -> assertEquals(ledger.ledgers.size(), 11));\n \n         // Set a new offloader to cleanup the execution times of getOffloadPolicies()\n         ledgerOffloader = mock(NullLedgerOffloader.class);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24320",
    "pr_id": 24320,
    "issue_id": 24319,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] pulsar-shell cannot produce message with quota and space\n### Search before reporting\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that [unsupported versions](https://pulsar.apache.org/contribute/release-policy/#supported-versions) don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### User environment\n\nBroker version (4.0.4)\n\n### Issue Description\n\nGot error when I run command\n\n ```\n./bin/pulsar-shell\nclient produce apache/pulsar/test-topic  -m \"hello pulsar\"\n```\n\n I believe it's a bug of pulsar-client-tools module after debug the source code.\n\n### Error messages\n\n```text\nUnmatched argument at index 5: 'pulsar'\nUsage: <main class> client produce [-chv] [-db] [-dr] [-ekn=<encKeyName>]\n                                   [-ekv=<encKeyValue>] [-k=<key>]\n                                   [-ks=<keySchema>]\n                                   [-kvet=<keyValueEncodingType>]\n                                   [-kvk=<keyValueKey>]\n                                   [-kvkf=<keyValueKeyFile>]\n                                   [-n=<numTimesProduce>] [-r=<publishRate>]\n                                   [-s=<separator>] [-vs=<valueSchema>]\n                                   [-f=<messageFileNames>]...\n                                   [-m=<messages>]... [-p=<properties>]...\n                                   <topic>\nProduce messages to a specified topic\n      <topic>                TopicName\n  -c, --chunking             Should split the message and publish in chunks if\n                               message size is larger than allowed max size\n      -db, --disable-batching\n                             Disable batch sending of messages\n      -dr, --disable-replication\n                             Disable geo-replication for messages.\n      -ekn, --encryption-key-name=<encKeyName>\n                             The public key name to encrypt payload\n      -ekv, --encryption-key-value=<encKeyValue>\n                             The URI of public key to encrypt payload, for\n                               example file:///path/to/public.key or data:\n                               application/x-pem-file;base64,*****\n  -f, --files=<messageFileNames>\n                             Comma separated file paths to send, either -m or\n                               -f must be specified.\n  -h, --help                 Show this help message and exit.\n  -k, --key=<key>            Partitioning key to add to each message\n      -ks, --key-schema=<keySchema>\n                             Schema type (can be bytes,avro,json,string...)\n      -kvet, --key-value-encoding-type=<keyValueEncodingType>\n                             Key Value Encoding Type (it can be separated or\n                               inline)\n      -kvk, --key-value-key=<keyValueKey>\n                             Value to add as message key in KeyValue schema\n      -kvkf, --key-value-key-file=<keyValueKeyFile>\n                             Path to file containing the value to add as\n                               message key in KeyValue schema. JSON and AVRO\n                               files are supported.\n  -m, --messages=<messages>  Messages to send, either -m or -f must be\n                               specified. Specify -m for each message.\n  -n, --num-produce=<numTimesProduce>\n                             Number of times to send message(s), the count of\n                               messages/files * num-produce should below than\n                               1000.\n  -p, --properties=<properties>\n                             Properties to add, Comma separated key=value\n                               string, like k1=v1,k2=v2.\n  -r, --rate=<publishRate>   Rate (in msg/sec) at which to produce, value 0\n                               means to produce messages as fast as possible.\n  -s, --separator=<separator>\n                             Character to split messages string on default is\n                               comma\n  -v, --version              Print version information and exit.\n      -vs, --value-schema=<valueSchema>\n                             Schema type (can be bytes,avro,json,string...)\n```\n\n### Reproducing the issue\n\nThere is two way to reproduce.\n\n**1. Reproduce by shell**\n```\n./bin/pulsar-shell\nclient produce apache/pulsar/test-topic  -m \"hello pulsar\"\n```\n\n**2. Reproduce by change unit test**\n\n1. just change the unit test [line](https://github.com/apache/pulsar/blob/v4.0.4/pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java#L151) to\n```\nlinereader.addCmd(\"client produce -m \\\"hello pulsar\\\" my-topic\");\n```\n2. run the unit test **testInteractiveMode**\n3. The ut will fail\n\n### Additional information\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 550,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-client-tools/src/main/java/org/apache/pulsar/shell/PulsarShell.java",
      "pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java"
    ],
    "base_commit": "610060e89a4f6e9107852ba1c5cd0f4aa4bc8c9a",
    "head_commit": "de6a0575076d2c2b4de3594fbace378e9d4b522b",
    "repo_url": "https://github.com/apache/pulsar/pull/24320",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24320",
    "dockerfile": "",
    "pr_merged_at": "2025-05-21T11:25:14.000Z",
    "patch": "diff --git a/pulsar-client-tools/src/main/java/org/apache/pulsar/shell/PulsarShell.java b/pulsar-client-tools/src/main/java/org/apache/pulsar/shell/PulsarShell.java\nindex 3cc99126fb8d7..fada88494227f 100644\n--- a/pulsar-client-tools/src/main/java/org/apache/pulsar/shell/PulsarShell.java\n+++ b/pulsar-client-tools/src/main/java/org/apache/pulsar/shell/PulsarShell.java\n@@ -48,6 +48,7 @@\n import org.jline.console.impl.SystemRegistryImpl;\n import org.jline.reader.LineReader;\n import org.jline.reader.LineReaderBuilder;\n+import org.jline.reader.Parser;\n import org.jline.reader.impl.DefaultParser;\n import org.jline.terminal.Terminal;\n import org.jline.terminal.TerminalBuilder;\n@@ -290,7 +291,7 @@ public String readLine() {\n \n                 @Override\n                 public List<String> parseLine(String line) {\n-                    return reader.getParser().parse(line, 0).words();\n+                    return reader.getParser().parse(line, 0, Parser.ParseContext.SPLIT_LINE).words();\n                 }\n             };\n         }, () -> terminal);\n",
    "test_patch": "diff --git a/pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java b/pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java\nindex 165fee923782b..370db8febe7ef 100644\n--- a/pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java\n+++ b/pulsar-client-tools/src/test/java/org/apache/pulsar/shell/PulsarShellTest.java\n@@ -42,6 +42,7 @@\n import org.apache.pulsar.client.admin.Topics;\n import org.apache.pulsar.client.cli.CmdProduce;\n import org.jline.reader.EndOfFileException;\n+import org.jline.reader.Parser;\n import org.jline.reader.UserInterruptException;\n import org.jline.reader.impl.LineReaderImpl;\n import org.jline.terminal.Terminal;\n@@ -82,7 +83,7 @@ public String readLine() throws UserInterruptException, EndOfFileException {\n \n         @Override\n         public List<String> parseLine(String line) {\n-            return getParser().parse(line, 0).words();\n+            return getParser().parse(line, 0, Parser.ParseContext.SPLIT_LINE).words();\n         }\n     }\n \n@@ -149,11 +150,12 @@ public void testInteractiveMode() throws Exception {\n         props.setProperty(\"webServiceUrl\", \"http://localhost:8080\");\n         linereader.addCmd(\"admin topics create my-topic --metadata a=b \");\n         linereader.addCmd(\"client produce -m msg my-topic\");\n+        linereader.addCmd(\"client produce -m \\\"hello pulsar\\\" my-topic\");\n         linereader.addCmd(\"quit\");\n         final TestPulsarShell testPulsarShell = new TestPulsarShell(new String[]{}, props, pulsarAdmin);\n         testPulsarShell.run((a) -> linereader, () -> terminal);\n         verify(topics).createNonPartitionedTopic(eq(\"persistent://public/default/my-topic\"), any(Map.class));\n-        verify(testPulsarShell.cmdProduceHolder.get()).call();\n+        verify(testPulsarShell.cmdProduceHolder.get(), times(2)).call();\n         assertEquals((int) testPulsarShell.exitCode, 0);\n \n     }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24316",
    "pr_id": 24316,
    "issue_id": 91,
    "repo": "apache/pulsar",
    "problem_statement": "Intermittent test failure in SimpleProducerConsumerTest.testSharedConsumerAckDifferentConsumer\nThe test is failing from time to time. It seems to be related to expecting the 2 consumer to get the same amount of messages, but after calling `receive()` on `consumer1`, the broker will push more messages to the consumer.\n\n```\ntestSharedConsumerAckDifferentConsumer(com.yahoo.pulsar.client.api.SimpleProducerConsumerTest)  Time elapsed: 3.05 sec  <<< FAILURE!\njava.lang.AssertionError: null\n    at com.yahoo.pulsar.client.api.SimpleProducerConsumerTest.lambda$testSharedConsumerAckDifferentConsumer$28(SimpleProducerConsumerTest.java:916)\n    at com.yahoo.pulsar.client.api.SimpleProducerConsumerTest.testSharedConsumerAckDifferentConsumer(SimpleProducerConsumerTest.java:912)\n```\n",
    "issue_word_count": 87,
    "test_files_count": 3,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java"
    ],
    "pr_changed_test_files": [
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java"
    ],
    "base_commit": "aa3ce89c6c39b0773d36d90a4aa9e1750bdd6cb9",
    "head_commit": "d7fb9a7e361083ba1ddea893a69bf3a2e664eee6",
    "repo_url": "https://github.com/apache/pulsar/pull/24316",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24316",
    "dockerfile": "",
    "pr_merged_at": "2025-05-20T15:19:00.000Z",
    "patch": "diff --git a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\nindex 22412c395759a..a44d081cd2cef 100644\n--- a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\n+++ b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\n@@ -23,6 +23,7 @@\n import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n import com.fasterxml.jackson.databind.node.ObjectNode;\n import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n import java.time.Instant;\n import java.time.LocalDate;\n import java.time.LocalTime;\n@@ -78,11 +79,13 @@ public static JsonNode toJson(Schema schema, Object value, boolean convertBytesT\n             case BOOLEAN:\n                 return jsonNodeFactory.booleanNode((Boolean) value);\n             case BYTES:\n+                byte[] bytes = new byte[((ByteBuffer) value).remaining()];\n+                ((ByteBuffer) value).get(bytes);\n                 // Workaround for https://github.com/wnameless/json-flattener/issues/91\n                 if (convertBytesToString) {\n-                    return jsonNodeFactory.textNode(Base64.getEncoder().encodeToString((byte[]) value));\n+                    return jsonNodeFactory.textNode(Base64.getEncoder().encodeToString(bytes));\n                 }\n-                return jsonNodeFactory.binaryNode((byte[]) value);\n+                return jsonNodeFactory.binaryNode(bytes);\n             case FIXED:\n                 // Workaround for https://github.com/wnameless/json-flattener/issues/91\n                 if (convertBytesToString) {\n",
    "test_patch": "diff --git a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\nindex 1eda566df04c3..55505af4b7bb1 100644\n--- a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\n+++ b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\n@@ -30,7 +30,6 @@\n \n import java.nio.ByteBuffer;\n import java.nio.charset.StandardCharsets;\n-import java.util.Base64;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.Map;\n@@ -279,6 +278,7 @@ public void testSerializeRecordToJsonExpandingValue(SchemaType schemaType) throw\n         RecordSchemaBuilder udtSchemaBuilder = SchemaBuilder.record(\"type1\");\n         udtSchemaBuilder.field(\"a\").type(SchemaType.STRING).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"b\").type(SchemaType.BOOLEAN).optional().defaultValue(null);\n+        udtSchemaBuilder.field(\"c\").type(SchemaType.BYTES).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"d\").type(SchemaType.DOUBLE).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"f\").type(SchemaType.FLOAT).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"i\").type(SchemaType.INT32).optional().defaultValue(null);\n@@ -293,8 +293,9 @@ public void testSerializeRecordToJsonExpandingValue(SchemaType schemaType) throw\n                 .set(\"e\", udtGenericSchema.newRecordBuilder()\n                         .set(\"a\", \"a\")\n                         .set(\"b\", true)\n-                        .set(\"d\", 1.0)\n-                        .set(\"f\", 1.0f)\n+                        .set(\"c\", ByteBuffer.wrap(\"10\".getBytes(StandardCharsets.UTF_8)))\n+                        .set(\"d\", 0.5)\n+                        .set(\"f\", 0.25f)\n                         .set(\"i\", 1)\n                         .set(\"l\", 10L)\n                         .build())\n@@ -303,7 +304,7 @@ public void testSerializeRecordToJsonExpandingValue(SchemaType schemaType) throw\n         Map<String, String> properties = new HashMap<>();\n         properties.put(\"prop-key\", \"prop-value\");\n \n-        Record<GenericObject> genericObjectRecord = new Record<GenericObject>() {\n+        Record<GenericObject> genericObjectRecord = new Record<>() {\n             @Override\n             public Optional<String> getTopicName() {\n                 return Optional.of(\"data-ks1.table1\");\n@@ -321,7 +322,8 @@ public Optional<String> getKey() {\n \n             @Override\n             public GenericObject getValue() {\n-                return valueGenericRecord;\n+                // Ensure the record in encoded amd decoded correctly\n+                return valueSchema.decode(valueSchema.encode(valueGenericRecord));\n             }\n \n             @Override\n@@ -339,7 +341,7 @@ public Optional<Long> getEventTime() {\n         String json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, false);\n \n         assertEquals(json, \"{\\\"topicName\\\":\\\"data-ks1.table1\\\",\\\"key\\\":\\\"message-key\\\",\\\"payload\\\":{\\\"c\\\":\\\"1\\\",\"\n-                + \"\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"d\\\":1.0,\\\"f\\\":1.0,\\\"i\\\":1,\\\"l\\\":10}},\"\n+                + \"\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"c\\\":\\\"MTA=\\\",\\\"d\\\":0.5,\\\"f\\\":0.25,\\\"i\\\":1,\\\"l\\\":10}},\"\n                 + \"\\\"properties\\\":{\\\"prop-key\\\":\\\"prop-value\\\"},\\\"eventTime\\\":1648502845803}\");\n     }\n \n@@ -369,18 +371,15 @@ public void testKeyValueSerializeRecordToJsonExpandingValue(SchemaType schemaTyp\n         valueSchemaBuilder.field(\"e\", udtGenericSchema).type(schemaType).optional().defaultValue(null);\n         GenericSchema<GenericRecord> valueSchema = Schema.generic(valueSchemaBuilder.build(schemaType));\n \n-        byte[] bytes = \"10\".getBytes(StandardCharsets.UTF_8);\n         GenericRecord valueGenericRecord = valueSchema.newRecordBuilder()\n                 .set(\"c\", \"1\")\n                 .set(\"d\", 1)\n                 .set(\"e\", udtGenericSchema.newRecordBuilder()\n                         .set(\"a\", \"a\")\n                         .set(\"b\", true)\n-                        // There's a bug in json-flattener that doesn't handle byte[] fields correctly.\n-                        // But since we use AUTO_CONSUME, we won't get byte[] fields for JSON schema anyway.\n-                        .set(\"c\", schemaType == SchemaType.AVRO ? bytes : Base64.getEncoder().encodeToString(bytes))\n-                        .set(\"d\", 1.0)\n-                        .set(\"f\", 1.0f)\n+                        .set(\"c\", ByteBuffer.wrap(\"10\".getBytes(StandardCharsets.UTF_8)))\n+                        .set(\"d\", 0.5)\n+                        .set(\"f\", 0.25f)\n                         .set(\"i\", 1)\n                         .set(\"l\", 10L)\n                         .build())\n@@ -398,7 +397,7 @@ public SchemaType getSchemaType() {\n \n             @Override\n             public Object getNativeObject() {\n-                return keyValue;\n+                return keyValueSchema.decode(keyValueSchema.encode(keyValue));\n             }\n         };\n \n@@ -441,15 +440,15 @@ public Optional<Long> getEventTime() {\n         String json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, false);\n \n         assertEquals(json, \"{\\\"topicName\\\":\\\"data-ks1.table1\\\",\\\"key\\\":\\\"message-key\\\",\"\n-                + \"\\\"payload\\\":{\\\"value\\\":{\\\"c\\\":\\\"1\\\",\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"c\\\":\\\"MTA=\\\",\\\"d\\\":1.0,\"\n-                + \"\\\"f\\\":1.0,\\\"i\\\":1,\\\"l\\\":10}},\\\"key\\\":{\\\"a\\\":\\\"1\\\",\\\"b\\\":1}},\"\n+                + \"\\\"payload\\\":{\\\"value\\\":{\\\"c\\\":\\\"1\\\",\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"c\\\":\\\"MTA=\\\",\\\"d\\\":0.5,\"\n+                + \"\\\"f\\\":0.25,\\\"i\\\":1,\\\"l\\\":10}},\\\"key\\\":{\\\"a\\\":\\\"1\\\",\\\"b\\\":1}},\"\n                 + \"\\\"properties\\\":{\\\"prop-key\\\":\\\"prop-value\\\"},\\\"eventTime\\\":1648502845803}\");\n \n         json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, true);\n \n         assertEquals(json, \"{\\\"topicName\\\":\\\"data-ks1.table1\\\",\\\"key\\\":\\\"message-key\\\",\\\"payload.value.c\\\":\\\"1\\\",\"\n                 + \"\\\"payload.value.d\\\":1,\\\"payload.value.e.a\\\":\\\"a\\\",\\\"payload.value.e.b\\\":true,\"\n-                + \"\\\"payload.value.e.c\\\":\\\"MTA=\\\",\\\"payload.value.e.d\\\":1.0,\\\"payload.value.e.f\\\":1.0,\"\n+                + \"\\\"payload.value.e.c\\\":\\\"MTA=\\\",\\\"payload.value.e.d\\\":0.5,\\\"payload.value.e.f\\\":0.25,\"\n                 + \"\\\"payload.value.e.i\\\":1,\\\"payload.value.e.l\\\":10,\\\"payload.key.a\\\":\\\"1\\\",\\\"payload.key.b\\\":1,\"\n                 + \"\\\"properties.prop-key\\\":\\\"prop-value\\\",\\\"eventTime\\\":1648502845803}\");\n     }\n@@ -476,7 +475,7 @@ public SchemaType getSchemaType() {\n \n             @Override\n             public Object getNativeObject() {\n-                return keyValue;\n+                return keyValueSchema.decode(keyValueSchema.encode(keyValue));\n             }\n         };\n \n\ndiff --git a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\nindex c3bbaa06d014d..c762b713de2d5 100644\n--- a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\n+++ b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\n@@ -35,6 +35,7 @@\n import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n import java.nio.charset.StandardCharsets;\n import java.util.Arrays;\n import java.util.Calendar;\n@@ -71,7 +72,7 @@ public void testAvroToJson() throws IOException {\n         genericRecord.put(\"l\", 1L);\n         genericRecord.put(\"i\", 1);\n         genericRecord.put(\"b\", true);\n-        genericRecord.put(\"bb\", \"10\".getBytes(StandardCharsets.UTF_8));\n+        genericRecord.put(\"bb\", ByteBuffer.wrap(\"10\".getBytes(StandardCharsets.UTF_8)));\n         genericRecord.put(\"d\", 10.0);\n         genericRecord.put(\"f\", 10.0f);\n         genericRecord.put(\"s\", \"toto\");\n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java\nindex 83cb0088cd76b..e1e339f6a82a2 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/io/sinks/KinesisSinkTester.java\n@@ -23,6 +23,7 @@\n import com.google.common.collect.ImmutableMap;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Base64;\n import java.util.HashSet;\n import java.util.LinkedHashMap;\n import java.util.List;\n@@ -156,13 +157,15 @@ public void produceMessage(int numMessages, PulsarClient client,\n                         \"f2_\" + i,\n                         Arrays.asList(i, i +1),\n                         new HashSet<>(Arrays.asList((long) i)),\n-                        ImmutableMap.of(\"map1_k_\" + i, \"map1_kv_\" + i));\n+                        ImmutableMap.of(\"map1_k_\" + i, \"map1_kv_\" + i),\n+                        (\"key_bytes_\" + i).getBytes(StandardCharsets.UTF_8));\n                 final SimplePojo valuePojo = new SimplePojo(\n                         String.valueOf(i),\n                         \"v2_\" + i,\n                         Arrays.asList(i, i +1),\n                         new HashSet<>(Arrays.asList((long) i)),\n-                        ImmutableMap.of(\"map1_v_\" + i, \"map1_vv_\" + i));\n+                        ImmutableMap.of(\"map1_v_\" + i, \"map1_vv_\" + i),\n+                        (\"value_bytes_\" + i).getBytes(StandardCharsets.UTF_8));\n                 producer.newMessage()\n                         .value(new KeyValue<>(keyPojo, valuePojo))\n                         .send();\n@@ -222,8 +225,12 @@ private void parseRecordData(Map<String, String> actualKvs, String data, String\n             JsonNode payload = READER.readTree(data).at(\"/payload\");\n             String i = payload.at(\"/value/field1\").asText();\n             assertEquals(payload.at(\"/value/field2\").asText(), \"v2_\" + i);\n+            assertEquals(payload.at(\"/value/bytes\").asText(),\n+                    Base64.getEncoder().encodeToString((\"value_bytes_\" + i).getBytes(StandardCharsets.UTF_8)));\n             assertEquals(payload.at(\"/key/field1\").asText(), \"f1_\" + i);\n             assertEquals(payload.at(\"/key/field2\").asText(), \"f2_\" + i);\n+            assertEquals(payload.at(\"/key/bytes\").asText(),\n+                    Base64.getEncoder().encodeToString((\"key_bytes_\" + i).getBytes(StandardCharsets.UTF_8)));\n             actualKvs.put(i, i);\n         } else {\n             actualKvs.put(partitionKey, data);\n@@ -271,6 +278,7 @@ public static final class SimplePojo {\n         private List<Integer> list1;\n         private Set<Long> set1;\n         private Map<String, String> map1;\n+        private byte[] bytes;\n     }\n \n     @Override\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24282",
    "pr_id": 24282,
    "issue_id": 24262,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: SchemaTest.testPendingQueueSizeIfIncompatible\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14875735514/job/41772909879?pr=24261#step:11:1736\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  Tests run: 49, Failures: 1, Errors: 0, Skipped: 25, Time elapsed: 160.862 s <<< FAILURE! - in org.apache.pulsar.schema.SchemaTest\n  Error:  org.apache.pulsar.schema.SchemaTest.testPendingQueueSizeIfIncompatible  Time elapsed: 10.205 s  <<< FAILURE!\n  org.awaitility.core.ConditionTimeoutException: Assertion condition expected [0] but found [48] within 10 seconds.\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\n  \tat org.apache.pulsar.schema.SchemaTest.testPendingQueueSizeIfIncompatible(SchemaTest.java:1546)\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n  Caused by: java.lang.AssertionError: expected [0] but found [48]\n  \tat org.testng.Assert.fail(Assert.java:110)\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\n  \tat org.apache.pulsar.schema.SchemaTest.lambda$testPendingQueueSizeIfIncompatible$10(SchemaTest.java:1548)\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\n  \t... 4 more\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 387,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java"
    ],
    "base_commit": "b58e99b003262dcb13c207e413570facb3dba459",
    "head_commit": "c0beb5cab60a5ac3cd78cbdf4bf24b177e371222",
    "repo_url": "https://github.com/apache/pulsar/pull/24282",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24282",
    "dockerfile": "",
    "pr_merged_at": "2025-05-12T11:15:25.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java\nindex 21b79da9d5ac5..9960af6046ac3 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java\n@@ -2464,6 +2464,7 @@ protected void updateLastSeqPushed(OpSendMsg op) {\n      *     3-1-1. If {@link #pauseSendingToPreservePublishOrderOnSchemaRegFailure} is true pause all following\n      *       publishing to avoid out-of-order issue.\n      *     3-1-2. Otherwise, discard the failed message anc continuously publishing the following messages.\n+     *            Additionally, the following messages may need schema registration also.\n      *   3-2. The new schema registration failed due to other error, retry registering.\n      * Note: Since the current method accesses & modifies {@link #pendingMessages}, you should acquire a lock on\n      *       {@link ProducerImpl} before calling method.\n@@ -2482,6 +2483,7 @@ private void recoverProcessOpSendMsgFrom(ClientCnx cnx, MessageImpl latestMsgAtt\n         Iterator<OpSendMsg> msgIterator = pendingMessages.iterator();\n         MessageImpl loopStartAt = latestMsgAttemptedRegisteredSchema;\n         OpSendMsg loopEndDueToSchemaRegisterNeeded = null;\n+        boolean pausedSendingToPreservePublishOrderOnSchemaRegFailure = false;\n         while (msgIterator.hasNext()) {\n             OpSendMsg op = msgIterator.next();\n             if (loopStartAt != null) {\n@@ -2526,6 +2528,7 @@ private void recoverProcessOpSendMsgFrom(ClientCnx cnx, MessageImpl latestMsgAtt\n                                 + \" 2) Unload topic on target cluster. Schema details: {}\",\n                                 topic, producerName, SchemaUtils.jsonifySchemaInfo(msgSchemaInfo, false));\n                         loopEndDueToSchemaRegisterNeeded = op;\n+                        pausedSendingToPreservePublishOrderOnSchemaRegFailure = true;\n                         break;\n                     }\n                     // Event 3-1-2.\n@@ -2581,7 +2584,7 @@ private void recoverProcessOpSendMsgFrom(ClientCnx cnx, MessageImpl latestMsgAtt\n         }\n         cnx.ctx().flush();\n \n-        // \"Event 1-1\" or \"Event 3-1-1\" or \"Event 3-2\".\n+        // \"Event 1-1\" or \"Event 3-1-1\" or \"Event 3-1-2\" or \"Event 3-2\".\n         if (loopEndDueToSchemaRegisterNeeded != null) {\n             if (compareAndSetState(State.Connecting, State.Ready)) {\n                 // \"Event 1-1\" happens after \"Event 3-1-1\".\n@@ -2589,15 +2592,19 @@ private void recoverProcessOpSendMsgFrom(ClientCnx cnx, MessageImpl latestMsgAtt\n                 // after users changed the compatibility strategy to make the schema is compatible.\n                 tryRegisterSchema(cnx, loopEndDueToSchemaRegisterNeeded.msg, loopEndDueToSchemaRegisterNeeded.callback,\n                     expectedEpoch);\n-            } else if (!failedIncompatibleSchema && compareAndSetState(State.RegisteringSchema, State.Ready)) {\n-                // \"Event 2-1\" or \"Event 3-2\".\n+            } else if (pausedSendingToPreservePublishOrderOnSchemaRegFailure) {\n+                // Nothing to do if the event is \"Event 3-1-1\", just keep stuck.\n+                return;\n+            } else if (compareAndSetState(State.RegisteringSchema, State.Ready)) {\n+                // \"Event 2-1\" or \"Event 3-1-2\" or \"Event 3-2\".\n                 // \"pendingMessages\" has more messages to register new schema.\n                 // This operation will not be conflict with another schema registration because both operations are\n                 // attempt to acquire the same lock \"ProducerImpl.this\".\n                 tryRegisterSchema(cnx, loopEndDueToSchemaRegisterNeeded.msg, loopEndDueToSchemaRegisterNeeded.callback,\n                         expectedEpoch);\n             }\n-            // Nothing to do if the event is \"Event 3-1-1\", just keep stuck.\n+            // Schema registration will trigger a new \"recoverProcessOpSendMsgFrom\", so return here. If failed to switch\n+            // state, it means another task will trigger a new \"recoverProcessOpSendMsgFrom\".\n             return;\n         } else if (latestMsgAttemptedRegisteredSchema != null) {\n             // Event 2-2 or \"Event 3-1-2\".\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\nindex 711e8ba5ad7ec..07c626a549d00 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\n@@ -1528,8 +1528,7 @@ public SchemaStorageFormat.SchemaLocator deserialize(String path, byte[] content\n         producer.close();\n     }\n \n-    // This test fails consistently, disabling until it is fixed. Issue https://github.com/apache/pulsar/issues/24262\n-    @Test(enabled = false)\n+    @Test\n     public void testPendingQueueSizeIfIncompatible() throws Exception {\n         final String namespace = BrokerTestUtil.newUniqueName(PUBLIC_TENANT + \"/ns\");\n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(CLUSTER_NAME));\n@@ -1538,17 +1537,28 @@ public void testPendingQueueSizeIfIncompatible() throws Exception {\n         admin.topics().createNonPartitionedTopic(topic);\n \n         ProducerImpl producer = (ProducerImpl) pulsarClient.newProducer(Schema.AUTO_PRODUCE_BYTES())\n-                .maxPendingMessages(50).enableBatching(false).topic(topic).create();\n-        producer.newMessage(Schema.STRING).value(\"msg\").sendAsync();\n+                .maxPendingMessages(1000).enableBatching(false).topic(topic).create();\n+        producer.newMessage(Schema.STRING).value(\"msg-1\").sendAsync();\n         AtomicReference<CompletableFuture<MessageId>> latestSend = new AtomicReference<>();\n         for (int i = 0; i < 100; i++) {\n-            latestSend.set(producer.newMessage(Schema.BOOL).value(false).sendAsync());\n+            final String msg = \"msg-with-broken-schema-\" + i;\n+            latestSend.set(producer.newMessage(Schema.BOOL).value(false).sendAsync().thenApply(v -> {\n+                log.info(\"send complete {}\", msg);\n+                return null;\n+            }).exceptionally(ex -> {\n+                log.error(\"failed to send {}\", msg, ex);\n+                return null;\n+            }));\n         }\n+        // Verify: msgs with broken schema will be discarded.\n         Awaitility.await().untilAsserted(() -> {\n             assertTrue(latestSend.get().isDone());\n             assertEquals(producer.getPendingQueueSize(), 0);\n         });\n \n+        // Verify: msgs with compatible schema can be sent successfully.\n+        producer.newMessage(Schema.STRING).value(\"msg-2\").sendAsync();\n+\n         // cleanup.\n         producer.close();\n         admin.topics().delete(topic, false);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24261",
    "pr_id": 24261,
    "issue_id": 24262,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: SchemaTest.testPendingQueueSizeIfIncompatible\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14875735514/job/41772909879?pr=24261#step:11:1736\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  Tests run: 49, Failures: 1, Errors: 0, Skipped: 25, Time elapsed: 160.862 s <<< FAILURE! - in org.apache.pulsar.schema.SchemaTest\n  Error:  org.apache.pulsar.schema.SchemaTest.testPendingQueueSizeIfIncompatible  Time elapsed: 10.205 s  <<< FAILURE!\n  org.awaitility.core.ConditionTimeoutException: Assertion condition expected [0] but found [48] within 10 seconds.\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\n  \tat org.apache.pulsar.schema.SchemaTest.testPendingQueueSizeIfIncompatible(SchemaTest.java:1546)\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n  Caused by: java.lang.AssertionError: expected [0] but found [48]\n  \tat org.testng.Assert.fail(Assert.java:110)\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\n  \tat org.apache.pulsar.schema.SchemaTest.lambda$testPendingQueueSizeIfIncompatible$10(SchemaTest.java:1548)\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\n  \t... 4 more\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 387,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java",
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java"
    ],
    "base_commit": "de1d4c96c7b77df87a1ab5be2ea87a8d570cd572",
    "head_commit": "04cf6dbf9373277bed6c726e2e48f2057fcb26bd",
    "repo_url": "https://github.com/apache/pulsar/pull/24261",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24261",
    "dockerfile": "",
    "pr_merged_at": "2025-05-07T11:10:33.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\nindex f4a64d267fd3e..17988135c80aa 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n@@ -1460,8 +1460,8 @@ public void operationComplete() {\n                                 ledger.getName(), newReadPosition, name);\n                     }\n                 }\n-                callback.resetComplete(newReadPosition);\n                 updateLastActive();\n+                callback.resetComplete(newReadPosition);\n             }\n \n             @Override\n",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\nindex 61822999c7614..879bc7bcd55bd 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n@@ -1004,6 +1004,9 @@ void testLastActiveAfterResetCursor() throws Exception {\n \n         long lastActive = cursor.getLastActive();\n \n+        // ensure that the next last active time will be greater than the current one\n+        Thread.sleep(1L);\n+\n         cursor.asyncResetCursor(lastPosition, false, new AsyncCallbacks.ResetCursorCallback() {\n             @Override\n             public void resetComplete(Object ctx) {\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\nindex b61c902d759e4..711e8ba5ad7ec 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/schema/SchemaTest.java\n@@ -1528,7 +1528,8 @@ public SchemaStorageFormat.SchemaLocator deserialize(String path, byte[] content\n         producer.close();\n     }\n \n-    @Test\n+    // This test fails consistently, disabling until it is fixed. Issue https://github.com/apache/pulsar/issues/24262\n+    @Test(enabled = false)\n     public void testPendingQueueSizeIfIncompatible() throws Exception {\n         final String namespace = BrokerTestUtil.newUniqueName(PUBLIC_TENANT + \"/ns\");\n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(CLUSTER_NAME));\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24210",
    "pr_id": 24210,
    "issue_id": 23413,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BrokerRegistryMetadataStoreIntegrationTest.cleanup\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Example failure\r\n\r\nhttps://github.com/apache/pulsar/actions/runs/11231028428/job/31223989424?pr=23410#step:11:1773\r\n\r\nLogs: https://gist.github.com/lhotari/f8271c5229f85862c5a471e56a2c56c9\r\n\r\n### Exception stacktrace\r\n\r\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 69.073 s <<< FAILURE! - in org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryMetadataStoreIntegrationTest\r\n  Error:  org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryMetadataStoreIntegrationTest.cleanup  Time elapsed: 62.361 s  <<< FAILURE!\r\n  java.lang.RuntimeException: Broker took 61822ms to close\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.cleanup(BrokerRegistryIntegrationTest.java:73)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethodConsideringTimeout(MethodInvocationHelper.java:69)\r\n  \tat org.testng.internal.invokers.ConfigInvoker.invokeConfigurationMethod(ConfigInvoker.java:361)\r\n  \tat org.testng.internal.invokers.ConfigInvoker.invokeConfigurations(ConfigInvoker.java:296)\r\n  \tat org.testng.internal.invokers.TestMethodWorker.invokeAfterClassMethods(TestMethodWorker.java:222)\r\n  \tat org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:131)\r\n  \tat java.base/java.util.ArrayList.forEach(ArrayList.java:1596)\r\n  \tat org.testng.TestRunner.privateRun(TestRunner.java:829)\r\n  \tat org.testng.TestRunner.run(TestRunner.java:602)\r\n  \tat org.testng.SuiteRunner.runTest(SuiteRunner.java:437)\r\n  \tat org.testng.SuiteRunner.runSequentially(SuiteRunner.java:431)\r\n  \tat org.testng.SuiteRunner.privateRun(SuiteRunner.java:391)\r\n  \tat org.testng.SuiteRunner.run(SuiteRunner.java:330)\r\n  \tat org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\r\n  \tat org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95)\r\n  \tat org.testng.TestNG.runSuitesSequentially(TestNG.java:1256)\r\n  \tat org.testng.TestNG.runSuitesLocally(TestNG.java:1176)\r\n  \tat org.testng.TestNG.runSuites(TestNG.java:1099)\r\n  \tat org.testng.TestNG.run(TestNG.java:1067)\r\n  \tat org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:155)\r\n  \tat org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeSingleClass(TestNGDirectoryTestSuite.java:102)\r\n  \tat org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.executeLazy(TestNGDirectoryTestSuite.java:117)\r\n  \tat org.apache.maven.surefire.testng.TestNGDirectoryTestSuite.execute(TestNGDirectoryTestSuite.java:86)\r\n  \tat org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:137)\r\n  \tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)\r\n  \tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)\r\n  \tat org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)\r\n  \tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)\r\n```\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 419,
    "test_files_count": 5,
    "non_test_files_count": 4,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/HealthChecker.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java"
    ],
    "base_commit": "0a9c439cd3bc88f93baaefb1e2616c33fa06c567",
    "head_commit": "8bf6787aefce695af867c6e1d5494d3a5cdaf852",
    "repo_url": "https://github.com/apache/pulsar/pull/24210",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24210",
    "dockerfile": "",
    "pr_merged_at": "2025-04-24T16:11:52.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\nindex c63f17c031e49..51eecb53f9da9 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\n@@ -21,7 +21,6 @@\n import static com.google.common.base.Preconditions.checkNotNull;\n import static org.apache.commons.lang3.StringUtils.isBlank;\n import static org.apache.commons.lang3.StringUtils.isNotBlank;\n-import static org.apache.pulsar.broker.admin.impl.BrokersBase.getHeartbeatTopicName;\n import static org.apache.pulsar.broker.resourcegroup.ResourceUsageTransportManager.DISABLE_RESOURCE_USAGE_TRANSPORT_MANAGER;\n import static org.apache.pulsar.common.naming.SystemTopicNames.isTransactionInternalName;\n import com.google.common.annotations.VisibleForTesting;\n@@ -75,7 +74,6 @@\n import org.apache.bookkeeper.mledger.LedgerOffloader;\n import org.apache.bookkeeper.mledger.LedgerOffloaderFactory;\n import org.apache.bookkeeper.mledger.LedgerOffloaderStats;\n-import org.apache.bookkeeper.mledger.ManagedLedgerException;\n import org.apache.bookkeeper.mledger.ManagedLedgerFactory;\n import org.apache.bookkeeper.mledger.impl.NullLedgerOffloader;\n import org.apache.bookkeeper.mledger.offload.Offloaders;\n@@ -105,6 +103,7 @@\n import org.apache.pulsar.broker.resources.PulsarResources;\n import org.apache.pulsar.broker.rest.Topics;\n import org.apache.pulsar.broker.service.BrokerService;\n+import org.apache.pulsar.broker.service.HealthChecker;\n import org.apache.pulsar.broker.service.PulsarMetadataEventSynchronizer;\n import org.apache.pulsar.broker.service.SystemTopicBasedTopicPoliciesService;\n import org.apache.pulsar.broker.service.Topic;\n@@ -156,6 +155,7 @@\n import org.apache.pulsar.common.naming.NamespaceBundle;\n import org.apache.pulsar.common.naming.NamespaceName;\n import org.apache.pulsar.common.naming.TopicName;\n+import org.apache.pulsar.common.naming.TopicVersion;\n import org.apache.pulsar.common.policies.data.ClusterDataImpl;\n import org.apache.pulsar.common.policies.data.OffloadPoliciesImpl;\n import org.apache.pulsar.common.protocol.schema.SchemaStorage;\n@@ -317,6 +317,7 @@ public enum State {\n     private volatile CompletableFuture<Void> closeFuture;\n     // key is listener name, value is pulsar address and pulsar ssl address\n     private Map<String, AdvertisedListener> advertisedListeners;\n+    private volatile HealthChecker healthChecker;\n \n     public PulsarService(ServiceConfiguration config) {\n         this(config, Optional.empty(), (exitCode) -> LOG.info(\"Process termination requested with code {}. \"\n@@ -447,41 +448,6 @@ private void closeLeaderElectionService() throws Exception {\n         }\n     }\n \n-    private boolean isManagedLedgerNotFoundException(Throwable e) {\n-        Throwable realCause = e.getCause();\n-        return realCause instanceof ManagedLedgerException.MetadataNotFoundException\n-                || realCause instanceof MetadataStoreException.NotFoundException;\n-    }\n-\n-    private void deleteHeartbeatResource() {\n-        if (this.brokerService != null) {\n-            LOG.info(\"forcefully delete heartbeat topic when close broker\");\n-\n-            String heartbeatTopicNameV1 = getHeartbeatTopicName(getBrokerId(), getConfiguration(), false);\n-            String heartbeatTopicNameV2 = getHeartbeatTopicName(getBrokerId(), getConfiguration(), true);\n-\n-            try {\n-                this.brokerService.deleteTopic(heartbeatTopicNameV1, true).get();\n-            } catch (Exception e) {\n-                if (!isManagedLedgerNotFoundException(e)) {\n-                    LOG.error(\"Closed with errors in delete heartbeat topic [{}]\",\n-                            heartbeatTopicNameV1, e);\n-                }\n-            }\n-\n-            try {\n-                this.brokerService.deleteTopic(heartbeatTopicNameV2, true).get();\n-            } catch (Exception e) {\n-                if (!isManagedLedgerNotFoundException(e)) {\n-                    LOG.error(\"Closed with errors in delete heartbeat topic [{}]\",\n-                            heartbeatTopicNameV2, e);\n-                }\n-            }\n-\n-            LOG.info(\"finish forcefully delete heartbeat topic when close broker\");\n-        }\n-    }\n-\n     @Override\n     public void close() throws PulsarServerException {\n         try {\n@@ -531,9 +497,9 @@ public CompletableFuture<Void> closeAsync() {\n             // It only tells the Pulsar clients that this service is not ready to serve for the lookup requests\n             state = State.Closing;\n \n-            if (brokerId != null) {\n-                // forcefully delete heartbeat topic when close broker\n-                deleteHeartbeatResource();\n+            if (healthChecker != null) {\n+                healthChecker.close();\n+                healthChecker = null;\n             }\n \n             // close the service in reverse order v.s. in which they are started\n@@ -1699,78 +1665,36 @@ protected synchronized OrderedScheduler getOffloaderReadScheduler(OffloadPolicie\n         return this.offloaderReadExecutor;\n     }\n \n-    public PulsarClientImpl createClientImpl(ClientConfigurationData clientConf)\n+    public PulsarClientImpl createClientImpl(ClientConfigurationData conf) throws PulsarClientException {\n+        return createClientImpl(conf, null);\n+    }\n+\n+    public PulsarClientImpl createClientImpl(Consumer<PulsarClientImpl.PulsarClientImplBuilder> customizer)\n+            throws PulsarClientException {\n+        return createClientImpl(null, customizer);\n+    }\n+\n+    public PulsarClientImpl createClientImpl(ClientConfigurationData conf,\n+                                             Consumer<PulsarClientImpl.PulsarClientImplBuilder> customizer)\n             throws PulsarClientException {\n-        return PulsarClientImpl.builder()\n-                .conf(clientConf)\n+        PulsarClientImpl.PulsarClientImplBuilder pulsarClientImplBuilder = PulsarClientImpl.builder()\n+                .conf(conf != null ? conf : createClientConfigurationData())\n                 .eventLoopGroup(ioEventLoopGroup)\n                 .timer(brokerClientSharedTimer)\n                 .internalExecutorProvider(brokerClientSharedInternalExecutorProvider)\n                 .externalExecutorProvider(brokerClientSharedExternalExecutorProvider)\n                 .scheduledExecutorProvider(brokerClientSharedScheduledExecutorProvider)\n-                .lookupExecutorProvider(brokerClientSharedLookupExecutorProvider)\n-                .build();\n+                .lookupExecutorProvider(brokerClientSharedLookupExecutorProvider);\n+        if (customizer != null) {\n+            customizer.accept(pulsarClientImplBuilder);\n+        }\n+        return pulsarClientImplBuilder.build();\n     }\n \n     public synchronized PulsarClient getClient() throws PulsarServerException {\n         if (this.client == null) {\n             try {\n-                ClientConfigurationData initialConf = new ClientConfigurationData();\n-\n-                // Disable memory limit for broker client and disable stats\n-                initialConf.setMemoryLimitBytes(0);\n-                initialConf.setStatsIntervalSeconds(0);\n-\n-                // Apply all arbitrary configuration. This must be called before setting any fields annotated as\n-                // @Secret on the ClientConfigurationData object because of the way they are serialized.\n-                // See https://github.com/apache/pulsar/issues/8509 for more information.\n-                Map<String, Object> overrides = PropertiesUtils\n-                        .filterAndMapProperties(this.getConfiguration().getProperties(), \"brokerClient_\");\n-                ClientConfigurationData conf =\n-                        ConfigurationDataUtils.loadData(overrides, initialConf, ClientConfigurationData.class);\n-\n-                // Disabled auto release useless connections\n-                // The automatic release connection feature is not yet perfect for transaction scenarios, so turn it\n-                // off first.\n-                conf.setConnectionMaxIdleSeconds(-1);\n-\n-                boolean tlsEnabled = this.getConfiguration().isBrokerClientTlsEnabled();\n-                conf.setServiceUrl(tlsEnabled ? this.brokerServiceUrlTls : this.brokerServiceUrl);\n-\n-                if (tlsEnabled) {\n-                    conf.setTlsCiphers(this.getConfiguration().getBrokerClientTlsCiphers());\n-                    conf.setTlsProtocols(this.getConfiguration().getBrokerClientTlsProtocols());\n-                    conf.setTlsAllowInsecureConnection(this.getConfiguration().isTlsAllowInsecureConnection());\n-                    conf.setTlsHostnameVerificationEnable(this.getConfiguration().isTlsHostnameVerificationEnabled());\n-                    conf.setSslFactoryPlugin(this.getConfiguration().getBrokerClientSslFactoryPlugin());\n-                    conf.setSslFactoryPluginParams(this.getConfiguration().getBrokerClientSslFactoryPluginParams());\n-                    if (this.getConfiguration().isBrokerClientTlsEnabledWithKeyStore()) {\n-                        conf.setUseKeyStoreTls(true);\n-                        conf.setTlsTrustStoreType(this.getConfiguration().getBrokerClientTlsTrustStoreType());\n-                        conf.setTlsTrustStorePath(this.getConfiguration().getBrokerClientTlsTrustStore());\n-                        conf.setTlsTrustStorePassword(this.getConfiguration().getBrokerClientTlsTrustStorePassword());\n-                        conf.setTlsKeyStoreType(this.getConfiguration().getBrokerClientTlsKeyStoreType());\n-                        conf.setTlsKeyStorePath(this.getConfiguration().getBrokerClientTlsKeyStore());\n-                        conf.setTlsKeyStorePassword(this.getConfiguration().getBrokerClientTlsKeyStorePassword());\n-                    } else {\n-                        conf.setTlsTrustCertsFilePath(\n-                                isNotBlank(this.getConfiguration().getBrokerClientTrustCertsFilePath())\n-                                        ? this.getConfiguration().getBrokerClientTrustCertsFilePath()\n-                                        : this.getConfiguration().getTlsTrustCertsFilePath());\n-                        conf.setTlsKeyFilePath(this.getConfiguration().getBrokerClientKeyFilePath());\n-                        conf.setTlsCertificateFilePath(this.getConfiguration().getBrokerClientCertificateFilePath());\n-                    }\n-                }\n-\n-                if (isNotBlank(this.getConfiguration().getBrokerClientAuthenticationPlugin())) {\n-                    conf.setAuthPluginClassName(this.getConfiguration().getBrokerClientAuthenticationPlugin());\n-                    conf.setAuthParams(this.getConfiguration().getBrokerClientAuthenticationParameters());\n-                    conf.setAuthParamMap(null);\n-                    conf.setAuthentication(AuthenticationFactory.create(\n-                            this.getConfiguration().getBrokerClientAuthenticationPlugin(),\n-                            this.getConfiguration().getBrokerClientAuthenticationParameters()));\n-                }\n-                this.client = createClientImpl(conf);\n+                this.client = createClientImpl(null, null);\n             } catch (Exception e) {\n                 throw new PulsarServerException(e);\n             }\n@@ -1778,63 +1702,126 @@ public synchronized PulsarClient getClient() throws PulsarServerException {\n         return this.client;\n     }\n \n+    protected ClientConfigurationData createClientConfigurationData()\n+            throws PulsarClientException.UnsupportedAuthenticationException {\n+        ClientConfigurationData initialConf = new ClientConfigurationData();\n+\n+        // Disable memory limit for broker client and disable stats\n+        initialConf.setMemoryLimitBytes(0);\n+        initialConf.setStatsIntervalSeconds(0);\n+\n+        // Apply all arbitrary configuration. This must be called before setting any fields annotated as\n+        // @Secret on the ClientConfigurationData object because of the way they are serialized.\n+        // See https://github.com/apache/pulsar/issues/8509 for more information.\n+        Map<String, Object> overrides = PropertiesUtils\n+                .filterAndMapProperties(this.getConfiguration().getProperties(), \"brokerClient_\");\n+        ClientConfigurationData conf =\n+                ConfigurationDataUtils.loadData(overrides, initialConf, ClientConfigurationData.class);\n+\n+        // Disabled auto release useless connections\n+        // The automatic release connection feature is not yet perfect for transaction scenarios, so turn it\n+        // off first.\n+        conf.setConnectionMaxIdleSeconds(-1);\n+\n+        boolean tlsEnabled = this.getConfiguration().isBrokerClientTlsEnabled();\n+        conf.setServiceUrl(tlsEnabled ? this.brokerServiceUrlTls : this.brokerServiceUrl);\n+\n+        if (tlsEnabled) {\n+            conf.setTlsCiphers(this.getConfiguration().getBrokerClientTlsCiphers());\n+            conf.setTlsProtocols(this.getConfiguration().getBrokerClientTlsProtocols());\n+            conf.setTlsAllowInsecureConnection(this.getConfiguration().isTlsAllowInsecureConnection());\n+            conf.setTlsHostnameVerificationEnable(this.getConfiguration().isTlsHostnameVerificationEnabled());\n+            conf.setSslFactoryPlugin(this.getConfiguration().getBrokerClientSslFactoryPlugin());\n+            conf.setSslFactoryPluginParams(this.getConfiguration().getBrokerClientSslFactoryPluginParams());\n+            if (this.getConfiguration().isBrokerClientTlsEnabledWithKeyStore()) {\n+                conf.setUseKeyStoreTls(true);\n+                conf.setTlsTrustStoreType(this.getConfiguration().getBrokerClientTlsTrustStoreType());\n+                conf.setTlsTrustStorePath(this.getConfiguration().getBrokerClientTlsTrustStore());\n+                conf.setTlsTrustStorePassword(this.getConfiguration().getBrokerClientTlsTrustStorePassword());\n+                conf.setTlsKeyStoreType(this.getConfiguration().getBrokerClientTlsKeyStoreType());\n+                conf.setTlsKeyStorePath(this.getConfiguration().getBrokerClientTlsKeyStore());\n+                conf.setTlsKeyStorePassword(this.getConfiguration().getBrokerClientTlsKeyStorePassword());\n+            } else {\n+                conf.setTlsTrustCertsFilePath(\n+                        isNotBlank(this.getConfiguration().getBrokerClientTrustCertsFilePath())\n+                                ? this.getConfiguration().getBrokerClientTrustCertsFilePath()\n+                                : this.getConfiguration().getTlsTrustCertsFilePath());\n+                conf.setTlsKeyFilePath(this.getConfiguration().getBrokerClientKeyFilePath());\n+                conf.setTlsCertificateFilePath(this.getConfiguration().getBrokerClientCertificateFilePath());\n+            }\n+        }\n+\n+        if (isNotBlank(this.getConfiguration().getBrokerClientAuthenticationPlugin())) {\n+            conf.setAuthPluginClassName(this.getConfiguration().getBrokerClientAuthenticationPlugin());\n+            conf.setAuthParams(this.getConfiguration().getBrokerClientAuthenticationParameters());\n+            conf.setAuthParamMap(null);\n+            conf.setAuthentication(AuthenticationFactory.create(\n+                    this.getConfiguration().getBrokerClientAuthenticationPlugin(),\n+                    this.getConfiguration().getBrokerClientAuthenticationParameters()));\n+        }\n+        return conf;\n+    }\n+\n     public synchronized PulsarAdmin getAdminClient() throws PulsarServerException {\n         if (this.adminClient == null) {\n             try {\n-                ServiceConfiguration conf = this.getConfiguration();\n-                final String adminApiUrl = conf.isBrokerClientTlsEnabled() ? webServiceAddressTls : webServiceAddress;\n-                if (adminApiUrl == null) {\n-                    throw new IllegalArgumentException(\"Web service address was not set properly \"\n-                            + \", isBrokerClientTlsEnabled: \" + conf.isBrokerClientTlsEnabled()\n-                            + \", webServiceAddressTls: \" + webServiceAddressTls\n-                            + \", webServiceAddress: \" + webServiceAddress);\n-                }\n-                PulsarAdminBuilder builder = PulsarAdmin.builder().serviceHttpUrl(adminApiUrl);\n-\n-                // Apply all arbitrary configuration. This must be called before setting any fields annotated as\n-                // @Secret on the ClientConfigurationData object because of the way they are serialized.\n-                // See https://github.com/apache/pulsar/issues/8509 for more information.\n-                builder.loadConf(PropertiesUtils.filterAndMapProperties(conf.getProperties(), \"brokerClient_\"));\n-\n-                builder.authentication(\n-                        conf.getBrokerClientAuthenticationPlugin(),\n-                        conf.getBrokerClientAuthenticationParameters());\n-\n-                if (conf.isBrokerClientTlsEnabled()) {\n-                    builder.tlsCiphers(conf.getBrokerClientTlsCiphers())\n-                            .tlsProtocols(conf.getBrokerClientTlsProtocols())\n-                            .sslFactoryPlugin(conf.getBrokerClientSslFactoryPlugin())\n-                            .sslFactoryPluginParams(conf.getBrokerClientSslFactoryPluginParams());\n-                    if (conf.isBrokerClientTlsEnabledWithKeyStore()) {\n-                        builder.useKeyStoreTls(true).tlsTrustStoreType(conf.getBrokerClientTlsTrustStoreType())\n-                                .tlsTrustStorePath(conf.getBrokerClientTlsTrustStore())\n-                                .tlsTrustStorePassword(conf.getBrokerClientTlsTrustStorePassword())\n-                                .tlsKeyStoreType(conf.getBrokerClientTlsKeyStoreType())\n-                                .tlsKeyStorePath(conf.getBrokerClientTlsKeyStore())\n-                                .tlsKeyStorePassword(conf.getBrokerClientTlsKeyStorePassword());\n-                    } else {\n-                        builder.tlsTrustCertsFilePath(conf.getBrokerClientTrustCertsFilePath())\n-                                .tlsKeyFilePath(conf.getBrokerClientKeyFilePath())\n-                                .tlsCertificateFilePath(conf.getBrokerClientCertificateFilePath());\n-                    }\n-                    builder.allowTlsInsecureConnection(conf.isTlsAllowInsecureConnection())\n-                            .enableTlsHostnameVerification(conf.isTlsHostnameVerificationEnabled());\n-                }\n-\n-                // most of the admin request requires to make zk-call so, keep the max read-timeout based on\n-                // zk-operation timeout\n-                builder.readTimeout(conf.getMetadataStoreOperationTimeoutSeconds(), TimeUnit.SECONDS);\n-\n-                this.adminClient = builder.build();\n-                LOG.info(\"created admin with url {} \", adminApiUrl);\n+                this.adminClient = getCreateAdminClientBuilder().build();\n+                LOG.info(\"created admin with url {} \", adminClient.getServiceUrl());\n             } catch (Exception e) {\n                 throw new PulsarServerException(e);\n             }\n         }\n-\n         return this.adminClient;\n     }\n \n+    protected PulsarAdminBuilder getCreateAdminClientBuilder()\n+            throws PulsarClientException.UnsupportedAuthenticationException {\n+        ServiceConfiguration conf = this.getConfiguration();\n+        final String adminApiUrl = conf.isBrokerClientTlsEnabled() ? webServiceAddressTls : webServiceAddress;\n+        if (adminApiUrl == null) {\n+            throw new IllegalArgumentException(\"Web service address was not set properly \"\n+                    + \", isBrokerClientTlsEnabled: \" + conf.isBrokerClientTlsEnabled()\n+                    + \", webServiceAddressTls: \" + webServiceAddressTls\n+                    + \", webServiceAddress: \" + webServiceAddress);\n+        }\n+        PulsarAdminBuilder builder = PulsarAdmin.builder().serviceHttpUrl(adminApiUrl);\n+\n+        // Apply all arbitrary configuration. This must be called before setting any fields annotated as\n+        // @Secret on the ClientConfigurationData object because of the way they are serialized.\n+        // See https://github.com/apache/pulsar/issues/8509 for more information.\n+        builder.loadConf(PropertiesUtils.filterAndMapProperties(conf.getProperties(), \"brokerClient_\"));\n+\n+        builder.authentication(\n+                conf.getBrokerClientAuthenticationPlugin(),\n+                conf.getBrokerClientAuthenticationParameters());\n+\n+        if (conf.isBrokerClientTlsEnabled()) {\n+            builder.tlsCiphers(conf.getBrokerClientTlsCiphers())\n+                    .tlsProtocols(conf.getBrokerClientTlsProtocols())\n+                    .sslFactoryPlugin(conf.getBrokerClientSslFactoryPlugin())\n+                    .sslFactoryPluginParams(conf.getBrokerClientSslFactoryPluginParams());\n+            if (conf.isBrokerClientTlsEnabledWithKeyStore()) {\n+                builder.useKeyStoreTls(true).tlsTrustStoreType(conf.getBrokerClientTlsTrustStoreType())\n+                        .tlsTrustStorePath(conf.getBrokerClientTlsTrustStore())\n+                        .tlsTrustStorePassword(conf.getBrokerClientTlsTrustStorePassword())\n+                        .tlsKeyStoreType(conf.getBrokerClientTlsKeyStoreType())\n+                        .tlsKeyStorePath(conf.getBrokerClientTlsKeyStore())\n+                        .tlsKeyStorePassword(conf.getBrokerClientTlsKeyStorePassword());\n+            } else {\n+                builder.tlsTrustCertsFilePath(conf.getBrokerClientTrustCertsFilePath())\n+                        .tlsKeyFilePath(conf.getBrokerClientKeyFilePath())\n+                        .tlsCertificateFilePath(conf.getBrokerClientCertificateFilePath());\n+            }\n+            builder.allowTlsInsecureConnection(conf.isTlsAllowInsecureConnection())\n+                    .enableTlsHostnameVerification(conf.isTlsHostnameVerificationEnabled());\n+        }\n+\n+        // most of the admin request requires to make zk-call so, keep the max read-timeout based on\n+        // zk-operation timeout\n+        builder.readTimeout(conf.getMetadataStoreOperationTimeoutSeconds(), TimeUnit.SECONDS);\n+        return builder;\n+    }\n+\n     /**\n      * Gets the broker service URL (non-TLS) associated with the internal listener.\n      */\n@@ -2181,4 +2168,40 @@ private TopicPoliciesService initTopicPoliciesService() throws Exception {\n         return (TopicPoliciesService) Reflections.createInstance(className,\n                 Thread.currentThread().getContextClassLoader());\n     }\n+\n+    /**\n+     * Run health check for the broker.\n+     *\n+     * @return CompletableFuture\n+     */\n+    public CompletableFuture<Void> runHealthCheck(TopicVersion topicVersion, String clientId) {\n+        if (!isRunning()) {\n+            return CompletableFuture.failedFuture(new PulsarServerException(\"Broker is not running\"));\n+        }\n+        HealthChecker localHealthChecker = getHealthChecker();\n+        if (localHealthChecker == null) {\n+            return CompletableFuture.failedFuture(new PulsarServerException(\"Broker is not running\"));\n+        }\n+        return localHealthChecker.checkHealth(topicVersion, clientId);\n+    }\n+\n+    @VisibleForTesting\n+    public HealthChecker getHealthChecker() {\n+        if (healthChecker == null) {\n+            synchronized (this) {\n+                if (healthChecker == null) {\n+                    if (!isRunning()) {\n+                        return null;\n+                    }\n+                    try {\n+                        healthChecker = new HealthChecker(this);\n+                    } catch (PulsarServerException e) {\n+                        LOG.error(\"Failed to create health checker\", e);\n+                        throw new RuntimeException(e);\n+                    }\n+                }\n+            }\n+        }\n+        return healthChecker;\n+    }\n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\nindex a24a78d8e3102..ea25367ca3aca 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\n@@ -26,16 +26,11 @@\n import java.lang.management.ManagementFactory;\n import java.lang.management.ThreadInfo;\n import java.lang.management.ThreadMXBean;\n-import java.time.Duration;\n-import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n import javax.ws.rs.DELETE;\n import javax.ws.rs.DefaultValue;\n@@ -50,23 +45,12 @@\n import javax.ws.rs.core.Response.Status;\n import org.apache.commons.lang.StringUtils;\n import org.apache.pulsar.PulsarVersion;\n-import org.apache.pulsar.broker.PulsarServerException;\n-import org.apache.pulsar.broker.PulsarService;\n import org.apache.pulsar.broker.PulsarService.State;\n import org.apache.pulsar.broker.ServiceConfiguration;\n import org.apache.pulsar.broker.admin.AdminResource;\n import org.apache.pulsar.broker.loadbalance.LeaderBroker;\n-import org.apache.pulsar.broker.namespace.NamespaceService;\n-import org.apache.pulsar.broker.service.Subscription;\n-import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.broker.web.RestException;\n-import org.apache.pulsar.client.api.MessageId;\n-import org.apache.pulsar.client.api.Producer;\n-import org.apache.pulsar.client.api.PulsarClient;\n-import org.apache.pulsar.client.api.Reader;\n-import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.common.conf.InternalConfigurationData;\n-import org.apache.pulsar.common.naming.NamespaceName;\n import org.apache.pulsar.common.naming.TopicVersion;\n import org.apache.pulsar.common.policies.data.BrokerInfo;\n import org.apache.pulsar.common.policies.data.BrokerOperation;\n@@ -81,16 +65,9 @@\n  */\n public class BrokersBase extends AdminResource {\n     private static final Logger LOG = LoggerFactory.getLogger(BrokersBase.class);\n-    public static final String HEALTH_CHECK_TOPIC_SUFFIX = \"healthcheck\";\n     // log a full thread dump when a deadlock is detected in healthcheck once every 10 minutes\n     // to prevent excessive logging\n     private static final long LOG_THREADDUMP_INTERVAL_WHEN_DEADLOCK_DETECTED = 600000L;\n-    // there is a timeout of 60 seconds default in the client(readTimeoutMs), so we need to set the timeout\n-    // a bit shorter than 60 seconds to avoid the client timeout exception thrown before the server timeout exception.\n-    // or we can't propagate the server timeout exception to the client.\n-    private static final Duration HEALTH_CHECK_READ_TIMEOUT = Duration.ofSeconds(58);\n-    private static final TimeoutException HEALTH_CHECK_TIMEOUT_EXCEPTION =\n-            FutureUtil.createTimeoutException(\"Timeout\", BrokersBase.class, \"healthCheckRecursiveReadNext(...)\");\n     private static volatile long threadDumpLoggedTimestamp;\n \n     @GET\n@@ -385,16 +362,21 @@ public void isReady(@Suspended AsyncResponse asyncResponse) {\n         @ApiResponse(code = 307, message = \"Current broker is not the target broker\"),\n         @ApiResponse(code = 403, message = \"Don't have admin permission\"),\n         @ApiResponse(code = 404, message = \"Cluster doesn't exist\"),\n-        @ApiResponse(code = 500, message = \"Internal server error\")})\n+        @ApiResponse(code = 500, message = \"Internal server error\"),\n+        @ApiResponse(code = 503, message = \"Service unavailable\")})\n     public void healthCheck(@Suspended AsyncResponse asyncResponse,\n                             @ApiParam(value = \"Topic Version\")\n                             @QueryParam(\"topicVersion\") TopicVersion topicVersion,\n                             @QueryParam(\"brokerId\") String brokerId) {\n+        if (pulsar().getState() == State.Closed || pulsar().getState() == State.Closing) {\n+            asyncResponse.resume(Response.status(Status.SERVICE_UNAVAILABLE).build());\n+            return;\n+        }\n         validateBothSuperuserAndBrokerOperation(pulsar().getConfig().getClusterName(), StringUtils.isBlank(brokerId)\n                 ? pulsar().getBrokerId() : brokerId, BrokerOperation.HEALTH_CHECK)\n-                .thenAccept(__ -> checkDeadlockedThreads())\n                 .thenCompose(__ -> maybeRedirectToBroker(\n                         StringUtils.isBlank(brokerId) ? pulsar().getBrokerId() : brokerId))\n+                .thenAccept(__ -> checkDeadlockedThreads())\n                 .thenCompose(__ -> internalRunHealthCheck(topicVersion))\n                 .thenAccept(__ -> {\n                     LOG.info(\"[{}] Successfully run health check.\", clientAppId());\n@@ -432,143 +414,8 @@ private void checkDeadlockedThreads() {\n         }\n     }\n \n-    public static String getHeartbeatTopicName(String brokerId, ServiceConfiguration configuration, boolean isV2) {\n-        NamespaceName namespaceName = isV2\n-                ? NamespaceService.getHeartbeatNamespaceV2(brokerId, configuration)\n-                : NamespaceService.getHeartbeatNamespace(brokerId, configuration);\n-        return String.format(\"persistent://%s/%s\", namespaceName, HEALTH_CHECK_TOPIC_SUFFIX);\n-    }\n-\n     private CompletableFuture<Void> internalRunHealthCheck(TopicVersion topicVersion) {\n-        return internalRunHealthCheck(topicVersion, pulsar(), clientAppId());\n-    }\n-\n-\n-    public static CompletableFuture<Void> internalRunHealthCheck(TopicVersion topicVersion, PulsarService pulsar,\n-                                                                 String clientAppId) {\n-        NamespaceName namespaceName = (topicVersion == TopicVersion.V2)\n-                ? NamespaceService.getHeartbeatNamespaceV2(pulsar.getAdvertisedAddress(), pulsar.getConfiguration())\n-                : NamespaceService.getHeartbeatNamespace(pulsar.getAdvertisedAddress(), pulsar.getConfiguration());\n-        String brokerId = pulsar.getBrokerId();\n-        final String topicName =\n-                getHeartbeatTopicName(brokerId, pulsar.getConfiguration(), (topicVersion == TopicVersion.V2));\n-        LOG.info(\"[{}] Running healthCheck with topic={}\", clientAppId, topicName);\n-        final String messageStr = UUID.randomUUID().toString();\n-        final String subscriptionName = \"healthCheck-\" + messageStr;\n-        // create non-partitioned topic manually and close the previous reader if present.\n-        return pulsar.getBrokerService().getTopic(topicName, true)\n-            .thenCompose(topicOptional -> {\n-                if (!topicOptional.isPresent()) {\n-                    LOG.error(\"[{}] Fail to run health check while get topic {}. because get null value.\",\n-                            clientAppId, topicName);\n-                    throw new RestException(Status.NOT_FOUND,\n-                            String.format(\"Topic [%s] not found after create.\", topicName));\n-                }\n-                PulsarClient client;\n-                try {\n-                    client = pulsar.getClient();\n-                } catch (PulsarServerException e) {\n-                    LOG.error(\"[{}] Fail to run health check while get client.\", clientAppId);\n-                    throw new RestException(e);\n-                }\n-                CompletableFuture<Void> resultFuture = new CompletableFuture<>();\n-                client.newProducer(Schema.STRING).topic(topicName).createAsync()\n-                        .thenCompose(producer -> client.newReader(Schema.STRING).topic(topicName)\n-                                .subscriptionName(subscriptionName)\n-                                .startMessageId(MessageId.latest)\n-                                .createAsync().exceptionally(createException -> {\n-                                    producer.closeAsync().exceptionally(ex -> {\n-                                        LOG.error(\"[{}] Close producer fail while heath check.\", clientAppId);\n-                                        return null;\n-                                    });\n-                                    throw FutureUtil.wrapToCompletionException(createException);\n-                                }).thenCompose(reader -> producer.sendAsync(messageStr)\n-                                        .thenCompose(__ -> FutureUtil.addTimeoutHandling(\n-                                                healthCheckRecursiveReadNext(reader, messageStr),\n-                                                HEALTH_CHECK_READ_TIMEOUT, pulsar.getBrokerService().executor(),\n-                                                () -> HEALTH_CHECK_TIMEOUT_EXCEPTION))\n-                                        .whenComplete((__, ex) -> {\n-                                            closeAndReCheck(producer, reader, topicOptional.get(), subscriptionName,\n-                                                    clientAppId)\n-                                                    .whenComplete((unused, innerEx) -> {\n-                                                        if (ex != null) {\n-                                                            resultFuture.completeExceptionally(ex);\n-                                                        } else {\n-                                                            resultFuture.complete(null);\n-                                                        }\n-                                                    });\n-                                        }\n-                                ))\n-                        ).exceptionally(ex -> {\n-                            resultFuture.completeExceptionally(ex);\n-                            return null;\n-                        });\n-                return resultFuture;\n-            });\n-    }\n-\n-    private CompletableFuture<Void> closeAndReCheck(Producer<String> producer, Reader<String> reader,\n-                                                           Topic topic, String subscriptionName) {\n-        return closeAndReCheck(producer, reader, topic, subscriptionName, clientAppId());\n-    }\n-\n-    /**\n-     * Close producer and reader and then to re-check if this operation is success.\n-     *\n-     * Re-check\n-     * - Producer: If close fails we will print error log to notify user.\n-     * - Consumer: If close fails we will force delete subscription.\n-     *\n-     * @param producer Producer\n-     * @param reader Reader\n-     * @param topic  Topic\n-     * @param subscriptionName  Subscription name\n-     */\n-    private static CompletableFuture<Void> closeAndReCheck(Producer<String> producer, Reader<String> reader,\n-                                                    Topic topic, String subscriptionName, String clientAppId) {\n-        // no matter exception or success, we still need to\n-        // close producer/reader\n-        CompletableFuture<Void> producerFuture = producer.closeAsync();\n-        CompletableFuture<Void> readerFuture = reader.closeAsync();\n-        List<CompletableFuture<Void>> futures = new ArrayList<>(2);\n-        futures.add(producerFuture);\n-        futures.add(readerFuture);\n-        return FutureUtil.waitForAll(Collections.unmodifiableList(futures))\n-                .exceptionally(closeException -> {\n-                    if (readerFuture.isCompletedExceptionally()) {\n-                        LOG.error(\"[{}] Close reader fail while heath check.\", clientAppId);\n-                        Subscription subscription =\n-                                topic.getSubscription(subscriptionName);\n-                        // re-check subscription after reader close\n-                        if (subscription != null) {\n-                            LOG.warn(\"[{}] Force delete subscription {} \"\n-                                            + \"when it still exists after the\"\n-                                            + \" reader is closed.\",\n-                                    clientAppId, subscription);\n-                            subscription.deleteForcefully()\n-                                    .exceptionally(ex -> {\n-                                        LOG.error(\"[{}] Force delete subscription fail\"\n-                                                        + \" while health check\",\n-                                                clientAppId, ex);\n-                                        return null;\n-                                    });\n-                        }\n-                    } else {\n-                        // producer future fail.\n-                        LOG.error(\"[{}] Close producer fail while heath check.\", clientAppId);\n-                    }\n-                    return null;\n-                });\n-    }\n-\n-    private static CompletableFuture<Void> healthCheckRecursiveReadNext(Reader<String> reader, String content) {\n-        return reader.readNextAsync()\n-                .thenCompose(msg -> {\n-                    if (!Objects.equals(content, msg.getValue())) {\n-                        return healthCheckRecursiveReadNext(reader, content);\n-                    }\n-                    return CompletableFuture.completedFuture(null);\n-                });\n+        return pulsar().runHealthCheck(topicVersion, clientAppId());\n     }\n \n     private CompletableFuture<Void> internalDeleteDynamicConfigurationOnMetadataAsync(String configName) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex dd3486496e906..9f6f3dacbbea2 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -24,7 +24,6 @@\n import static org.apache.bookkeeper.mledger.ManagedLedgerConfig.PROPERTY_SOURCE_TOPIC_KEY;\n import static org.apache.commons.collections4.CollectionUtils.isEmpty;\n import static org.apache.commons.lang3.StringUtils.isNotBlank;\n-import static org.apache.pulsar.broker.admin.impl.BrokersBase.internalRunHealthCheck;\n import static org.apache.pulsar.client.util.RetryMessageUtil.DLQ_GROUP_TOPIC_SUFFIX;\n import static org.apache.pulsar.client.util.RetryMessageUtil.RETRY_GROUP_TOPIC_SUFFIX;\n import static org.apache.pulsar.common.naming.SystemTopicNames.isTransactionInternalName;\n@@ -679,7 +678,10 @@ protected void initializeHealthChecker() {\n     }\n \n     public CompletableFuture<Void> checkHealth() {\n-        return internalRunHealthCheck(TopicVersion.V2, pulsar(), null).thenAccept(__ -> {\n+        if (!pulsar().isRunning()) {\n+            return CompletableFuture.completedFuture(null);\n+        }\n+        return pulsar().runHealthCheck(TopicVersion.V2, null).thenAccept(__ -> {\n             this.pulsarStats.getBrokerOperabilityMetrics().recordHealthCheckStatusSuccess();\n         }).exceptionally(ex -> {\n             this.pulsarStats.getBrokerOperabilityMetrics().recordHealthCheckStatusFail();\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/HealthChecker.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/HealthChecker.java\nnew file mode 100644\nindex 0000000000000..e80e0b094750d\n--- /dev/null\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/HealthChecker.java\n@@ -0,0 +1,330 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.service;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeoutException;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException;\n+import org.apache.pulsar.broker.PulsarServerException;\n+import org.apache.pulsar.broker.PulsarService;\n+import org.apache.pulsar.broker.ServiceConfiguration;\n+import org.apache.pulsar.broker.namespace.NamespaceService;\n+import org.apache.pulsar.client.api.MessageId;\n+import org.apache.pulsar.client.api.Producer;\n+import org.apache.pulsar.client.api.PulsarClient;\n+import org.apache.pulsar.client.api.PulsarClientException;\n+import org.apache.pulsar.client.api.Reader;\n+import org.apache.pulsar.client.api.Schema;\n+import org.apache.pulsar.client.util.ScheduledExecutorProvider;\n+import org.apache.pulsar.common.naming.NamespaceName;\n+import org.apache.pulsar.common.naming.TopicVersion;\n+import org.apache.pulsar.common.util.FutureUtil;\n+import org.apache.pulsar.metadata.api.MetadataStoreException;\n+\n+/**\n+ * The HealthChecker class provides functionality to monitor and verify the health of a Pulsar broker.\n+ * It performs health checks by creating test topics, producing and consuming messages to verify broker functionality.\n+ * This class implements AutoCloseable to ensure proper cleanup of resources when the broker is shut down.\n+ */\n+@Slf4j\n+public class HealthChecker implements AutoCloseable{\n+    /**\n+     * Suffix used for health check topic names.\n+     */\n+    public static final String HEALTH_CHECK_TOPIC_SUFFIX = \"healthcheck\";\n+    /**\n+     * Timeout duration for health check operations.\n+     * Set to 58 seconds to be shorter than the client's default 60-second timeout,\n+     * allowing server timeout exceptions to propagate properly to the client.\n+     */\n+    private static final Duration DEFAULT_HEALTH_CHECK_READ_TIMEOUT = Duration.ofSeconds(58);\n+    /**\n+     * Pre-created timeout exception for health check operations.\n+     */\n+    private static final TimeoutException HEALTH_CHECK_TIMEOUT_EXCEPTION =\n+            FutureUtil.createTimeoutException(\"Timeout\", HealthChecker.class, \"healthCheckRecursiveReadNext(...)\");\n+    /**\n+     * Reference to the main Pulsar service.\n+     */\n+    private final PulsarService pulsar;\n+    /**\n+     * Topic name for v1 heartbeat checks.\n+     */\n+    private final String heartbeatTopicV1;\n+    /**\n+     * Topic name for v2 heartbeat checks.\n+     */\n+    private final String heartbeatTopicV2;\n+    /**\n+     * Pulsar client instance for health check operations.\n+     * A separate client is needed so that it can be shutdown before the webservice is closed.\n+     * Pending requests for healthchecks to the /health endpoint can be cancelled this way.\n+     */\n+    private final PulsarClient client;\n+    /**\n+     * Executor for lookup operations.\n+     * This is also needed so that pending healthchecks can be properly cancelled at shutdown.\n+     */\n+    private final ScheduledExecutorProvider lookupExecutor;\n+    /**\n+     * Executor for scheduled tasks.\n+     * This is also needed so that pending healthchecks can be properly cancelled at shutdown.\n+     */\n+    private final ScheduledExecutorProvider scheduledExecutorProvider;\n+    /**\n+     * Set of pending health check operations.\n+     */\n+    private final Set<CompletableFuture<Void>> pendingFutures = new HashSet<>();\n+\n+    private final Duration timeout = DEFAULT_HEALTH_CHECK_READ_TIMEOUT;\n+\n+    public HealthChecker(PulsarService pulsar) throws PulsarServerException {\n+        this.pulsar = pulsar;\n+        this.heartbeatTopicV1 = getHeartbeatTopicName(pulsar.getBrokerId(), pulsar.getConfiguration(), false);\n+        this.heartbeatTopicV2 = getHeartbeatTopicName(pulsar.getBrokerId(), pulsar.getConfiguration(), true);\n+        this.lookupExecutor =\n+                new ScheduledExecutorProvider(1, \"health-checker-client-lookup-executor\");\n+        this.scheduledExecutorProvider =\n+                new ScheduledExecutorProvider(1, \"health-checker-client-scheduled-executor\");\n+        try {\n+            this.client = pulsar.createClientImpl(builder -> {\n+                builder.lookupExecutorProvider(lookupExecutor);\n+                builder.scheduledExecutorProvider(scheduledExecutorProvider);\n+            });\n+        } catch (PulsarClientException e) {\n+            throw new PulsarServerException(\"Error creating client for HealthChecker\", e);\n+        }\n+    }\n+\n+    private static String getHeartbeatTopicName(String brokerId, ServiceConfiguration configuration, boolean isV2) {\n+        NamespaceName namespaceName = isV2\n+                ? NamespaceService.getHeartbeatNamespaceV2(brokerId, configuration)\n+                : NamespaceService.getHeartbeatNamespace(brokerId, configuration);\n+        return String.format(\"persistent://%s/%s\", namespaceName, HEALTH_CHECK_TOPIC_SUFFIX);\n+    }\n+\n+    /**\n+     * Performs a health check on the broker by verifying message production and consumption.\n+     * The health check process includes:\n+     * 1. Producing a test message\n+     * 2. Reading the message back to verify end-to-end functionality\n+     *\n+     * @param topicVersion The version of the topic to use (V1 or V2)\n+     * @param clientAppId  The identifier of the client application requesting the health check\n+     * @return A CompletableFuture that completes when the health check is successful, or completes exceptionally if the\n+     * check fails\n+     */\n+    public CompletableFuture<Void> checkHealth(TopicVersion topicVersion, String clientAppId) {\n+        final String topicName = topicVersion == TopicVersion.V2 ? heartbeatTopicV2 : heartbeatTopicV1;\n+        log.info(\"[{}] Running healthCheck with topic={}\", clientAppId, topicName);\n+        final String messageStr = UUID.randomUUID().toString();\n+        final String subscriptionName = \"healthCheck-\" + messageStr;\n+        // create non-partitioned topic manually and close the previous reader if present.\n+        CompletableFuture<Void> resultFuture = new CompletableFuture<>();\n+        addToPending(resultFuture);\n+        resultFuture.whenComplete((result, ex) -> {\n+            removeFromPending(resultFuture);\n+        });\n+        try {\n+            pulsar.getBrokerService().getTopic(topicName, true)\n+                    .thenCompose(topicOptional -> {\n+                        if (!topicOptional.isPresent()) {\n+                            log.error(\"[{}] Fail to run health check while get topic {}. because get null value.\",\n+                                    clientAppId, topicName);\n+                            return CompletableFuture.failedFuture(new BrokerServiceException.TopicNotFoundException(\n+                                    String.format(\"Topic [%s] not found after create.\", topicName)));\n+                        }\n+                        return doHealthCheck(clientAppId, topicName, subscriptionName, messageStr, resultFuture);\n+                    }).whenComplete((result, t) -> {\n+                        if (t != null) {\n+                            resultFuture.completeExceptionally(t);\n+                        } else {\n+                            if (!resultFuture.isDone()) {\n+                                resultFuture.complete(null);\n+                            }\n+                        }\n+                    });\n+        } catch (Exception e) {\n+            log.error(\"[{}] Fail to run health check while get topic {}. because get exception.\",\n+                    clientAppId, topicName, e);\n+            resultFuture.completeExceptionally(e);\n+        }\n+        return resultFuture;\n+    }\n+\n+    private synchronized void addToPending(CompletableFuture<Void> resultFuture) {\n+        pendingFutures.add(resultFuture);\n+    }\n+\n+    private synchronized void removeFromPending(CompletableFuture<Void> resultFuture) {\n+        pendingFutures.remove(resultFuture);\n+    }\n+\n+    private CompletableFuture<Void> doHealthCheck(String clientAppId, String topicName, String subscriptionName,\n+                                                  String messageStr, CompletableFuture<Void> resultFuture) {\n+        return client.newProducer(Schema.STRING).topic(topicName).createAsync()\n+                .thenCompose(producer -> client.newReader(Schema.STRING).topic(topicName)\n+                        .subscriptionName(subscriptionName)\n+                        .startMessageId(MessageId.latest)\n+                        .createAsync().exceptionally(createException -> {\n+                            producer.closeAsync().exceptionally(ex -> {\n+                                log.error(\"[{}] Close producer fail while heath check.\", clientAppId);\n+                                return null;\n+                            });\n+                            throw FutureUtil.wrapToCompletionException(createException);\n+                        }).thenCompose(reader -> producer.sendAsync(messageStr)\n+                                .thenCompose(__ -> FutureUtil.addTimeoutHandling(\n+                                        healthCheckRecursiveReadNext(reader, messageStr),\n+                                        timeout, pulsar.getBrokerService().executor(),\n+                                        () -> HEALTH_CHECK_TIMEOUT_EXCEPTION))\n+                                .whenComplete((__, ex) -> {\n+                                            closeAndReCheck(producer, reader, topicName,\n+                                                    subscriptionName,\n+                                                    clientAppId)\n+                                                    .whenComplete((unused, innerEx) -> {\n+                                                        if (ex != null) {\n+                                                            resultFuture.completeExceptionally(ex);\n+                                                        } else {\n+                                                            resultFuture.complete(null);\n+                                                        }\n+                                                    });\n+                                        }\n+                                ))\n+                ).exceptionally(ex -> {\n+                    resultFuture.completeExceptionally(ex);\n+                    return null;\n+                });\n+    }\n+\n+    /**\n+     * Close producer and reader and then to re-check if this operation is success.\n+     *\n+     * Re-check\n+     * - Producer: If close fails we will print error log to notify user.\n+     * - Consumer: If close fails we will force delete subscription.\n+     *\n+     * @param producer         Producer\n+     * @param reader           Reader\n+     * @param subscriptionName Subscription name\n+     */\n+    private CompletableFuture<Void> closeAndReCheck(Producer<String> producer, Reader<String> reader,\n+                                                    String topicName, String subscriptionName, String clientAppId) {\n+        // no matter exception or success, we still need to\n+        // close producer/reader\n+        CompletableFuture<Void> producerFuture = producer.closeAsync();\n+        CompletableFuture<Void> readerFuture = reader.closeAsync();\n+        List<CompletableFuture<Void>> futures = new ArrayList<>(2);\n+        futures.add(producerFuture);\n+        futures.add(readerFuture);\n+        return FutureUtil.waitForAll(Collections.unmodifiableList(futures))\n+                .exceptionally(closeException -> {\n+                    if (readerFuture.isCompletedExceptionally()) {\n+                        log.error(\"[{}] Close reader fail while health check.\", clientAppId);\n+                        Optional<Topic> topic = pulsar.getBrokerService().getTopicReference(topicName);\n+                        if (topic.isPresent()) {\n+                            Subscription subscription =\n+                                    topic.get().getSubscription(subscriptionName);\n+                            // re-check subscription after reader close\n+                            if (subscription != null) {\n+                                log.warn(\"[{}] Force delete subscription {} \"\n+                                                + \"when it still exists after the\"\n+                                                + \" reader is closed.\",\n+                                        clientAppId, subscription);\n+                                subscription.deleteForcefully()\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"[{}] Force delete subscription fail\"\n+                                                            + \" while health check\",\n+                                                    clientAppId, ex);\n+                                            return null;\n+                                        });\n+                            }\n+                        }\n+                    } else {\n+                        // producer future fail.\n+                        log.error(\"[{}] Close producer fail while heath check.\", clientAppId);\n+                    }\n+                    return null;\n+                });\n+    }\n+\n+    private static CompletableFuture<Void> healthCheckRecursiveReadNext(Reader<String> reader, String content) {\n+        return reader.readNextAsync()\n+                .thenCompose(msg -> {\n+                    if (!Objects.equals(content, msg.getValue())) {\n+                        return healthCheckRecursiveReadNext(reader, content);\n+                    }\n+                    return CompletableFuture.completedFuture(null);\n+                });\n+    }\n+\n+    private void deleteHeartbeatTopics() {\n+        log.info(\"forcefully deleting heartbeat topics\");\n+        deleteTopic(heartbeatTopicV1);\n+        deleteTopic(heartbeatTopicV2);\n+        log.info(\"finish forcefully deleting heartbeat topics\");\n+    }\n+\n+    private void deleteTopic(String heartbeatTopicV1) {\n+        try {\n+            pulsar.getBrokerService().deleteTopic(heartbeatTopicV1, true).get();\n+        } catch (Exception e) {\n+            Throwable realCause = e.getCause();\n+            if (!(realCause instanceof ManagedLedgerException.MetadataNotFoundException\n+                    || realCause instanceof MetadataStoreException.NotFoundException)) {\n+                log.error(\"Errors in deleting heartbeat topic [{}]\", heartbeatTopicV1, e);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public synchronized void close() throws Exception {\n+        try {\n+            scheduledExecutorProvider.shutdownNow();\n+        } catch (Exception e) {\n+            log.warn(\"Failed to shutdown scheduled executor\", e);\n+        }\n+        try {\n+            lookupExecutor.shutdownNow();\n+        } catch (Exception e) {\n+            log.warn(\"Failed to shutdown lookup executor\", e);\n+        }\n+        try {\n+            client.close();\n+        } catch (PulsarClientException e) {\n+            log.warn(\"Failed to close pulsar client\", e);\n+        }\n+        for (CompletableFuture<Void> pendingFuture : new ArrayList<>(pendingFutures)) {\n+            if (!pendingFuture.isDone()) {\n+                pendingFuture.completeExceptionally(\n+                        new PulsarClientException.AlreadyClosedException(\"HealthChecker is closed\"));\n+            }\n+        }\n+        deleteHeartbeatTopics();\n+    }\n+}\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java\nindex 618e023ccbf25..b39f1f955a35d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiHealthCheckTest.java\n@@ -18,10 +18,11 @@\n  */\n package org.apache.pulsar.broker.admin;\n \n-import static org.apache.pulsar.broker.admin.impl.BrokersBase.HEALTH_CHECK_TOPIC_SUFFIX;\n+import static org.apache.pulsar.broker.service.HealthChecker.HEALTH_CHECK_TOPIC_SUFFIX;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertNull;\n import static org.testng.Assert.assertTrue;\n+import static org.testng.Assert.fail;\n import java.lang.management.ManagementFactory;\n import java.lang.management.ThreadMXBean;\n import java.lang.reflect.Field;\n@@ -33,9 +34,9 @@\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n import java.util.stream.Collectors;\n import lombok.extern.slf4j.Slf4j;\n-import org.apache.pulsar.broker.PulsarService;\n import org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest;\n import org.apache.pulsar.broker.namespace.NamespaceService;\n+import org.apache.pulsar.broker.service.HealthChecker;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.client.api.MessageId;\n import org.apache.pulsar.client.api.Producer;\n@@ -231,17 +232,23 @@ public CompletableFuture<Producer<T>> createAsync() {\n     public void testHealthCheckTimeOut() throws Exception {\n         final String testHealthCheckTopic = String.format(\"persistent://pulsar/localhost:%s/healthcheck\",\n                 pulsar.getConfig().getWebServicePort().get());\n-        PulsarClient client = pulsar.getClient();\n+        HealthChecker healthChecker = pulsar.getHealthChecker();\n+        Field clientField = HealthChecker.class.getDeclaredField(\"client\");\n+        clientField.setAccessible(true);\n+        PulsarClient client = (PulsarClient) clientField.get(healthChecker);\n         PulsarClient spyClient = Mockito.spy(client);\n         Mockito.doReturn(new DummyProducerBuilder<>((PulsarClientImpl) spyClient, Schema.BYTES))\n                 .when(spyClient).newProducer(Schema.STRING);\n-        // use reflection to replace the client in the broker\n-        Field field = PulsarService.class.getDeclaredField(\"client\");\n-        field.setAccessible(true);\n-        field.set(pulsar, spyClient);\n+        clientField.set(healthChecker, spyClient);\n+\n+        // change timeout to 1 second to speed up test\n+        Field timeoutField = HealthChecker.class.getDeclaredField(\"timeout\");\n+        timeoutField.setAccessible(true);\n+        timeoutField.set(healthChecker, Duration.ofSeconds(1));\n+\n         try {\n             admin.brokers().healthcheck(TopicVersion.V2);\n-            throw new Exception(\"Should not reach here\");\n+            fail(\"Should not reach here\");\n         } catch (PulsarAdminException e) {\n             log.info(\"Exception caught\", e);\n             assertTrue(e.getMessage().contains(\"LowOverheadTimeoutException\"));\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\nindex 189c29400c4f9..e975671fa12e8 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n@@ -37,7 +37,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class BrokerRegistryIntegrationTest {\n \n     private static final String clusterName = \"test\";\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java\nindex 15097b565db6c..3e01b1fad0f21 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java\n@@ -22,7 +22,7 @@\n import org.apache.pulsar.broker.loadbalance.extensions.channel.ServiceUnitStateMetadataStoreTableViewImpl;\n import org.testng.annotations.Test;\n \n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class BrokerRegistryMetadataStoreIntegrationTest extends BrokerRegistryIntegrationTest {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java\nindex e31f78665b394..fb0801181c87f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/systopic/PartitionedSystemTopicTest.java\n@@ -34,9 +34,9 @@\n import org.apache.bookkeeper.mledger.impl.NullLedgerOffloader;\n import org.apache.commons.lang.RandomStringUtils;\n import org.apache.commons.lang3.reflect.MethodUtils;\n-import org.apache.pulsar.broker.admin.impl.BrokersBase;\n import org.apache.pulsar.broker.namespace.NamespaceService;\n import org.apache.pulsar.broker.service.BrokerTestBase;\n+import org.apache.pulsar.broker.service.HealthChecker;\n import org.apache.pulsar.broker.service.TopicPolicyTestUtils;\n import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n@@ -168,7 +168,7 @@ public void testProduceAndConsumeUnderSystemNamespace() throws Exception {\n     public void testHealthCheckTopicNotOffload() throws Exception {\n         NamespaceName namespaceName = NamespaceService.getHeartbeatNamespaceV2(pulsar.getBrokerId(),\n                 pulsar.getConfig());\n-        TopicName topicName = TopicName.get(\"persistent\", namespaceName, BrokersBase.HEALTH_CHECK_TOPIC_SUFFIX);\n+        TopicName topicName = TopicName.get(\"persistent\", namespaceName, HealthChecker.HEALTH_CHECK_TOPIC_SUFFIX);\n         PersistentTopic persistentTopic = (PersistentTopic) pulsar.getBrokerService()\n                 .getTopic(topicName.toString(), true).get().get();\n         ManagedLedgerConfig config = persistentTopic.getManagedLedger().getConfig();\n@@ -194,7 +194,7 @@ public void testSystemNamespaceNotCreateChangeEventsTopic() throws Exception {\n         Assert.assertTrue(optionalTopic.isEmpty());\n \n         TopicName heartbeatTopicName = TopicName.get(\"persistent\",\n-                namespaceName, BrokersBase.HEALTH_CHECK_TOPIC_SUFFIX);\n+                namespaceName, HealthChecker.HEALTH_CHECK_TOPIC_SUFFIX);\n         admin.topics().getRetention(heartbeatTopicName.toString());\n         optionalTopic = pulsar.getBrokerService()\n                 .getTopic(topicName.getPartition(1).toString(), false).join();\n@@ -221,7 +221,7 @@ public void testHeartbeatTopicBeDeleted() throws Exception {\n         admin.brokers().healthcheck(TopicVersion.V2);\n         NamespaceName namespaceName = NamespaceService.getHeartbeatNamespaceV2(pulsar.getBrokerId(),\n                 pulsar.getConfig());\n-        TopicName heartbeatTopicName = TopicName.get(\"persistent\", namespaceName, BrokersBase.HEALTH_CHECK_TOPIC_SUFFIX);\n+        TopicName heartbeatTopicName = TopicName.get(\"persistent\", namespaceName, HealthChecker.HEALTH_CHECK_TOPIC_SUFFIX);\n \n         List<String> topics = getPulsar().getNamespaceService().getListOfPersistentTopics(namespaceName).join();\n         Assert.assertEquals(topics.size(), 1);\n@@ -246,7 +246,7 @@ public void testHeartbeatNamespaceNotCreateTransactionInternalTopic() throws Exc\n         List<String> topics = getPulsar().getNamespaceService().getListOfPersistentTopics(namespaceName).join();\n         Assert.assertEquals(topics.size(), 1);\n         TopicName heartbeatTopicName = TopicName.get(\"persistent\",\n-                namespaceName, BrokersBase.HEALTH_CHECK_TOPIC_SUFFIX);\n+                namespaceName, HealthChecker.HEALTH_CHECK_TOPIC_SUFFIX);\n         Assert.assertEquals(topics.get(0), heartbeatTopicName.toString());\n     }\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java\nindex 70e386c68aa26..46e41be012511 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/testcontext/NonStartableTestPulsarService.java\n@@ -26,6 +26,7 @@\n import java.util.Collections;\n import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n import java.util.function.Function;\n import java.util.function.Supplier;\n import org.apache.pulsar.broker.BookKeeperClientFactory;\n@@ -116,13 +117,16 @@ public Supplier<NamespaceService> getNamespaceServiceProvider() throws PulsarSer\n     }\n \n     @Override\n-    public PulsarClientImpl createClientImpl(ClientConfigurationData clientConf) throws PulsarClientException {\n+    public PulsarClientImpl createClientImpl(ClientConfigurationData clientConf,\n+                                             Consumer<PulsarClientImpl.PulsarClientImplBuilder> customizer)\n+            throws PulsarClientException {\n         try {\n             return (PulsarClientImpl) getClient();\n         } catch (PulsarServerException e) {\n             throw new PulsarClientException(e);\n         }\n     }\n+\n     @Override\n     protected BrokerService newBrokerService(PulsarService pulsar) throws Exception {\n         return getBrokerService();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24194",
    "pr_id": 24194,
    "issue_id": 24193,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: NamespacesTest.testNamespacesApiRedirects\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14587816306/job/40916776610#step:11:1196\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  Tests run: 47, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 125.249 s <<< FAILURE! - in org.apache.pulsar.broker.admin.NamespacesTest\n  Error:  org.apache.pulsar.broker.admin.NamespacesTest.testNamespacesApiRedirects  Time elapsed: 0.015 s  <<< FAILURE!\n  java.lang.AssertionError: expected [http://127.0.0.3:8083/admin/namespace/my-tenant/usc/test-other-namespace-1/unload] but found [http://127.0.0.3:8083/admin/namespace/my-tenant/usc/test-other-namespace-1]\n  \tat org.testng.Assert.fail(Assert.java:110)\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\n  \tat org.testng.Assert.assertEquals(Assert.java:655)\n  \tat org.testng.Assert.assertEquals(Assert.java:665)\n  \tat org.apache.pulsar.broker.admin.NamespacesTest.testNamespacesApiRedirects(NamespacesTest.java:729)\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n  \tat java.base/java.lang.Thread.run(Thread.java:840)\n```\n\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 325,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java"
    ],
    "base_commit": "c6be44c710141bb55af0af2c0e94ecf2cac40fdd",
    "head_commit": "97da62a89b2e262260a8b5f999a90426d1ae12aa",
    "repo_url": "https://github.com/apache/pulsar/pull/24194",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24194",
    "dockerfile": "",
    "pr_merged_at": "2025-04-23T04:26:06.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java\nindex 18cc449d15dcb..26107c4bab9e7 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/NamespacesTest.java\n@@ -721,6 +721,7 @@ public void testNamespacesApiRedirects() throws Exception {\n                 + this.testLocalNamespaces.get(2).toString() + \"/unload\");\n         doReturn(uri).when(uriInfo).getRequestUri();\n \n+        response = mock(AsyncResponse.class);\n         namespaces.unloadNamespaceBundle(response, this.testTenant, this.testOtherCluster,\n                 this.testLocalNamespaces.get(2).getLocalName(), \"0x00000000_0xffffffff\", false, null);\n         captor = ArgumentCaptor.forClass(WebApplicationException.class);\n@@ -730,6 +731,7 @@ public void testNamespacesApiRedirects() throws Exception {\n                 UriBuilder.fromUri(uri).host(\"127.0.0.3\").port(8083).toString());\n \n         // check the bundle should not unload to an inactive destination broker\n+        response = mock(AsyncResponse.class);\n         namespaces.unloadNamespaceBundle(response, this.testTenant, this.testOtherCluster,\n                 this.testLocalNamespaces.get(2).getLocalName(), \"0x00000000_0xffffffff\", false, \"inactive_destination:8080\");\n         captor = ArgumentCaptor.forClass(WebApplicationException.class);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24170",
    "pr_id": 24170,
    "issue_id": 24169,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: org.apache.pulsar.broker.intercept.ManagedLedgerInterceptorImplTest.testManagedLedgerPayloadInputProcessorFailure\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14378361661/job/40332050279?pr=24168\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\nError:  Failures: \n  Error:  org.apache.pulsar.broker.intercept.ManagedLedgerInterceptorImplTest.testManagedLedgerPayloadInputProcessorFailure\n  [INFO]   Run 1: PASS\n  Error:    Run 2: ManagedLedgerInterceptorImplTest.testManagedLedgerPayloadInputProcessorFailure:495 expected [5] but found [4]\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 93,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java"
    ],
    "base_commit": "98c99830ccbe208fbee3aedf1e55901cd31f942f",
    "head_commit": "1143e9f624ca108e2d1cc30c0456454e555a2149",
    "repo_url": "https://github.com/apache/pulsar/pull/24170",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24170",
    "dockerfile": "",
    "pr_merged_at": "2025-04-11T05:24:43.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java\nindex b57b5ce94be42..3d83ac86d6cf5 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/intercept/ManagedLedgerInterceptorImplTest.java\n@@ -470,8 +470,8 @@ public void release(ByteBuf processedPayload) {\n         var addEntryCallback = new AsyncCallbacks.AddEntryCallback() {\n             @Override\n             public void addComplete(Position position, ByteBuf entryData, Object ctx) {\n-                countDownLatch.countDown();\n                 successCount.incrementAndGet();\n+                countDownLatch.countDown();\n             }\n \n             @Override\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24162",
    "pr_id": 24162,
    "issue_id": 24160,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14332259126/job/40171224624?pr=24158#step:11:1874\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  Failures: \n  Error:  org.apache.pulsar.broker.service.BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh\n  [INFO]   Run 1: PASS\n  Error:    Run 2: BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh:100  ServerSideError \n   --- An unexpected error occurred in the server ---\n  \n  Message: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \n  Stacktrace:\n  \n  org.apache.pulsar.metadata.api.MetadataStoreException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:501)\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$13(ZKMetadataStore.java:378)\n  \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n  Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \tat org.apache.zookeeper.KeeperException.create(KeeperException.java:101)\n  \tat org.apache.zookeeper.KeeperException.create(KeeperException.java:53)\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:491)\n  \t... 8 more\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 285,
    "test_files_count": 3,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java"
    ],
    "base_commit": "0d6c6f4b9e88a4cd10df50e6f1a9422772ca0779",
    "head_commit": "696eb1ba2523551c1c3470b951ca0335b69f02e1",
    "repo_url": "https://github.com/apache/pulsar/pull/24162",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24162",
    "dockerfile": "",
    "pr_merged_at": "2025-04-08T17:38:36.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java\nindex d49489d8a84b0..a1f0f8fa25616 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BkEnsemblesChaosTest.java\n@@ -55,13 +55,13 @@ public void testBookieInfoIsCorrectEvenIfLostNotificationDueToZKClientReconnect(\n         for (int i = 0; i < numberOfBookies - 1; i++){\n             bkEnsemble.stopBK(i);\n         }\n-        makeLocalMetadataStoreKeepReconnect();\n+        startLocalMetadataStoreConnectionTermination();\n         for (int i = 0; i < numberOfBookies - 1; i++){\n             bkEnsemble.startBK(i);\n         }\n         // Sleep 100ms to lose the notifications of ZK node create.\n         Thread.sleep(100);\n-        stopLocalMetadataStoreAlwaysReconnect();\n+        stopLocalMetadataStoreConnectionTermination();\n \n         // Ensure broker still works.\n         admin.topics().unload(topicName);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java\nindex 4187364e46f65..5650fe6e72fab 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceChaosTest.java\n@@ -20,8 +20,9 @@\n \n import static org.testng.Assert.assertEquals;\n import java.nio.charset.StandardCharsets;\n-import java.util.UUID;\n+import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.partition.PartitionedTopicMetadata;\n import org.apache.pulsar.common.policies.data.AutoTopicCreationOverride;\n@@ -55,9 +56,10 @@ public void cleanup() throws Exception {\n     public void testFetchPartitionedTopicMetadataWithCacheRefresh() throws Exception {\n         final String configMetadataStoreConnectString =\n                 WhiteboxImpl.getInternalState(pulsar.getConfigurationMetadataStore(), \"zkConnectString\");\n+        @Cleanup\n         final ZooKeeper anotherZKCli = new ZooKeeper(configMetadataStoreConnectString, 5000, null);\n         // Set policy of auto create topic to PARTITIONED.\n-        final String ns = defaultTenant + \"/ns_\" + UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n+        final String ns = BrokerTestUtil.newUniqueName(defaultTenant + \"/ns\");\n         final TopicName topicName1 = TopicName.get(\"persistent://\" + ns + \"/tp1\");\n         final TopicName topicName2 = TopicName.get(\"persistent://\" + ns + \"/tp2\");\n         admin.namespaces().createNamespace(ns);\n@@ -79,11 +81,11 @@ public void testFetchPartitionedTopicMetadataWithCacheRefresh() throws Exception\n \n         // Create the partitioned metadata by another zk client.\n         // Make a error to make the cache could not update.\n-        makeLocalMetadataStoreKeepReconnect();\n+        startLocalMetadataStoreConnectionTermination();\n         anotherZKCli.create(\"/admin/partitioned-topics/\" + ns + \"/persistent/\" + topicName2.getLocalName(),\n                 \"{\\\"partitions\\\":3}\".getBytes(StandardCharsets.UTF_8),\n                 ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n-        stopLocalMetadataStoreAlwaysReconnect();\n+        stopLocalMetadataStoreConnectionTermination();\n \n         // Get the partitioned metadata from cache, there is 90% chance that partitions count of metadata is 0.\n         PartitionedTopicMetadata partitionedTopicMetadata2 =\n@@ -95,9 +97,5 @@ public void testFetchPartitionedTopicMetadataWithCacheRefresh() throws Exception\n         PartitionedTopicMetadata partitionedTopicMetadata3 =\n                 pulsar.getBrokerService().fetchPartitionedTopicMetadataAsync(topicName2, true).get();\n         assertEquals(partitionedTopicMetadata3.partitions, 3);\n-\n-        // cleanup.\n-        admin.topics().deletePartitionedTopic(topicName2.toString());\n-        anotherZKCli.close();\n     }\n }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\nindex 787b4d3154e90..dc41764ca211e 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\n@@ -25,6 +25,7 @@\n import java.nio.channels.SelectionKey;\n import java.util.Collections;\n import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.atomic.AtomicBoolean;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.broker.PulsarService;\n@@ -65,7 +66,8 @@ public abstract class CanReconnectZKClientPulsarServiceBaseTest extends TestRetr\n     protected PulsarClient client;\n     protected ZooKeeper localZkOfBroker;\n     protected Object localMetaDataStoreClientCnx;\n-    protected final AtomicBoolean LocalMetadataStoreInReconnectFinishSignal = new AtomicBoolean();\n+    protected final AtomicBoolean connectionTerminationThreadKeepRunning = new AtomicBoolean();\n+    private volatile Thread connectionTerminationThread;\n \n     protected void startZKAndBK() throws Exception {\n         // Start ZK.\n@@ -95,25 +97,29 @@ protected void startBrokers() throws Exception {\n         client = PulsarClient.builder().serviceUrl(url.toString()).build();\n     }\n \n-    protected void makeLocalMetadataStoreKeepReconnect() throws Exception {\n-        if (!LocalMetadataStoreInReconnectFinishSignal.compareAndSet(false, true)) {\n-            throw new RuntimeException(\"Local metadata store is already keeping reconnect\");\n+    protected void startLocalMetadataStoreConnectionTermination() throws Exception {\n+        if (!connectionTerminationThreadKeepRunning.compareAndSet(false, true)) {\n+            throw new RuntimeException(\"Local metadata store connection is already being terminated\");\n         }\n+        CompletableFuture<Void> future = new CompletableFuture<>();\n         if (localMetaDataStoreClientCnx.getClass().getSimpleName().equals(\"ClientCnxnSocketNIO\")) {\n-            makeLocalMetadataStoreKeepReconnectNIO();\n+            startNIOImplTermination(future);\n         } else {\n             // ClientCnxnSocketNetty.\n-            makeLocalMetadataStoreKeepReconnectNetty();\n+            startNettyImplTermination(future);\n         }\n+        // wait until connection is closed at least once\n+        future.get();\n     }\n \n-    protected void makeLocalMetadataStoreKeepReconnectNIO() {\n-        new Thread(() -> {\n-            while (LocalMetadataStoreInReconnectFinishSignal.get()) {\n+    private void startNIOImplTermination(CompletableFuture<Void> future) {\n+        connectionTerminationThread = new Thread(() -> {\n+            while (connectionTerminationThreadKeepRunning.get()) {\n                 try {\n                     SelectionKey sockKey = WhiteboxImpl.getInternalState(localMetaDataStoreClientCnx, \"sockKey\");\n                     if (sockKey != null) {\n                         sockKey.channel().close();\n+                        future.complete(null);\n                     }\n                     // Prevents high cpu usage.\n                     Thread.sleep(5);\n@@ -121,16 +127,18 @@ protected void makeLocalMetadataStoreKeepReconnectNIO() {\n                     log.error(\"Try close the ZK connection of local metadata store failed: {}\", e.toString());\n                 }\n             }\n-        }).start();\n+        });\n+        connectionTerminationThread.start();\n     }\n \n-    protected void makeLocalMetadataStoreKeepReconnectNetty() {\n-        new Thread(() -> {\n-            while (LocalMetadataStoreInReconnectFinishSignal.get()) {\n+    private void startNettyImplTermination(CompletableFuture<Void> future) {\n+        connectionTerminationThread = new Thread(() -> {\n+            while (connectionTerminationThreadKeepRunning.get()) {\n                 try {\n                     Channel channel = WhiteboxImpl.getInternalState(localMetaDataStoreClientCnx, \"channel\");\n                     if (channel != null) {\n                         channel.close();\n+                        future.complete(null);\n                     }\n                     // Prevents high cpu usage.\n                     Thread.sleep(5);\n@@ -138,11 +146,17 @@ protected void makeLocalMetadataStoreKeepReconnectNetty() {\n                     log.error(\"Try close the ZK connection of local metadata store failed: {}\", e.toString());\n                 }\n             }\n-        }).start();\n+        });\n+        connectionTerminationThread.start();\n     }\n \n-    protected void stopLocalMetadataStoreAlwaysReconnect() {\n-        LocalMetadataStoreInReconnectFinishSignal.set(false);\n+    protected void stopLocalMetadataStoreConnectionTermination() throws InterruptedException {\n+        connectionTerminationThreadKeepRunning.set(false);\n+        if (connectionTerminationThread != null) {\n+            // Wait for the reconnect thread to finish.\n+            connectionTerminationThread.join();\n+            connectionTerminationThread = null;\n+        }\n     }\n \n     protected void createDefaultTenantsAndClustersAndNamespace() throws Exception {\n@@ -205,7 +219,7 @@ protected void cleanup() throws Exception {\n         markCurrentSetupNumberCleaned();\n         log.info(\"--- Shutting down ---\");\n \n-        stopLocalMetadataStoreAlwaysReconnect();\n+        stopLocalMetadataStoreConnectionTermination();\n \n         // Stop brokers.\n         if (client != null) {\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24161",
    "pr_id": 24161,
    "issue_id": 24160,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/14332259126/job/40171224624?pr=24158#step:11:1874\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  Failures: \n  Error:  org.apache.pulsar.broker.service.BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh\n  [INFO]   Run 1: PASS\n  Error:    Run 2: BrokerServiceChaosTest.testFetchPartitionedTopicMetadataWithCacheRefresh:100  ServerSideError \n   --- An unexpected error occurred in the server ---\n  \n  Message: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \n  Stacktrace:\n  \n  org.apache.pulsar.metadata.api.MetadataStoreException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:501)\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$13(ZKMetadataStore.java:378)\n  \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n  Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /managed-ledgers/public/ns_8470299b52574235a3e0afa8bb25ea70/persistent/__change_events-partition-0\n  \tat org.apache.zookeeper.KeeperException.create(KeeperException.java:101)\n  \tat org.apache.zookeeper.KeeperException.create(KeeperException.java:53)\n  \tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:491)\n  \t... 8 more\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 285,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java"
    ],
    "base_commit": "d59664ca9ca7300a8a7bc3faa1869f623eaac8ae",
    "head_commit": "d217e6d1850a401f51b38f465b9486beba5071d9",
    "repo_url": "https://github.com/apache/pulsar/pull/24161",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24161",
    "dockerfile": "",
    "pr_merged_at": "2025-04-09T04:10:38.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\nindex dc41764ca211e..b2db0e84749c5 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/CanReconnectZKClientPulsarServiceBaseTest.java\n@@ -35,12 +35,14 @@\n import org.apache.pulsar.common.policies.data.ClusterData;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.policies.data.TopicType;\n+import org.apache.pulsar.metadata.api.extended.SessionEvent;\n import org.apache.pulsar.metadata.impl.ZKMetadataStore;\n import org.apache.pulsar.tests.TestRetrySupport;\n import org.apache.pulsar.zookeeper.LocalBookkeeperEnsemble;\n import org.apache.pulsar.zookeeper.ZookeeperServerTest;\n import org.apache.zookeeper.ClientCnxn;\n import org.apache.zookeeper.ZooKeeper;\n+import org.awaitility.Awaitility;\n import org.awaitility.reflect.WhiteboxImpl;\n \n @Slf4j\n@@ -65,6 +67,7 @@ public abstract class CanReconnectZKClientPulsarServiceBaseTest extends TestRetr\n     protected PulsarAdmin admin;\n     protected PulsarClient client;\n     protected ZooKeeper localZkOfBroker;\n+    protected volatile SessionEvent sessionEvent;\n     protected Object localMetaDataStoreClientCnx;\n     protected final AtomicBoolean connectionTerminationThreadKeepRunning = new AtomicBoolean();\n     private volatile Thread connectionTerminationThread;\n@@ -87,6 +90,10 @@ protected void startBrokers() throws Exception {\n         broker = pulsar.getBrokerService();\n         ZKMetadataStore zkMetadataStore = (ZKMetadataStore) pulsar.getLocalMetadataStore();\n         localZkOfBroker = zkMetadataStore.getZkClient();\n+        zkMetadataStore.registerSessionListener(n -> {\n+            log.info(\"Received session event: {}\", n);\n+            sessionEvent = n;\n+        });\n         ClientCnxn cnxn = WhiteboxImpl.getInternalState(localZkOfBroker, \"cnxn\");\n         Object sendThread = WhiteboxImpl.getInternalState(cnxn, \"sendThread\");\n         localMetaDataStoreClientCnx = WhiteboxImpl.getInternalState(sendThread, \"clientCnxnSocket\");\n@@ -157,6 +164,7 @@ protected void stopLocalMetadataStoreConnectionTermination() throws InterruptedE\n             connectionTerminationThread.join();\n             connectionTerminationThread = null;\n         }\n+        Awaitility.await().until(() -> SessionEvent.Reconnected.equals(sessionEvent));\n     }\n \n     protected void createDefaultTenantsAndClustersAndNamespace() throws Exception {\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24141",
    "pr_id": 24141,
    "issue_id": 23827,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: DisabledCreateTopicToRemoteClusterForReplicationTest.testCreatePartitionedTopicWithNsReplication\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n### Example failures\r\n\r\n- [2025-01-02T10:04:01.9336740Z](https://github.com/apache/pulsar/actions/runs/12580383927/job/35062462009#step:10:1316) \r\n\r\n\r\n### Exception stacktrace\r\n\r\n```\r\njava.lang.NullPointerException: Cannot invoke \"org.apache.pulsar.client.api.Message.getValue()\" because the return value of \"org.apache.pulsar.client.api.Consumer.receive(int, java.util.concurrent.TimeUnit)\" is null\r\n\tat org.apache.pulsar.broker.service.DisabledCreateTopicToRemoteClusterForReplicationTest.testCreatePartitionedTopicWithNsReplication(DisabledCreateTopicToRemoteClusterForReplicationTest.java:111)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!\r\n",
    "issue_word_count": 229,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java"
    ],
    "base_commit": "371020d66ee01fb79d223fb815f51d3cd69276c9",
    "head_commit": "969165714478c839f20a2dd983cea4d4a5c25cf1",
    "repo_url": "https://github.com/apache/pulsar/pull/24141",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24141",
    "dockerfile": "",
    "pr_merged_at": "2025-04-07T02:18:17.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\nindex 0f8db4aaa7316..ec9e8b6c27039 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n@@ -108,7 +108,7 @@ public void testCreatePartitionedTopicWithNsReplication() throws Exception {\n         admin2.topics().createPartitionedTopic(tp, 1);\n         Consumer<String> consumer2 = client2.newConsumer(Schema.STRING).topic(tp).isAckReceiptEnabled(true)\n                 .subscriptionName(\"s1\").subscribe();\n-        assertEquals(consumer2.receive(10, TimeUnit.SECONDS).getValue(), msgValue);\n+        assertEquals(consumer2.receive(20, TimeUnit.SECONDS).getValue(), msgValue);\n         consumer2.close();\n \n         // cleanup.\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24134",
    "pr_id": 24134,
    "issue_id": 20386,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: NonPersistentTopicTest.testMsgDropStat\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/5067587816/jobs/9099067231#step:10:1471\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 151, Failures: 1, Errors: 0, Skipped: 145, Time elapsed: 61.004 s <<< FAILURE! - in org.apache.pulsar.client.api.NonPersistentTopicTest\r\n  Error:  org.apache.pulsar.client.api.NonPersistentTopicTest.testMsgDropStat  Time elapsed: 2.251 s  <<< FAILURE!\r\n  java.lang.AssertionError: expected [true] but found [false]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertTrue(Assert.java:56)\r\n  \tat org.testng.Assert.assertTrue(Assert.java:66)\r\n  \tat org.apache.pulsar.client.api.NonPersistentTopicTest.testMsgDropStat(NonPersistentTopicTest.java:859)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:833)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 279,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java"
    ],
    "base_commit": "7aa49c6bd206fcde0a467c29440f458b43f7ad1e",
    "head_commit": "436c26d655bf9028b8f028a0f5454294d1723fca",
    "repo_url": "https://github.com/apache/pulsar/pull/24134",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24134",
    "dockerfile": "",
    "pr_merged_at": "2025-03-28T10:08:46.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java\nindex e5c992ec6f858..a62da5c1a4d79 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/NonPersistentTopicTest.java\n@@ -871,14 +871,15 @@ public void testMsgDropStat() throws Exception {\n                 .messageRoutingMode(MessageRoutingMode.SinglePartition)\n                 .create();\n             @Cleanup(\"shutdownNow\")\n-            ExecutorService executor = Executors.newFixedThreadPool(5);\n+            ExecutorService executor = Executors.newFixedThreadPool(10);\n             byte[] msgData = \"testData\".getBytes();\n             final int totalProduceMessages = 1000;\n             CountDownLatch latch = new CountDownLatch(1);\n             AtomicInteger messagesSent = new AtomicInteger(0);\n             for (int i = 0; i < totalProduceMessages; i++) {\n                 executor.submit(() -> {\n-                    producer.sendAsync(msgData).handle((msgId, e) -> {\n+                    try {\n+                        MessageId msgId = producer.send(msgData);\n                         int count = messagesSent.incrementAndGet();\n                         // process at least 20% of messages before signalling the latch\n                         // a non-persistent message will return entryId as -1 when it has been dropped\n@@ -888,8 +889,14 @@ public void testMsgDropStat() throws Exception {\n                                 && ((MessageIdImpl) msgId).getEntryId() == -1) {\n                             latch.countDown();\n                         }\n-                        return null;\n-                    });\n+\n+                        Thread.sleep(10);\n+                    } catch (PulsarClientException e) {\n+                        throw new RuntimeException(e);\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                        throw new RuntimeException(e);\n+                    }\n                 });\n             }\n             assertTrue(latch.await(5, TimeUnit.SECONDS));\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24132",
    "pr_id": 24132,
    "issue_id": 24129,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] KinesisSink with jsonFlatten doesn't handle SchemaType.BYTES correctly\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nHEAD\n\n### Minimal reproduce step\n\nRun the following test\n```java\n    @Test\n    public void testSerializeRecordToJsonExpandingValue() throws Exception {\n        SchemaType schemaType = SchemaType.AVRO;\n        RecordSchemaBuilder valueSchemaBuilder = org.apache.pulsar.client.api.schema.SchemaBuilder.record(\"value\");\n        valueSchemaBuilder.field(\"a\").type(SchemaType.BYTES).optional().defaultValue(null);\n        GenericSchema<GenericRecord> valueSchema = Schema.generic(valueSchemaBuilder.build(schemaType));\n\n        GenericRecord valueGenericRecord = valueSchema.newRecordBuilder()\n                .set(\"a\", \"10\".getBytes(StandardCharsets.UTF_8))\n                .build();\n\n        Record<GenericObject> genericObjectRecord = new Record<>() {\n\n            @Override\n            public org.apache.pulsar.client.api.Schema getSchema() {\n                return valueSchema;\n            }\n\n            @Override\n            public GenericObject getValue() {\n                return valueGenericRecord;\n            }\n        };\n\n        ObjectMapper objectMapper = new ObjectMapper().setSerializationInclusion(JsonInclude.Include.NON_NULL);\n        String json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, true);\n\n        assertEquals(json, \"{\\\"payload.a\\\":\\\"MTA=\\\"}\");\n    }\n```\n\n### What did you expect to see?\n\nThe test should pass.\n\n### What did you see instead?\n\nThe test fails because `payload.a` is `null`.\n```sh\njava.lang.AssertionError:\nExpected :{\"payload.a\":\"MTA=\"}\nActual   :{\"payload.a\":null}\n```\n\n### Anything else?\n\nThe problem is in the flattening library `json-flattener` which doesn't handle Jackson's BinaryNode.\nIn `JsonJacksonValue`, `isString` should also return `true` when the underlying `JsonNode` `isBinary` is `true`.\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 243,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/Utils.java",
      "pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java"
    ],
    "pr_changed_test_files": [
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java",
      "pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java"
    ],
    "base_commit": "7aa49c6bd206fcde0a467c29440f458b43f7ad1e",
    "head_commit": "63206718bb0fa91fa002ef7f3c361807a40f1d57",
    "repo_url": "https://github.com/apache/pulsar/pull/24132",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24132",
    "dockerfile": "",
    "pr_merged_at": "2025-03-28T09:59:26.000Z",
    "patch": "diff --git a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/Utils.java b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/Utils.java\nindex 32d3470524876..a52e42e9c6a55 100644\n--- a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/Utils.java\n+++ b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/Utils.java\n@@ -222,7 +222,7 @@ public static String serializeRecordToJsonExpandingValue(ObjectMapper mapper, Re\n         JsonRecord jsonRecord = new JsonRecord();\n         GenericObject value = record.getValue();\n         if (value != null) {\n-            jsonRecord.setPayload(toJsonSerializable(record.getSchema(), value.getNativeObject()));\n+            jsonRecord.setPayload(toJsonSerializable(record.getSchema(), value.getNativeObject(), flatten));\n         }\n         record.getKey().ifPresent(jsonRecord::setKey);\n         record.getTopicName().ifPresent(jsonRecord::setTopicName);\n@@ -242,7 +242,7 @@ public static org.apache.pulsar.client.api.Message<GenericObject> getMessage(Rec\n                 .orElseThrow(() -> new IllegalArgumentException(\"Record does not carry message information\"));\n     }\n \n-    private static Object toJsonSerializable(Schema<?> schema, Object val) {\n+    private static Object toJsonSerializable(Schema<?> schema, Object val, boolean convertBytesToString) {\n         if (schema == null || schema.getSchemaInfo().getType().isPrimitive()) {\n             return val;\n         }\n@@ -254,15 +254,15 @@ private static Object toJsonSerializable(Schema<?> schema, Object val) {\n                 Map<String, Object> jsonKeyValue = new HashMap<>();\n                 if (keyValue.getKey() != null) {\n                     jsonKeyValue.put(\"key\", toJsonSerializable(keyValueSchema.getKeySchema(),\n-                            keyValue.getKey().getNativeObject()));\n+                            keyValue.getKey().getNativeObject(), convertBytesToString));\n                 }\n                 if (keyValue.getValue() != null) {\n                     jsonKeyValue.put(\"value\", toJsonSerializable(keyValueSchema.getValueSchema(),\n-                            keyValue.getValue().getNativeObject()));\n+                            keyValue.getValue().getNativeObject(), convertBytesToString));\n                 }\n                 return jsonKeyValue;\n             case AVRO:\n-                return JsonConverter.toJson((org.apache.avro.generic.GenericRecord) val);\n+                return JsonConverter.toJson((org.apache.avro.generic.GenericRecord) val, convertBytesToString);\n             case JSON:\n                 return val;\n             default:\n\ndiff --git a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\nindex 5308971e8d24e..22412c395759a 100644\n--- a/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\n+++ b/pulsar-io/kinesis/src/main/java/org/apache/pulsar/io/kinesis/json/JsonConverter.java\n@@ -26,6 +26,7 @@\n import java.time.Instant;\n import java.time.LocalDate;\n import java.time.LocalTime;\n+import java.util.Base64;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.UUID;\n@@ -45,18 +46,18 @@ public class JsonConverter {\n     private static final Map<String, LogicalTypeConverter<?>> logicalTypeConverters = new HashMap<>();\n     private static final JsonNodeFactory jsonNodeFactory = JsonNodeFactory.withExactBigDecimals(true);\n \n-    public static JsonNode toJson(GenericRecord genericRecord) {\n+    public static JsonNode toJson(GenericRecord genericRecord, boolean convertBytesToString) {\n         if (genericRecord == null) {\n             return null;\n         }\n         ObjectNode objectNode = jsonNodeFactory.objectNode();\n         for (Schema.Field field : genericRecord.getSchema().getFields()) {\n-            objectNode.set(field.name(), toJson(field.schema(), genericRecord.get(field.name())));\n+            objectNode.set(field.name(), toJson(field.schema(), genericRecord.get(field.name()), convertBytesToString));\n         }\n         return objectNode;\n     }\n \n-    public static JsonNode toJson(Schema schema, Object value) {\n+    public static JsonNode toJson(Schema schema, Object value, boolean convertBytesToString) {\n         if (schema.getLogicalType() != null && logicalTypeConverters.containsKey(schema.getLogicalType().getName())) {\n             return logicalTypeConverters.get(schema.getLogicalType().getName()).toJson(schema, value);\n         }\n@@ -77,8 +78,16 @@ public static JsonNode toJson(Schema schema, Object value) {\n             case BOOLEAN:\n                 return jsonNodeFactory.booleanNode((Boolean) value);\n             case BYTES:\n+                // Workaround for https://github.com/wnameless/json-flattener/issues/91\n+                if (convertBytesToString) {\n+                    return jsonNodeFactory.textNode(Base64.getEncoder().encodeToString((byte[]) value));\n+                }\n                 return jsonNodeFactory.binaryNode((byte[]) value);\n             case FIXED:\n+                // Workaround for https://github.com/wnameless/json-flattener/issues/91\n+                if (convertBytesToString) {\n+                    return jsonNodeFactory.textNode(Base64.getEncoder().encodeToString(((GenericFixed) value).bytes()));\n+                }\n                 return jsonNodeFactory.binaryNode(((GenericFixed) value).bytes());\n             case ENUM: // GenericEnumSymbol\n             case STRING:\n@@ -93,7 +102,7 @@ public static JsonNode toJson(Schema schema, Object value) {\n                     iterable = (Object[]) value;\n                 }\n                 for (Object elem : iterable) {\n-                    JsonNode fieldValue = toJson(elementSchema, elem);\n+                    JsonNode fieldValue = toJson(elementSchema, elem, convertBytesToString);\n                     arrayNode.add(fieldValue);\n                 }\n                 return arrayNode;\n@@ -102,7 +111,7 @@ public static JsonNode toJson(Schema schema, Object value) {\n                 Map<Object, Object> map = (Map<Object, Object>) value;\n                 ObjectNode objectNode = jsonNodeFactory.objectNode();\n                 for (Map.Entry<Object, Object> entry : map.entrySet()) {\n-                    JsonNode jsonNode = toJson(schema.getValueType(), entry.getValue());\n+                    JsonNode jsonNode = toJson(schema.getValueType(), entry.getValue(), convertBytesToString);\n                     // can be a String or org.apache.avro.util.Utf8\n                     final String entryKey = entry.getKey() == null ? null : entry.getKey().toString();\n                     objectNode.set(entryKey, jsonNode);\n@@ -110,13 +119,13 @@ public static JsonNode toJson(Schema schema, Object value) {\n                 return objectNode;\n             }\n             case RECORD:\n-                return toJson((GenericRecord) value);\n+                return toJson((GenericRecord) value, convertBytesToString);\n             case UNION:\n                 for (Schema s : schema.getTypes()) {\n                     if (s.getType() == Schema.Type.NULL) {\n                         continue;\n                     }\n-                    return toJson(s, value);\n+                    return toJson(s, value, convertBytesToString);\n                 }\n                 // this case should not happen\n                 return jsonNodeFactory.textNode(value.toString());\n",
    "test_patch": "diff --git a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\nindex b0f9456b9487c..1eda566df04c3 100644\n--- a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\n+++ b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/UtilsTest.java\n@@ -29,6 +29,8 @@\n import com.google.gson.Gson;\n \n import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Base64;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.Map;\n@@ -358,6 +360,7 @@ public void testKeyValueSerializeRecordToJsonExpandingValue(SchemaType schemaTyp\n         RecordSchemaBuilder udtSchemaBuilder = SchemaBuilder.record(\"type1\");\n         udtSchemaBuilder.field(\"a\").type(SchemaType.STRING).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"b\").type(SchemaType.BOOLEAN).optional().defaultValue(null);\n+        udtSchemaBuilder.field(\"c\").type(SchemaType.BYTES).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"d\").type(SchemaType.DOUBLE).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"f\").type(SchemaType.FLOAT).optional().defaultValue(null);\n         udtSchemaBuilder.field(\"i\").type(SchemaType.INT32).optional().defaultValue(null);\n@@ -366,12 +369,16 @@ public void testKeyValueSerializeRecordToJsonExpandingValue(SchemaType schemaTyp\n         valueSchemaBuilder.field(\"e\", udtGenericSchema).type(schemaType).optional().defaultValue(null);\n         GenericSchema<GenericRecord> valueSchema = Schema.generic(valueSchemaBuilder.build(schemaType));\n \n+        byte[] bytes = \"10\".getBytes(StandardCharsets.UTF_8);\n         GenericRecord valueGenericRecord = valueSchema.newRecordBuilder()\n                 .set(\"c\", \"1\")\n                 .set(\"d\", 1)\n                 .set(\"e\", udtGenericSchema.newRecordBuilder()\n                         .set(\"a\", \"a\")\n                         .set(\"b\", true)\n+                        // There's a bug in json-flattener that doesn't handle byte[] fields correctly.\n+                        // But since we use AUTO_CONSUME, we won't get byte[] fields for JSON schema anyway.\n+                        .set(\"c\", schemaType == SchemaType.AVRO ? bytes : Base64.getEncoder().encodeToString(bytes))\n                         .set(\"d\", 1.0)\n                         .set(\"f\", 1.0f)\n                         .set(\"i\", 1)\n@@ -434,16 +441,17 @@ public Optional<Long> getEventTime() {\n         String json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, false);\n \n         assertEquals(json, \"{\\\"topicName\\\":\\\"data-ks1.table1\\\",\\\"key\\\":\\\"message-key\\\",\"\n-                + \"\\\"payload\\\":{\\\"value\\\":{\\\"c\\\":\\\"1\\\",\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"d\\\":1.0,\\\"f\\\":1.0,\"\n-                + \"\\\"i\\\":1,\\\"l\\\":10}},\\\"key\\\":{\\\"a\\\":\\\"1\\\",\\\"b\\\":1}},\\\"properties\\\":{\\\"prop-key\\\":\\\"prop-value\\\"},\"\n-                + \"\\\"eventTime\\\":1648502845803}\");\n+                + \"\\\"payload\\\":{\\\"value\\\":{\\\"c\\\":\\\"1\\\",\\\"d\\\":1,\\\"e\\\":{\\\"a\\\":\\\"a\\\",\\\"b\\\":true,\\\"c\\\":\\\"MTA=\\\",\\\"d\\\":1.0,\"\n+                + \"\\\"f\\\":1.0,\\\"i\\\":1,\\\"l\\\":10}},\\\"key\\\":{\\\"a\\\":\\\"1\\\",\\\"b\\\":1}},\"\n+                + \"\\\"properties\\\":{\\\"prop-key\\\":\\\"prop-value\\\"},\\\"eventTime\\\":1648502845803}\");\n \n         json = Utils.serializeRecordToJsonExpandingValue(objectMapper, genericObjectRecord, true);\n \n         assertEquals(json, \"{\\\"topicName\\\":\\\"data-ks1.table1\\\",\\\"key\\\":\\\"message-key\\\",\\\"payload.value.c\\\":\\\"1\\\",\"\n-                + \"\\\"payload.value.d\\\":1,\\\"payload.value.e.a\\\":\\\"a\\\",\\\"payload.value.e.b\\\":true,\\\"payload.value.e\"\n-                + \".d\\\":1.0,\\\"payload.value.e.f\\\":1.0,\\\"payload.value.e.i\\\":1,\\\"payload.value.e.l\\\":10,\\\"payload.key\"\n-                + \".a\\\":\\\"1\\\",\\\"payload.key.b\\\":1,\\\"properties.prop-key\\\":\\\"prop-value\\\",\\\"eventTime\\\":1648502845803}\");\n+                + \"\\\"payload.value.d\\\":1,\\\"payload.value.e.a\\\":\\\"a\\\",\\\"payload.value.e.b\\\":true,\"\n+                + \"\\\"payload.value.e.c\\\":\\\"MTA=\\\",\\\"payload.value.e.d\\\":1.0,\\\"payload.value.e.f\\\":1.0,\"\n+                + \"\\\"payload.value.e.i\\\":1,\\\"payload.value.e.l\\\":10,\\\"payload.key.a\\\":\\\"1\\\",\\\"payload.key.b\\\":1,\"\n+                + \"\\\"properties.prop-key\\\":\\\"prop-value\\\",\\\"eventTime\\\":1648502845803}\");\n     }\n \n     @Test(dataProvider = \"schemaType\")\n\ndiff --git a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\nindex 94fd73135b398..c3bbaa06d014d 100644\n--- a/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\n+++ b/pulsar-io/kinesis/src/test/java/org/apache/pulsar/io/kinesis/json/JsonConverterTests.java\n@@ -81,7 +81,7 @@ public void testAvroToJson() throws IOException {\n         genericRecord.put(\"arrayavro\", new GenericData.Array<>(avroArraySchema, Arrays.asList(\"toto\")));\n         genericRecord.put(\"map\", ImmutableMap.of(\"a\",10));\n         genericRecord.put(\"maputf8\", ImmutableMap.of(new org.apache.avro.util.Utf8(\"a\"),10));\n-        JsonNode jsonNode = JsonConverter.toJson(genericRecord);\n+        JsonNode jsonNode = JsonConverter.toJson(genericRecord, false);\n         assertEquals(jsonNode.get(\"n\"), NullNode.getInstance());\n         assertEquals(jsonNode.get(\"l\").asLong(), 1L);\n         assertEquals(jsonNode.get(\"i\").asInt(), 1);\n@@ -135,7 +135,7 @@ public void testLogicalTypesToJson() throws IOException {\n         genericRecord.put(\"myuuid\", myUuid.toString());\n \n         GenericRecord genericRecord2 = deserialize(serialize(genericRecord, schema), schema);\n-        JsonNode jsonNode = JsonConverter.toJson(genericRecord2);\n+        JsonNode jsonNode = JsonConverter.toJson(genericRecord2, false);\n         assertEquals(jsonNode.get(\"mydate\").asInt(), calendar.toInstant().getEpochSecond());\n         assertEquals(jsonNode.get(\"tsmillis\").asInt(), (int)calendar.getTimeInMillis());\n         assertEquals(jsonNode.get(\"tsmicros\").asLong(), calendar.getTimeInMillis() * 1000);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24122",
    "pr_id": 24122,
    "issue_id": 24121,
    "repo": "apache/pulsar",
    "problem_statement": "[Enhancement] Pulsar Functions Go: Return error on NewOutputMessage to enable error handling\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\nWhen an error occurs during the sending of a message using `NewOutputMessage`, the go function exits with a panic. This behavior prevents the application from handling the error gracefully, as it bypasses any error-handling logic.\n\nErrors should be returned by `NewOutputMessage `so they can be handled by the calling code, rather than causing a panic.\n\n### Solution\n\nAdapt the outputMessage in the context as following\n\n```go\n\tgoInstance.context.outputMessage = func(topic string) (pulsar.Producer, error) {\n\t\tproducer, err := goInstance.getProducer(topic)\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"getting producer failed, error is:%v\", err)\n\t\t\treturn nil, err\n\t\t}\n\t\treturn producer, nil\n\t}\n``` \n\n### Alternatives\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 152,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-function-go/pf/context.go",
      "pulsar-function-go/pf/context_test.go",
      "pulsar-function-go/pf/instance.go",
      "pulsar-function-go/pf/util_test.go"
    ],
    "pr_changed_test_files": [
      "pulsar-function-go/pf/context_test.go",
      "pulsar-function-go/pf/util_test.go"
    ],
    "base_commit": "7aa49c6bd206fcde0a467c29440f458b43f7ad1e",
    "head_commit": "c288ae022cfdb06e5fd7ced60e0ac73a995231a6",
    "repo_url": "https://github.com/apache/pulsar/pull/24122",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24122",
    "dockerfile": "",
    "pr_merged_at": "2025-03-28T10:31:47.000Z",
    "patch": "diff --git a/pulsar-function-go/pf/context.go b/pulsar-function-go/pf/context.go\nindex 0b269a568ffec..69959cb3c1ac9 100644\n--- a/pulsar-function-go/pf/context.go\n+++ b/pulsar-function-go/pf/context.go\n@@ -34,12 +34,13 @@ import (\n // message, what are our operating constraints, etc can be accessed by the\n // executing function\n type FunctionContext struct {\n-\tinstanceConf  *instanceConf\n-\tuserConfigs   map[string]interface{}\n-\tlogAppender   *LogAppender\n-\toutputMessage func(topic string) pulsar.Producer\n-\tuserMetrics   sync.Map\n-\trecord        pulsar.Message\n+\tinstanceConf           *instanceConf\n+\tuserConfigs            map[string]interface{}\n+\tlogAppender            *LogAppender\n+\toutputMessage          func(topic string) pulsar.Producer\n+\toutputMessageWithError func(topic string) (pulsar.Producer, error)\n+\tuserMetrics            sync.Map\n+\trecord                 pulsar.Message\n }\n \n // NewFuncContext returns a new Function context\n@@ -161,6 +162,13 @@ func (c *FunctionContext) NewOutputMessage(topicName string) pulsar.Producer {\n \treturn c.outputMessage(topicName)\n }\n \n+// NewOutputMessageWithError send message to the topic and returns a potential error\n+// @param topicName: The name of the topic for output message\n+// @return A Pulsar producer for the given topic and an error, if any.\n+func (c *FunctionContext) NewOutputMessageWithError(topicName string) (pulsar.Producer, error) {\n+\treturn c.outputMessageWithError(topicName)\n+}\n+\n // SetCurrentRecord sets the current message into the function context called\n // for each message before executing a handler function\n func (c *FunctionContext) SetCurrentRecord(record pulsar.Message) {\n\ndiff --git a/pulsar-function-go/pf/instance.go b/pulsar-function-go/pf/instance.go\nindex 1064aece46fe8..4c6294d22bd4e 100644\n--- a/pulsar-function-go/pf/instance.go\n+++ b/pulsar-function-go/pf/instance.go\n@@ -77,6 +77,15 @@ func newGoInstance() *goInstance {\n \t\treturn producer\n \t}\n \n+\tgoInstance.context.outputMessageWithError = func(topic string) (pulsar.Producer, error) {\n+\t\tproducer, err := goInstance.getProducer(topic)\n+\t\tif err != nil {\n+\t\t\tlog.Errorf(\"getting producer failed, error is:%v\", err)\n+\t\t\treturn nil, err\n+\t\t}\n+\t\treturn producer, nil\n+\t}\n+\n \tgoInstance.lastHealthCheckTS = now.UnixNano()\n \tgoInstance.properties = make(map[string]string)\n \tgoInstance.stats = NewStatWithLabelValues(goInstance.getMetricsLabels()...)\n",
    "test_patch": "diff --git a/pulsar-function-go/pf/context_test.go b/pulsar-function-go/pf/context_test.go\nindex 52a8abc3117c2..0c9f78775ca4d 100644\n--- a/pulsar-function-go/pf/context_test.go\n+++ b/pulsar-function-go/pf/context_test.go\n@@ -21,6 +21,8 @@ package pf\n \n import (\n \t\"context\"\n+\t\"errors\"\n+\t\"fmt\"\n \t\"testing\"\n \t\"time\"\n \n@@ -82,3 +84,46 @@ func TestFunctionContext_NewOutputMessage(t *testing.T) {\n \tactualProducer := fc.NewOutputMessage(publishTopic)\n \tassert.IsType(t, &MockPulsarProducer{}, actualProducer)\n }\n+\n+func TestFunctionContext_NewOutputMessageWithError(t *testing.T) {\n+\ttestErr := errors.New(\"test error\")\n+\n+\ttestCases := []struct {\n+\t\tname                 string\n+\t\toutputFunc           func(topic string) (pulsar.Producer, error)\n+\t\texpectedError        error\n+\t\texpectedProducerType *MockPulsarProducer\n+\t}{\n+\n+\t\t{\n+\t\t\tname:                 \"Test producer\",\n+\t\t\toutputFunc:           func(topic string) (pulsar.Producer, error) { return &MockPulsarProducer{}, nil },\n+\t\t\texpectedError:        nil,\n+\t\t\texpectedProducerType: &MockPulsarProducer{},\n+\t\t},\n+\t\t{\n+\t\t\tname:                 \"Test error\",\n+\t\t\toutputFunc:           func(topic string) (pulsar.Producer, error) { return nil, errors.New(\"test error\") },\n+\t\t\texpectedError:        testErr,\n+\t\t\texpectedProducerType: nil,\n+\t\t},\n+\t}\n+\n+\tfor i, testCase := range testCases {\n+\t\tt.Run(fmt.Sprintf(\"testCase[%d] %s\", i, testCase.name), func(t *testing.T) {\n+\n+\t\t\tfc := NewFuncContext()\n+\t\t\tpublishTopic := \"publish-topic\"\n+\n+\t\t\tfc.outputMessageWithError = testCase.outputFunc\n+\n+\t\t\tactualProducer, err := fc.NewOutputMessageWithError(publishTopic)\n+\t\t\tif testCase.expectedProducerType == nil {\n+\t\t\t\tassert.Nil(t, actualProducer)\n+\t\t\t} else {\n+\t\t\t\tassert.IsType(t, testCase.expectedProducerType, actualProducer)\n+\t\t\t}\n+\t\t\tassert.Equal(t, testCase.expectedError, err)\n+\t\t})\n+\t}\n+}\n\ndiff --git a/pulsar-function-go/pf/util_test.go b/pulsar-function-go/pf/util_test.go\nindex fa0871b49ff32..d6d3a2b54b8c5 100644\n--- a/pulsar-function-go/pf/util_test.go\n+++ b/pulsar-function-go/pf/util_test.go\n@@ -44,8 +44,8 @@ func TestUtils(t *testing.T) {\n \texpectedFQFN := getDefaultSubscriptionName(tenant, namespace, name)\n \tassert.Equal(t, expectedFQFN, fqfn)\n \n-\tactualtMap := getProperties(fqfn, 100)\n-\tassert.Equal(t, propertiesMap, actualtMap)\n+\tactualMap := getProperties(fqfn, 100)\n+\tassert.Equal(t, propertiesMap, actualMap)\n \n \texpectedRes := getFullyQualifiedInstanceID(tenant, namespace, name, instanceID)\n \tassert.Equal(t, expectedRes, \"pulsar/function/go:100\")\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24117",
    "pr_id": 24117,
    "issue_id": 24094,
    "repo": "apache/pulsar",
    "problem_statement": "Add tests for the dispatcherMaxRoundRobinBatchSize config\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\nThis config limits the max number of entries to dispatch for a `Shared` or `Key_Shared` subscription. However, there is no related test, so a regression could be introduced.\n\nSee https://github.com/apache/pulsar/blob/3e6f7deb0afec2675aac74750f7526557f43c9e7/pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java#L1299\n\nI added a TODO here: https://github.com/apache/pulsar/blob/76e9f9f927e9e21784761ea222cc155f40169c94/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java#L852\n\nIf this line was changed like:\n\n```java\n            int maxEntriesInThisBatch =\n                            // use the average batch size per message to calculate the number of entries to\n                            // dispatch. round up to the next integer without using floating point arithmetic.\n                            (maxMessagesInThisBatch + avgBatchSizePerMsg - 1) / avgBatchSizePerMsg);\n```\n\nno tests will fail. This is dangerous because there is no test that guarantees the config works\n\n### Solution\n\n_No response_\n\n### Alternatives\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 181,
    "test_files_count": 1,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest.java"
    ],
    "base_commit": "d7962a100ad8bfaa5444aaeff465f8c0cc742d32",
    "head_commit": "1274ec380e450cecf029c98aefc98b1bfadf088e",
    "repo_url": "https://github.com/apache/pulsar/pull/24117",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24117",
    "dockerfile": "",
    "pr_merged_at": "2025-03-28T21:19:08.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\nindex 08c79d1daa3c8..d469ce1daa1a8 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\n@@ -437,7 +437,7 @@ public CompletableFuture<Void> doUnsubscribe(Consumer consumer) {\n      *\n      * @param consumer consumer object that is initiating the unsubscribe operation\n      * @param force unsubscribe forcefully by disconnecting consumers and closing subscription\n-     * @return CompletableFuture indicating the completion of ubsubscribe operation\n+     * @return CompletableFuture indicating the completion of unsubscribe operation\n      */\n     @Override\n     public CompletableFuture<Void> doUnsubscribe(Consumer consumer, boolean force) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\nindex 2af04044aae45..c35d802f43d54 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n@@ -834,7 +834,6 @@ protected synchronized boolean trySendMessagesToConsumers(ReadType readType, Lis\n                 lastNumberOfEntriesProcessed = (int) totalEntriesProcessed;\n                 return false;\n             }\n-\n             // round-robin dispatch batch size for this consumer\n             int availablePermits = c.isWritable() ? c.getAvailablePermits() : 1;\n             if (log.isDebugEnabled() && !c.isWritable()) {\n@@ -843,20 +842,10 @@ protected synchronized boolean trySendMessagesToConsumers(ReadType readType, Lis\n                         c, c.getAvailablePermits());\n             }\n \n-            int maxMessagesInThisBatch = Math.min(remainingMessages, availablePermits);\n-            if (c.getMaxUnackedMessages() > 0) {\n-                // Calculate the maximum number of additional unacked messages allowed\n-                int maxAdditionalUnackedMessages = Math.max(c.getMaxUnackedMessages() - c.getUnackedMessages(), 0);\n-                maxMessagesInThisBatch = Math.min(maxMessagesInThisBatch, maxAdditionalUnackedMessages);\n-            }\n-            // TODO: add tests to verify dispatcherMaxRoundRobinBatchSize is respected\n-            int maxEntriesInThisBatch = Math.min(serviceConfig.getDispatcherMaxRoundRobinBatchSize(),\n-                            // use the average batch size per message to calculate the number of entries to\n-                            // dispatch. round up to the next integer without using floating point arithmetic.\n-                            (maxMessagesInThisBatch + avgBatchSizePerMsg - 1) / avgBatchSizePerMsg);\n-            // pick at least one entry to dispatch\n-            maxEntriesInThisBatch = Math.max(maxEntriesInThisBatch, 1);\n-\n+            int maxEntriesInThisBatch = getMaxEntriesInThisBatch(\n+                    remainingMessages, c.getMaxUnackedMessages(), c.getUnackedMessages(), avgBatchSizePerMsg,\n+                    availablePermits, serviceConfig.getDispatcherMaxRoundRobinBatchSize()\n+            );\n             int end = Math.min(start + maxEntriesInThisBatch, entries.size());\n             List<Entry> entriesForThisConsumer = entries.subList(start, end);\n \n@@ -909,6 +898,29 @@ protected synchronized boolean trySendMessagesToConsumers(ReadType readType, Lis\n         return true;\n     }\n \n+\n+    @VisibleForTesting\n+    static int getMaxEntriesInThisBatch(int remainingMessages,\n+                                        int maxUnackedMessages,\n+                                        int unackedMessages,\n+                                        int avgBatchSizePerMsg,\n+                                        int availablePermits,\n+                                        int dispatcherMaxRoundRobinBatchSize) {\n+        int maxMessagesInThisBatch = Math.min(remainingMessages, availablePermits);\n+        if (maxUnackedMessages > 0) {\n+            // Calculate the maximum number of additional unacked messages allowed\n+            int maxAdditionalUnackedMessages = Math.max(maxUnackedMessages - unackedMessages, 0);\n+            maxMessagesInThisBatch = Math.min(maxMessagesInThisBatch, maxAdditionalUnackedMessages);\n+        }\n+        int maxEntriesInThisBatch = Math.min(dispatcherMaxRoundRobinBatchSize,\n+                // use the average batch size per message to calculate the number of entries to\n+                // dispatch. round up to the next integer without using floating point arithmetic.\n+                (maxMessagesInThisBatch + avgBatchSizePerMsg - 1) / avgBatchSizePerMsg);\n+        // pick at least one entry to dispatch\n+        maxEntriesInThisBatch = Math.max(maxEntriesInThisBatch, 1);\n+        return maxEntriesInThisBatch;\n+    }\n+\n     protected boolean addEntryToReplay(Entry entry) {\n         long stickyKeyHash = getStickyKeyHash(entry);\n         boolean addedToReplay = addMessageToReplay(entry.getLedgerId(), entry.getEntryId(), stickyKeyHash);\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest.java\nnew file mode 100644\nindex 0000000000000..f639936799157\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest.java\n@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.service.persistent;\n+\n+import static org.testng.Assert.assertEquals;\n+import org.testng.annotations.Test;\n+\n+@Test(groups = \"broker-api\")\n+public class PersistentDispatcherMultipleConsumerMaxEntriesInBatchTest {\n+\n+    /**\n+     * in this test, remainingMessages > consumer's permits >\n+     * {@link org.apache.pulsar.broker.ServiceConfiguration#getDispatcherMaxRoundRobinBatchSize()}\n+     * so, dispatcherMaxRoundRobinBatchSize's limitation will reach first.\n+     */\n+    @Test\n+    public void testMaxEntriesInBatchWithDispatcherMaxRoundRobinBatchSizeSmallest() {\n+        final int dispatcherMaxRoundRobinBatchSize = 20;\n+        final int remainingMessages = 200;\n+        final int availablePermits = 200;\n+        final int avgBatchSizePerMsg = 5;\n+        final int maxUnackedMessages = 50000;\n+        final int unackedMessages = 0;\n+\n+        for (int i = 1; i < remainingMessages; i++) {\n+            int maxEntriesInThisBatch =\n+                    PersistentDispatcherMultipleConsumers.getMaxEntriesInThisBatch(i, maxUnackedMessages,\n+                            unackedMessages,\n+                            avgBatchSizePerMsg, availablePermits, dispatcherMaxRoundRobinBatchSize);\n+            int entries = i / avgBatchSizePerMsg;\n+            // if entries < dispatcherMaxRoundRobinBatchSize,  maxEntriesInThisBatch will be entries itself.\n+            if (entries < dispatcherMaxRoundRobinBatchSize) {\n+                assertEquals(maxEntriesInThisBatch,\n+                        i % avgBatchSizePerMsg == 0 ? entries : entries + 1);\n+            } else {\n+                // as entries getting bigger, will reach the dispatcherMaxRoundRobinBatchSize limitation, so maxEntriesInThisBatch will be dispatcherMaxRoundRobinBatchSize\n+                assertEquals(maxEntriesInThisBatch, dispatcherMaxRoundRobinBatchSize);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * in this test, remainingMessages >\n+     * {@link org.apache.pulsar.broker.ServiceConfiguration#getDispatcherMaxRoundRobinBatchSize()} > consumer' permits.\n+     * so, consumer's permits limitation will reach first.\n+     */\n+    @Test\n+    public void testMaxEntriesInBatchWithMessageRangeAndSmallestQueueSize() {\n+        final int dispatcherMaxRoundRobinBatchSize = 20;\n+        final int remainingMessages = 200;\n+        final int availablePermits = 75;\n+        final int avgBatchSizePerMsg = 5;\n+        final int maxUnackedMessages = 50000;\n+        final int unackedMessages = 0;\n+\n+        for (int i = 1; i < remainingMessages; i++) {\n+            int maxEntriesInThisBatch =\n+                    PersistentDispatcherMultipleConsumers.getMaxEntriesInThisBatch(i, maxUnackedMessages,\n+                            unackedMessages,\n+                            avgBatchSizePerMsg, availablePermits, dispatcherMaxRoundRobinBatchSize);\n+            // if remainingMessages less than availablePermits, maxEntriesInThisBatch will be entries itself.\n+            if (i < availablePermits) {\n+                int entries = i / avgBatchSizePerMsg;\n+                assertEquals(maxEntriesInThisBatch,\n+                        i % avgBatchSizePerMsg == 0 ? entries : entries + 1);\n+            } else {\n+                // as entries getting bigger, will reach the consumer's permits limitation, so maxEntriesInThisBatch will be (availablePermits / avgBatchSizePerMsg)\n+                assertEquals(maxEntriesInThisBatch,\n+                        availablePermits % avgBatchSizePerMsg == 0 ? availablePermits / avgBatchSizePerMsg :\n+                                availablePermits / avgBatchSizePerMsg + 1);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * in this test, entry size >\n+     * {@link org.apache.pulsar.broker.ServiceConfiguration#getDispatcherMaxRoundRobinBatchSize()} > consumer' permits >\n+     * unAckedMessages\n+     * so, unAckedMessages limitation will reach first.\n+     */\n+    @Test\n+    public void testMaxEntriesInBatchWithUnackedMessagesLimitation() {\n+        final int dispatcherMaxRoundRobinBatchSize = 20;\n+        final int remainingMessages = 200;\n+        final int availablePermits = 75;\n+        final int avgBatchSizePerMsg = 5;\n+        final int maxUnackedMessages = 500;\n+        final int unackedMessages = 480;\n+\n+        for (int i = 1; i < remainingMessages; i++) {\n+            int maxEntriesInThisBatch =\n+                    PersistentDispatcherMultipleConsumers.getMaxEntriesInThisBatch(i, maxUnackedMessages,\n+                            unackedMessages,\n+                            avgBatchSizePerMsg, availablePermits, dispatcherMaxRoundRobinBatchSize);\n+            // if remainingMessages less than maxAdditionalUnackedMessages, maxEntriesInThisBatch will be entries itself.\n+            int maxAdditionalUnackedMessages = maxUnackedMessages - unackedMessages;\n+\n+            if (i < maxAdditionalUnackedMessages) {\n+                int entries = i / avgBatchSizePerMsg;\n+                assertEquals(maxEntriesInThisBatch,\n+                        i % avgBatchSizePerMsg == 0 ? entries : entries + 1);\n+            } else {\n+                // as entries getting bigger, will reach the unAckedMessages limitation, so maxEntriesInThisBatch will be (maxAdditionalUnackedMessages / avgBatchSizePerMsg)\n+                assertEquals(maxEntriesInThisBatch, maxAdditionalUnackedMessages / avgBatchSizePerMsg);\n+            }\n+        }\n+    }\n+}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24092",
    "pr_id": 24092,
    "issue_id": 23825,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BatchMessageTest.testBatchMessageDispatchingAccordingToPermits\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n### Example failures\r\n\r\n- [2025-01-07T10:46:47.4307801Z](https://github.com/apache/pulsar/actions/runs/12635032254/job/35247450509#step:11:1178) \r\n- [2025-01-03T19:03:01.9270671Z](https://github.com/apache/pulsar/actions/runs/12602408785/job/35125717078#step:11:1222) \r\n\r\n\r\n### Exception stacktrace\r\n\r\n```\r\njava.lang.AssertionError: expected [10.0] but found [100.0]\r\n\tat org.testng.Assert.fail(Assert.java:110)\r\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n\tat org.testng.Assert.assertEquals(Assert.java:836)\r\n\tat org.testng.Assert.assertEquals(Assert.java:849)\r\n\tat org.apache.pulsar.broker.service.BatchMessageTest.testBatchMessageDispatchingAccordingToPermits(BatchMessageTest.java:1016)\r\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!\r\n",
    "issue_word_count": 238,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java"
    ],
    "base_commit": "3e6f7deb0afec2675aac74750f7526557f43c9e7",
    "head_commit": "0a960a2d733e8bfb717770a608c3d7628b7a7b59",
    "repo_url": "https://github.com/apache/pulsar/pull/24092",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24092",
    "dockerfile": "",
    "pr_merged_at": "2025-03-19T07:58:06.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\nindex 6f3fe19f0a104..2af04044aae45 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n@@ -843,14 +843,14 @@ protected synchronized boolean trySendMessagesToConsumers(ReadType readType, Lis\n                         c, c.getAvailablePermits());\n             }\n \n-            int maxMessagesInThisBatch =\n-                    Math.max(remainingMessages, serviceConfig.getDispatcherMaxRoundRobinBatchSize());\n+            int maxMessagesInThisBatch = Math.min(remainingMessages, availablePermits);\n             if (c.getMaxUnackedMessages() > 0) {\n                 // Calculate the maximum number of additional unacked messages allowed\n                 int maxAdditionalUnackedMessages = Math.max(c.getMaxUnackedMessages() - c.getUnackedMessages(), 0);\n                 maxMessagesInThisBatch = Math.min(maxMessagesInThisBatch, maxAdditionalUnackedMessages);\n             }\n-            int maxEntriesInThisBatch = Math.min(availablePermits,\n+            // TODO: add tests to verify dispatcherMaxRoundRobinBatchSize is respected\n+            int maxEntriesInThisBatch = Math.min(serviceConfig.getDispatcherMaxRoundRobinBatchSize(),\n                             // use the average batch size per message to calculate the number of entries to\n                             // dispatch. round up to the next integer without using floating point arithmetic.\n                             (maxMessagesInThisBatch + avgBatchSizePerMsg - 1) / avgBatchSizePerMsg);\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\nindex e5f9e43b8bb4a..b821c0cc66351 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\n@@ -1012,6 +1012,10 @@ public void testBatchMessageDispatchingAccordingToPermits() throws Exception {\n         }\n         FutureUtil.waitForAll(sendFutureList).get();\n \n+        Awaitility.await().atMost(3, TimeUnit.SECONDS).untilAsserted(() -> {\n+            assertTrue(consumer1.numMessagesInQueue() > 0);\n+            assertTrue(consumer2.numMessagesInQueue() > 0);\n+        });\n         assertEquals(consumer1.numMessagesInQueue(), batchMessages, batchMessages);\n         assertEquals(consumer2.numMessagesInQueue(), batchMessages, batchMessages);\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24059",
    "pr_id": 24059,
    "issue_id": 24053,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] message eventtime is reset to 0 on reconsumeLater\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nOS - macOS Sequoia 15.3.1\nJava - 21\nPulsar client - 4.0.2\nPulsar broker - 4.0.2\n\n\n### Minimal reproduce step\n\npublish a message to a topic with eventTime set to some value, e.g., current epoch seconds. \nOn consumption, call reconsumeLater method. \nOn reconsumption, log message.getEventTime.\n\n### What did you expect to see?\n\nmessage.getEventTime should return the original eventTime set during publish\n\n### What did you see instead?\n\n0\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 149,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/TypedMessageBuilderImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java"
    ],
    "base_commit": "0cc266d54d69205c78dc1bcf03f0b608c20fb62b",
    "head_commit": "f28094f7b5693190f45dcbd45af61c108bdcb6d2",
    "repo_url": "https://github.com/apache/pulsar/pull/24059",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24059",
    "dockerfile": "",
    "pr_merged_at": "2025-03-05T19:26:16.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\nindex 4691c402b2fef..26414583b90a4 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n@@ -717,6 +717,7 @@ protected CompletableFuture<Void> doReconsumeLater(Message<?> message, AckType a\n                                             .value(retryMessage.getData())\n                                             .properties(propertiesMap);\n                             copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                            copyMessageEventTime(message, typedMessageBuilderNew);\n                             typedMessageBuilderNew.sendAsync().thenAccept(msgId -> {\n                                 consumerDlqMessagesCounter.increment();\n \n@@ -749,6 +750,7 @@ protected CompletableFuture<Void> doReconsumeLater(Message<?> message, AckType a\n                                 typedMessageBuilderNew.deliverAfter(delayTime, unit);\n                             }\n                             copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                            copyMessageEventTime(message, typedMessageBuilderNew);\n                             typedMessageBuilderNew.sendAsync()\n                                     .thenCompose(\n                                             __ -> doAcknowledge(finalMessageId, ackType, Collections.emptyMap(), null))\n@@ -824,6 +826,11 @@ private MessageImpl<?> getMessageImpl(Message<?> message) {\n         return null;\n     }\n \n+    private static void copyMessageEventTime(Message<?> message,\n+                                             TypedMessageBuilder<byte[]> typedMessageBuilderNew) {\n+        typedMessageBuilderNew.eventTime(message.getEventTime());\n+    }\n+\n     @Override\n     public void negativeAcknowledge(MessageId messageId) {\n         consumerNacksCounter.increment();\n@@ -2242,6 +2249,7 @@ private CompletableFuture<Boolean> processPossibleToDLQ(MessageIdAdv messageId)\n                                         .value(message.getData())\n                                         .properties(getPropertiesMap(message, originMessageIdStr, originTopicNameStr));\n                         copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                        copyMessageEventTime(message, typedMessageBuilderNew);\n                         typedMessageBuilderNew.sendAsync()\n                                 .thenAccept(messageIdInDLQ -> {\n                                     possibleSendToDeadLetterTopicMessages.remove(messageId);\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TypedMessageBuilderImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TypedMessageBuilderImpl.java\nindex d90c2e8828364..8ef9079091aa2 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TypedMessageBuilderImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TypedMessageBuilderImpl.java\n@@ -186,7 +186,6 @@ public TypedMessageBuilder<T> properties(Map<String, String> properties) {\n \n     @Override\n     public TypedMessageBuilder<T> eventTime(long timestamp) {\n-        checkArgument(timestamp > 0, \"Invalid timestamp : '%s'\", timestamp);\n         msgMetadata.setEventTime(timestamp);\n         return this;\n     }\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\nindex ab26949c04fc6..f624b0105341b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n@@ -25,6 +25,7 @@\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n import java.time.Duration;\n+import java.time.Instant;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -261,6 +262,67 @@ public void testDeadLetterTopicMessagesWithOrderingKey() throws Exception {\n         consumer.close();\n     }\n \n+    @Test\n+    public void testDeadLetterTopicMessagesWithEventTime() throws Exception {\n+        final String topic = \"persistent://my-property/my-ns/dead-letter-topic\";\n+\n+        final int maxRedeliveryCount = 1;\n+\n+        final int sendMessages = 100;\n+\n+        Consumer<byte[]> consumer = pulsarClient.newConsumer(Schema.BYTES)\n+                .topic(topic)\n+                .subscriptionName(\"my-subscription\")\n+                .subscriptionType(SubscriptionType.Shared)\n+                .ackTimeout(1, TimeUnit.SECONDS)\n+                .deadLetterPolicy(DeadLetterPolicy.builder().maxRedeliverCount(maxRedeliveryCount).build())\n+                .receiverQueueSize(100)\n+                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n+                .subscribe();\n+\n+        @Cleanup\n+        PulsarClient newPulsarClient = newPulsarClient(lookupUrl.toString(), 0);// Creates new client connection\n+        Consumer<byte[]> deadLetterConsumer = newPulsarClient.newConsumer(Schema.BYTES)\n+                .topic(\"persistent://my-property/my-ns/dead-letter-topic-my-subscription-DLQ\")\n+                .subscriptionName(\"my-subscription\")\n+                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n+                .subscribe();\n+\n+        Producer<byte[]> producer = pulsarClient.newProducer(Schema.BYTES)\n+                .topic(topic)\n+                .create();\n+\n+        long testEventTime = Instant.now().toEpochMilli();\n+        for (int i = 0; i < sendMessages; i++) {\n+            producer.newMessage()\n+                    .eventTime(testEventTime)\n+                    .value(String.format(\"Hello Pulsar, eventTime: [%d]\", testEventTime).getBytes())\n+                    .send();\n+        }\n+\n+        producer.close();\n+\n+        int totalReceived = 0;\n+        do {\n+            Message<byte[]> message = consumer.receive();\n+            log.info(\"consumer received message : {} {}\", message.getMessageId(),\n+                    new String(message.getData()));\n+            totalReceived++;\n+        } while (totalReceived < sendMessages * (maxRedeliveryCount + 1));\n+\n+        int totalInDeadLetter = 0;\n+        do {\n+            Message<byte[]> message = deadLetterConsumer.receive();\n+            assertEquals(message.getEventTime(), testEventTime);\n+            log.info(\"dead letter consumer received message : {} {}\", message.getMessageId(), new String(message.getData()));\n+            deadLetterConsumer.acknowledge(message);\n+            totalInDeadLetter++;\n+        } while (totalInDeadLetter < sendMessages);\n+\n+        deadLetterConsumer.close();\n+        consumer.close();\n+    }\n+\n     public void testDeadLetterTopicWithProducerName() throws Exception {\n         final String topic = \"persistent://my-property/my-ns/dead-letter-topic\";\n         final String subscription = \"my-subscription\";\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\nindex 2b897760b6f00..8cb595a685408 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\n@@ -24,6 +24,7 @@\n import static org.testng.Assert.assertNull;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n+import java.time.Instant;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n@@ -300,6 +301,7 @@ public void testRetryTopicProperties() throws Exception {\n \n         byte[] key = \"key\".getBytes();\n         byte[] orderingKey = \"orderingKey\".getBytes();\n+        long eventTime = Instant.now().toEpochMilli();\n \n         final int maxRedeliveryCount = 3;\n \n@@ -333,6 +335,7 @@ public void testRetryTopicProperties() throws Exception {\n                     .value(String.format(\"Hello Pulsar [%d]\", i).getBytes())\n                     .keyBytes(key)\n                     .orderingKey(orderingKey)\n+                    .eventTime(eventTime)\n                     .send();\n             originMessageIds.add(msgId.toString());\n         }\n@@ -350,6 +353,7 @@ public void testRetryTopicProperties() throws Exception {\n                 assertEquals(message.getKeyBytes(), key);\n                 assertTrue(message.hasOrderingKey());\n                 assertEquals(message.getOrderingKey(), orderingKey);\n+                assertEquals(message.getEventTime(), eventTime);\n                 retryMessageIds.add(message.getProperty(RetryMessageUtil.SYSTEM_PROPERTY_ORIGIN_MESSAGE_ID));\n             }\n             consumer.reconsumeLater(message, 1, TimeUnit.SECONDS);\n@@ -373,6 +377,7 @@ public void testRetryTopicProperties() throws Exception {\n                 assertEquals(message.getKeyBytes(), key);\n                 assertTrue(message.hasOrderingKey());\n                 assertEquals(message.getOrderingKey(), orderingKey);\n+                assertEquals(message.getEventTime(), eventTime);\n                 deadLetterMessageIds.add(message.getProperty(RetryMessageUtil.SYSTEM_PROPERTY_ORIGIN_MESSAGE_ID));\n             }\n             deadLetterConsumer.acknowledge(message);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24048",
    "pr_id": 24048,
    "issue_id": 24043,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Getting UnsupportedOperationException while setting subscription level dispatch rate policy\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nPulsar Version: 3.0.7\n\n\n### Minimal reproduce step\n\nNote: The issue is coming intermittently \n1. Create a topic and subscription or use an existing topic/subscription\n2. Set dispatch rate policy at subscription level using below command\n3.`bin\\pulsar-admin topicPolicies set-subscription-dispatch-rate  -bd 34323 -s <<subname>> <<topicfqn>>`\n\n\n### What did you expect to see?\n\nThe subscription dispatch rate should get set with 200 response. \n\n### What did you see instead?\n\nGetting below exception\n\n```\nMessage: null\n\nStacktrace:\n\n**java.lang.UnsupportedOperationException**\n        at java.base/java.util.Collections$EmptyMap.**computeIfAbsent**(Collections.java:4764)\n        at org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.lambda$**internalSetSubscriptionLevelDispatchRate**$487(PersistentTopicsBase.java:4960)\n        at java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1150)\n        at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n        at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\n        at org.apache.pulsar.client.util.RetryUtil.lambda$executeWithRetry$2(RetryUtil.java:62)\n        at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n        at java.base/java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:887)\n        at java.base/java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2325)\n        at org.apache.pulsar.client.util.RetryUtil.executeWithRetry(RetryUtil.java:48)\n        at org.apache.pulsar.client.util.RetryUtil.lambda$retryAsynchronously$0(RetryUtil.java:42)\n        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n        at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n        at java.base/java.lang.Thread.run(Thread.java:840)\n```\n\n\n### Anything else?\n\nThe error is coming when  `subscriptionPolicies` is null; it's returning `Collections.emptyMap()` which is immutable, and `internalSetSubscriptionLevelDispatchRate` is trying to add the element in that map.\nFix would be instead of returning an immutable map, it should be a mutable map. \nRef: https://github.com/apache/pulsar/blob/master/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java#L4778\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 430,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/policies/data/TopicPolicies.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java"
    ],
    "base_commit": "c75018a6db712493de33664d78ced31f4e0e7094",
    "head_commit": "1dec51beb57acb93ef791c3d93a9ee5d9384b777",
    "repo_url": "https://github.com/apache/pulsar/pull/24048",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24048",
    "dockerfile": "",
    "pr_merged_at": "2025-03-17T07:07:10.000Z",
    "patch": "diff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/policies/data/TopicPolicies.java b/pulsar-common/src/main/java/org/apache/pulsar/common/policies/data/TopicPolicies.java\nindex 5403b84a4f7b8..5aa62509746a5 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/policies/data/TopicPolicies.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/policies/data/TopicPolicies.java\n@@ -19,12 +19,13 @@\n package org.apache.pulsar.common.policies.data;\n \n import com.google.common.collect.Sets;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n import java.util.ArrayList;\n-import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n import lombok.AllArgsConstructor;\n import lombok.Builder;\n import lombok.Data;\n@@ -42,6 +43,7 @@\n @Builder\n @NoArgsConstructor\n @AllArgsConstructor\n+@SuppressFBWarnings(value = \"RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE\")\n public class TopicPolicies {\n \n     @Builder.Default\n@@ -193,6 +195,9 @@ public Set<String> getReplicationClustersSet() {\n     }\n \n     public Map<String, SubscriptionPolicies> getSubscriptionPolicies() {\n-        return subscriptionPolicies == null ? Collections.emptyMap() : subscriptionPolicies;\n+        if (subscriptionPolicies == null) {\n+            subscriptionPolicies = new ConcurrentHashMap<>();\n+        }\n+        return subscriptionPolicies;\n     }\n }\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\nindex c6a78d275dd27..3419a4b161e92 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\n@@ -86,9 +86,11 @@\n import org.apache.pulsar.common.policies.data.PublishRate;\n import org.apache.pulsar.common.policies.data.RetentionPolicies;\n import org.apache.pulsar.common.policies.data.SubscribeRate;\n+import org.apache.pulsar.common.policies.data.SubscriptionPolicies;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.policies.data.TopicPolicies;\n import org.apache.pulsar.common.policies.data.TopicStats;\n+import org.apache.pulsar.common.policies.data.impl.DispatchRateImpl;\n import org.assertj.core.api.Assertions;\n import org.awaitility.Awaitility;\n import org.mockito.Mockito;\n@@ -3215,7 +3217,7 @@ public void testDelayedDeliveryPolicy() throws Exception {\n \n         admin.topics().delete(topic, true);\n     }\n-    \n+\n     @Test\n     public void testUpdateRetentionWithPartialFailure() throws Exception {\n         String tpName = BrokerTestUtil.newUniqueName(\"persistent://\" + myNamespace + \"/tp\");\n@@ -3259,4 +3261,40 @@ public void testUpdateRetentionWithPartialFailure() throws Exception {\n         admin.namespaces().removeRetention(myNamespace);\n         admin.topics().delete(tpName, false);\n     }\n+\n+    @Test\n+    public void testTopicPoliciesGetSubscriptionPolicies() throws Exception {\n+        TopicPolicies topicPolicies = TopicPolicies.builder()\n+                .maxProducerPerTopic(10).subscriptionPolicies(null).build();\n+        Assert.assertNotNull(topicPolicies.getSubscriptionPolicies());\n+        Assert.assertEquals(topicPolicies.getMaxProducerPerTopic(), 10);\n+        Assert.assertTrue(topicPolicies.getSubscriptionPolicies().isEmpty());\n+        topicPolicies.getSubscriptionPolicies().computeIfAbsent(\"sub\", k ->\n+                new SubscriptionPolicies()).setDispatchRate(new DispatchRateImpl());\n+        Assert.assertEquals(topicPolicies.getSubscriptionPolicies().get(\"sub\").getDispatchRate()\n+                .getDispatchThrottlingRateInByte(), 0);\n+    }\n+\n+    @Test\n+    public void testSetSubRateWithNoSub() throws Exception {\n+        String topic = \"persistent://\" + myNamespace + \"/testSetSubRateWithNoSub\";\n+        admin.topics().createNonPartitionedTopic(topic);\n+        admin.topicPolicies().setSubscriptionDispatchRate(topic, DispatchRate.builder()\n+                .dispatchThrottlingRateInMsg(10)\n+                .dispatchThrottlingRateInByte(10)\n+                .ratePeriodInSecond(10)\n+                .build());\n+    }\n+\n+    @Test\n+    public void testSetSubRateWithSub() throws Exception {\n+        String topic = \"persistent://\" + myNamespace + \"/testSetSubRateWithSub\";\n+        admin.topics().createNonPartitionedTopic(topic);\n+        admin.topics().createSubscription(topic, \"sub1\", MessageId.earliest);\n+        admin.topicPolicies().setSubscriptionDispatchRate(topic, \"sub1\", DispatchRate.builder()\n+                .dispatchThrottlingRateInMsg(10)\n+                .dispatchThrottlingRateInByte(10)\n+                .ratePeriodInSecond(10)\n+                .build());\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-24042",
    "pr_id": 24042,
    "issue_id": 24041,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: PrometheusMetricsTest.testBrokerMetrics\n\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n### Example failures\n\n- [2025-01-17T12:27:55.6479535Z](https://github.com/apache/pulsar/actions/runs/12828782765/job/35774002940#step:11:1140) \n\n\n### Exception stacktrace\n\n```\njava.lang.AssertionError: expected [195.0] but found [0.0]\n\tat org.testng.Assert.fail(Assert.java:110)\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\n\tat org.testng.Assert.assertEquals(Assert.java:727)\n\tat org.testng.Assert.assertEquals(Assert.java:774)\n\tat org.apache.pulsar.broker.stats.PrometheusMetricsTest.testBrokerMetrics(PrometheusMetricsTest.java:315)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\n```\n\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!\n",
    "issue_word_count": 220,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java"
    ],
    "base_commit": "966a396007aba232357170954fb866e50169bdd6",
    "head_commit": "3aac8f4d29988e2955dec3bb7d5abc14275a9ff5",
    "repo_url": "https://github.com/apache/pulsar/pull/24042",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/24042",
    "dockerfile": "",
    "pr_merged_at": "2025-03-14T07:22:16.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\nindex fa073d3694b26..ea2023e01c2e7 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\n@@ -306,8 +306,7 @@ public void testBrokerMetrics() throws Exception {\n \n         double systemCursorOutBytes = 0.0;\n         for (Metric metric : topicLevelBytesOutTotal) {\n-            if (metric.tags.get(\"subscription\").startsWith(SystemTopicNames.SYSTEM_READER_PREFIX)\n-                    || metric.tags.get(\"subscription\").equals(Compactor.COMPACTION_SUBSCRIPTION)) {\n+            if (metric.tags.get(\"subscription\").startsWith(SystemTopicNames.SYSTEM_READER_PREFIX)) {\n                 systemCursorOutBytes = metric.value;\n             }\n         }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23986",
    "pr_id": 23986,
    "issue_id": 23885,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: NegativeAcksTest.testNegativeAcksWithBackoff\n\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n### Example failures\n\n- [2025-01-21T06:22:11.8350781Z](https://github.com/apache/pulsar/actions/runs/12881023585/job/35911260374#step:10:690) \n\n\n### Exception stacktrace\n\n```\njava.lang.AssertionError: expected [null] but found [org.apache.pulsar.client.impl.MessageImpl@6c98609e]\n\tat org.testng.Assert.fail(Assert.java:110)\n\tat org.testng.Assert.failNotSame(Assert.java:1573)\n\tat org.testng.Assert.assertNull(Assert.java:1506)\n\tat org.testng.Assert.assertNull(Assert.java:1494)\n\tat org.apache.pulsar.client.impl.NegativeAcksTest.testNegativeAcksWithBackoff(NegativeAcksTest.java:285)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!\n",
    "issue_word_count": 244,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java"
    ],
    "base_commit": "eb1391a199d2c85f1ad7ce22a4d3eefa78d2fed3",
    "head_commit": "4ab5cc3241e0e569b848a150e1a2cdae8273b796",
    "repo_url": "https://github.com/apache/pulsar/pull/23986",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23986",
    "dockerfile": "",
    "pr_merged_at": "2025-02-14T11:18:07.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java\nindex 7ab3e545e981e..182c952eac82d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/NegativeAcksTest.java\n@@ -256,9 +256,16 @@ public void testNegativeAcksWithBackoff(boolean batching, boolean usePartitions,\n         long firstReceivedAt = System.currentTimeMillis();\n         long expectedTotalRedeliveryDelay = 0;\n         for (int i = 0; i < redeliverCount; i++) {\n+            Message<String> msg = null;\n             for (int j = 0; j < N; j++) {\n-                Message<String> msg = consumer.receive();\n+                msg = consumer.receive();\n                 log.info(\"Received message {}\", msg.getValue());\n+                if (!batching) {\n+                    consumer.negativeAcknowledge(msg);\n+                }\n+            }\n+            if (batching) {\n+                // for batching, we only need to nack one message in the batch to trigger redelivery\n                 consumer.negativeAcknowledge(msg);\n             }\n             expectedTotalRedeliveryDelay += backoff.next(i);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23984",
    "pr_id": 23984,
    "issue_id": 23889,
    "repo": "apache/pulsar",
    "problem_statement": "Metadata information is not cleaned when broker exits abnormally\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\nWhen a broker starts, it registers its metadata with the metadata service (such as Zookeeper or ETCD) under the `/loadbalance/brokers` directory.  When the broker exits gracefully, it actively calls the unregister method to remove its own metadata.\nhttps://github.com/apache/pulsar/blob/66d1bb0d734f12d758b0f0e9e3c0b42543508f8d/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java#L134-L143\n\nhttps://github.com/apache/pulsar/blob/66d1bb0d734f12d758b0f0e9e3c0b42543508f8d/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java#L172-L178\n\nHowever, if the broker is forced to exit due to issues like hardware failure, network problems, or being terminated with `kill -9`, it does not call the unregister method to delete its metadata.  This results in the metadata for brokers that are no longer accessible remaining in the system.\n\nCurrently, Pulsar retrieves all active brokers by fetching all child nodes under the metadata service's `/loadbalance/brokers` path.  This can lead to offline brokers being considered active, and bundles may be assigned to brokers that are not accessible, causing new namespace clients to experience read and write failures.\nhttps://github.com/apache/pulsar/blob/66d1bb0d734f12d758b0f0e9e3c0b42543508f8d/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java#L197-L201\n\n\n### Solution\n\nI am not yet certain how to resolve this issue. I am currently reviewing the relevant code and drafting a solution document. If you have any suggestions, please feel free to leave a comment.\n\n### Alternatives\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 288,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-metadata/src/main/java/org/apache/pulsar/metadata/impl/ZKMetadataStore.java",
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java"
    ],
    "base_commit": "d3ea0ee8515949808f2067c3cc2874ac379b5f28",
    "head_commit": "4255386c1e004b26a052ae1b2cf1100e33c9d460",
    "repo_url": "https://github.com/apache/pulsar/pull/23984",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23984",
    "dockerfile": "",
    "pr_merged_at": "2025-02-14T10:52:13.000Z",
    "patch": "diff --git a/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/impl/ZKMetadataStore.java b/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/impl/ZKMetadataStore.java\nindex 4c24aa5938b93..8fd8252152898 100644\n--- a/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/impl/ZKMetadataStore.java\n+++ b/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/impl/ZKMetadataStore.java\n@@ -439,8 +439,8 @@ private void internalStorePut(OpPut opPut) {\n                                 future.completeExceptionally(getException(Code.BADVERSION, opPut.getPath()));\n                             } else {\n                                 // The z-node does not exist, let's create it first\n-                                put(opPut.getPath(), opPut.getData(), Optional.of(-1L)).thenAccept(\n-                                                s -> future.complete(s))\n+                                put(opPut.getPath(), opPut.getData(), Optional.of(-1L), opPut.getOptions())\n+                                        .thenAccept(s -> future.complete(s))\n                                         .exceptionally(ex -> {\n                                             if (ex.getCause() instanceof BadVersionException) {\n                                                 // The z-node exist now, let's overwrite it\n",
    "test_patch": "diff --git a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java\nindex 9a38cdbcd2f85..a4c937611fd3f 100644\n--- a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java\n+++ b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/MetadataStoreExtendedTest.java\n@@ -66,4 +66,38 @@ public void sequentialKeys(String provider, Supplier<String> urlSupplier) throws\n         assertNotEquals(seq1, seq2);\n         assertTrue(n1 < n2);\n     }\n+\n+    @Test(dataProvider = \"impl\")\n+    public void testPersistentOrEphemeralPut(String provider, Supplier<String> urlSupplier) throws Exception {\n+        final String key1 = newKey();\n+        MetadataStoreExtended store = MetadataStoreExtended.create(urlSupplier.get(), MetadataStoreConfig.builder().build());\n+        store.put(key1, \"value-1\".getBytes(), Optional.empty(), EnumSet.noneOf(CreateOption.class)).join();\n+        var value = store.get(key1).join().get();\n+        assertEquals(value.getValue(), \"value-1\".getBytes());\n+        // assertFalse(value.getStat().isEphemeral()); // Todo : fix zkStat.getEphemeralOwner() != 0 from test zk\n+        assertTrue(value.getStat().isFirstVersion());\n+        var version = value.getStat().getVersion();\n+\n+        store.put(key1, \"value-2\".getBytes(), Optional.empty(), EnumSet.noneOf(CreateOption.class)).join();\n+        value = store.get(key1).join().get();\n+        assertEquals(value.getValue(), \"value-2\".getBytes());\n+       //assertFalse(value.getStat().isEphemeral());  // Todo : fix zkStat.getEphemeralOwner() != 0 from test zk\n+        assertEquals(value.getStat().getVersion(), version + 1);\n+\n+        final String key2 = newKey();\n+        store.put(key2, \"value-4\".getBytes(), Optional.empty(), EnumSet.of(CreateOption.Ephemeral)).join();\n+        value = store.get(key2).join().get();\n+        assertEquals(value.getValue(), \"value-4\".getBytes());\n+        assertTrue(value.getStat().isEphemeral());\n+        assertTrue(value.getStat().isFirstVersion());\n+        version = value.getStat().getVersion();\n+\n+\n+        store.put(key2, \"value-5\".getBytes(), Optional.empty(), EnumSet.of(CreateOption.Ephemeral)).join();\n+        value = store.get(key2).join().get();\n+        assertEquals(value.getValue(), \"value-5\".getBytes());\n+        assertTrue(value.getStat().isEphemeral());\n+        assertEquals(value.getStat().getVersion(), version + 1);\n+    }\n+\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23981",
    "pr_id": 23981,
    "issue_id": 23963,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Pulsar Proxy Keep-Alive Interval is Hardcoded to 30s and Cannot Be Configured\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\napachepulsar/pulsar-all:3.0.2\n\n### Minimal reproduce step\n\n- Start a connection to the Pulsar Broker through Pulsar Proxy.\n- Observe the debug logskeep-alive is scheduled every 30 seconds, regardless of configuration settings.\n\n### What did you expect to see?\n\nI expected the keep-alive interval for connections in Pulsar Proxy to be configurable through proxy.conf like as described [here](https://pulsar.apache.org/reference/#/3.0.x/config/reference-configuration-broker?id=keepaliveintervalseconds)\n\n### What did you see instead?\n\nThe keep-alive interval is hardcoded to 30 seconds, with no way to modify it. The logs confirm this behavior:\n\n```\n2025-02-11T09:18:20,392+0000 [pulsar-proxy-io-2-8] DEBUG org.apache.pulsar.common.protocol.PulsarHandler - [[id: 0x4bf907e2, L:/xxx:6651 - R:/xxx:60882]] Scheduling keep-alive task every 30 s\n```\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 217,
    "test_files_count": 6,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "conf/proxy.conf",
      "pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConfiguration.java",
      "pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConnection.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java",
      "pulsar-proxy/src/test/resources/proxy.conf"
    ],
    "pr_changed_test_files": [
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java",
      "pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java",
      "pulsar-proxy/src/test/resources/proxy.conf"
    ],
    "base_commit": "ee5b13af5cf229c2e4846c6d34ebda59eb82330a",
    "head_commit": "86796836afcd8b89522a48a042ccfc9e36ed33a3",
    "repo_url": "https://github.com/apache/pulsar/pull/23981",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23981",
    "dockerfile": "",
    "pr_merged_at": "2025-02-14T06:56:41.000Z",
    "patch": "diff --git a/conf/proxy.conf b/conf/proxy.conf\nindex 6e6c960e8009e..cda1034d65392 100644\n--- a/conf/proxy.conf\n+++ b/conf/proxy.conf\n@@ -59,6 +59,13 @@ bindAddress=0.0.0.0\n # If not set, the value of `InetAddress.getLocalHost().getCanonicalHostName()` is used.\n advertisedAddress=\n \n+# Specifies the interval (in seconds) for sending ping messages to the client. Set to 0 to disable\n+# ping messages. This setting applies to client connections used for topic lookups and\n+# partition metadata requests. When a client establishes a broker connection via the proxy,\n+# the client and broker will communicate directly without the proxy intercepting the messages.\n+# In that case, the broker's keepAliveIntervalSeconds configuration becomes relevant.\n+keepAliveIntervalSeconds=30\n+\n # Enable or disable the HAProxy protocol.\n # If true, the real IP addresses of consumers and producers can be obtained when getting topic statistics data.\n haProxyProtocolEnabled=false\n\ndiff --git a/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConfiguration.java b/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConfiguration.java\nindex b9360e403f6f4..4734485a62bea 100644\n--- a/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConfiguration.java\n+++ b/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConfiguration.java\n@@ -266,6 +266,15 @@ public class ProxyConfiguration implements PulsarConfiguration {\n     )\n     private String advertisedAddress;\n \n+    @FieldContext(\n+            category = CATEGORY_SERVER,\n+            doc = \"Specifies the interval (in seconds) for sending ping messages to the client. Set to 0 to disable \"\n+                    + \"ping messages. This setting applies to client connections used for topic lookups and \"\n+                    + \"partition metadata requests. When a client establishes a broker connection via the proxy, \"\n+                    + \"the client and broker will communicate directly without the proxy intercepting the messages. \"\n+                    + \"In that case, the broker's keepAliveIntervalSeconds configuration becomes relevant.\")\n+    private int keepAliveIntervalSeconds = 30;\n+\n     @FieldContext(category = CATEGORY_SERVER,\n             doc = \"Enable or disable the proxy protocol.\")\n     private boolean haProxyProtocolEnabled;\n\ndiff --git a/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConnection.java b/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConnection.java\nindex f8b5d0844509e..540771c86fbe4 100644\n--- a/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConnection.java\n+++ b/pulsar-proxy/src/main/java/org/apache/pulsar/proxy/server/ProxyConnection.java\n@@ -155,7 +155,7 @@ ConnectionPool getConnectionPool() {\n     }\n \n     public ProxyConnection(ProxyService proxyService, DnsAddressResolverGroup dnsAddressResolverGroup) {\n-        super(30, TimeUnit.SECONDS);\n+        super(proxyService.getConfiguration().getKeepAliveIntervalSeconds(), TimeUnit.SECONDS);\n         this.service = proxyService;\n         this.dnsAddressResolverGroup = dnsAddressResolverGroup;\n         this.state = State.Init;\n",
    "test_patch": "diff --git a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java\nindex a9a562e04c899..18e7efbd7b5c6 100644\n--- a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java\n+++ b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyConfigurationTest.java\n@@ -147,7 +147,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerServiceURL must start with pulsar://\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"brokerServiceURL must start with pulsar://\"));\n@@ -161,7 +161,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerServiceURLTLS must start with pulsar+ssl://\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"brokerServiceURLTLS must start with pulsar+ssl://\"));\n@@ -174,7 +174,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerServiceURL does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n@@ -188,7 +188,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerServiceURLTLS does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n@@ -202,7 +202,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerWebServiceURL does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n@@ -216,7 +216,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"brokerWebServiceURLTLS does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n@@ -230,7 +230,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"functionWorkerWebServiceURL does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n@@ -244,7 +244,7 @@ public void testBrokerUrlCheck() throws IOException {\n             theMock.when(PulsarConfigurationLoader.create(Mockito.anyString(), Mockito.any()))\n                     .thenReturn(configuration);\n             try {\n-                new ProxyServiceStarter(ProxyServiceStarterTest.ARGS);\n+                new ProxyServiceStarter(ProxyServiceStarterTest.getArgs());\n                 fail(\"functionWorkerWebServiceURLTLS does not support multi urls yet\");\n             } catch (Exception ex) {\n                 assertTrue(ex.getMessage().contains(\"does not support multi urls yet\"));\n\ndiff --git a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java\nindex b267439d47113..50ae6e627e820 100644\n--- a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java\n+++ b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyOriginalClientIPTest.java\n@@ -39,7 +39,6 @@\n @Slf4j\n @Test(groups = \"broker\")\n public class ProxyOriginalClientIPTest extends MockedPulsarServiceBaseTest {\n-    static final String[] ARGS = new String[]{\"-c\", \"./src/test/resources/proxy.conf\"};\n     HttpClient httpClient;\n     ProxyServiceStarter serviceStarter;\n     String webServiceUrl;\n@@ -49,7 +48,7 @@ public class ProxyOriginalClientIPTest extends MockedPulsarServiceBaseTest {\n     @BeforeClass\n     protected void setup() throws Exception {\n         internalSetup();\n-        serviceStarter = new ProxyServiceStarter(ARGS, proxyConfig -> {\n+        serviceStarter = new ProxyServiceStarter(ProxyServiceStarterTest.getArgs(), proxyConfig -> {\n             proxyConfig.setBrokerServiceURL(pulsar.getBrokerServiceUrl());\n             proxyConfig.setBrokerWebServiceURL(pulsar.getWebServiceAddress());\n             proxyConfig.setWebServicePort(Optional.of(0));\n\ndiff --git a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java\nindex 937526629acf0..b645c47242546 100644\n--- a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java\n+++ b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterDisableZeroCopyTest.java\n@@ -27,7 +27,7 @@ public class ProxyServiceStarterDisableZeroCopyTest extends ProxyServiceStarterT\n     @BeforeClass\n     protected void setup() throws Exception {\n         internalSetup();\n-        serviceStarter = new ProxyServiceStarter(ARGS, null, true);\n+        serviceStarter = new ProxyServiceStarter(getArgs(), null, true);\n         serviceStarter.getConfig().setBrokerServiceURL(pulsar.getBrokerServiceUrl());\n         serviceStarter.getConfig().setBrokerWebServiceURL(pulsar.getWebServiceAddress());\n         serviceStarter.getConfig().setWebServicePort(Optional.of(0));\n\ndiff --git a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java\nindex d96d2cd1f6e9c..6ef24874387a8 100644\n--- a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java\n+++ b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceStarterTest.java\n@@ -21,16 +21,23 @@\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n import java.net.URI;\n import java.nio.ByteBuffer;\n import java.util.Base64;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.Properties;\n import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.Future;\n import java.util.function.Consumer;\n import lombok.Cleanup;\n+import lombok.SneakyThrows;\n import org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest;\n import org.apache.pulsar.client.api.Authentication;\n import org.apache.pulsar.client.api.Producer;\n@@ -50,17 +57,38 @@\n import org.testng.annotations.Test;\n \n public class ProxyServiceStarterTest extends MockedPulsarServiceBaseTest {\n-\n-    public static final String[] ARGS = new String[]{\"-c\", \"./src/test/resources/proxy.conf\"};\n-\n     protected ProxyServiceStarter serviceStarter;\n     protected String serviceUrl;\n+    private static File proxyConfFileForTests;\n+\n+    @SneakyThrows\n+    public static String[] getArgs() {\n+        if (proxyConfFileForTests == null) {\n+            // load the properties from the proxy.conf file\n+            Properties properties = new Properties();\n+            try (InputStream inputStream = new FileInputStream(\"../conf/proxy.conf\")) {\n+                properties.load(inputStream);\n+            }\n+            // set dummy values for the required properties so that validation is passed\n+            properties.setProperty(\"brokerServiceURL\", \"pulsar://0.0.0.0:0\");\n+            properties.setProperty(\"brokerWebServiceURL\", \"http://0.0.0.0:0\");\n+            // change keepAliveIntervalSeconds default value so that it's possible to validate that it's configured\n+            properties.setProperty(\"keepAliveIntervalSeconds\", \"25\");\n+            // write the properties to a temporary file\n+            proxyConfFileForTests = File.createTempFile(\"proxy\", \".conf\");\n+            proxyConfFileForTests.deleteOnExit();\n+            try (OutputStream out = new FileOutputStream(proxyConfFileForTests)) {\n+                properties.store(out, null);\n+            }\n+        }\n+        return new String[] { \"-c\", proxyConfFileForTests.getAbsolutePath() };\n+    }\n \n     @Override\n     @BeforeClass\n     protected void setup() throws Exception {\n         internalSetup();\n-        serviceStarter = new ProxyServiceStarter(ARGS, null, true);\n+        serviceStarter = new ProxyServiceStarter(getArgs(), null, true);\n         serviceStarter.getConfig().setBrokerServiceURL(pulsar.getBrokerServiceUrl());\n         serviceStarter.getConfig().setBrokerWebServiceURL(pulsar.getWebServiceAddress());\n         serviceStarter.getConfig().setWebServicePort(Optional.of(0));\n@@ -100,6 +128,11 @@ public void testProducer() throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testKeepAliveIntervalSecondsIsConfigured() throws Exception {\n+        assertEquals(serviceStarter.getConfig().getKeepAliveIntervalSeconds(), 25);\n+    }\n+\n     @Test\n     public void testProduceAndConsumeMessageWithWebsocket() throws Exception {\n         @Cleanup(\"stop\")\n@@ -180,7 +213,7 @@ public void testProxyClientAuthentication() throws Exception {\n \n \n \n-        ProxyServiceStarter serviceStarter = new ProxyServiceStarter(ARGS, null, true);\n+        ProxyServiceStarter serviceStarter = new ProxyServiceStarter(getArgs(), null, true);\n         initConfig.accept(serviceStarter.getConfig());\n         // ProxyServiceStarter will throw an exception when Authentication#start is failed\n         serviceStarter.getConfig().setBrokerClientAuthenticationPlugin(ExceptionAuthentication1.class.getName());\n@@ -192,7 +225,7 @@ public void testProxyClientAuthentication() throws Exception {\n             assertTrue(serviceStarter.getProxyClientAuthentication() instanceof ExceptionAuthentication1);\n         }\n \n-        serviceStarter = new ProxyServiceStarter(ARGS, null, true);\n+        serviceStarter = new ProxyServiceStarter(getArgs(), null, true);\n         initConfig.accept(serviceStarter.getConfig());\n         // ProxyServiceStarter will throw an exception when Authentication#start and Authentication#close are failed\n         serviceStarter.getConfig().setBrokerClientAuthenticationPlugin(ExceptionAuthentication2.class.getName());\n\ndiff --git a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java\nindex ee8ae8d4afb3c..3e1c1200a747a 100644\n--- a/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java\n+++ b/pulsar-proxy/src/test/java/org/apache/pulsar/proxy/server/ProxyServiceTlsStarterTest.java\n@@ -18,6 +18,15 @@\n  */\n package org.apache.pulsar.proxy.server;\n \n+import static org.apache.pulsar.proxy.server.ProxyServiceStarterTest.getArgs;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.util.Base64;\n+import java.util.Optional;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Future;\n import lombok.Cleanup;\n import org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest;\n import org.apache.pulsar.client.api.Producer;\n@@ -35,17 +44,6 @@\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n \n-import java.net.URI;\n-import java.nio.ByteBuffer;\n-import java.util.Base64;\n-import java.util.Optional;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Future;\n-\n-import static org.apache.pulsar.proxy.server.ProxyServiceStarterTest.ARGS;\n-import static org.testng.Assert.assertEquals;\n-import static org.testng.Assert.assertTrue;\n-\n public class ProxyServiceTlsStarterTest extends MockedPulsarServiceBaseTest {\n     private ProxyServiceStarter serviceStarter;\n     private String serviceUrl;\n@@ -55,7 +53,7 @@ public class ProxyServiceTlsStarterTest extends MockedPulsarServiceBaseTest {\n     @BeforeClass\n     protected void setup() throws Exception {\n         internalSetup();\n-        serviceStarter = new ProxyServiceStarter(ARGS, null, true);\n+        serviceStarter = new ProxyServiceStarter(getArgs(), null, true);\n         serviceStarter.getConfig().setBrokerServiceURL(pulsar.getBrokerServiceUrl());\n         serviceStarter.getConfig().setBrokerServiceURLTLS(pulsar.getBrokerServiceUrlTls());\n         serviceStarter.getConfig().setBrokerWebServiceURL(pulsar.getWebServiceAddress());\n\ndiff --git a/pulsar-proxy/src/test/resources/proxy.conf b/pulsar-proxy/src/test/resources/proxy.conf\ndeleted file mode 100644\nindex aec9f5ee1c5e9..0000000000000\n--- a/pulsar-proxy/src/test/resources/proxy.conf\n+++ /dev/null\n@@ -1,250 +0,0 @@\n-#\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#   http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-#\n-\n-### --- Broker Discovery --- ###\n-\n-# The metadata store URL\n-# Examples:\n-# * zk:my-zk-1:2181,my-zk-2:2181,my-zk-3:2181\n-# * my-zk-1:2181,my-zk-2:2181,my-zk-3:2181 (will default to ZooKeeper when the schema is not specified)\n-# * zk:my-zk-1:2181,my-zk-2:2181,my-zk-3:2181/my-chroot-path (to add a ZK chroot path)\n-metadataStoreUrl=\n-\n-# The metadata store URL for the configuration data. If empty, we fall back to use metadataStoreUrl\n-configurationMetadataStoreUrl=\n-\n-# if Service Discovery is Disabled this url should point to the discovery service provider.\n-brokerServiceURL=pulsar://0.0.0.0:0\n-brokerServiceURLTLS=\n-\n-# These settings are unnecessary if `zookeeperServers` is specified\n-brokerWebServiceURL=http://0.0.0.0:0\n-brokerWebServiceURLTLS=\n-\n-# If function workers are setup in a separate cluster, configure the following 2 settings\n-# to point to the function workers cluster\n-functionWorkerWebServiceURL=\n-functionWorkerWebServiceURLTLS=\n-\n-# ZooKeeper session timeout (in milliseconds)\n-zookeeperSessionTimeoutMs=30000\n-\n-# ZooKeeper cache expiry time in seconds\n-zooKeeperCacheExpirySeconds=300\n-\n-### --- Server --- ###\n-\n-# Hostname or IP address the service binds on, default is 0.0.0.0.\n-bindAddress=0.0.0.0\n-\n-# Hostname or IP address the service advertises to the outside world.\n-# If not set, the value of `InetAddress.getLocalHost().getCanonicalHostName()` is used.\n-advertisedAddress=\n-\n-# Enable or disable the HAProxy protocol.\n-haProxyProtocolEnabled=false\n-\n-# Enables zero-copy transport of data across network interfaces using the splice system call.\n-# Zero copy mode cannot be used when TLS is enabled or when proxyLogLevel is > 0.\n-proxyZeroCopyModeEnabled=true\n-\n-# The port to use for server binary Protobuf requests\n-servicePort=6650\n-\n-# The port to use to server binary Protobuf TLS requests\n-servicePortTls=\n-\n-# Port that discovery service listen on\n-webServicePort=8080\n-\n-# Port to use to server HTTPS request\n-webServicePortTls=\n-\n-# Path for the file used to determine the rotation status for the proxy instance when responding\n-# to service discovery health checks\n-statusFilePath=\n-\n-# Proxy log level, default is 0.\n-# 0: Do not log any tcp channel info\n-# 1: Parse and log any tcp channel info and command info without message body\n-# 2: Parse and log channel info, command info and message body\n-proxyLogLevel=0\n-\n-### ---Authorization --- ###\n-\n-# Role names that are treated as \"super-users,\" meaning that they will be able to perform all admin\n-# operations and publish/consume to/from all topics (as a comma-separated list)\n-superUserRoles=\n-\n-# Whether authorization is enforced by the Pulsar proxy\n-authorizationEnabled=false\n-\n-# Authorization provider as a fully qualified class name\n-authorizationProvider=org.apache.pulsar.broker.authorization.PulsarAuthorizationProvider\n-\n-# Whether client authorization credentials are forwared to the broker for re-authorization.\n-# Authentication must be enabled via authenticationEnabled=true for this to take effect.\n-forwardAuthorizationCredentials=false\n-\n-### --- Authentication --- ###\n-\n-# Whether authentication is enabled for the Pulsar proxy\n-authenticationEnabled=false\n-\n-# Authentication provider name list (a comma-separated list of class names)\n-authenticationProviders=\n-\n-# When this parameter is not empty, unauthenticated users perform as anonymousUserRole\n-anonymousUserRole=\n-\n-### --- Client Authentication --- ###\n-\n-# The three brokerClient* authentication settings below are for the proxy itself and determine how it\n-# authenticates with Pulsar brokers\n-\n-# The authentication plugin used by the Pulsar proxy to authenticate with Pulsar brokers\n-brokerClientAuthenticationPlugin=\n-\n-# The authentication parameters used by the Pulsar proxy to authenticate with Pulsar brokers\n-brokerClientAuthenticationParameters=\n-\n-# The path to trusted certificates used by the Pulsar proxy to authenticate with Pulsar brokers\n-brokerClientTrustCertsFilePath=\n-\n-# Whether TLS is enabled when communicating with Pulsar brokers\n-tlsEnabledWithBroker=false\n-\n-# Tls cert refresh duration in seconds (set 0 to check on every new connection)\n-tlsCertRefreshCheckDurationSec=300\n-\n-##### --- Rate Limiting --- #####\n-\n-# Max concurrent inbound connections. The proxy will reject requests beyond that.\n-maxConcurrentInboundConnections=10000\n-\n-# Max concurrent outbound connections. The proxy will error out requests beyond that.\n-maxConcurrentLookupRequests=50000\n-\n-##### --- TLS --- #####\n-\n-# Deprecated - use servicePortTls and webServicePortTls instead\n-tlsEnabledInProxy=false\n-\n-# Path for the TLS certificate file\n-tlsCertificateFilePath=\n-\n-# Path for the TLS private key file\n-tlsKeyFilePath=\n-\n-# Path for the trusted TLS certificate file.\n-# This cert is used to verify that any certs presented by connecting clients\n-# are signed by a certificate authority. If this verification\n-# fails, then the certs are untrusted and the connections are dropped.\n-tlsTrustCertsFilePath=\n-\n-# Accept untrusted TLS certificate from client.\n-# If true, a client with a cert which cannot be verified with the\n-# 'tlsTrustCertsFilePath' cert will allowed to connect to the server,\n-# though the cert will not be used for client authentication.\n-tlsAllowInsecureConnection=false\n-\n-# Whether the hostname is validated when the proxy creates a TLS connection with brokers\n-tlsHostnameVerificationEnabled=false\n-\n-# Specify the tls protocols the broker will use to negotiate during TLS handshake\n-# (a comma-separated list of protocol names).\n-# Examples:- [TLSv1.3, TLSv1.2]\n-tlsProtocols=\n-\n-# Specify the tls cipher the broker will use to negotiate during TLS Handshake\n-# (a comma-separated list of ciphers).\n-# Examples:- [TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256]\n-tlsCiphers=\n-\n-# Whether client certificates are required for TLS. Connections are rejected if the client\n-# certificate isn't trusted.\n-tlsRequireTrustedClientCertOnConnect=false\n-\n-##### --- HTTP --- #####\n-\n-# Http directs to redirect to non-pulsar services.\n-httpReverseProxyConfigs=\n-\n-# Http output buffer size. The amount of data that will be buffered for http requests\n-# before it is flushed to the channel. A larger buffer size may result in higher http throughput\n-# though it may take longer for the client to see data.\n-# If using HTTP streaming via the reverse proxy, this should be set to the minimum value, 1,\n-# so that clients see the data as soon as possible.\n-httpOutputBufferSize=32768\n-\n-# Number of threads to use for HTTP requests processing. Default is\n-# 2 * Runtime.getRuntime().availableProcessors()\n-httpNumThreads=\n-\n-# Enable the enforcement of limits on the incoming HTTP requests\n-httpRequestsLimitEnabled=false\n-\n-# Max HTTP requests per seconds allowed. The excess of requests will be rejected with HTTP code 429 (Too many requests)\n-httpRequestsMaxPerSecond=100.0\n-\n-\n-### --- Token Authentication Provider --- ###\n-\n-## Symmetric key\n-# Configure the secret key to be used to validate auth tokens\n-# The key can be specified like:\n-# tokenSecretKey=data:;base64,xxxxxxxxx\n-# tokenSecretKey=file:///my/secret.key    ( Note: key file must be DER-encoded )\n-tokenSecretKey=\n-\n-## Asymmetric public/private key pair\n-# Configure the public key to be used to validate auth tokens\n-# The key can be specified like:\n-# tokenPublicKey=data:;base64,xxxxxxxxx\n-# tokenPublicKey=file:///my/public.key    ( Note: key file must be DER-encoded )\n-tokenPublicKey=\n-\n-# The token \"claim\" that will be interpreted as the authentication \"role\" or \"principal\" by AuthenticationProviderToken (defaults to \"sub\" if blank)\n-tokenAuthClaim=\n-\n-# The token audience \"claim\" name, e.g. \"aud\", that will be used to get the audience from token.\n-# If not set, audience will not be verified.\n-tokenAudienceClaim=\n-\n-# The token audience stands for this broker. The field `tokenAudienceClaim` of a valid token, need contains this.\n-tokenAudience=\n-\n-### --- WebSocket config variables --- ###\n-\n-# Enable or disable the WebSocket servlet.\n-webSocketServiceEnabled=false\n-\n-# Name of the cluster to which this broker belongs to\n-clusterName=\n-\n-### --- Deprecated config variables --- ###\n-\n-# Deprecated. Use configurationStoreServers\n-globalZookeeperServers=\n-\n-# The ZooKeeper quorum connection string (as a comma-separated list)\n-zookeeperServers=\n-\n-# Configuration store connection string (as a comma-separated list)\n-configurationStoreServers=\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23930",
    "pr_id": 23930,
    "issue_id": 23920,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Producers getting timed out intermittently\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nSetup summary:\n * Pulsar 4.0.1, 3 brokers, 5 bookies, 3 ZKs, JVM - 17.0.13\n * Produce and Consume through Pulsar Java client (4.0.1) - Clients are using Java 11\n\nAlso tried with 4.0.2 version\n\nPulsar Deployment - VM based, we are running on EC2 machines.\n\nAs far as configurations are concerned, we had following settings enabled\n * Extensible load balnacer and TransferShedder \n * Bundle split algorithm - `flow_or_qps_equally_divide`\n * Tiered storage to S3\n\nWe updated the load balancer configurations to use the Pulsar defaults, i.e. Modular Load balancer, ThresholdShedder and `range_equally_divide` for bundle split strategy. Reason for this change was because we observed errors in broker logs related to topic shedding.\n\n\nThen we also disabled tiered storage.\n\nIn all cases, the reported issue is observed.\n\n\n### Minimal reproduce step\n\nThis issue is continuation of Apache Pulsar's slack thread - https://apache-pulsar.slack.com/archives/C5Z4T36F7/p1738158630009249\nTo and fro discussion with @lhotari can be found there.\n\nWe are observing an intermittent issue where Pulsar producer client is unable to produce message to a partitioned topic, it is failing with org.apache.pulsar.client.api.PulsarClientException$TimeoutException  after 30 seconds.\n\n```java\n// Pulsar client\nthis.pulsarClient =\n          PulsarClient.builder()\n              .serviceUrl(connectionUrl)\n              .memoryLimit(0, SizeUnit.MEGA_BYTES)\n              .build();\n\n// Producer configurations\nProducerBuilder<T> builder =\n        pulsarClient\n            .newProducer(schema)\n            .producerName(producerName)\n            .topic(topicName)\n            .compressionType(CompressionType.LZ4)\n            .enableBatching(true)\n            .batchingMaxPublishDelay(30, TimeUnit.MILLISECONDS)\n            .blockIfQueueFull(true);\n```\n\nPulsar brokers, bookies and client instances are running in the same AWS VPC, so chances of network outage are quite low. Brokers are configured to use advertisedAddress , advertisedListeners is not configured.\n\nIn the client application, the Pulsar client and Producer object is initialized once and then messages are produced in sporadic intervals.\nThere is no other producer or consumer running on the cluster and there is more than sufficient resources available to cater to produce request.\n\nPulsar topics are partitioned.\nWe also have applied publish rate and dispatch rate policies of 1 MBps on the said topic (per partition)\nBut the throughput of messages being produced is far less than applied quota, for example, 1-5 messages in 2-5 minutes.\n\n![Image](https://github.com/user-attachments/assets/c8f6a1d7-ebe0-4d8b-849a-319f1fb4ea60)\n\nWe did try to remove the publish and dispatch rates on the topic and issue was resolved.\nAlthough we could not conclusively say that issue got resolved after removing those policies.\nWe also applied those policies back and did not observe issue for a day and when issue occurred again, we unload the namespace bundles and assigned to different brokers.\n\nWe did this several times so unloading namespace bundles seems to quick fix for the issue.\n\nWe also enabled debug logs on client and the server side.\n\nObserved a \"Setting auto read to false\" false in broker logs (see below)\n\n```\n2025-02-02T16:49:45,932+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-8] Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf Got request to create producer \n2025-02-02T16:49:45,932+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-8] [Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf] Added producer -- count: 1\n2025-02-02T16:49:45,932+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Put schema finished\n2025-02-02T16:49:45,933+0000 [broker-topic-workers-OrderedExecutor-5-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:39103] Created new producer: Producer{topic=PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-8}, client=[id: 0x8eacecff, L:/10.10.17.40:6650 - R:/10.22.2.15:39103] [SR:10.22.2.15, state:Connected], producerName=Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf, producerId=8}, role: null\n2025-02-02T16:49:45,933+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Schema is already exists\n2025-02-02T16:49:45,933+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-9] Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf Got request to create producer \n2025-02-02T16:49:45,933+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-9] [Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf] Added producer -- count: 1\n2025-02-02T16:49:45,933+0000 [broker-topic-workers-OrderedExecutor-5-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:39103] Created new producer: Producer{topic=PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-9}, client=[id: 0x8eacecff, L:/10.10.17.40:6650 - R:/10.22.2.15:39103] [SR:10.22.2.15, state:Connected], producerName=Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf, producerId=9}, role: null\n2025-02-02T16:49:45,933+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Put schema finished\n2025-02-02T16:49:46,175+0000 [pulsar-io-3-12] DEBUG org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:39103] Received send message request. producer: 9:0 Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf:0 size: 133, partition key is: 1, ordering key is null, uncompressedSize is 45\n2025-02-02T16:49:46,175+0000 [pulsar-io-3-12] DEBUG org.apache.pulsar.broker.service.ServerCnxThrottleTracker - [[id: 0x8eacecff, L:/10.10.17.40:6650 - R:/10.22.2.15:39103] [SR:10.22.2.15, state:Connected]] Setting auto read to false\n2025-02-02T16:49:46,180+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.Producer - [PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-9}] [Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf] [9] triggered send callback. cnx /10.22.2.15:39103, sequenceId 0\n2025-02-02T16:49:46,180+0000 [pulsar-io-3-12] DEBUG org.apache.pulsar.broker.service.Producer - [PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-9}] [Producer352f00f6-a898-4ed4-9469-8eb62c2ed0bf] [9] Persisted message. cnx [id: 0x8eacecff, L:/10.10.17.40:6650 - R:/10.22.2.15:39103] [SR:10.22.2.15, state:Connected], sequenceId 0\n2025-02-02T16:49:47,082+0000 [pulsar-io-3-13] DEBUG org.apache.pulsar.broker.service.ServerCnx - New connection from /127.0.0.1:57030\n2025-02-02T16:49:47,083+0000 [pulsar-io-3-13] INFO  org.apache.pulsar.broker.service.ServerCnx - Closed connection from /127.0.0.1:57030\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-6] No backlog. Update old position info is null\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-6] Time backlog quota = [-1]. Checking if exceeded.\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.BrokerService - quota not exceeded for [persistent://public/default/default_shivam_stream-partition-6]\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-7] No backlog. Update old position info is null\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-7] Time backlog quota = [-1]. Checking if exceeded.\n2025-02-02T16:49:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.BrokerService - quota not exceeded for [persistent://public/default/default_shivam_stream-partition-7]\n--\n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-7] Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf Got request to create producer \n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-7] [Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf] Added producer -- count: 1\n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Put schema finished\n2025-02-02T16:52:39,369+0000 [broker-topic-workers-OrderedExecutor-4-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:54474] Created new producer: Producer{topic=PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-7}, client=[id: 0x83526df1, L:/10.10.17.40:6650 - R:/10.22.2.15:54474] [SR:10.22.2.15, state:Connected], producerName=Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf, producerId=7}, role: null\n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Schema is already exists\n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-4] Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf Got request to create producer \n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-4] [Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf] Added producer -- count: 1\n2025-02-02T16:52:39,369+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Put schema finished\n2025-02-02T16:52:39,369+0000 [broker-topic-workers-OrderedExecutor-3-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:54474] Created new producer: Producer{topic=PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-4}, client=[id: 0x83526df1, L:/10.10.17.40:6650 - R:/10.22.2.15:54474] [SR:10.22.2.15, state:Connected], producerName=Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf, producerId=4}, role: null\n2025-02-02T16:52:39,596+0000 [pulsar-io-3-7] DEBUG org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:54474] Received send message request. producer: 9:0 Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf:0 size: 133, partition key is: 1, ordering key is null, uncompressedSize is 45\n2025-02-02T16:52:39,596+0000 [pulsar-io-3-7] DEBUG org.apache.pulsar.broker.service.ServerCnxThrottleTracker - [[id: 0x83526df1, L:/10.10.17.40:6650 - R:/10.22.2.15:54474] [SR:10.22.2.15, state:Connected]] Setting auto read to false\n2025-02-02T16:52:39,601+0000 [BookKeeperClientWorker-OrderedExecutor-4-0] DEBUG org.apache.pulsar.broker.service.Producer - [PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-9}] [Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf] [9] triggered send callback. cnx /10.22.2.15:54474, sequenceId 0\n2025-02-02T16:52:39,601+0000 [pulsar-io-3-7] DEBUG org.apache.pulsar.broker.service.Producer - [PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-9}] [Producer3e526aac-10f4-4a5e-8c51-2dbda8545bbf] [9] Persisted message. cnx [id: 0x83526df1, L:/10.10.17.40:6650 - R:/10.22.2.15:54474] [SR:10.22.2.15, state:Connected], sequenceId 0\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-6] No backlog. Update old position info is null\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-6] Time backlog quota = [-1]. Checking if exceeded.\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.BrokerService - quota not exceeded for [persistent://public/default/default_shivam_stream-partition-6]\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-7] No backlog. Update old position info is null\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-7] Time backlog quota = [-1]. Checking if exceeded.\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.BrokerService - quota not exceeded for [persistent://public/default/default_shivam_stream-partition-7]\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-8] No backlog. Update old position info is null\n2025-02-02T16:52:51,001+0000 [pulsar-backlog-quota-checker-OrderedScheduler-0-0] DEBUG org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://public/default/default_shivam_stream-partition-8] Time backlog quota = [-1]. Checking if exceeded.\n--\n2025-02-02T16:54:29,252+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-4] Producerbc584de6-13d3-46c3-9d7f-9f5c4f7619b2 Got request to create producer \n2025-02-02T16:54:29,252+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.AbstractTopic - [persistent://public/default/default_shivam_stream-partition-4] [Producerbc584de6-13d3-46c3-9d7f-9f5c4f7619b2] Added producer -- count: 1\n2025-02-02T16:54:29,252+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Put schema finished\n2025-02-02T16:54:29,252+0000 [broker-topic-workers-OrderedExecutor-3-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.22.2.15:55876] Created new producer: Producer{topic=PersistentTopic{topic=persistent://public/default/default_shivam_stream-partition-4}, client=[id: 0x4b78fe29, L:/10.10.17.40:6650 - R:/10.22.2.15:55876] [SR:10.22.2.15, state:Connected], producerName=Producerbc584de6-13d3-46c3-9d7f-9f5c4f7619b2, producerId=4}, role: null\n2025-02-02T16:54:29,253+0000 [BookKeeperClientWorker-OrderedExecutor-1-0] DEBUG org.apache.pulsar.broker.service.schema.SchemaRegistryServiceImpl - [public/default/default_shivam_stream] Schema is already exists\n20...\n```\n\n\nWe also observed that `pulsar.pulsar_publish_rate_limit_times` for the topics with this issue and found that they had non-zero values for this metric.\n\n<img width=\"1678\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/8adda537-9d4c-4484-873b-38baa4e07cea\" />\n\n\nAnother observation when we encounter this issue is that no messages are delivered to subscriptions. We tried consuming data from topic using Pulsar's CLI client from earliest position but no records were delivered.\nWe enabled `unblockStuckSubscriptionEnabled=true` in broker.conf but still observed this issue.\n\n\nCurrently we are removing the topicPolicies - publish rate and dispatch rate and will observe if the issue recurs.\n\nAs per our tests, these policies are working fine when there is sufficient records being produced and consumed from pulsar topics.\nBut when producer load is sparse, we are encountering the issue where producer is unable to produce message.\n\nLet me know if any other details are required around this.\n\n### What did you expect to see?\n\nRecords getting produced successfully\n\n### What did you see instead?\n\nRecords not being produced or consumed at sporadic intervals.\nThe issue happens intermittently and gets some solved on it's own, we haven't been able to nail the scenarios which deterministically leads to this issue.\n\nThe client patterns would be sparse producer and non zero values of `pulsar.pulsar_publish_rate_limit_times` during the duration of issue.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 2567,
    "test_files_count": 9,
    "non_test_files_count": 14,
    "pr_changed_files": [
      "microbench/README.md",
      "microbench/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBenchmark.java",
      "microbench/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockBenchmark.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucket.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBuilder.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClock.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucket.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucketBuilder.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucket.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucketBuilder.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PublishRateLimiterImpl.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/DispatchRateLimiter.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/SubscribeRateLimiter.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/AbstractMessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/AbstractMessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java"
    ],
    "base_commit": "cdab2d6dc4b620bdf129b05882b5f3bf4925ff61",
    "head_commit": "42fb876b873dc7e77766a6f7918a88b3dc18244b",
    "repo_url": "https://github.com/apache/pulsar/pull/23930",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23930",
    "dockerfile": "",
    "pr_merged_at": "2025-02-08T17:01:07.000Z",
    "patch": "diff --git a/microbench/README.md b/microbench/README.md\nindex 780e3a5a1d3e8..f50c3036ff494 100644\n--- a/microbench/README.md\n+++ b/microbench/README.md\n@@ -41,3 +41,29 @@ For fast recompiling of the benchmarks (without compiling Pulsar modules) and cr\n mvn -Pmicrobench -pl microbench clean package\n ```\n \n+### Running specific benchmarks\n+\n+Display help:\n+\n+```shell\n+java -jar microbench/target/microbenchmarks.jar -h\n+```\n+\n+Listing all benchmarks:\n+\n+```shell\n+java -jar microbench/target/microbenchmarks.jar -l\n+```\n+\n+Running specific benchmarks:\n+\n+```shell\n+java -jar microbench/target/microbenchmarks.jar \".*BenchmarkName.*\"\n+```\n+\n+Checking what benchmarks match the pattern:\n+\n+```shell\n+java -jar microbench/target/microbenchmarks.jar \".*BenchmarkName.*\" -lp\n+```\n+\n\ndiff --git a/microbench/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBenchmark.java b/microbench/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBenchmark.java\nindex 4c069e72ea3ba..1b210258f13d2 100644\n--- a/microbench/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBenchmark.java\n+++ b/microbench/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBenchmark.java\n@@ -33,6 +33,7 @@\n import org.openjdk.jmh.annotations.TearDown;\n import org.openjdk.jmh.annotations.Threads;\n import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n \n @Fork(3)\n @BenchmarkMode(Mode.Throughput)\n@@ -59,23 +60,29 @@ public void teardown() {\n     @Benchmark\n     @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n     @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n-    public void consumeTokensBenchmark001Threads() {\n-        asyncTokenBucket.consumeTokens(1);\n+    public void consumeTokensBenchmark001Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole);\n     }\n \n     @Threads(10)\n     @Benchmark\n     @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n     @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n-    public void consumeTokensBenchmark010Threads() {\n-        asyncTokenBucket.consumeTokens(1);\n+    public void consumeTokensBenchmark010Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole);\n     }\n \n     @Threads(100)\n     @Benchmark\n     @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n     @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n-    public void consumeTokensBenchmark100Threads() {\n+    public void consumeTokensBenchmark100Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole);\n+    }\n+\n+    private void consumeTokenAndGetTokens(Blackhole blackhole) {\n         asyncTokenBucket.consumeTokens(1);\n+        // blackhole is used to ensure that the compiler doesn't do dead code elimination\n+        blackhole.consume(asyncTokenBucket.getTokens());\n     }\n }\n\ndiff --git a/microbench/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockBenchmark.java b/microbench/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockBenchmark.java\nnew file mode 100644\nindex 0000000000000..d9054b8fe4be8\n--- /dev/null\n+++ b/microbench/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockBenchmark.java\n@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pulsar.broker.qos;\n+\n+import java.util.concurrent.TimeUnit;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Threads;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+@Fork(3)\n+@BenchmarkMode(Mode.Throughput)\n+@OutputTimeUnit(TimeUnit.SECONDS)\n+@State(Scope.Thread)\n+public class DefaultMonotonicSnapshotClockBenchmark {\n+    private DefaultMonotonicSnapshotClock monotonicSnapshotClock =\n+            new DefaultMonotonicSnapshotClock(TimeUnit.MILLISECONDS.toNanos(1), System::nanoTime);\n+\n+    @TearDown(Level.Iteration)\n+    public void teardown() {\n+        monotonicSnapshotClock.close();\n+    }\n+\n+    @Threads(1)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanos001Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, false);\n+    }\n+\n+    @Threads(10)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanos010Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, false);\n+    }\n+\n+    @Threads(100)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanos100Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, false);\n+    }\n+\n+    @Threads(1)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanosRequestSnapshot001Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, true);\n+    }\n+\n+    @Threads(10)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanosRequestSnapshot010Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, true);\n+    }\n+\n+    @Threads(100)\n+    @Benchmark\n+    @Measurement(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    @Warmup(time = 10, timeUnit = TimeUnit.SECONDS, iterations = 1)\n+    public void getTickNanosRequestSnapshot100Threads(Blackhole blackhole) {\n+        consumeTokenAndGetTokens(blackhole, true);\n+    }\n+\n+    private void consumeTokenAndGetTokens(Blackhole blackhole, boolean requestSnapshot) {\n+        // blackhole is used to ensure that the compiler doesn't do dead code elimination\n+        blackhole.consume(monotonicSnapshotClock.getTickNanos(requestSnapshot));\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucket.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucket.java\nindex ac9a1f03e592b..8c43fa0a816fa 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucket.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucket.java\n@@ -42,6 +42,10 @@\n  * connection or client from the throttling queue to unthrottle. Before unthrottling, the application should check\n  * for available tokens. If tokens are still not available, the application should continue with throttling and\n  * repeat the throttling loop.\n+ * <p>By default, the AsyncTokenBucket is eventually consistent. This means that the token balance is updated\n+ * with added tokens and consumed tokens at most once during each \"increment\", when time advances more than the\n+ * configured resolution. There are settings for configuring consistency, please see {@link AsyncTokenBucketBuilder}\n+ * for details.\n  * <p>This class does not produce side effects outside its own scope. It functions similarly to a stateful function,\n  * akin to a counter function. In essence, it is a sophisticated counter. It can serve as a foundational component for\n  * constructing higher-level asynchronous rate limiter implementations, which require side effects for throttling.\n@@ -119,9 +123,28 @@ public static void resetToDefaultEventualConsistentTokensView() {\n      */\n     private final LongAdder pendingConsumedTokens = new LongAdder();\n \n-    protected AsyncTokenBucket(MonotonicSnapshotClock clockSource, long resolutionNanos) {\n+    /**\n+     * By default, AsyncTokenBucket is eventually consistent. This means that the consumed tokens are subtracted from\n+     * the total amount of tokens at most once during each \"increment\", when time advances more than the configured\n+     * resolution. This setting determines if the consumed tokens are subtracted from tokens balance consistently.\n+     * For high performance, it is recommended to keep this setting as false.\n+     */\n+    private final boolean consistentConsumedTokens;\n+    /**\n+     * By default, AsyncTokenBucket is eventually consistent. This means that the added tokens are calculated based\n+     * on elapsed time at most once during each \"increment\", when time advances more than the configured\n+     * resolution. This setting determines if the added tokens are calculated and added to tokens balance consistently.\n+     * For high performance, it is recommended to keep this setting as false.\n+     */\n+    private final boolean consistentAddedTokens;\n+\n+    protected AsyncTokenBucket(MonotonicSnapshotClock clockSource, long resolutionNanos,\n+                               boolean consistentConsumedTokens, boolean consistentAddedTokens) {\n         this.clockSource = clockSource;\n         this.resolutionNanos = resolutionNanos;\n+        this.lastNanos = Long.MIN_VALUE;\n+        this.consistentConsumedTokens = consistentConsumedTokens;\n+        this.consistentAddedTokens = consistentAddedTokens;\n     }\n \n     public static FinalRateAsyncTokenBucketBuilder builder() {\n@@ -139,36 +162,46 @@ public static DynamicRateAsyncTokenBucketBuilder builderForDynamicRate() {\n     /**\n      * Consumes tokens and possibly updates the tokens balance. New tokens are calculated and added to the current\n      * tokens balance each time the update takes place. The update takes place once in every interval of the configured\n-     * resolutionNanos or when the forceUpdateTokens parameter is true.\n+     * resolutionNanos or when the forceConsistentTokens parameter is true.\n      * When the tokens balance isn't updated, the consumed tokens are added to the pendingConsumedTokens LongAdder\n      * counter which gets flushed the next time the tokens are updated. This makes the tokens balance\n      * eventually consistent. The reason for this design choice is to optimize performance by preventing CAS loop\n      * contention which could cause excessive CPU consumption.\n      *\n      * @param consumeTokens     number of tokens to consume, can be 0 to update the tokens balance\n-     * @param forceUpdateTokens if true, the tokens are updated even if the configured resolution hasn't passed\n+     * @param forceConsistentTokens if true, the token balance is updated consistently\n      * @return the current number of tokens in the bucket or Long.MIN_VALUE when the number of tokens is unknown due\n      * to eventual consistency\n      */\n-    private long consumeTokensAndMaybeUpdateTokensBalance(long consumeTokens, boolean forceUpdateTokens) {\n+    private long consumeTokensAndMaybeUpdateTokensBalance(long consumeTokens, boolean forceConsistentTokens) {\n         if (consumeTokens < 0) {\n             throw new IllegalArgumentException(\"consumeTokens must be >= 0\");\n         }\n-        long currentNanos = clockSource.getTickNanos(forceUpdateTokens);\n+        boolean requestConsistentTickNanosSnapshot =\n+                consistentAddedTokens || consistentConsumedTokens || forceConsistentTokens || resolutionNanos == 0;\n+        long currentNanos = clockSource.getTickNanos(requestConsistentTickNanosSnapshot);\n+        long newTokens = 0;\n         // check if the tokens should be updated immediately\n-        if (shouldUpdateTokensImmediately(currentNanos, forceUpdateTokens)) {\n+        if (shouldAddTokensImmediately(currentNanos, forceConsistentTokens)) {\n             // calculate the number of new tokens since the last update\n-            long newTokens = calculateNewTokensSinceLastUpdate(currentNanos);\n-            // calculate the total amount of tokens to consume in this update\n+            newTokens = calculateNewTokensSinceLastUpdate(currentNanos, forceConsistentTokens);\n+        }\n+        // update tokens if there are new tokens or if resolutionNanos is set to 0 which is currently used for testing\n+        if (newTokens > 0 || resolutionNanos == 0 || consistentConsumedTokens || forceConsistentTokens) {\n             // flush the pendingConsumedTokens by calling \"sumThenReset\"\n-            long totalConsumedTokens = consumeTokens + pendingConsumedTokens.sumThenReset();\n-            // update the tokens and return the current token value\n-            return TOKENS_UPDATER.updateAndGet(this,\n-                    currentTokens ->\n-                            // after adding new tokens, limit the tokens to the capacity\n-                            Math.min(currentTokens + newTokens, getCapacity())\n-                                    // subtract the consumed tokens\n-                                    - totalConsumedTokens);\n+            long currentPendingConsumedTokens = pendingConsumedTokens.sumThenReset();\n+            // calculate the token delta by subtracting the consumed tokens from the new tokens\n+            long tokenDelta = newTokens - currentPendingConsumedTokens;\n+            if (tokenDelta != 0 || consumeTokens != 0) {\n+                // update the tokens and return the current token value\n+                return TOKENS_UPDATER.updateAndGet(this,\n+                        // limit the tokens to the capacity of the bucket\n+                        currentTokens -> Math.min(currentTokens + tokenDelta, getCapacity())\n+                                // subtract the consumed tokens from the capped tokens\n+                                - consumeTokens);\n+            } else {\n+                return tokens;\n+            }\n         } else {\n             // eventual consistent fast path, tokens are not updated immediately\n \n@@ -187,19 +220,19 @@ private long consumeTokensAndMaybeUpdateTokensBalance(long consumeTokens, boolea\n      *\n      * The tokens will be updated once every resolutionNanos nanoseconds.\n      * This method checks if the configured resolutionNanos has passed since the last update.\n-     * If the forceUpdateTokens is true, the tokens will be updated immediately.\n+     * If the forceConsistentTokens is true, the tokens will be updated immediately.\n      *\n-     * @param currentNanos the current monotonic clock time in nanoseconds\n-     * @param forceUpdateTokens if true, the tokens will be updated immediately\n+     * @param currentNanos      the current monotonic clock time in nanoseconds\n+     * @param forceConsistentTokens if true, the tokens are added even if the configured resolution hasn't fully passed\n      * @return true if the tokens should be updated immediately, false otherwise\n      */\n-    private boolean shouldUpdateTokensImmediately(long currentNanos, boolean forceUpdateTokens) {\n+    private boolean shouldAddTokensImmediately(long currentNanos, boolean forceConsistentTokens) {\n         long currentIncrement = resolutionNanos != 0 ? currentNanos / resolutionNanos : 0;\n         long currentLastIncrement = lastIncrement;\n         return currentIncrement == 0\n                 || (currentIncrement > currentLastIncrement\n                 && LAST_INCREMENT_UPDATER.compareAndSet(this, currentLastIncrement, currentIncrement))\n-                || forceUpdateTokens;\n+                || consistentAddedTokens || forceConsistentTokens;\n     }\n \n     /**\n@@ -209,10 +242,22 @@ private boolean shouldUpdateTokensImmediately(long currentNanos, boolean forceUp\n      * @param currentNanos the current monotonic clock time in nanoseconds\n      * @return the number of new tokens to add since the last update\n      */\n-    private long calculateNewTokensSinceLastUpdate(long currentNanos) {\n+    private long calculateNewTokensSinceLastUpdate(long currentNanos, boolean forceConsistentTokens) {\n+        long previousLastNanos = lastNanos;\n+        long newLastNanos;\n+        // update lastNanos only if at least resolutionNanos/2 nanoseconds has passed since the last update\n+        // unless consistency is needed\n+        long minimumIncrementNanos = forceConsistentTokens || consistentAddedTokens ? 0L : resolutionNanos / 2;\n+        if (currentNanos > previousLastNanos + minimumIncrementNanos) {\n+            newLastNanos = currentNanos;\n+        } else {\n+            newLastNanos = previousLastNanos;\n+        }\n         long newTokens;\n-        long previousLastNanos = LAST_NANOS_UPDATER.getAndSet(this, currentNanos);\n-        if (previousLastNanos == 0) {\n+        if (newLastNanos == previousLastNanos\n+                // prevent races with a CAS update of lastNanos\n+                || !LAST_NANOS_UPDATER.compareAndSet(this, previousLastNanos, newLastNanos)\n+                || previousLastNanos == Long.MIN_VALUE) {\n             newTokens = 0;\n         } else {\n             long durationNanos = currentNanos - previousLastNanos + REMAINDER_NANOS_UPDATER.getAndSet(this, 0);\n@@ -267,15 +312,14 @@ public boolean consumeTokensAndCheckIfContainsTokens(long consumeTokens) {\n     }\n \n     /**\n-     * Returns the current token balance. When forceUpdateTokens is true, the tokens balance is updated before\n-     * returning. If forceUpdateTokens is false, the tokens balance could be updated if the last updated happened\n+     * Returns the current token balance. When forceConsistentTokens is true, the tokens balance is updated before\n+     * returning. If forceConsistentTokens is false, the tokens balance could be updated if the last updated happened\n      * more than resolutionNanos nanoseconds ago.\n      *\n-     * @param forceUpdateTokens if true, the tokens balance is updated before returning\n      * @return the current token balance\n      */\n-    protected long tokens(boolean forceUpdateTokens) {\n-        long currentTokens = consumeTokensAndMaybeUpdateTokensBalance(0, forceUpdateTokens);\n+    private long tokens() {\n+        long currentTokens = consumeTokensAndMaybeUpdateTokensBalance(0, false);\n         if (currentTokens != Long.MIN_VALUE) {\n             // when currentTokens isn't Long.MIN_VALUE, the current tokens balance is known\n             return currentTokens;\n@@ -295,7 +339,7 @@ public long calculateThrottlingDuration() {\n         long currentTokens = consumeTokensAndMaybeUpdateTokensBalance(0, true);\n         if (currentTokens == Long.MIN_VALUE) {\n             throw new IllegalArgumentException(\n-                    \"Unexpected result from updateAndConsumeTokens with forceUpdateTokens set to true\");\n+                    \"Unexpected result from updateAndConsumeTokens with forceConsistentTokens set to true\");\n         }\n         if (currentTokens > 0) {\n             return 0L;\n@@ -309,10 +353,11 @@ public long calculateThrottlingDuration() {\n \n     /**\n      * Returns the current number of tokens in the bucket.\n-     * The token balance is updated if the configured resolutionNanos has passed since the last update.\n+     * The token balance is updated if the configured resolutionNanos has passed since the last update unless\n+     * consistentConsumedTokens is true.\n      */\n     public final long getTokens() {\n-        return tokens(false);\n+        return tokens();\n     }\n \n     public abstract long getRate();\n@@ -320,25 +365,13 @@ public final long getTokens() {\n     /**\n      * Checks if the bucket contains tokens.\n      * The token balance is updated before the comparison if the configured resolutionNanos has passed since the last\n-     * update. It's possible that the returned result is not definite since the token balance is eventually consistent.\n+     * update. It's possible that the returned result is not definite since the token balance is eventually consistent\n+     * if consistentConsumedTokens is false.\n      *\n      * @return true if the bucket contains tokens, false otherwise\n      */\n     public boolean containsTokens() {\n-        return containsTokens(false);\n-    }\n-\n-    /**\n-     * Checks if the bucket contains tokens.\n-     * The token balance is updated before the comparison if the configured resolutionNanos has passed since the last\n-     * update. The token balance is also updated when forceUpdateTokens is true.\n-     * It's possible that the returned result is not definite since the token balance is eventually consistent.\n-     *\n-     * @param forceUpdateTokens if true, the token balance is updated before the comparison\n-     * @return true if the bucket contains tokens, false otherwise\n-     */\n-    public boolean containsTokens(boolean forceUpdateTokens) {\n-        return tokens(forceUpdateTokens) > 0;\n+        return tokens() > 0;\n     }\n \n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBuilder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBuilder.java\nindex ee256d5a37d64..1c05f1a213e3a 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBuilder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/AsyncTokenBucketBuilder.java\n@@ -23,6 +23,8 @@\n public abstract class AsyncTokenBucketBuilder<SELF extends AsyncTokenBucketBuilder<SELF>> {\n     protected MonotonicSnapshotClock clock = AsyncTokenBucket.DEFAULT_SNAPSHOT_CLOCK;\n     protected long resolutionNanos = AsyncTokenBucket.defaultResolutionNanos;\n+    protected boolean consistentConsumedTokens;\n+    protected boolean consistentAddedTokens;\n \n     protected AsyncTokenBucketBuilder() {\n     }\n@@ -31,15 +33,47 @@ protected SELF self() {\n         return (SELF) this;\n     }\n \n+    /**\n+     * Set the clock source for the token bucket. It's recommended to use the {@link DefaultMonotonicSnapshotClock}\n+     * for most use cases.\n+     */\n     public SELF clock(MonotonicSnapshotClock clock) {\n         this.clock = clock;\n         return self();\n     }\n \n+    /**\n+     * By default, AsyncTokenBucket is eventually consistent. This means that the token balance is updated, when time\n+     * advances more than the configured resolution. This setting determines the duration of the increment.\n+     * Setting this value to 0 will make the token balance fully consistent. There's a performance trade-off\n+     * when setting this value to 0.\n+     */\n     public SELF resolutionNanos(long resolutionNanos) {\n         this.resolutionNanos = resolutionNanos;\n         return self();\n     }\n \n+    /**\n+     * By default, AsyncTokenBucket is eventually consistent. This means that the consumed tokens are subtracted from\n+     * the total amount of tokens at most once during each \"increment\", when time advances more than the configured\n+     * resolution. This setting determines if the consumed tokens are subtracted from tokens balance consistently.\n+     * For high performance, it is recommended to keep this setting as false.\n+     */\n+    public SELF consistentConsumedTokens(boolean consistentConsumedTokens) {\n+        this.consistentConsumedTokens = consistentConsumedTokens;\n+        return self();\n+    }\n+\n+    /**\n+     * By default, AsyncTokenBucket is eventually consistent. This means that the added tokens are calculated based\n+     * on elapsed time at most once during each \"increment\", when time advances more than the configured\n+     * resolution. This setting determines if the added tokens are calculated and added to tokens balance consistently.\n+     * For high performance, it is recommended to keep this setting as false.\n+     */\n+    public SELF consistentAddedTokens(boolean consistentAddedTokens) {\n+        this.consistentAddedTokens = consistentAddedTokens;\n+        return self();\n+    }\n+\n     public abstract AsyncTokenBucket build();\n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClock.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClock.java\nindex df3843921ed55..23b9359c8042d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClock.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClock.java\n@@ -19,71 +19,269 @@\n \n package org.apache.pulsar.broker.qos;\n \n+import java.util.Objects;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.function.LongConsumer;\n import java.util.function.LongSupplier;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * Default implementation of {@link MonotonicSnapshotClock}.\n+ * Default implementation of {@link MonotonicSnapshotClock} optimized for use with {@link AsyncTokenBucket}.\n  *\n- * Starts a daemon thread that updates the snapshot value periodically with a configured interval. The close method\n- * should be called to stop the thread.\n+ * <p>\n+ * This class provides a monotonic snapshot value that consistently increases, ensuring reliable behavior\n+ * even in environments where the underlying clock source may not be strictly monotonic across all CPUs,\n+ * such as certain virtualized platforms.\n+ * </p>\n+ *\n+ * <p>\n+ * Upon instantiation, a daemon thread is launched to periodically update the snapshot value at a configured\n+ * interval. It is essential to invoke the {@link #close()} method to gracefully terminate this thread when it is\n+ * no longer needed.\n+ * </p>\n+ *\n+ * <p>\n+ * The {@link AsyncTokenBucket} utilizes this clock to obtain tick values. It does not require a consistent value on\n+ * every retrieval. However, when a consistent snapshot is necessary, the {@link #getTickNanos(boolean)} method\n+ * is called with the {@code requestSnapshot} parameter set to {@code true}.\n+ * </p>\n+ *\n+ * <p>\n+ * By employing a single thread to update the monotonic clock value, this implementation ensures that the snapshot\n+ * value remains strictly increasing. This approach mitigates potential inconsistencies that may arise from clock\n+ * source discrepancies across different CPUs.\n+ * </p>\n  */\n public class DefaultMonotonicSnapshotClock implements MonotonicSnapshotClock, AutoCloseable {\n     private static final Logger LOG = LoggerFactory.getLogger(DefaultMonotonicSnapshotClock.class);\n-    private final long sleepMillis;\n-    private final int sleepNanos;\n-    private final LongSupplier clockSource;\n-    private final Thread thread;\n+    private final TickUpdaterThread tickUpdaterThread;\n     private volatile long snapshotTickNanos;\n \n     public DefaultMonotonicSnapshotClock(long snapshotIntervalNanos, LongSupplier clockSource) {\n         if (snapshotIntervalNanos < TimeUnit.MILLISECONDS.toNanos(1)) {\n             throw new IllegalArgumentException(\"snapshotIntervalNanos must be at least 1 millisecond\");\n         }\n-        this.sleepMillis = TimeUnit.NANOSECONDS.toMillis(snapshotIntervalNanos);\n-        this.sleepNanos = (int) (snapshotIntervalNanos - TimeUnit.MILLISECONDS.toNanos(sleepMillis));\n-        this.clockSource = clockSource;\n-        updateSnapshotTickNanos();\n-        thread = new Thread(this::snapshotLoop, getClass().getSimpleName() + \"-update-loop\");\n-        thread.setDaemon(true);\n-        thread.start();\n+        tickUpdaterThread = new TickUpdaterThread(snapshotIntervalNanos,\n+                Objects.requireNonNull(clockSource, \"clockSource must not be null\"), this::setSnapshotTickNanos);\n+        tickUpdaterThread.start();\n+    }\n+\n+    private void setSnapshotTickNanos(long snapshotTickNanos) {\n+        this.snapshotTickNanos = snapshotTickNanos;\n     }\n \n     /** {@inheritDoc} */\n     @Override\n     public long getTickNanos(boolean requestSnapshot) {\n         if (requestSnapshot) {\n-            updateSnapshotTickNanos();\n+            tickUpdaterThread.requestUpdateAndWait();\n         }\n         return snapshotTickNanos;\n     }\n \n-    private void updateSnapshotTickNanos() {\n-        snapshotTickNanos = clockSource.getAsLong();\n+    @Override\n+    public void close() {\n+        tickUpdaterThread.interrupt();\n     }\n \n-    private void snapshotLoop() {\n-        try {\n-            while (!Thread.currentThread().isInterrupted()) {\n-                updateSnapshotTickNanos();\n+    /**\n+     * A thread that updates snapshotTickNanos value periodically with a configured interval.\n+     * The thread is started when the DefaultMonotonicSnapshotClock is created and runs until the close method is\n+     * called.\n+     * A single thread is used to read the clock source value since on some hardware of virtualized platforms,\n+     * System.nanoTime() isn't strictly monotonic across all CPUs. Reading by a single thread will improve the\n+     * stability of the read value since a single thread is scheduled on a single CPU. If the thread is migrated\n+     * to another CPU, the clock source value might leap backward or forward, but logic in this class will handle it.\n+     */\n+    private static class TickUpdaterThread extends Thread {\n+        private final Object tickUpdateDelayMonitor = new Object();\n+        private final Object tickUpdatedMonitor = new Object();\n+        private final MonotonicLeapDetectingTickUpdater tickUpdater;\n+        private volatile boolean running;\n+        private boolean tickUpdateDelayMonitorNotified;\n+        private AtomicLong requestCount = new AtomicLong();\n+        private final long sleepMillis;\n+        private final int sleepNanos;\n+\n+        TickUpdaterThread(long snapshotIntervalNanos, LongSupplier clockSource, LongConsumer setSnapshotTickNanos) {\n+            super(DefaultMonotonicSnapshotClock.class.getSimpleName() + \"-update-loop\");\n+            // set as daemon thread so that it doesn't prevent the JVM from exiting\n+            setDaemon(true);\n+            // set the highest priority\n+            setPriority(MAX_PRIORITY);\n+            this.sleepMillis = TimeUnit.NANOSECONDS.toMillis(snapshotIntervalNanos);\n+            this.sleepNanos = (int) (snapshotIntervalNanos - TimeUnit.MILLISECONDS.toNanos(sleepMillis));\n+            tickUpdater = new MonotonicLeapDetectingTickUpdater(clockSource, setSnapshotTickNanos,\n+                    snapshotIntervalNanos);\n+        }\n+\n+        @Override\n+        public void run() {\n+            try {\n+                running = true;\n+                long updatedForRequestCount = -1;\n+                while (!isInterrupted()) {\n+                    try {\n+                        // track if the thread has waited for the whole duration of the snapshot interval\n+                        // before updating the tick value\n+                        boolean waitedSnapshotInterval = false;\n+                        // sleep for the configured interval on a monitor that can be notified to stop the sleep\n+                        // and update the tick value immediately. This is used in requestUpdate method.\n+                        synchronized (tickUpdateDelayMonitor) {\n+                            tickUpdateDelayMonitorNotified = false;\n+                            // only wait if no explicit request has been made since the last update\n+                            if (requestCount.get() == updatedForRequestCount) {\n+                                // if no request has been made, sleep for the configured interval\n+                                tickUpdateDelayMonitor.wait(sleepMillis, sleepNanos);\n+                                waitedSnapshotInterval = !tickUpdateDelayMonitorNotified;\n+                            }\n+                        }\n+                        updatedForRequestCount = requestCount.get();\n+                        // update the tick value using the tick updater which will tolerate leaps backward\n+                        tickUpdater.update(waitedSnapshotInterval);\n+                        notifyAllTickUpdated();\n+                    } catch (InterruptedException e) {\n+                        interrupt();\n+                        break;\n+                    }\n+                }\n+            } catch (Throwable t) {\n+                // report unexpected error since this would be a fatal error when the clock doesn't progress anymore\n+                // this is very unlikely to happen, but it's better to log it in any case\n+                LOG.error(\"Unexpected fatal error that stopped the clock.\", t);\n+            } finally {\n+                LOG.info(\"DefaultMonotonicSnapshotClock's TickUpdaterThread stopped. {},tid={}\", this, getId());\n+                running = false;\n+                notifyAllTickUpdated();\n+            }\n+        }\n+\n+        private void notifyAllTickUpdated() {\n+            synchronized (tickUpdatedMonitor) {\n+                // notify all threads that are waiting for the tick value to be updated\n+                tickUpdatedMonitor.notifyAll();\n+            }\n+        }\n+\n+        public void requestUpdateAndWait() {\n+            if (!running) {\n+                synchronized (tickUpdater) {\n+                    // thread has stopped running, fallback to update the value directly without optimizations\n+                    tickUpdater.update(false);\n+                }\n+                return;\n+            }\n+            // increment the request count that ensures that the thread will update the tick value after this request\n+            // was made also when there's a race condition between the request and the update\n+            // this solution doesn't prevent all races, and it's not guaranteed that the tick value is always updated\n+            // it will prevent the request having to wait for the delayed update cycle. This is sufficient for the\n+            // use case.\n+            requestCount.incrementAndGet();\n+            synchronized (tickUpdatedMonitor) {\n+                // notify the thread to stop waiting and update the tick value\n+                synchronized (tickUpdateDelayMonitor) {\n+                    tickUpdateDelayMonitorNotified = true;\n+                    tickUpdateDelayMonitor.notify();\n+                }\n+                // wait until the tick value has been updated\n                 try {\n-                    Thread.sleep(sleepMillis, sleepNanos);\n+                    tickUpdatedMonitor.wait();\n                 } catch (InterruptedException e) {\n-                    Thread.currentThread().interrupt();\n-                    break;\n+                    currentThread().interrupt();\n+                }\n+            }\n+        }\n+\n+        @Override\n+        public synchronized void start() {\n+            // wait until the thread is started and the tick value has been updated\n+            synchronized (tickUpdatedMonitor) {\n+                super.start();\n+                try {\n+                    tickUpdatedMonitor.wait();\n+                } catch (InterruptedException e) {\n+                    currentThread().interrupt();\n                 }\n             }\n-        } catch (Throwable t) {\n-            // report unexpected error since this would be a fatal error when the clock doesn't progress anymore\n-            // this is very unlikely to happen, but it's better to log it in any case\n-            LOG.error(\"Unexpected fatal error that stopped the clock.\", t);\n         }\n     }\n \n-    @Override\n-    public void close() {\n-        thread.interrupt();\n+    /**\n+     * Handles updating the tick value in a monotonic way so that the value is always increasing,\n+     * regardless of leaps backward in the clock source value.\n+     */\n+    static class MonotonicLeapDetectingTickUpdater {\n+        private final LongSupplier clockSource;\n+        private final long snapshotInternalNanos;\n+        private final long maxDeltaNanosForLeapDetection;\n+        private final LongConsumer tickUpdatedCallback;\n+        private long referenceClockSourceValue = Long.MIN_VALUE;\n+        private long baseSnapshotTickNanos;\n+        private long previousSnapshotTickNanos;\n+\n+        MonotonicLeapDetectingTickUpdater(LongSupplier clockSource, LongConsumer tickUpdatedCallback,\n+                                          long snapshotInternalNanos) {\n+            this.clockSource = clockSource;\n+            this.snapshotInternalNanos = snapshotInternalNanos;\n+            this.maxDeltaNanosForLeapDetection = 2 * snapshotInternalNanos;\n+            this.tickUpdatedCallback = tickUpdatedCallback;\n+        }\n+\n+        /**\n+         * Updates the snapshot tick value. The tickUpdatedCallback is called if the value has changed.\n+         * The value is updated in a monotonic way so that the value is always increasing, regardless of leaps backward\n+         * in the clock source value.\n+         * Leap detection is done by comparing the new value with the previous value and the maximum delta value.\n+         *\n+         * @param waitedSnapshotInterval if true, the method has waited for the snapshot interval since the previous\n+         *                               call.\n+         */\n+        public void update(boolean waitedSnapshotInterval) {\n+            // get the current clock source value\n+            long clockValue = clockSource.getAsLong();\n+\n+            // Initialization on first call\n+            if (referenceClockSourceValue == Long.MIN_VALUE) {\n+                referenceClockSourceValue = clockValue;\n+                baseSnapshotTickNanos = clockValue;\n+                previousSnapshotTickNanos = clockValue;\n+                // update the tick value using the callback\n+                tickUpdatedCallback.accept(clockValue);\n+                return;\n+            }\n+\n+            // calculate the duration since the reference clock source value\n+            // so that the snapshot value is always increasing and tolerates it when the clock source is not strictly\n+            // monotonic across all CPUs and leaps backward\n+            long durationSinceReference = clockValue - referenceClockSourceValue;\n+            // calculate the new snapshot tick value as a duration since the reference clock source value\n+            // and add it to the base snapshot tick value\n+            long newSnapshotTickNanos = baseSnapshotTickNanos + durationSinceReference;\n+\n+            // reset the reference clock source value if the clock source value leaps backward\n+            // more than the maximum delta value\n+            if (newSnapshotTickNanos < previousSnapshotTickNanos - maxDeltaNanosForLeapDetection) {\n+                // when the clock source value leaps backward, reset the reference value to the new value\n+                // for future duration calculations\n+                referenceClockSourceValue = clockValue;\n+                // if the updater thread has waited for the snapshot interval since the previous call,\n+                // increment the base snapshot tick value by the snapshot interval value\n+                long incrementWhenLeapDetected = waitedSnapshotInterval ? snapshotInternalNanos : 0;\n+                // set the base snapshot tick value to the new value\n+                baseSnapshotTickNanos = previousSnapshotTickNanos + incrementWhenLeapDetected;\n+                // set the new snapshot tick value to the base value\n+                newSnapshotTickNanos = baseSnapshotTickNanos;\n+            }\n+\n+            // update snapshotTickNanos value if the new value is greater than the previous value\n+            if (newSnapshotTickNanos > previousSnapshotTickNanos) {\n+                // store the previous value\n+                previousSnapshotTickNanos = newSnapshotTickNanos;\n+                // update the tick value using the callback\n+                tickUpdatedCallback.accept(newSnapshotTickNanos);\n+            }\n+        }\n     }\n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucket.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucket.java\nindex 8edc73d1f51e3..f2eae8aed8d9c 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucket.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucket.java\n@@ -34,15 +34,16 @@ public class DynamicRateAsyncTokenBucket extends AsyncTokenBucket {\n \n     protected DynamicRateAsyncTokenBucket(double capacityFactor, LongSupplier rateFunction,\n                                           MonotonicSnapshotClock clockSource, LongSupplier ratePeriodNanosFunction,\n-                                          long resolutionNanos, double initialTokensFactor,\n+                                          long resolutionNanos, boolean consistentConsumedTokens,\n+                                          boolean consistentAddedTokens, double initialTokensFactor,\n                                           double targetFillFactorAfterThrottling) {\n-        super(clockSource, resolutionNanos);\n+        super(clockSource, resolutionNanos, consistentConsumedTokens, consistentAddedTokens);\n         this.capacityFactor = capacityFactor;\n         this.rateFunction = rateFunction;\n         this.ratePeriodNanosFunction = ratePeriodNanosFunction;\n         this.targetFillFactorAfterThrottling = targetFillFactorAfterThrottling;\n         this.tokens = (long) (rateFunction.getAsLong() * initialTokensFactor);\n-        tokens(false);\n+        getTokens();\n     }\n \n     @Override\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucketBuilder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucketBuilder.java\nindex 22270484c72f0..8aebecddf90c7 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucketBuilder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/DynamicRateAsyncTokenBucketBuilder.java\n@@ -64,9 +64,7 @@ public DynamicRateAsyncTokenBucketBuilder targetFillFactorAfterThrottling(\n     @Override\n     public AsyncTokenBucket build() {\n         return new DynamicRateAsyncTokenBucket(this.capacityFactor, this.rateFunction,\n-                this.clock,\n-                this.ratePeriodNanosFunction, this.resolutionNanos,\n-                this.initialFillFactor,\n-                targetFillFactorAfterThrottling);\n+                this.clock, this.ratePeriodNanosFunction, this.resolutionNanos, this.consistentConsumedTokens,\n+                this.consistentAddedTokens, this.initialFillFactor, targetFillFactorAfterThrottling);\n     }\n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucket.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucket.java\nindex 627c5ee1334b2..d83290b723f07 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucket.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucket.java\n@@ -30,15 +30,16 @@ class FinalRateAsyncTokenBucket extends AsyncTokenBucket {\n     private final long targetAmountOfTokensAfterThrottling;\n \n     protected FinalRateAsyncTokenBucket(long capacity, long rate, MonotonicSnapshotClock clockSource,\n-                                        long ratePeriodNanos, long resolutionNanos, long initialTokens) {\n-        super(clockSource, resolutionNanos);\n+                                        long ratePeriodNanos, long resolutionNanos, boolean consistentConsumedTokens,\n+                                        boolean consistentAddedTokens, long initialTokens) {\n+        super(clockSource, resolutionNanos, consistentConsumedTokens, consistentAddedTokens);\n         this.capacity = capacity;\n         this.rate = rate;\n         this.ratePeriodNanos = ratePeriodNanos != -1 ? ratePeriodNanos : ONE_SECOND_NANOS;\n         // The target amount of tokens is the amount of tokens made available in the resolution duration\n         this.targetAmountOfTokensAfterThrottling = Math.max(this.resolutionNanos * rate / ratePeriodNanos, 1);\n         this.tokens = initialTokens;\n-        tokens(false);\n+        getTokens();\n     }\n \n     @Override\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucketBuilder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucketBuilder.java\nindex ff4ed53c6c7fa..a292000eaa825 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucketBuilder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/qos/FinalRateAsyncTokenBucketBuilder.java\n@@ -55,7 +55,7 @@ public FinalRateAsyncTokenBucketBuilder initialTokens(long initialTokens) {\n     public AsyncTokenBucket build() {\n         return new FinalRateAsyncTokenBucket(this.capacity != null ? this.capacity : this.rate, this.rate,\n                 this.clock,\n-                this.ratePeriodNanos, this.resolutionNanos,\n+                this.ratePeriodNanos, this.resolutionNanos, this.consistentConsumedTokens, this.consistentAddedTokens,\n                 this.initialTokens != null ? this.initialTokens : this.rate\n         );\n     }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex 79e6fb2b02e31..3e9c6302ceade 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -2506,6 +2506,12 @@ public long getNumberOfNamespaceBundles() {\n \n \n     private void handleMetadataChanges(Notification n) {\n+        if (!pulsar.isRunning()) {\n+            // Ignore metadata changes when broker is not running\n+            log.info(\"Ignoring metadata change since broker is not running (id={}, state={}) {}\", pulsar.getBrokerId(),\n+                    pulsar.getState(), n);\n+            return;\n+        }\n         if (n.getType() == NotificationType.Modified && NamespaceResources.pathIsFromNamespace(n.getPath())) {\n             NamespaceName ns = NamespaceResources.namespaceFromPath(n.getPath());\n             handlePoliciesUpdates(ns);\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PublishRateLimiterImpl.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PublishRateLimiterImpl.java\nindex 8255d9b6931ff..90c8de5f97a05 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PublishRateLimiterImpl.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PublishRateLimiterImpl.java\n@@ -20,11 +20,11 @@\n package org.apache.pulsar.broker.service;\n \n import com.google.common.annotations.VisibleForTesting;\n-import io.netty.channel.EventLoopGroup;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicInteger;\n+import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n import org.apache.pulsar.broker.qos.MonotonicSnapshotClock;\n import org.apache.pulsar.common.policies.data.Policies;\n@@ -32,6 +32,7 @@\n import org.jctools.queues.MessagePassingQueue;\n import org.jctools.queues.MpscUnboundedArrayQueue;\n \n+@Slf4j\n public class PublishRateLimiterImpl implements PublishRateLimiter {\n     private volatile AsyncTokenBucket tokenBucketOnMessage;\n     private volatile AsyncTokenBucket tokenBucketOnByte;\n@@ -80,7 +81,7 @@ private void scheduleDecrementThrottleCount(Producer producer) {\n         // schedule unthrottling when the throttling count is incremented to 1\n         // this is to avoid scheduling unthrottling multiple times for concurrent producers\n         if (throttledProducersCount.incrementAndGet() == 1) {\n-            EventLoopGroup executor = producer.getCnx().getBrokerService().executor();\n+            ScheduledExecutorService executor = producer.getCnx().getBrokerService().executor().next();\n             scheduleUnthrottling(executor, calculateThrottlingDurationNanos());\n         }\n     }\n@@ -134,7 +135,11 @@ private void unthrottleQueuedProducers(ScheduledExecutorService executor) {\n             // unthrottle as many producers as possible while there are token available\n             while ((throttlingDuration = calculateThrottlingDurationNanos()) == 0L\n                     && (producer = unthrottlingQueue.poll()) != null) {\n-                producer.decrementThrottleCount();\n+                try {\n+                    producer.decrementThrottleCount();\n+                } catch (Exception e) {\n+                    log.error(\"Failed to unthrottle producer {}\", producer, e);\n+                }\n                 throttledProducersCount.decrementAndGet();\n             }\n             // if there are still producers to be unthrottled, schedule unthrottling again\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/DispatchRateLimiter.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/DispatchRateLimiter.java\nindex b29cbcd660db1..f43b134eb122a 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/DispatchRateLimiter.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/DispatchRateLimiter.java\n@@ -23,6 +23,7 @@\n import java.util.concurrent.TimeUnit;\n import org.apache.pulsar.broker.ServiceConfiguration;\n import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n+import org.apache.pulsar.broker.qos.AsyncTokenBucketBuilder;\n import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.common.naming.NamespaceName;\n import org.apache.pulsar.common.naming.TopicName;\n@@ -76,7 +77,9 @@ public DispatchRateLimiter(BrokerService brokerService) {\n      * @return\n      */\n     public long getAvailableDispatchRateLimitOnMsg() {\n-        return dispatchRateLimiterOnMessage == null ? -1 : Math.max(dispatchRateLimiterOnMessage.getTokens(), 0);\n+        AsyncTokenBucket localDispatchRateLimiterOnMessage = dispatchRateLimiterOnMessage;\n+        return localDispatchRateLimiterOnMessage == null ? -1 :\n+                Math.max(localDispatchRateLimiterOnMessage.getTokens(), 0);\n     }\n \n     /**\n@@ -85,7 +88,8 @@ public long getAvailableDispatchRateLimitOnMsg() {\n      * @return\n      */\n     public long getAvailableDispatchRateLimitOnByte() {\n-        return dispatchRateLimiterOnByte == null ? -1 : Math.max(dispatchRateLimiterOnByte.getTokens(), 0);\n+        AsyncTokenBucket localDispatchRateLimiterOnByte = dispatchRateLimiterOnByte;\n+        return localDispatchRateLimiterOnByte == null ? -1 : Math.max(localDispatchRateLimiterOnByte.getTokens(), 0);\n     }\n \n     /**\n@@ -95,11 +99,13 @@ public long getAvailableDispatchRateLimitOnByte() {\n      * @param byteSize\n      */\n     public void consumeDispatchQuota(long numberOfMessages, long byteSize) {\n-        if (numberOfMessages > 0 && dispatchRateLimiterOnMessage != null) {\n-            dispatchRateLimiterOnMessage.consumeTokens(numberOfMessages);\n+        AsyncTokenBucket localDispatchRateLimiterOnMessage = dispatchRateLimiterOnMessage;\n+        if (numberOfMessages > 0 && localDispatchRateLimiterOnMessage != null) {\n+            localDispatchRateLimiterOnMessage.consumeTokens(numberOfMessages);\n         }\n-        if (byteSize > 0 && dispatchRateLimiterOnByte != null) {\n-            dispatchRateLimiterOnByte.consumeTokens(byteSize);\n+        AsyncTokenBucket localDispatchRateLimiterOnByte = dispatchRateLimiterOnByte;\n+        if (byteSize > 0 && localDispatchRateLimiterOnByte != null) {\n+            localDispatchRateLimiterOnByte.consumeTokens(byteSize);\n         }\n     }\n \n@@ -221,13 +227,14 @@ public synchronized void updateDispatchRate(DispatchRate dispatchRate) {\n         if (msgRate > 0) {\n             if (dispatchRate.isRelativeToPublishRate()) {\n                 this.dispatchRateLimiterOnMessage =\n-                        AsyncTokenBucket.builderForDynamicRate()\n+                        configureAsyncTokenBucket(AsyncTokenBucket.builderForDynamicRate())\n                                 .rateFunction(() -> getRelativeDispatchRateInMsg(dispatchRate))\n                                 .ratePeriodNanosFunction(() -> ratePeriodNanos)\n                                 .build();\n             } else {\n                 this.dispatchRateLimiterOnMessage =\n-                        AsyncTokenBucket.builder().rate(msgRate).ratePeriodNanos(ratePeriodNanos)\n+                        configureAsyncTokenBucket(AsyncTokenBucket.builder())\n+                                .rate(msgRate).ratePeriodNanos(ratePeriodNanos)\n                                 .build();\n             }\n         } else {\n@@ -238,13 +245,14 @@ public synchronized void updateDispatchRate(DispatchRate dispatchRate) {\n         if (byteRate > 0) {\n             if (dispatchRate.isRelativeToPublishRate()) {\n                 this.dispatchRateLimiterOnByte =\n-                        AsyncTokenBucket.builderForDynamicRate()\n+                        configureAsyncTokenBucket(AsyncTokenBucket.builderForDynamicRate())\n                                 .rateFunction(() -> getRelativeDispatchRateInByte(dispatchRate))\n                                 .ratePeriodNanosFunction(() -> ratePeriodNanos)\n                                 .build();\n             } else {\n                 this.dispatchRateLimiterOnByte =\n-                        AsyncTokenBucket.builder().rate(byteRate).ratePeriodNanos(ratePeriodNanos)\n+                        configureAsyncTokenBucket(AsyncTokenBucket.builder())\n+                                .rate(byteRate).ratePeriodNanos(ratePeriodNanos)\n                                 .build();\n             }\n         } else {\n@@ -252,6 +260,11 @@ public synchronized void updateDispatchRate(DispatchRate dispatchRate) {\n         }\n     }\n \n+    private <T extends AsyncTokenBucketBuilder<T>> T configureAsyncTokenBucket(T builder) {\n+        builder.clock(brokerService.getPulsar().getMonotonicSnapshotClock());\n+        return builder;\n+    }\n+\n     private long getRelativeDispatchRateInMsg(DispatchRate dispatchRate) {\n         return (topic != null && dispatchRate != null)\n                 ? (long) topic.getLastUpdatedAvgPublishRateInMsg() + dispatchRate.getDispatchThrottlingRateInMsg()\n@@ -270,7 +283,8 @@ private long getRelativeDispatchRateInByte(DispatchRate dispatchRate) {\n      * @return\n      */\n     public long getDispatchRateOnMsg() {\n-        return dispatchRateLimiterOnMessage != null ? dispatchRateLimiterOnMessage.getRate() : -1;\n+        AsyncTokenBucket localDispatchRateLimiterOnMessage = dispatchRateLimiterOnMessage;\n+        return localDispatchRateLimiterOnMessage != null ? localDispatchRateLimiterOnMessage.getRate() : -1;\n     }\n \n     /**\n@@ -279,7 +293,8 @@ public long getDispatchRateOnMsg() {\n      * @return\n      */\n     public long getDispatchRateOnByte() {\n-        return dispatchRateLimiterOnByte != null ? dispatchRateLimiterOnByte.getRate() : -1;\n+        AsyncTokenBucket localDispatchRateLimiterOnByte = dispatchRateLimiterOnByte;\n+        return localDispatchRateLimiterOnByte != null ? localDispatchRateLimiterOnByte.getRate() : -1;\n     }\n \n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/SubscribeRateLimiter.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/SubscribeRateLimiter.java\nindex b1de10e73b76f..0f98ab94142c8 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/SubscribeRateLimiter.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/SubscribeRateLimiter.java\n@@ -70,7 +70,7 @@ public synchronized boolean tryAcquire(ConsumerIdentifier consumerIdentifier) {\n         if (tokenBucket == null) {\n             return true;\n         }\n-        if (!tokenBucket.containsTokens(true)) {\n+        if (!tokenBucket.containsTokens()) {\n             return false;\n         }\n         tokenBucket.consumeTokens(1);\n@@ -117,7 +117,11 @@ private synchronized void updateSubscribeRate(ConsumerIdentifier consumerIdentif\n         // update subscribe-rateLimiter\n         if (ratePerConsumer > 0) {\n             AsyncTokenBucket tokenBucket =\n-                    AsyncTokenBucket.builder().rate(ratePerConsumer).ratePeriodNanos(ratePeriodNanos).build();\n+                    AsyncTokenBucket.builder()\n+                            .consistentAddedTokens(true)\n+                            .consistentConsumedTokens(true)\n+                            .clock(brokerService.getPulsar().getMonotonicSnapshotClock())\n+                            .rate(ratePerConsumer).ratePeriodNanos(ratePeriodNanos).build();\n             this.subscribeRateLimiter.put(consumerIdentifier, tokenBucket);\n         } else {\n             // subscribe-rate should be disable and close\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java\nindex 8dd2fc1c3c26d..42e2c00f73acf 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/MockedPulsarServiceBaseTest.java\n@@ -170,20 +170,26 @@ protected final void resetConfig() {\n \n     protected final void internalSetup() throws Exception {\n         init();\n-        lookupUrl = new URI(brokerUrl.toString());\n-        if (isTcpLookup) {\n-            lookupUrl = new URI(pulsar.getBrokerServiceUrl());\n-\n+        lookupUrl = resolveLookupUrl();\n+        if (isTcpLookup && enableBrokerGateway) {\n             // setup port forwarding from the advertised port to the listen port\n-            if (enableBrokerGateway) {\n-                InetSocketAddress gatewayAddress = new InetSocketAddress(lookupUrl.getHost(), lookupUrl.getPort());\n-                InetSocketAddress brokerAddress = new InetSocketAddress(\"127.0.0.1\", pulsar.getBrokerListenPort().get());\n-                brokerGateway = new PortForwarder(gatewayAddress, brokerAddress);\n-            }\n+            InetSocketAddress gatewayAddress = new InetSocketAddress(lookupUrl.getHost(), lookupUrl.getPort());\n+            InetSocketAddress brokerAddress = new InetSocketAddress(\"127.0.0.1\", pulsar.getBrokerListenPort().get());\n+            brokerGateway = new PortForwarder(gatewayAddress, brokerAddress);\n         }\n         pulsarClient = newPulsarClient(lookupUrl.toString(), 0);\n     }\n \n+    private URI resolveLookupUrl() {\n+        if (isTcpLookup) {\n+            return URI.create(pulsar.getBrokerServiceUrl());\n+        } else {\n+            return URI.create(brokerUrl != null\n+                    ? brokerUrl.toString()\n+                    : brokerUrlTls.toString());\n+        }\n+    }\n+\n     protected final void internalSetup(ServiceConfiguration serviceConfiguration) throws Exception {\n         this.conf = serviceConfiguration;\n         internalSetup();\n@@ -228,11 +234,10 @@ protected PulsarClient replacePulsarClient(ClientBuilder clientBuilder) throws P\n \n     protected final void internalSetupForStatsTest() throws Exception {\n         init();\n-        String lookupUrl = brokerUrl.toString();\n-        if (isTcpLookup) {\n-            lookupUrl = new URI(pulsar.getBrokerServiceUrl()).toString();\n+        if (pulsarClient != null) {\n+            pulsarClient.shutdown();\n         }\n-        pulsarClient = newPulsarClient(lookupUrl, 1);\n+        pulsarClient = newPulsarClient(resolveLookupUrl().toString(), 1);\n     }\n \n     protected void doInitConf() throws Exception {\n@@ -360,6 +365,9 @@ protected void afterPulsarStart(PulsarService pulsar) throws Exception {\n     protected void restartBroker() throws Exception {\n         stopBroker();\n         startBroker();\n+        if (pulsarClient == null) {\n+            pulsarClient = newPulsarClient(lookupUrl.toString(), 0);\n+        }\n     }\n \n     protected void stopBroker() throws Exception {\n@@ -384,12 +392,16 @@ protected void startBroker() throws Exception {\n         brokerUrl = pulsar.getWebServiceAddress() != null ? new URL(pulsar.getWebServiceAddress()) : null;\n         brokerUrlTls = pulsar.getWebServiceAddressTls() != null ? new URL(pulsar.getWebServiceAddressTls()) : null;\n \n-        if (admin != null) {\n-            admin.close();\n-            if (MockUtil.isMock(admin)) {\n-                Mockito.reset(admin);\n+        URI newLookupUrl = resolveLookupUrl();\n+        if (lookupUrl == null || !newLookupUrl.equals(lookupUrl)) {\n+            lookupUrl = newLookupUrl;\n+            if (pulsarClient != null) {\n+                pulsarClient.shutdown();\n+                pulsarClient = newPulsarClient(lookupUrl.toString(), 0);\n             }\n         }\n+\n+        closeAdmin();\n         PulsarAdminBuilder pulsarAdminBuilder = PulsarAdmin.builder().serviceHttpUrl(brokerUrl != null\n                 ? brokerUrl.toString()\n                 : brokerUrlTls.toString());\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java\nindex b446f9e902f2a..82793f2748d78 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/AsyncTokenBucketTest.java\n@@ -19,6 +19,7 @@\n \n package org.apache.pulsar.broker.qos;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.testng.Assert.assertEquals;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicLong;\n@@ -50,7 +51,8 @@ private void incrementMillis(long millis) {\n     @Test\n     void shouldAddTokensWithConfiguredRate() {\n         asyncTokenBucket =\n-                AsyncTokenBucket.builder().capacity(100).rate(10).initialTokens(0).clock(clockSource).build();\n+                AsyncTokenBucket.builder().consistentConsumedTokens(true)\n+                        .capacity(100).rate(10).initialTokens(0).clock(clockSource).build();\n         incrementSeconds(5);\n         assertEquals(asyncTokenBucket.getTokens(), 50);\n         incrementSeconds(1);\n@@ -64,7 +66,7 @@ void shouldAddTokensWithConfiguredRate() {\n \n         // Consume all and verify none available and then wait 1 period and check replenished\n         asyncTokenBucket.consumeTokens(100);\n-        assertEquals(asyncTokenBucket.tokens(true), 0);\n+        assertEquals(asyncTokenBucket.getTokens(), 0);\n         incrementSeconds(1);\n         assertEquals(asyncTokenBucket.getTokens(), 10);\n     }\n@@ -91,13 +93,148 @@ void shouldSupportFractionsWhenUpdatingTokens() {\n     @Test\n     void shouldSupportFractionsAndRetainLeftoverWhenUpdatingTokens() {\n         asyncTokenBucket =\n-                AsyncTokenBucket.builder().capacity(100).rate(10).initialTokens(0).clock(clockSource).build();\n+                AsyncTokenBucket.builder().capacity(100)\n+                        .resolutionNanos(TimeUnit.MILLISECONDS.toNanos(1))\n+                        .rate(10)\n+                        .initialTokens(0)\n+                        .clock(clockSource)\n+                        .build();\n         for (int i = 0; i < 150; i++) {\n             incrementMillis(1);\n         }\n         assertEquals(asyncTokenBucket.getTokens(), 1);\n         incrementMillis(150);\n         assertEquals(asyncTokenBucket.getTokens(), 3);\n+        incrementMillis(1);\n+        assertEquals(asyncTokenBucket.getTokens(), 3);\n+        incrementMillis(99);\n+        assertEquals(asyncTokenBucket.getTokens(), 4);\n+    }\n+\n+    @Test\n+    void shouldSupportFractionsAndRetainLeftoverWhenUpdatingTokens2() {\n+        asyncTokenBucket =\n+                AsyncTokenBucket.builder().capacity(100)\n+                        .resolutionNanos(TimeUnit.MILLISECONDS.toNanos(1))\n+                        .rate(1)\n+                        .initialTokens(0)\n+                        .clock(clockSource)\n+                        .build();\n+        for (int i = 0; i < 150; i++) {\n+            incrementMillis(1);\n+            assertEquals(asyncTokenBucket.getTokens(), 0);\n+        }\n+        incrementMillis(150);\n+        assertEquals(asyncTokenBucket.getTokens(), 0);\n+        incrementMillis(699);\n+        assertEquals(asyncTokenBucket.getTokens(), 0);\n+        incrementMillis(1);\n+        assertEquals(asyncTokenBucket.getTokens(), 1);\n+        incrementMillis(1000);\n+        assertEquals(asyncTokenBucket.getTokens(), 2);\n+    }\n+\n+    @Test\n+    void shouldHandleNegativeBalanceWithEventuallyConsistentTokenUpdates() {\n+        asyncTokenBucket =\n+                AsyncTokenBucket.builder()\n+                        // intentionally pick a coarse resolution\n+                        .resolutionNanos(TimeUnit.SECONDS.toNanos(51))\n+                        .capacity(100).rate(10).initialTokens(0).clock(clockSource).build();\n+        // assert that the token balance is 0 initially\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(0);\n+\n+        // consume tokens without exceeding the rate\n+        for (int i = 0; i < 10000; i++) {\n+            asyncTokenBucket.consumeTokens(500);\n+            incrementSeconds(50);\n+        }\n+\n+        // let 9 seconds pass\n+        incrementSeconds(9);\n+\n+        // there should be 90 tokens available\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(90);\n     }\n \n+    @Test\n+    void shouldNotExceedTokenBucketSizeWithNegativeTokens() {\n+        asyncTokenBucket =\n+                AsyncTokenBucket.builder()\n+                        // intentionally pick a coarse resolution\n+                        .resolutionNanos(TimeUnit.SECONDS.toNanos(51))\n+                        .capacity(100).rate(10).initialTokens(0).clock(clockSource).build();\n+        // assert that the token balance is 0 initially\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(0);\n+\n+        // consume tokens without exceeding the rate\n+        for (int i = 0; i < 100; i++) {\n+            asyncTokenBucket.consumeTokens(600);\n+            incrementSeconds(50);\n+            // let tokens accumulate back to 0 every 10 seconds\n+            if ((i + 1) % 10 == 0) {\n+                incrementSeconds(100);\n+            }\n+        }\n+\n+        // let 9 seconds pass\n+        incrementSeconds(9);\n+\n+        // there should be 90 tokens available\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(90);\n+    }\n+\n+    @Test\n+    void shouldAccuratelyCalculateTokensWhenTimeIsLaggingBehindInInconsistentUpdates() {\n+        clockSource = requestSnapshot -> {\n+          if (requestSnapshot) {\n+              return manualClockSource.get();\n+          } else {\n+              // let the clock lag behind\n+              return manualClockSource.get() - TimeUnit.SECONDS.toNanos(52);\n+          }\n+        };\n+        incrementSeconds(1);\n+        asyncTokenBucket =\n+                AsyncTokenBucket.builder().resolutionNanos(TimeUnit.SECONDS.toNanos(51))\n+                        .capacity(100).rate(10).initialTokens(100).clock(clockSource).build();\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(100);\n+\n+        // consume tokens without exceeding the rate\n+        for (int i = 0; i < 10000; i++) {\n+            asyncTokenBucket.consumeTokens(500);\n+            incrementSeconds(i == 0 ? 40 : 50);\n+        }\n+\n+        // let 9 seconds pass\n+        incrementSeconds(9);\n+\n+        // there should be 90 tokens available\n+        assertThat(asyncTokenBucket.getTokens()).isEqualTo(90);\n+    }\n+\n+    @Test\n+    void shouldHandleEventualConsistency() {\n+        AtomicLong offset = new AtomicLong(0);\n+        long resolutionNanos = TimeUnit.MILLISECONDS.toNanos(1);\n+        DefaultMonotonicSnapshotClock monotonicSnapshotClock =\n+                new DefaultMonotonicSnapshotClock(resolutionNanos,\n+                        () -> offset.get() + manualClockSource.get());\n+        long initialTokens = 500L;\n+        asyncTokenBucket =\n+                AsyncTokenBucket.builder()\n+                        .consistentConsumedTokens(true)\n+                        .resolutionNanos(resolutionNanos)\n+                        .capacity(100000).rate(1000).initialTokens(initialTokens).clock(monotonicSnapshotClock).build();\n+        for (int i = 0; i < 100000; i++) {\n+            // increment the clock by 1ms, since rate is 1000 tokens/s, this should make 1 token available\n+            incrementMillis(1);\n+            // consume 1 token\n+            asyncTokenBucket.consumeTokens(1);\n+        }\n+        assertThat(asyncTokenBucket.getTokens())\n+                // since the rate is 1/ms and the test increments the clock by 1ms and consumes 1 token in each\n+                // iteration, the tokens should be equal to the initial tokens\n+                .isEqualTo(initialTokens);\n+    }\n }\n\\ No newline at end of file\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockTest.java\nnew file mode 100644\nindex 0000000000000..0820b439915bb\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/qos/DefaultMonotonicSnapshotClockTest.java\n@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pulsar.broker.qos;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import java.time.Duration;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import org.assertj.core.data.Offset;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+@Slf4j\n+public class DefaultMonotonicSnapshotClockTest {\n+    @DataProvider\n+    private static Object[] booleanValues() {\n+        return new Object[]{ true, false };\n+    }\n+\n+    @Test(dataProvider = \"booleanValues\")\n+    void testClockHandlesTimeLeapsBackwards(boolean requestSnapshot) throws InterruptedException {\n+        long snapshotIntervalMillis = 5;\n+        AtomicLong clockValue = new AtomicLong(1);\n+        @Cleanup\n+        DefaultMonotonicSnapshotClock clock =\n+                new DefaultMonotonicSnapshotClock(Duration.ofMillis(snapshotIntervalMillis).toNanos(),\n+                        clockValue::get);\n+\n+\n+        long previousTick = -1;\n+        boolean leapDirection = true;\n+        for (int i = 0; i < 10000; i++) {\n+            clockValue.addAndGet(TimeUnit.MILLISECONDS.toNanos(1));\n+            long tick = clock.getTickNanos(requestSnapshot);\n+            //log.info(\"i = {}, tick = {}\", i, tick);\n+            if ((i + 1) % 5 == 0) {\n+                leapDirection = !leapDirection;\n+                //log.info(\"Time leap 5 minutes backwards\");\n+                clockValue.addAndGet(-Duration.ofMinutes(5).toNanos());\n+            }\n+            if (previousTick != -1) {\n+                assertThat(tick)\n+                        .describedAs(\"i = %d, tick = %d, previousTick = %d\", i, tick, previousTick)\n+                        .isGreaterThanOrEqualTo(previousTick)\n+                        .isCloseTo(previousTick,\n+                                // then snapshot is requested, the time difference between the two ticks is accurate\n+                                // otherwise allow time difference at most 4 times the snapshot interval since the\n+                                // clock is updated periodically by a background thread\n+                                Offset.offset(TimeUnit.MILLISECONDS.toNanos(\n+                                        requestSnapshot ? 1 : 4 * snapshotIntervalMillis)));\n+            }\n+            previousTick = tick;\n+        }\n+    }\n+\n+    @Test\n+    void testRequestUpdate() throws InterruptedException {\n+        @Cleanup\n+        DefaultMonotonicSnapshotClock clock =\n+                new DefaultMonotonicSnapshotClock(Duration.ofSeconds(5).toNanos(), System::nanoTime);\n+        long tick1 = clock.getTickNanos(false);\n+        long tick2 = clock.getTickNanos(true);\n+        assertThat(tick2).isGreaterThan(tick1);\n+    }\n+\n+    @Test\n+    void testRequestingSnapshotAfterClosed() throws InterruptedException {\n+        DefaultMonotonicSnapshotClock clock =\n+                new DefaultMonotonicSnapshotClock(Duration.ofSeconds(5).toNanos(), System::nanoTime);\n+        clock.close();\n+        long tick1 = clock.getTickNanos(true);\n+        Thread.sleep(10);\n+        long tick2 = clock.getTickNanos(true);\n+        assertThat(tick2).isGreaterThan(tick1);\n+    }\n+\n+    @Test\n+    void testConstructorValidation() {\n+        assertThatThrownBy(() -> new DefaultMonotonicSnapshotClock(0, System::nanoTime))\n+                .isInstanceOf(IllegalArgumentException.class)\n+                .hasMessage(\"snapshotIntervalNanos must be at least 1 millisecond\");\n+        assertThatThrownBy(() -> new DefaultMonotonicSnapshotClock(-1, System::nanoTime))\n+                .isInstanceOf(IllegalArgumentException.class)\n+                .hasMessage(\"snapshotIntervalNanos must be at least 1 millisecond\");\n+        assertThatThrownBy(() -> new DefaultMonotonicSnapshotClock(TimeUnit.MILLISECONDS.toNanos(1), null))\n+                .isInstanceOf(NullPointerException.class)\n+                .hasMessage(\"clockSource must not be null\");\n+    }\n+\n+    @Test\n+    void testFailureHandlingInClockSource() {\n+        @Cleanup\n+        DefaultMonotonicSnapshotClock clock =\n+                new DefaultMonotonicSnapshotClock(Duration.ofSeconds(5).toNanos(), () -> {\n+                    throw new RuntimeException(\"Test clock failure\");\n+                });\n+        // the exception should be propagated\n+        assertThatThrownBy(() -> clock.getTickNanos(true))\n+                .isInstanceOf(RuntimeException.class)\n+                .hasMessage(\"Test clock failure\");\n+    }\n+\n+    @Test\n+    void testLeapDetectionIndependently() {\n+        AtomicLong clockValue = new AtomicLong(0);\n+        AtomicLong tickValue = new AtomicLong(0);\n+        long expectedTickValue = 0;\n+        long snapshotIntervalNanos = TimeUnit.MILLISECONDS.toNanos(1);\n+        DefaultMonotonicSnapshotClock.MonotonicLeapDetectingTickUpdater updater =\n+                new DefaultMonotonicSnapshotClock.MonotonicLeapDetectingTickUpdater(clockValue::get, tickValue::set,\n+                        snapshotIntervalNanos);\n+\n+        updater.update(true);\n+\n+        // advance the clock\n+        clockValue.addAndGet(snapshotIntervalNanos);\n+        expectedTickValue += snapshotIntervalNanos;\n+        updater.update(true);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // simulate a leap backwards in time\n+        clockValue.addAndGet(-10 * snapshotIntervalNanos);\n+        expectedTickValue += snapshotIntervalNanos;\n+        updater.update(true);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // advance the clock\n+        clockValue.addAndGet(snapshotIntervalNanos);\n+        expectedTickValue += snapshotIntervalNanos;\n+        updater.update(true);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // simulate a leap backwards in time, without waiting a full snapshot interval\n+        clockValue.addAndGet(-10 * snapshotIntervalNanos);\n+        updater.update(false);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // advance the clock\n+        clockValue.addAndGet(snapshotIntervalNanos);\n+        expectedTickValue += snapshotIntervalNanos;\n+        updater.update(true);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // simulate a small leap backwards in time which isn't detected, without waiting a full snapshot interval\n+        clockValue.addAndGet(-1 * snapshotIntervalNanos);\n+        updater.update(false);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+        // clock doesn't advance for one snapshot interval\n+        clockValue.addAndGet(snapshotIntervalNanos);\n+        updater.update(false);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+        // now the clock should advance again\n+        clockValue.addAndGet(snapshotIntervalNanos);\n+        expectedTickValue += snapshotIntervalNanos;\n+        updater.update(false);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+\n+        // simulate a leap forward\n+        clockValue.addAndGet(10 * snapshotIntervalNanos);\n+        // no special handling for leap forward\n+        expectedTickValue += 10 * snapshotIntervalNanos;\n+        updater.update(true);\n+        assertThat(tickValue.get()).isEqualTo(expectedTickValue);\n+    }\n+}\n\\ No newline at end of file\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java\nindex 392ec0d3ff46f..8343680f9bf7b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/resourcegroup/RGUsageMTAggrWaitForAllMsgsTest.java\n@@ -25,6 +25,7 @@\n import java.util.Map;\n import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n import org.apache.pulsar.broker.resourcegroup.ResourceGroup.BytesAndMessagesCount;\n import org.apache.pulsar.broker.resourcegroup.ResourceGroup.ResourceGroupMonitoringClass;\n import org.apache.pulsar.broker.resourcegroup.ResourceGroupService.ResourceGroupUsageStatsType;\n@@ -58,9 +59,10 @@\n @Slf4j\n @Test(groups = \"flaky\")\n public class RGUsageMTAggrWaitForAllMsgsTest extends ProducerConsumerBase {\n-    @BeforeClass\n+    @BeforeClass(alwaysRun = true)\n     @Override\n     protected void setup() throws Exception {\n+        AsyncTokenBucket.switchToConsistentTokensView();\n         super.internalSetup();\n         this.prepareForOps();\n \n@@ -91,6 +93,7 @@ public long computeLocalQuota(long confUsage, long myUsage, long[] allUsages) {\n     @Override\n     protected void cleanup() throws Exception {\n         super.internalCleanup();\n+        AsyncTokenBucket.resetToDefaultEventualConsistentTokensView();\n     }\n \n     @Test\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java\nindex 2c44ba7e23004..5c149d4e1e792 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PublishRateLimiterTest.java\n@@ -26,6 +26,7 @@\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.when;\n import static org.testng.Assert.assertEquals;\n+import io.netty.channel.EventLoop;\n import io.netty.channel.EventLoopGroup;\n import java.util.HashMap;\n import java.util.concurrent.TimeUnit;\n@@ -73,7 +74,9 @@ public void setup() throws Exception {\n         when(transportCnx.getBrokerService()).thenReturn(brokerService);\n         EventLoopGroup eventLoopGroup = mock(EventLoopGroup.class);\n         when(brokerService.executor()).thenReturn(eventLoopGroup);\n-        doReturn(null).when(eventLoopGroup).schedule(any(Runnable.class), anyLong(), any());\n+        EventLoop eventLoop = mock(EventLoop.class);\n+        when(eventLoopGroup.next()).thenReturn(eventLoop);\n+        doReturn(null).when(eventLoop).schedule(any(Runnable.class), anyLong(), any());\n         incrementSeconds(1);\n     }\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/AbstractMessageDispatchThrottlingTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/AbstractMessageDispatchThrottlingTest.java\nnew file mode 100644\nindex 0000000000000..31c628b2bc4ca\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/AbstractMessageDispatchThrottlingTest.java\n@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.client.api;\n+\n+import java.lang.reflect.Field;\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.ScheduledExecutorService;\n+import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n+import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n+import org.apache.pulsar.broker.service.BrokerService;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.DataProvider;\n+\n+public abstract class AbstractMessageDispatchThrottlingTest extends ProducerConsumerBase {\n+    public static <T> T[] merge(T[] first, T[] last) {\n+        int totalLength = first.length + last.length;\n+        T[] result = Arrays.copyOf(first, totalLength);\n+        int offset = first.length;\n+        System.arraycopy(last, 0, result, offset, first.length);\n+        return result;\n+    }\n+\n+    @BeforeClass(alwaysRun = true)\n+    @Override\n+    protected void setup() throws Exception {\n+        AsyncTokenBucket.switchToConsistentTokensView();\n+        this.conf.setClusterName(\"test\");\n+        internalSetup();\n+        producerBaseSetup();\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    @Override\n+    protected void cleanup() throws Exception {\n+        internalCleanup();\n+        AsyncTokenBucket.resetToDefaultEventualConsistentTokensView();\n+    }\n+\n+    @AfterMethod(alwaysRun = true)\n+    protected void reset() throws Exception {\n+        pulsar.getConfiguration().setForceDeleteTenantAllowed(true);\n+        pulsar.getConfiguration().setForceDeleteNamespaceAllowed(true);\n+\n+        for (String tenant : admin.tenants().getTenants()) {\n+            for (String namespace : admin.namespaces().getNamespaces(tenant)) {\n+                admin.namespaces().deleteNamespace(namespace, true);\n+            }\n+            admin.tenants().deleteTenant(tenant, true);\n+        }\n+\n+        for (String cluster : admin.clusters().getClusters()) {\n+            admin.clusters().deleteCluster(cluster);\n+        }\n+\n+        pulsar.getConfiguration().setForceDeleteTenantAllowed(false);\n+        pulsar.getConfiguration().setForceDeleteNamespaceAllowed(false);\n+\n+        producerBaseSetup();\n+    }\n+\n+    @DataProvider(name = \"subscriptions\")\n+    public Object[][] subscriptionsProvider() {\n+        return new Object[][]{new Object[]{SubscriptionType.Shared}, {SubscriptionType.Exclusive}};\n+    }\n+\n+    @DataProvider(name = \"dispatchRateType\")\n+    public Object[][] dispatchRateProvider() {\n+        return new Object[][]{{DispatchRateType.messageRate}, {DispatchRateType.byteRate}};\n+    }\n+\n+    @DataProvider(name = \"subscriptionAndDispatchRateType\")\n+    public Object[][] subDisTypeProvider() {\n+        List<Object[]> mergeList = new LinkedList<>();\n+        for (Object[] sub : subscriptionsProvider()) {\n+            for (Object[] dispatch : dispatchRateProvider()) {\n+                mergeList.add(AbstractMessageDispatchThrottlingTest.merge(sub, dispatch));\n+            }\n+        }\n+        return mergeList.toArray(new Object[0][0]);\n+    }\n+\n+    protected void deactiveCursors(ManagedLedgerImpl ledger) throws Exception {\n+        Field statsUpdaterField = BrokerService.class.getDeclaredField(\"statsUpdater\");\n+        statsUpdaterField.setAccessible(true);\n+        ScheduledExecutorService statsUpdater = (ScheduledExecutorService) statsUpdaterField\n+                .get(pulsar.getBrokerService());\n+        statsUpdater.shutdownNow();\n+        ledger.getCursors().forEach(cursor -> {\n+            ledger.deactivateCursor(cursor);\n+        });\n+    }\n+\n+    enum DispatchRateType {\n+        messageRate, byteRate;\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java\nindex a544c7e13bc83..5d6f0c519abc6 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/MessageDispatchThrottlingTest.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.mockito.ArgumentMatchers.any;\n import static org.mockito.Mockito.atLeastOnce;\n import static org.mockito.Mockito.spy;\n@@ -27,15 +28,11 @@\n import static org.testng.Assert.fail;\n import com.google.common.collect.Sets;\n import java.lang.reflect.Field;\n-import java.util.Arrays;\n import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n import java.util.UUID;\n import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n import lombok.Cleanup;\n@@ -43,7 +40,7 @@\n import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n import org.apache.bookkeeper.mledger.impl.cache.PendingReadsManager;\n import org.apache.bookkeeper.mledger.impl.cache.RangeEntryCacheImpl;\n-import org.apache.pulsar.broker.service.BrokerService;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.broker.service.persistent.DispatchRateLimiter;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.common.policies.data.ClusterData;\n@@ -52,93 +49,17 @@\n import org.apache.pulsar.common.policies.data.PublishRate;\n import org.apache.pulsar.common.policies.data.RetentionPolicies;\n import org.apache.pulsar.common.policies.data.impl.DispatchRateImpl;\n-import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n+import org.assertj.core.data.Offset;\n import org.awaitility.Awaitility;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.testng.Assert;\n-import org.testng.annotations.AfterClass;\n-import org.testng.annotations.AfterMethod;\n-import org.testng.annotations.BeforeClass;\n-import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n-@Test(groups = \"flaky\")\n-public class MessageDispatchThrottlingTest extends ProducerConsumerBase {\n+@Test(groups = \"broker-api\")\n+public class MessageDispatchThrottlingTest extends AbstractMessageDispatchThrottlingTest {\n     private static final Logger log = LoggerFactory.getLogger(MessageDispatchThrottlingTest.class);\n \n-    @BeforeClass\n-    @Override\n-    protected void setup() throws Exception {\n-        AsyncTokenBucket.switchToConsistentTokensView();\n-        this.conf.setClusterName(\"test\");\n-        super.internalSetup();\n-        super.producerBaseSetup();\n-    }\n-\n-    @AfterClass(alwaysRun = true)\n-    @Override\n-    protected void cleanup() throws Exception {\n-        super.internalCleanup();\n-        AsyncTokenBucket.resetToDefaultEventualConsistentTokensView();\n-    }\n-\n-    @AfterMethod(alwaysRun = true)\n-    protected void reset() throws Exception {\n-        pulsar.getConfiguration().setForceDeleteTenantAllowed(true);\n-        pulsar.getConfiguration().setForceDeleteNamespaceAllowed(true);\n-\n-        for (String tenant : admin.tenants().getTenants()) {\n-            for (String namespace : admin.namespaces().getNamespaces(tenant)) {\n-                admin.namespaces().deleteNamespace(namespace, true);\n-            }\n-            admin.tenants().deleteTenant(tenant, true);\n-        }\n-\n-        for (String cluster : admin.clusters().getClusters()) {\n-            admin.clusters().deleteCluster(cluster);\n-        }\n-\n-        pulsar.getConfiguration().setForceDeleteTenantAllowed(false);\n-        pulsar.getConfiguration().setForceDeleteNamespaceAllowed(false);\n-\n-        super.producerBaseSetup();\n-    }\n-\n-\n-    @DataProvider(name = \"subscriptions\")\n-    public Object[][] subscriptionsProvider() {\n-        return new Object[][] { new Object[] { SubscriptionType.Shared }, { SubscriptionType.Exclusive } };\n-    }\n-\n-    @DataProvider(name = \"dispatchRateType\")\n-    public Object[][] dispatchRateProvider() {\n-        return new Object[][] { { DispatchRateType.messageRate }, { DispatchRateType.byteRate } };\n-    }\n-\n-    @DataProvider(name = \"subscriptionAndDispatchRateType\")\n-    public Object[][] subDisTypeProvider() {\n-        List<Object[]> mergeList = new LinkedList<>();\n-        for (Object[] sub : subscriptionsProvider()) {\n-            for (Object[] dispatch : dispatchRateProvider()) {\n-                mergeList.add(merge(sub, dispatch));\n-            }\n-        }\n-        return mergeList.toArray(new Object[0][0]);\n-    }\n-\n-    public static <T> T[] merge(T[] first, T[] last) {\n-        int totalLength = first.length + last.length;\n-        T[] result = Arrays.copyOf(first, totalLength);\n-        int offset = first.length;\n-        System.arraycopy(last, 0, result, offset, first.length);\n-        return result;\n-    }\n-\n-    enum DispatchRateType {\n-        messageRate, byteRate;\n-    }\n-\n     /**\n      * verifies: message-rate change gets reflected immediately into topic at runtime\n      *\n@@ -150,7 +71,7 @@ public void testMessageRateDynamicallyChange() throws Exception {\n \n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n \n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(\"test\"));\n@@ -220,7 +141,7 @@ public void testMessageRateDynamicallyChange() throws Exception {\n     @SuppressWarnings(\"deprecation\")\n     @Test\n     public void testSystemTopicDeliveryNonBlock() throws Exception {\n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(\"test\"));\n         final String topicName = \"persistent://\" + namespace + \"/\" + UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n         admin.topics().createNonPartitionedTopic(topicName);\n@@ -264,7 +185,7 @@ public void testMessageRateLimitingNotReceiveAllMessages(SubscriptionType subscr\n             DispatchRateType dispatchRateType) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n \n         final int messageRate = 100;\n@@ -332,7 +253,7 @@ public void testMessageRateLimitingNotReceiveAllMessages(SubscriptionType subscr\n     public void testClusterMsgByteRateLimitingClusterConfig() throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n         final int messageRate = 5;\n         final long byteRate = 1024 * 1024;// 1MB rate enough to let all msg to be delivered\n@@ -407,7 +328,7 @@ public void testMessageRateLimitingReceiveAllMessagesAfterThrottling(Subscriptio\n             throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingAll\";\n \n         final int messageRate = 10;\n@@ -475,7 +396,7 @@ public void testBytesRateLimitingReceiveAllMessagesAfterThrottling(SubscriptionT\n         conf.setDispatchThrottlingOnNonBacklogConsumerEnabled(true);\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingAll\";\n         final String subscriptionName = \"my-subscriber-name\";\n \n@@ -528,8 +449,9 @@ public void testBytesRateLimitingReceiveAllMessagesAfterThrottling(SubscriptionT\n     public void testRateLimitingMultipleConsumers() throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingMultipleConsumers\";\n+        conf.setDispatchThrottlingOnNonBacklogConsumerEnabled(true);\n \n         final int messageRate = 5;\n         DispatchRate dispatchRate = DispatchRate.builder()\n@@ -540,7 +462,8 @@ public void testRateLimitingMultipleConsumers() throws Exception {\n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(\"test\"));\n         admin.namespaces().setDispatchRate(namespace, dispatchRate);\n         // create producer and topic\n-        Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).create();\n+        @Cleanup\n+        Producer<byte[]> producer = pulsarClient.newProducer().enableBatching(false).topic(topicName).create();\n         PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService().getOrCreateTopic(topicName).get();\n \n         Awaitility.await()\n@@ -566,10 +489,15 @@ public void testRateLimitingMultipleConsumers() throws Exception {\n                         throw new RuntimeException(e);\n                     }\n                 });\n+        @Cleanup\n         Consumer<byte[]> consumer1 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer2 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer3 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer4 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer5 = consumerBuilder.subscribe();\n \n         // deactive cursors\n@@ -585,15 +513,10 @@ public void testRateLimitingMultipleConsumers() throws Exception {\n         Thread.sleep(1000);\n \n         // rate limiter should have limited messages with at least 10% accuracy (or 2 messages if messageRate is low)\n-        Assert.assertEquals(totalReceived.get(), messageRate, Math.max(messageRate / 10, 2));\n+        assertThat(totalReceived.get()).isCloseTo(messageRate, Offset.offset(Math.max(messageRate / 10, 2)));\n \n-        consumer1.close();\n-        consumer2.close();\n-        consumer3.close();\n-        consumer4.close();\n-        consumer5.close();\n-        producer.close();\n         log.info(\"-- Exiting {} test --\", methodName);\n+        conf.setDispatchThrottlingOnNonBacklogConsumerEnabled(false);\n     }\n \n     @Test\n@@ -602,7 +525,7 @@ public void testRateLimitingWithBatchMsgEnabled() throws Exception {\n \n         conf.setDispatchThrottlingOnBatchMessageEnabled(true);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingMultipleConsumers\";\n \n         final int messageRate = 5;\n@@ -614,6 +537,7 @@ public void testRateLimitingWithBatchMsgEnabled() throws Exception {\n         final int messagesPerBatch = 100;\n         final int numProducedMessages = messageRate * messagesPerBatch;\n         // create producer and topic\n+        @Cleanup\n         Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).enableBatching(true)\n                 .batchingMaxPublishDelay(1, TimeUnit.SECONDS).batchingMaxMessages(messagesPerBatch).create();\n         PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService().getOrCreateTopic(topicName).get();\n@@ -634,10 +558,15 @@ public void testRateLimitingWithBatchMsgEnabled() throws Exception {\n                     log.debug(\"Received message [{}] in the listener\", receivedMessage);\n                     totalReceived.incrementAndGet();\n                 });\n+        @Cleanup\n         Consumer<byte[]> consumer1 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer2 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer3 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer4 = consumerBuilder.subscribe();\n+        @Cleanup\n         Consumer<byte[]> consumer5 = consumerBuilder.subscribe();\n \n         // deactive cursors\n@@ -657,12 +586,6 @@ public void testRateLimitingWithBatchMsgEnabled() throws Exception {\n         // consumer should not have received all published message due to message-rate throttling\n         Assert.assertEquals(totalReceived.get(), numProducedMessages);\n \n-        consumer1.close();\n-        consumer2.close();\n-        consumer3.close();\n-        consumer4.close();\n-        consumer5.close();\n-        producer.close();\n         log.info(\"-- Exiting {} test --\", methodName);\n     }\n \n@@ -670,7 +593,7 @@ public void testRateLimitingWithBatchMsgEnabled() throws Exception {\n     public void testClusterRateLimitingConfiguration(SubscriptionType subscription) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n         final int messageRate = 5;\n \n@@ -688,12 +611,14 @@ public void testClusterRateLimitingConfiguration(SubscriptionType subscription)\n \n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(\"test\"));\n         // create producer and topic\n+        @Cleanup\n         Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).create();\n         PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService().getOrCreateTopic(topicName).get();\n         int numMessages = 500;\n \n         final AtomicInteger totalReceived = new AtomicInteger(0);\n \n+        @Cleanup\n         Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(\"my-subscriber-name\")\n                 .subscriptionType(subscription).messageListener((c1, msg) -> {\n                     Assert.assertNotNull(msg, \"Message cannot be null\");\n@@ -716,8 +641,6 @@ public void testClusterRateLimitingConfiguration(SubscriptionType subscription)\n         // consumer should not have received all published message due to message-rate throttling\n         Assert.assertNotEquals(totalReceived.get(), numMessages);\n \n-        consumer.close();\n-        producer.close();\n         admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRatePerTopicInMsg\",\n                 Integer.toString(initValue));\n         log.info(\"-- Exiting {} test --\", methodName);\n@@ -733,7 +656,7 @@ public void testClusterRateLimitingConfiguration(SubscriptionType subscription)\n     public void testMessageByteRateThrottlingCombined(SubscriptionType subscription) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingAll\";\n \n         final int messageRate = 5; // 5 msgs per second\n@@ -803,7 +726,7 @@ public void testMessageByteRateThrottlingCombined(SubscriptionType subscription)\n     public void testGlobalNamespaceThrottling() throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n \n         final int messageRate = 5;\n@@ -869,7 +792,7 @@ public void testGlobalNamespaceThrottling() throws Exception {\n     public void testNonBacklogConsumerWithThrottlingEnabled(SubscriptionType subscription) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/throttlingBlock\";\n \n         final int messageRate = 10;\n@@ -948,7 +871,7 @@ public void testNonBacklogConsumerWithThrottlingEnabled(SubscriptionType subscri\n     public void testClusterPolicyOverrideConfiguration() throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName1 = \"persistent://\" + namespace + \"/throttlingOverride1\";\n         final String topicName2 = \"persistent://\" + namespace + \"/throttlingOverride2\";\n         final int clusterMessageRate = 100;\n@@ -1018,7 +941,7 @@ public void testClusterPolicyOverrideConfiguration() throws Exception {\n     public void testClosingRateLimiter(SubscriptionType subscription) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/closingRateLimiter\" + subscription.name();\n         final String subName = \"mySubscription\" + subscription.name();\n \n@@ -1066,7 +989,7 @@ public void testClosingRateLimiter(SubscriptionType subscription) throws Excepti\n     @SuppressWarnings(\"deprecation\")\n     @Test\n     public void testDispatchRateCompatibility2() throws Exception {\n-        final String namespace = \"my-property/dispatch-rate-compatibility\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/dispatch-rate-compatibility\");\n         final String topicName = \"persistent://\" + namespace + \"/t1\";\n         final String cluster = \"test\";\n         admin.namespaces().createNamespace(namespace, Sets.newHashSet(cluster));\n@@ -1112,17 +1035,6 @@ public void testDispatchRateCompatibility2() throws Exception {\n         topic.close().get();\n     }\n \n-    protected void deactiveCursors(ManagedLedgerImpl ledger) throws Exception {\n-        Field statsUpdaterField = BrokerService.class.getDeclaredField(\"statsUpdater\");\n-        statsUpdaterField.setAccessible(true);\n-        ScheduledExecutorService statsUpdater = (ScheduledExecutorService) statsUpdaterField\n-                .get(pulsar.getBrokerService());\n-        statsUpdater.shutdownNow();\n-        ledger.getCursors().forEach(cursor -> {\n-            ledger.deactivateCursor(cursor);\n-        });\n-    }\n-\n     /**\n      * It verifies that relative throttling at least dispatch messages as publish-rate.\n      *\n@@ -1133,7 +1045,7 @@ protected void deactiveCursors(ManagedLedgerImpl ledger) throws Exception {\n     public void testRelativeMessageRateLimitingThrottling(SubscriptionType subscription) throws Exception {\n         log.info(\"-- Starting {} test --\", methodName);\n \n-        final String namespace = \"my-property/relative_throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/relative_throttling_ns\");\n         final String topicName = \"persistent://\" + namespace + \"/relative-throttle\" + subscription;\n \n         final int messageRate = 1;\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java\nindex ce554ab2d9c00..db40ec644e9ca 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SubscriptionMessageDispatchThrottlingTest.java\n@@ -18,8 +18,10 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.awaitility.Awaitility.await;\n import com.google.common.collect.Sets;\n+import java.time.Duration;\n import java.util.Optional;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.atomic.AtomicInteger;\n@@ -30,6 +32,7 @@\n import org.apache.pulsar.broker.service.persistent.PersistentDispatcherSingleActiveConsumer;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n+import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.common.policies.data.DispatchRate;\n import org.awaitility.Awaitility;\n import org.slf4j.Logger;\n@@ -37,8 +40,8 @@\n import org.testng.Assert;\n import org.testng.annotations.Test;\n \n-@Test(groups = \"flaky\")\n-public class SubscriptionMessageDispatchThrottlingTest extends MessageDispatchThrottlingTest {\n+@Test(groups = \"broker-api\")\n+public class SubscriptionMessageDispatchThrottlingTest extends AbstractMessageDispatchThrottlingTest {\n     private static final Logger log = LoggerFactory.getLogger(SubscriptionMessageDispatchThrottlingTest.class);\n \n     /**\n@@ -241,7 +244,7 @@ private void testMessageNotDuplicated(SubscriptionType subscription) throws Exce\n         admin.namespaces().setSubscriptionDispatchRate(namespace, subscriptionDispatchRate);\n         admin.namespaces().setDispatchRate(namespace, topicDispatchRate);\n         long initBytes = pulsar.getConfiguration().getDispatchThrottlingRatePerTopicInByte();\n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", \"\" + brokerRate);\n+        updateBrokerDispatchThrottlingRateInBytes(brokerRate);\n \n         final int numProducedMessages = 30;\n         final CountDownLatch latch = new CountDownLatch(numProducedMessages);\n@@ -272,10 +275,11 @@ private void testMessageNotDuplicated(SubscriptionType subscription) throws Exce\n             Assert.fail(\"Should only have PersistentDispatcher in this test\");\n         }\n         final DispatchRateLimiter subDispatchRateLimiter = subRateLimiter;\n-        Awaitility.await().untilAsserted(() -> {\n+        Awaitility.await().atMost(Duration.ofSeconds(15)).untilAsserted(() -> {\n             DispatchRateLimiter brokerDispatchRateLimiter = pulsar.getBrokerService().getBrokerDispatchRateLimiter();\n-            Assert.assertTrue(brokerDispatchRateLimiter != null\n-                    && brokerDispatchRateLimiter.getDispatchRateOnByte() > 0);\n+            assertThat(brokerDispatchRateLimiter)\n+                    .isNotNull()\n+                    .satisfies(l -> assertThat(l.getDispatchRateOnByte()).isEqualTo(brokerRate));\n             DispatchRateLimiter topicDispatchRateLimiter = topic.getDispatchRateLimiter().orElse(null);\n             Assert.assertTrue(topicDispatchRateLimiter != null\n                     && topicDispatchRateLimiter.getDispatchRateOnByte() > 0);\n@@ -301,10 +305,7 @@ private void testMessageNotDuplicated(SubscriptionType subscription) throws Exce\n         consumer.close();\n         producer.close();\n \n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", Long.toString(initBytes));\n-\n-        admin.topics().delete(topicName, true);\n-        admin.namespaces().deleteNamespace(namespace);\n+        updateBrokerDispatchThrottlingRateInBytes(initBytes);\n     }\n \n     /**\n@@ -401,7 +402,7 @@ public void testBytesRateLimitingReceiveAllMessagesAfterThrottling(SubscriptionT\n     private void testDispatchRate(SubscriptionType subscription,\n                                   int brokerRate, int topicRate, int subRate, int expectRate) throws Exception {\n \n-        final String namespace = \"my-property/throttling_ns\";\n+        final String namespace = BrokerTestUtil.newUniqueName(\"my-property/throttling_ns\");\n         final String topicName = BrokerTestUtil.newUniqueName(\"persistent://\" + namespace + \"/throttlingAll\");\n         final String subName = \"my-subscriber-name-\" + subscription;\n \n@@ -419,7 +420,7 @@ private void testDispatchRate(SubscriptionType subscription,\n         admin.namespaces().setSubscriptionDispatchRate(namespace, subscriptionDispatchRate);\n         admin.namespaces().setDispatchRate(namespace, topicDispatchRate);\n         long initBytes = pulsar.getConfiguration().getDispatchThrottlingRatePerTopicInByte();\n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", \"\" + brokerRate);\n+        updateBrokerDispatchThrottlingRateInBytes(brokerRate);\n \n         final int numProducedMessages = 30;\n         final CountDownLatch latch = new CountDownLatch(numProducedMessages);\n@@ -450,10 +451,11 @@ private void testDispatchRate(SubscriptionType subscription,\n             Assert.fail(\"Should only have PersistentDispatcher in this test\");\n         }\n         final DispatchRateLimiter subDispatchRateLimiter = subRateLimiter;\n-        Awaitility.await().untilAsserted(() -> {\n+        Awaitility.await().atMost(Duration.ofSeconds(15)).untilAsserted(() -> {\n             DispatchRateLimiter brokerDispatchRateLimiter = pulsar.getBrokerService().getBrokerDispatchRateLimiter();\n-            Assert.assertTrue(brokerDispatchRateLimiter != null\n-                    && brokerDispatchRateLimiter.getDispatchRateOnByte() > 0);\n+            assertThat(brokerDispatchRateLimiter)\n+                    .isNotNull()\n+                    .satisfies(l -> assertThat(l.getDispatchRateOnByte()).isEqualTo(brokerRate));\n             DispatchRateLimiter topicDispatchRateLimiter = topic.getDispatchRateLimiter().orElse(null);\n             Assert.assertTrue(topicDispatchRateLimiter != null\n                     && topicDispatchRateLimiter.getDispatchRateOnByte() > 0);\n@@ -482,9 +484,18 @@ private void testDispatchRate(SubscriptionType subscription,\n \n         consumer.close();\n         producer.close();\n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", Long.toString(initBytes));\n-        admin.topics().delete(topicName, true);\n-        admin.namespaces().deleteNamespace(namespace);\n+        updateBrokerDispatchThrottlingRateInBytes(initBytes);\n+    }\n+\n+    private void updateBrokerDispatchThrottlingRateInBytes(long bytes) throws PulsarAdminException {\n+        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", Long.toString(bytes));\n+        long expectedBytes = bytes > 0L ? bytes : -1L;\n+        await().untilAsserted(() -> {\n+            DispatchRateLimiter brokerDispatchRateLimiter = pulsar.getBrokerService().getBrokerDispatchRateLimiter();\n+            assertThat(brokerDispatchRateLimiter)\n+                    .isNotNull()\n+                    .satisfies(l -> assertThat(l.getDispatchRateOnByte()).isEqualTo(expectedBytes));\n+        });\n     }\n \n     /**\n@@ -537,7 +548,7 @@ public void testBrokerBytesRateLimitingReceiveAllMessagesAfterThrottling(Subscri\n \n         long initBytes = pulsar.getConfiguration().getDispatchThrottlingRatePerTopicInByte();\n         final int byteRate = 1000;\n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", \"\" + byteRate);\n+        updateBrokerDispatchThrottlingRateInBytes(byteRate);\n \n         Awaitility.await().untilAsserted(() -> {\n             Assert.assertEquals(pulsar.getConfiguration().getDispatchThrottlingRateInByte(), byteRate);\n@@ -576,12 +587,6 @@ public void testBrokerBytesRateLimitingReceiveAllMessagesAfterThrottling(Subscri\n         Producer<byte[]> producer1 = pulsarClient.newProducer().topic(topicName1).create();\n         Producer<byte[]> producer2 = pulsarClient.newProducer().topic(topicName2).create();\n \n-        Awaitility.await().untilAsserted(() -> {\n-            DispatchRateLimiter rateLimiter = pulsar.getBrokerService().getBrokerDispatchRateLimiter();\n-            Assert.assertTrue(rateLimiter != null\n-                    && rateLimiter.getDispatchRateOnByte() > 0);\n-        });\n-\n         long start = System.currentTimeMillis();\n         // Asynchronously produce messages\n         for (int i = 0; i < numProducedMessagesEachTopic; i++) {\n@@ -600,7 +605,7 @@ public void testBrokerBytesRateLimitingReceiveAllMessagesAfterThrottling(Subscri\n         consumer2.close();\n         producer1.close();\n         producer2.close();\n-        admin.brokers().updateDynamicConfiguration(\"dispatchThrottlingRateInByte\", Long.toString(initBytes));\n+        updateBrokerDispatchThrottlingRateInBytes(initBytes);\n         log.info(\"-- Exiting {} test --\", methodName);\n     }\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java\nindex 1c0ae5547d53b..a848d68f37f63 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessagePublishThrottlingTest.java\n@@ -41,7 +41,7 @@\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n \n-@Test\n+@Test(groups = \"broker-api\")\n public class MessagePublishThrottlingTest extends ProducerConsumerBase {\n     private static final Logger log = LoggerFactory.getLogger(MessagePublishThrottlingTest.class);\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23927",
    "pr_id": 23927,
    "issue_id": 23925,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] The RawMessageImpl.getProperties throw `Duplicate key` IllegalStateException.\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nmaster\n\n### Minimal reproduce step\n\nYou can run this code to reproduce it.\n```\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport java.util.Map;\nimport org.apache.pulsar.common.api.proto.KeyValue;\nimport org.apache.pulsar.common.api.proto.MessageMetadata;\nimport org.apache.pulsar.common.api.raw.RawMessage;\nimport org.apache.pulsar.common.api.raw.RawMessageImpl;\nimport org.apache.pulsar.common.api.raw.ReferenceCountedMessageMetadata;\nimport org.apache.pulsar.shade.io.netty.buffer.ByteBufAllocator;\n\npublic class Test {\n    public static void main(String[] args) {\n        byte[] messageContent = \"Hello, Pulsar!\".getBytes();\n        ByteBuf payload = Unpooled.wrappedBuffer(messageContent);\n\n        org.apache.pulsar.shade.io.netty.buffer.ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer();\n        ReferenceCountedMessageMetadata referenceCountedMessageMetadata = ReferenceCountedMessageMetadata.get(buffer);\n        MessageMetadata metadata1 = referenceCountedMessageMetadata.getMetadata();\n        KeyValue keyValue = metadata1.addProperty();\n        keyValue.setKey(\"aa\");\n        keyValue.setValue(\"bb\");\n\n        KeyValue keyValue1 = metadata1.addProperty();\n        keyValue1.setKey(\"aa\");\n        keyValue1.setValue(\"cc\");\n        RawMessage rawMessage = RawMessageImpl.get(referenceCountedMessageMetadata, null, null, 0, 0, 0);\n        Map<String, String> properties = rawMessage.getProperties();\n    }\n}\n\n```\n\n### What did you expect to see?\n\nDo not throw the exception.\n\n### What did you see instead?\n\nIt will throw the following exception.\n```\nException in thread \"main\" java.lang.IllegalStateException: Duplicate key aa (attempted merging values bb and cc)\n\tat java.base/java.util.stream.Collectors.duplicateKeyException(Collectors.java:135)\n\tat java.base/java.util.stream.Collectors.lambda$uniqKeysMapAccumulator$1(Collectors.java:182)\n\tat java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)\n\tat java.base/java.util.ArrayList$SubList$2.forEachRemaining(ArrayList.java:1481)\n\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\n\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\n\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921)\n\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)\n\tat org.apache.pulsar.common.api.raw.RawMessageImpl.getProperties(RawMessageImpl.java:102)\n\tat com.zy.Test.main(Test.java:38)\n```\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 391,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-common/src/main/java/org/apache/pulsar/common/api/raw/RawMessageImpl.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java"
    ],
    "base_commit": "d7b34dce94bdaada689c3f440e8280378eee16dc",
    "head_commit": "ffbb581362df67edd83c21917617fc5e86e44807",
    "repo_url": "https://github.com/apache/pulsar/pull/23927",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23927",
    "dockerfile": "",
    "pr_merged_at": "2025-03-11T12:13:06.000Z",
    "patch": "diff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/api/raw/RawMessageImpl.java b/pulsar-common/src/main/java/org/apache/pulsar/common/api/raw/RawMessageImpl.java\nindex daf7fd6a7644c..8240f234aa1ed 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/api/raw/RawMessageImpl.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/api/raw/RawMessageImpl.java\n@@ -99,7 +99,8 @@ public Map<String, String> getProperties() {\n                               (oldValue, newValue) -> newValue));\n         } else if (msgMetadata.getMetadata().getPropertiesCount() > 0) {\n             return msgMetadata.getMetadata().getPropertiesList().stream()\n-                    .collect(Collectors.toMap(KeyValue::getKey, KeyValue::getValue));\n+                    .collect(Collectors.toMap(KeyValue::getKey, KeyValue::getValue,\n+                            (oldValue, newValue) -> newValue));\n         } else {\n             return Collections.emptyMap();\n         }\n",
    "test_patch": "diff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java\nindex b0b9d42866cba..61783b36dca22 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/api/raw/RawMessageImplTest.java\n@@ -41,7 +41,7 @@ public class RawMessageImplTest {\n     private static final String HARD_CODE_KEY_ID_VALUE  = \"__pfn_input_msg_id_value__\";\n \n     @Test\n-    public void testGetProperties() {\n+    public void testGetMessageSingleMetadataProperties() {\n         ReferenceCountedMessageMetadata refCntMsgMetadata =\n                 ReferenceCountedMessageMetadata.get(mock(ByteBuf.class));\n         SingleMessageMetadata singleMessageMetadata = new SingleMessageMetadata();\n@@ -56,6 +56,24 @@ public void testGetProperties() {\n         assertEquals(HARD_CODE_KEY_ID_VALUE, properties.get(HARD_CODE_KEY_ID));\n     }\n \n+    @Test\n+    public void testGetMessageMetadataProperties() {\n+        ReferenceCountedMessageMetadata refCntMsgMetadata =\n+                ReferenceCountedMessageMetadata.get(mock(ByteBuf.class));\n+\n+        MessageMetadata messageMetadata = refCntMsgMetadata.getMetadata();\n+        messageMetadata.addProperty().setKey(HARD_CODE_KEY).setValue(KEY_VALUE_FIRST);\n+        messageMetadata.addProperty().setKey(HARD_CODE_KEY).setValue(KEY_VALUE_SECOND);\n+        messageMetadata.addProperty().setKey(HARD_CODE_KEY_ID).setValue(HARD_CODE_KEY_ID_VALUE);\n+\n+        RawMessage msg = RawMessageImpl.get(refCntMsgMetadata, null, null, 0, 0, 0);\n+        Map<String, String> properties = msg.getProperties();\n+        assertEquals(properties.get(HARD_CODE_KEY), KEY_VALUE_SECOND);\n+        assertEquals(properties.get(HARD_CODE_KEY_ID), HARD_CODE_KEY_ID_VALUE);\n+        assertEquals(KEY_VALUE_SECOND, properties.get(HARD_CODE_KEY));\n+        assertEquals(HARD_CODE_KEY_ID_VALUE, properties.get(HARD_CODE_KEY_ID));\n+    }\n+\n     @Test\n     public void testNonBatchedMessage() {\n         MessageMetadata messageMetadata = new MessageMetadata();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23919",
    "pr_id": 23919,
    "issue_id": 23910,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Seek on a timestamp causes the subscription to be resetted to the earliest position.\n### Search before asking\n\n- [ ] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nPulsar v4.0.2\nPulsar Go client v0.14\n\n### Minimal reproduce step\n\nWith v4.0.2, after restarting brokers, we observe a wrong position in subscription after a seek by timestamp. The position seems to be the earliest position instead of the next message after the timestamp.\n\nNote that after downgrading to v4.0.1, the seeking position gets back to the proper one so the message after the timestamp.\n\n### What did you expect to see?\n\nOn a seek by timestamp, we expect the subscription to reset to the next message after the timestamp available in the topic.\n\n### What did you see instead?\n\nWe observe subscriptions to reset on the earliest position when we use seek by timestamp.\n\nMay that be related to #22129 ?\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 207,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java"
    ],
    "base_commit": "cdab2d6dc4b620bdf129b05882b5f3bf4925ff61",
    "head_commit": "ec833407ab3d093b5c7c9ed2d66c1e49129fc7cc",
    "repo_url": "https://github.com/apache/pulsar/pull/23919",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23919",
    "dockerfile": "",
    "pr_merged_at": "2025-02-11T06:25:14.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\nindex 5a4631cf205f1..e780f1672848b 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\n@@ -19,6 +19,7 @@\n package org.apache.pulsar.broker.service.persistent;\n \n import static com.google.common.base.Preconditions.checkArgument;\n+import com.google.common.annotations.VisibleForTesting;\n import java.util.Optional;\n import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n import org.apache.bookkeeper.mledger.AsyncCallbacks;\n@@ -91,6 +92,7 @@ public void findMessages(final long timestamp, AsyncCallbacks.FindEntryCallback\n         }\n     }\n \n+    @VisibleForTesting\n     public static Pair<Position, Position> getFindPositionRange(Iterable<LedgerInfo> ledgerInfos,\n                                                                 Position lastConfirmedEntry, long targetTimestamp,\n                                                                 int ledgerCloseTimestampMaxClockSkewMillis) {\n@@ -105,15 +107,11 @@ public static Pair<Position, Position> getFindPositionRange(Iterable<LedgerInfo>\n         Position start = null;\n         Position end = null;\n \n-        LedgerInfo secondToLastLedgerInfo = null;\n-        LedgerInfo lastLedgerInfo = null;\n         for (LedgerInfo info : ledgerInfos) {\n             if (!info.hasTimestamp()) {\n                 // unexpected case, don't set start and end\n                 return Pair.of(null, null);\n             }\n-            secondToLastLedgerInfo = lastLedgerInfo;\n-            lastLedgerInfo = info;\n             long closeTimestamp = info.getTimestamp();\n             // For an open ledger, closeTimestamp is 0\n             if (closeTimestamp == 0) {\n@@ -128,19 +126,6 @@ public static Pair<Position, Position> getFindPositionRange(Iterable<LedgerInfo>\n                 break;\n             }\n         }\n-        // If the second-to-last ledger's close timestamp is less than the target timestamp, then start from the\n-        // first entry of the last ledger when there are confirmed entries in the ledger\n-        if (lastLedgerInfo != null && secondToLastLedgerInfo != null\n-                && secondToLastLedgerInfo.getTimestamp() > 0\n-                && secondToLastLedgerInfo.getTimestamp() < targetTimestampMin) {\n-            Position firstPositionInLedger = PositionFactory.create(lastLedgerInfo.getLedgerId(), 0);\n-            if (lastConfirmedEntry != null\n-                    && lastConfirmedEntry.compareTo(firstPositionInLedger) >= 0) {\n-                start = firstPositionInLedger;\n-            } else {\n-                start = lastConfirmedEntry;\n-            }\n-        }\n         return Pair.of(start, end);\n     }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\nindex 6f2f1f3a1a2c0..62e27eaea4169 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\n@@ -636,7 +636,7 @@ public void testGetFindPositionRange_LastTimestampIsZero() {\n         assertNotNull(range);\n         assertNotNull(range.getLeft());\n         assertNull(range.getRight());\n-        assertEquals(range.getLeft(), PositionFactory.create(3, 0));\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n     }\n \n     @Test\n@@ -654,7 +654,7 @@ public void testGetFindPositionRange_LastTimestampIsZeroWithNoEntries() {\n         assertNotNull(range);\n         assertNotNull(range.getLeft());\n         assertNull(range.getRight());\n-        assertEquals(range.getLeft(), PositionFactory.create(2, 9));\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n     }\n \n     @Test\n@@ -689,7 +689,7 @@ public void testGetFindPositionRange_MixedTimestamps() {\n         assertNotNull(range);\n         assertNotNull(range.getLeft());\n         assertNotNull(range.getRight());\n-        assertEquals(range.getLeft(), PositionFactory.create(3, 0));\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n         assertEquals(range.getRight(), PositionFactory.create(3, 9));\n     }\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java\nindex 582d10294a5a4..3a9c5c43f1c54 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionSeekTest.java\n@@ -27,8 +27,10 @@\n import static org.testng.Assert.fail;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n+import java.util.Map;\n import java.util.Set;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n@@ -38,6 +40,12 @@\n import java.util.function.Function;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.ManagedCursor;\n+import org.apache.bookkeeper.mledger.ManagedLedger;\n+import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n+import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n+import org.apache.commons.lang3.ArrayUtils;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n@@ -50,6 +58,7 @@\n import org.apache.pulsar.client.api.PulsarClientException;\n import org.apache.pulsar.client.api.Reader;\n import org.apache.pulsar.client.api.Schema;\n+import org.apache.pulsar.client.api.SubscriptionInitialPosition;\n import org.apache.pulsar.client.api.SubscriptionType;\n import org.apache.pulsar.client.impl.BatchMessageIdImpl;\n import org.apache.pulsar.client.impl.ClientBuilderImpl;\n@@ -61,6 +70,7 @@\n import org.apache.pulsar.common.policies.data.RetentionPolicies;\n import org.apache.pulsar.common.util.RelativeTimeUtil;\n import org.awaitility.Awaitility;\n+import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n@@ -72,6 +82,10 @@ public class SubscriptionSeekTest extends BrokerTestBase {\n     @BeforeClass\n     @Override\n     protected void setup() throws Exception {\n+        conf.setManagedLedgerMinLedgerRolloverTimeMinutes(0);\n+        conf.setManagedLedgerMaxEntriesPerLedger(10);\n+        conf.setDefaultRetentionSizeInMB(100);\n+        conf.setDefaultRetentionTimeInMinutes(100);\n         super.baseSetup();\n         conf.setAcknowledgmentAtBatchIndexLevelEnabled(true);\n     }\n@@ -489,6 +503,110 @@ public void testSeekTime() throws Exception {\n         assertEquals(sub.getNumberOfEntriesInBacklog(false), 10);\n     }\n \n+    @Test(timeOut = 30_000)\n+    public void testSeekByTimestamp() throws Exception {\n+        String topicName = \"persistent://prop/use/ns-abc/testSeekByTimestamp\";\n+        admin.topics().createNonPartitionedTopic(topicName);\n+        admin.topics().createSubscription(topicName, \"my-sub\", MessageId.earliest);\n+\n+        @Cleanup\n+        Producer<String> producer =\n+                pulsarClient.newProducer(Schema.STRING).topic(topicName).enableBatching(false).create();\n+        for (int i = 0; i < 25; i++) {\n+            producer.send((\"message-\" + i));\n+            Thread.sleep(10);\n+        }\n+\n+        PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService().getTopic(topicName, false).get().get();\n+\n+        Map<Long, MessageId> timestampToMessageId = new HashMap<>();\n+        @Cleanup\n+        Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topicName).startMessageId(MessageId.earliest).create();\n+        while (reader.hasMessageAvailable()) {\n+           Message<String> message = reader.readNext();\n+              timestampToMessageId.put(message.getPublishTime(), message.getMessageId());\n+        }\n+\n+        Assert.assertEquals(timestampToMessageId.size(), 25);\n+\n+        PersistentSubscription subscription = topic.getSubscription(\"my-sub\");\n+        ManagedCursor cursor = subscription.getCursor();\n+\n+        @Cleanup\n+        org.apache.pulsar.client.api.Consumer<String> consumer = pulsarClient.newConsumer(Schema.STRING)\n+                .topic(topicName).subscriptionName(\"my-sub\").subscriptionInitialPosition(SubscriptionInitialPosition.Earliest).subscribe();\n+        long[] timestamps = timestampToMessageId.keySet().stream().mapToLong(Long::longValue).toArray();\n+        ArrayUtils.shuffle(timestamps);\n+        for (long timestamp : timestamps) {\n+            MessageIdImpl messageId = (MessageIdImpl) timestampToMessageId.get(timestamp);\n+            consumer.seek(timestamp);\n+            Position readPosition = cursor.getReadPosition();\n+            Assert.assertEquals(readPosition.getLedgerId(), messageId.getLedgerId());\n+            Assert.assertEquals(readPosition.getEntryId(), messageId.getEntryId());\n+        }\n+    }\n+\n+    @Test(timeOut = 30_000)\n+    public void testSeekByTimestampWithLedgerTrim() throws Exception {\n+        String topicName = \"persistent://prop/use/ns-abc/testSeekByTimestampWithLedgerTrim\";\n+        admin.topics().createNonPartitionedTopic(topicName);\n+        admin.topics().createSubscription(topicName, \"my-sub\", MessageId.earliest);\n+\n+        @Cleanup\n+        Producer<String> producer =\n+                pulsarClient.newProducer(Schema.STRING).topic(topicName).enableBatching(false).create();\n+        for (int i = 0; i < 25; i++) {\n+            producer.send((\"message-\" + i));\n+            Thread.sleep(10);\n+        }\n+\n+        PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService().getTopic(topicName, false).get().get();\n+        ManagedLedger ledger = topic.getManagedLedger();\n+        ManagedLedgerConfig config = ledger.getConfig();\n+        config.setRetentionTime(0, TimeUnit.SECONDS);\n+        config.setRetentionSizeInMB(0);\n+\n+        Map<Long, MessageId> timestampToMessageId = new HashMap<>();\n+        @Cleanup\n+        Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topicName).startMessageId(MessageId.earliest).create();\n+        while (reader.hasMessageAvailable()) {\n+            Message<String> message = reader.readNext();\n+            timestampToMessageId.put(message.getPublishTime(), message.getMessageId());\n+        }\n+\n+        Assert.assertEquals(timestampToMessageId.size(), 25);\n+\n+        PersistentSubscription subscription = topic.getSubscription(\"my-sub\");\n+        ManagedCursor cursor = subscription.getCursor();\n+\n+        @Cleanup\n+        org.apache.pulsar.client.api.Consumer<String> consumer = pulsarClient.newConsumer(Schema.STRING)\n+                .topic(topicName).subscriptionName(\"my-sub\").subscriptionInitialPosition(SubscriptionInitialPosition.Earliest).subscribe();\n+        long[] timestamps = timestampToMessageId.keySet().stream().mapToLong(Long::longValue).toArray();\n+        ArrayUtils.shuffle(timestamps);\n+        boolean enterLedgerTrimmedBranch = false;\n+        for (long timestamp : timestamps) {\n+            MessageIdImpl messageId = (MessageIdImpl) timestampToMessageId.get(timestamp);\n+            consumer.seek(timestamp);\n+            CompletableFuture<?> trimFuture = new CompletableFuture<>();\n+            ledger.trimConsumedLedgersInBackground(trimFuture);\n+            trimFuture.get();\n+            Position readPosition = cursor.getReadPosition();\n+            Map.Entry<Long, MLDataFormats.ManagedLedgerInfo.LedgerInfo> firstLedger = ledger.getLedgersInfo().firstEntry();\n+            Assert.assertNotNull(firstLedger);\n+            if (firstLedger.getKey() > messageId.getLedgerId()) {\n+                Assert.assertEquals(readPosition.getLedgerId(), firstLedger.getKey());\n+                Assert.assertEquals(readPosition.getEntryId(), 0);\n+                enterLedgerTrimmedBranch = true;\n+            } else {\n+                Assert.assertEquals(readPosition.getLedgerId(), messageId.getLedgerId());\n+                Assert.assertEquals(readPosition.getEntryId(), messageId.getEntryId());\n+            }\n+        }\n+        // May have a chance to cause flaky test, because the result of `ArrayUtils.shuffle(timestamps);` is random.\n+        Assert.assertTrue(enterLedgerTrimmedBranch);\n+    }\n+\n     @Test\n     public void testSeekTimeByFunction() throws Exception {\n         final String topicName = \"persistent://prop/use/ns-abc/test\" + UUID.randomUUID();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23893",
    "pr_id": 23893,
    "issue_id": 23882,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: DelayedDeliveryTest.testEnableTopicDelayedDelivery\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/12923783677/job/36041928951?pr=23874#step:11:1423\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\n```\n  Error:  org.apache.pulsar.broker.service.persistent.DelayedDeliveryTest.testEnableTopicDelayedDelivery  Time elapsed: 6.941 s  <<< FAILURE!\n  java.lang.AssertionError: expected [null] but found [org.apache.pulsar.client.impl.TopicMessageImpl@728268b3]\n  \tat org.testng.Assert.fail(Assert.java:110)\n  \tat org.testng.Assert.failNotSame(Assert.java:1573)\n  \tat org.testng.Assert.assertNull(Assert.java:1506)\n  \tat org.testng.Assert.assertNull(Assert.java:1494)\n  \tat org.apache.pulsar.broker.service.persistent.DelayedDeliveryTest.testEnableTopicDelayedDelivery(DelayedDeliveryTest.java:488)\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\n```\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 245,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java"
    ],
    "base_commit": "223eea027beb1a7e95ff4519db181268b4636829",
    "head_commit": "c2d3f97f0edb63661a312e8a6a70920502140fc2",
    "repo_url": "https://github.com/apache/pulsar/pull/23893",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23893",
    "dockerfile": "",
    "pr_merged_at": "2025-01-28T22:17:22.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java\nindex e47857e8ec60f..793a1767fd8c5 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/DelayedDeliveryTest.java\n@@ -483,10 +483,10 @@ public void testEnableTopicDelayedDelivery() throws Exception {\n                 break;\n             }\n         }\n-        producer.newMessage().value(\"long-tick-msg\").deliverAfter(2, TimeUnit.SECONDS).send();\n+        producer.newMessage().value(\"long-tick-msg\").deliverAfter(3, TimeUnit.SECONDS).send();\n         msg = consumer.receive(1, TimeUnit.SECONDS);\n         assertNull(msg);\n-        msg = consumer.receive(3, TimeUnit.SECONDS);\n+        msg = consumer.receive(4, TimeUnit.SECONDS);\n         assertNotNull(msg);\n     }\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23881",
    "pr_id": 23881,
    "issue_id": 23880,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] pulsar-admin functions list without specifying tenant and namespace return a NPE error\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\n[e5bd774](https://github.com/apache/pulsar/commit/e5bd77419e91d1602731cd0c1d02a738e1b7ebc7)\n\n### Minimal reproduce step\n\n1. start pulsar in standalone mode:\n\n```\nbin/pulsar standalone\n```\n\n2. list functions:\n\n```\nbin/pulsar-admin functions list\n\nnull\n\nReason: java.lang.NullPointerException: path is 'null'.\n```\n\n### What did you expect to see?\n\nan empty list since no functions exist:\n\n```\n```\n\n### What did you see instead?\n\nan error:\n\n```\nnull\n\nReason: java.lang.NullPointerException: path is 'null'.\n```\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 148,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java",
      "pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdFunctions.java"
    ],
    "pr_changed_test_files": [
      "pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java"
    ],
    "base_commit": "6d8d73df727cceb8db265d9e33455ee5c52a8791",
    "head_commit": "2fca0181c8e1039a503dcdcea3cc371507f84f61",
    "repo_url": "https://github.com/apache/pulsar/pull/23881",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23881",
    "dockerfile": "",
    "pr_merged_at": "2025-01-24T04:11:00.000Z",
    "patch": "diff --git a/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdFunctions.java b/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdFunctions.java\nindex 4c7e058af6de1..a1b8d26ef1883 100644\n--- a/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdFunctions.java\n+++ b/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdFunctions.java\n@@ -105,6 +105,16 @@ abstract class NamespaceCommand extends BaseCommand {\n \n         @Option(names = \"--namespace\", description = \"The namespace of a Pulsar Function\")\n         protected String namespace;\n+\n+        @Override\n+        public void processArguments() {\n+            if (tenant == null) {\n+                tenant = PUBLIC_TENANT;\n+            }\n+            if (namespace == null) {\n+                namespace = DEFAULT_NAMESPACE;\n+            }\n+        }\n     }\n \n     /**\n",
    "test_patch": "diff --git a/pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java b/pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java\nindex d3087b7fc873c..5cac07502b47f 100644\n--- a/pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java\n+++ b/pulsar-client-tools-test/src/test/java/org/apache/pulsar/admin/cli/CmdFunctionsTest.java\n@@ -631,6 +631,19 @@ public void testListFunctions() throws Exception {\n         verify(functions, times(1)).getFunctions(eq(TENANT), eq(NAMESPACE));\n     }\n \n+    @Test\n+    public void testListFunctionsWithDefaultValue() throws Exception {\n+        cmd.run(new String[] {\n+                \"list\",\n+        });\n+\n+        ListFunctions lister = cmd.getLister();\n+        assertEquals(\"public\", lister.getTenant());\n+        assertEquals(\"default\", lister.getNamespace());\n+\n+        verify(functions, times(1)).getFunctions(eq(\"public\"), eq(\"default\"));\n+    }\n+\n     @Test\n     public void testStateGetter() throws Exception {\n         String key = TEST_NAME + \"-key\";\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23878",
    "pr_id": 23878,
    "issue_id": 23877,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] ConcurrentBitmapSortedLongPairSet doesn't support pairs where the right value of the pair is larger than Integer.MAX_VALUE\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nany released version\n\n### Minimal reproduce step\n\nConcurrentBitmapSortedLongPairSet uses internally RoaringBitmap which supports values up to 2^32.\nSince ConcurrentBitmapSortedLongPairSet uses `Iterator<Integer>` in the implementation, it can only support values up to 2^31-1 (`Integer.MAX_INTEGER`).\n\n### What did you expect to see?\n\nSince the class interface and name is about supporting a Long pair, it should support long values for both right and left values of the pair.\n\n### What did you see instead?\n\nLong value is not supported for the right value of the pair.\n\n### Anything else?\n\nA possible solution would be to replace org.roaringbitmap.RoaringBitmap with org.roaringbitmap.longlong.Roaring64Bitmap. \nHowever, Roaring64Bitmap interface is slightly different and would result in other changes. \n\nAn alternative mitigation is to improve ConcurrentBitmapSortedLongPairSet to support values up to 2^32. That is implemented in PR #23878.\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 218,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSet.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java"
    ],
    "base_commit": "e5bd77419e91d1602731cd0c1d02a738e1b7ebc7",
    "head_commit": "d36ac04b9412577514af40b448b306b1f340b786",
    "repo_url": "https://github.com/apache/pulsar/pull/23878",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23878",
    "dockerfile": "",
    "pr_merged_at": "2025-01-23T14:02:45.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSet.java b/pulsar-broker/src/main/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSet.java\nindex 7a4126fedec64..70437d07dbee0 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSet.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSet.java\n@@ -18,7 +18,6 @@\n  */\n package org.apache.pulsar.utils;\n \n-import java.util.Iterator;\n import java.util.Map;\n import java.util.NavigableMap;\n import java.util.NavigableSet;\n@@ -29,8 +28,13 @@\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n import org.apache.commons.lang3.mutable.MutableObject;\n import org.apache.pulsar.common.util.collections.LongPairSet;\n+import org.roaringbitmap.PeekableIntIterator;\n import org.roaringbitmap.RoaringBitmap;\n \n+/**\n+ * A concurrent set of pairs of longs.\n+ * The right side of the value supports unsigned values up to 2^32.\n+ */\n public class ConcurrentBitmapSortedLongPairSet {\n \n     private final NavigableMap<Long, RoaringBitmap> map = new TreeMap<>();\n@@ -139,10 +143,12 @@ public <T extends Comparable<T>> void processItems(LongPairSet.LongPairFunction<\n         lock.readLock().lock();\n         try {\n             for (Map.Entry<Long, RoaringBitmap> entry : map.entrySet()) {\n-                Iterator<Integer> iterator = entry.getValue().stream().iterator();\n+                PeekableIntIterator intIterator = entry.getValue().getIntIterator();\n                 boolean continueProcessing = true;\n-                while (continueProcessing && iterator.hasNext()) {\n-                    T item = longPairConverter.apply(entry.getKey(), iterator.next());\n+                while (continueProcessing && intIterator.hasNext()) {\n+                    // RoaringBitmap encodes values as unsigned 32-bit integers internally, it's necessary to use\n+                    // Integer.toUnsignedLong to convert them to unsigned long values\n+                    T item = longPairConverter.apply(entry.getKey(), Integer.toUnsignedLong(intIterator.next()));\n                     continueProcessing = itemProcessor.process(item);\n                 }\n                 if (!continueProcessing) {\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java\nindex 5f8f13288cfe8..34f971e8841ab 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/utils/ConcurrentBitmapSortedLongPairSetTest.java\n@@ -18,18 +18,19 @@\n  */\n package org.apache.pulsar.utils;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertTrue;\n-import lombok.Cleanup;\n-import org.apache.pulsar.common.util.collections.ConcurrentLongPairSet;\n-import org.testng.annotations.Test;\n import java.util.ArrayList;\n import java.util.List;\n import java.util.Set;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n+import lombok.Cleanup;\n+import org.apache.pulsar.common.util.collections.ConcurrentLongPairSet;\n+import org.testng.annotations.Test;\n \n @Test(groups = \"utils\")\n public class ConcurrentBitmapSortedLongPairSetTest {\n@@ -204,4 +205,27 @@ public void concurrentInsertions() throws Throwable {\n \n         assertEquals(set.size(), N * nThreads);\n     }\n+\n+    @Test\n+    public void testValueLargerThanIntegerMAX_VALUE() {\n+        ConcurrentBitmapSortedLongPairSet set = new ConcurrentBitmapSortedLongPairSet();\n+        long baseValue = Integer.MAX_VALUE;\n+        List<Long> addedValues = new ArrayList<>();\n+        int items = 10;\n+        for (int i = 0; i < items; i++) {\n+            long value = baseValue + i;\n+            set.add(1, value);\n+            addedValues.add(value);\n+        }\n+        assertEquals(set.size(), items);\n+        List<Long> values = new ArrayList<>();\n+        set.processItems((item1, item2) -> {\n+            assertEquals(item1, 1);\n+            return item2;\n+        }, (value) -> {\n+            values.add(value);\n+            return true;\n+        });\n+        assertThat(values).containsExactlyElementsOf(addedValues);\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23874",
    "pr_id": 23874,
    "issue_id": 23870,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] PIP-379 Key_Shared implementation can deliver messages out-of-order due to racecondition when a hash gets unblocked\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\n4.0.0, 4.0.1, 4.0.2\n\n### Minimal reproduce step\n\nIt was possible to reproduce the issue in a test case by disabling broker cache and by setting dispatcher retry backoff and keySharedUnblockingIntervalMs to 0. \n```\n        conf.setManagedLedgerCacheSizeMB(0);\n        conf.setManagedLedgerMaxReadsInFlightSizeInMB(0);\n        conf.setDispatcherRetryBackoffInitialTimeInMs(0);\n        conf.setDispatcherRetryBackoffMaxTimeInMs(0);\n        conf.setKeySharedUnblockingIntervalMs(0);\n```\nThe test case is\nhttps://github.com/lhotari/pulsar/blob/caac334465ca3de9a87e93a13b8fee377a2a467b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java\n\nThe problem doesn't reproduce in testing with the default configuration when the retry backoff and keySharedUnblockingIntervalMs are set to default. However, the test reveals a race condition that needs to be addressed.  \n\n### What did you expect to see?\n\nMessages should be delivered in order, also when retry backoff and keySharedUnblockingIntervalMs is set to 0.\n\n### What did you see instead?\n\nThere are message ordering issues in 25%-40% of the test runs.\n\n### Anything else?\n\nThe problem seems to be a race condition of the hash getting unblocked while sending of entries is in progress.\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 254,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java",
      "pulsar-broker/src/test/resources/log4j2.xml"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java",
      "pulsar-broker/src/test/resources/log4j2.xml"
    ],
    "base_commit": "e5bd77419e91d1602731cd0c1d02a738e1b7ebc7",
    "head_commit": "be9b80c6e1b52d4dd675ea6bfca4a1e95bada536",
    "repo_url": "https://github.com/apache/pulsar/pull/23874",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23874",
    "dockerfile": "",
    "pr_merged_at": "2025-01-23T10:21:45.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\nindex fa03a260e131e..82b96c365072f 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n@@ -1422,6 +1422,9 @@ public void cursorIsReset() {\n \n     protected boolean addMessageToReplay(long ledgerId, long entryId, long stickyKeyHash) {\n         if (checkIfMessageIsUnacked(ledgerId, entryId)) {\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"[{}] Adding message to replay for {}:{} hash: {}\", name, ledgerId, entryId, stickyKeyHash);\n+            }\n             redeliveryMessages.add(ledgerId, entryId, stickyKeyHash);\n             return true;\n         } else {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java\nindex 1a3e2f706cba8..8bddbde02c974 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentStickyKeyDispatcherMultipleConsumers.java\n@@ -20,6 +20,8 @@\n \n import static org.apache.pulsar.broker.service.StickyKeyConsumerSelector.STICKY_KEY_HASH_NOT_SET;\n import com.google.common.annotations.VisibleForTesting;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.ints.IntSet;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -407,6 +409,8 @@ private Map<Consumer, List<Entry>> filterAndGroupEntriesForDispatching(List<Entr\n         Set<Consumer> blockedByHashConsumers = lookAheadAllowed && readType == ReadType.Normal ? new HashSet<>() : null;\n         // in replay read mode, keep track of consumers for entries, used for look-ahead check\n         Set<Consumer> consumersForEntriesForLookaheadCheck = lookAheadAllowed ? new HashSet<>() : null;\n+        // track already blocked hashes to block any further messages with the same hash\n+        IntSet alreadyBlockedHashes = new IntOpenHashSet();\n \n         for (Entry inputEntry : entries) {\n             EntryAndMetadata entry;\n@@ -419,24 +423,29 @@ private Map<Consumer, List<Entry>> filterAndGroupEntriesForDispatching(List<Entr\n                         Commands.peekAndCopyMessageMetadata(inputEntry.getDataBuffer(), getSubscriptionName(), -1));\n             }\n             int stickyKeyHash = getStickyKeyHash(entry);\n-            Consumer consumer = selector.select(stickyKeyHash);\n+            Consumer consumer = null;\n             MutableBoolean blockedByHash = null;\n             boolean dispatchEntry = false;\n-            if (consumer != null) {\n-                if (lookAheadAllowed) {\n-                    consumersForEntriesForLookaheadCheck.add(consumer);\n-                }\n-                blockedByHash = lookAheadAllowed && readType == ReadType.Normal ? new MutableBoolean(false) : null;\n-                MutableInt permits =\n-                        permitsForConsumer.computeIfAbsent(consumer,\n-                                k -> new MutableInt(getAvailablePermits(consumer)));\n-                // a consumer was found for the sticky key hash and the entry can be dispatched\n-                if (permits.intValue() > 0\n-                        && canDispatchEntry(consumer, entry, readType, stickyKeyHash, blockedByHash)) {\n-                    // decrement the permits for the consumer\n-                    permits.decrement();\n-                    // allow the entry to be dispatched\n-                    dispatchEntry = true;\n+            // check if the hash is already blocked\n+            boolean hashIsAlreadyBlocked = alreadyBlockedHashes.contains(stickyKeyHash);\n+            if (!hashIsAlreadyBlocked) {\n+                consumer = selector.select(stickyKeyHash);\n+                if (consumer != null) {\n+                    if (lookAheadAllowed) {\n+                        consumersForEntriesForLookaheadCheck.add(consumer);\n+                    }\n+                    blockedByHash = lookAheadAllowed && readType == ReadType.Normal ? new MutableBoolean(false) : null;\n+                    MutableInt permits =\n+                            permitsForConsumer.computeIfAbsent(consumer,\n+                                    k -> new MutableInt(getAvailablePermits(k)));\n+                    // a consumer was found for the sticky key hash and the entry can be dispatched\n+                    if (permits.intValue() > 0\n+                            && canDispatchEntry(consumer, entry, readType, stickyKeyHash, blockedByHash)) {\n+                        // decrement the permits for the consumer\n+                        permits.decrement();\n+                        // allow the entry to be dispatched\n+                        dispatchEntry = true;\n+                    }\n                 }\n             }\n             if (dispatchEntry) {\n@@ -445,6 +454,10 @@ && canDispatchEntry(consumer, entry, readType, stickyKeyHash, blockedByHash)) {\n                         entriesGroupedByConsumer.computeIfAbsent(consumer, k -> new ArrayList<>());\n                 consumerEntries.add(entry);\n             } else {\n+                if (!hashIsAlreadyBlocked) {\n+                    // the hash is blocked, add it to the set of blocked hashes\n+                    alreadyBlockedHashes.add(stickyKeyHash);\n+                }\n                 if (blockedByHash != null && blockedByHash.isTrue()) {\n                     // the entry is blocked by hash, add the consumer to the blocked set\n                     blockedByHashConsumers.add(consumer);\n@@ -536,6 +549,9 @@ private class ReplayPositionFilter implements Predicate<Position> {\n         // tracks the available permits for each consumer for the duration of the filter usage\n         // the filter is stateful and shouldn't be shared or reused later\n         private final Map<Consumer, MutableInt> availablePermitsMap = new HashMap<>();\n+        // tracks the hashes that have been blocked during the filtering\n+        // it is necessary to block all later messages after a hash gets blocked so that ordering is preserved\n+        private final Set<Long> alreadyBlockedHashes = new HashSet<>();\n \n         @Override\n         public boolean test(Position position) {\n@@ -553,25 +569,34 @@ public boolean test(Position position) {\n                 }\n                 return true;\n             }\n+            // check if the hash is already blocked, if so, then replaying of the position should be skipped\n+            // to preserve ordering\n+            if (alreadyBlockedHashes.contains(stickyKeyHash)) {\n+                return false;\n+            }\n \n             // find the consumer for the sticky key hash\n             Consumer consumer = selector.select(stickyKeyHash.intValue());\n             // skip replaying the message position if there's no assigned consumer\n             if (consumer == null) {\n+                alreadyBlockedHashes.add(stickyKeyHash);\n                 return false;\n             }\n+\n             // lookup the available permits for the consumer\n             MutableInt availablePermits =\n                     availablePermitsMap.computeIfAbsent(consumer,\n                             k -> new MutableInt(getAvailablePermits(consumer)));\n             // skip replaying the message position if the consumer has no available permits\n             if (availablePermits.intValue() <= 0) {\n+                alreadyBlockedHashes.add(stickyKeyHash);\n                 return false;\n             }\n \n             if (drainingHashesRequired\n                     && drainingHashesTracker.shouldBlockStickyKeyHash(consumer, stickyKeyHash.intValue())) {\n                 // the hash is draining and the consumer is not the draining consumer\n+                alreadyBlockedHashes.add(stickyKeyHash);\n                 return false;\n             }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java\nnew file mode 100644\nindex 0000000000000..45f776b41e78a\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionDisabledBrokerCacheTest.java\n@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.client.api;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.apache.pulsar.broker.BrokerTestUtil.newUniqueName;\n+import static org.assertj.core.api.SoftAssertions.assertSoftly;\n+import static org.testng.Assert.fail;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.Cleanup;\n+import lombok.SneakyThrows;\n+import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.PositionFactory;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.pulsar.broker.ServiceConfiguration;\n+import org.apache.pulsar.broker.service.StickyKeyConsumerSelector;\n+import org.apache.pulsar.broker.service.StickyKeyDispatcher;\n+import org.apache.pulsar.broker.service.Topic;\n+import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n+import org.apache.pulsar.tests.KeySharedImplementationType;\n+import org.awaitility.Awaitility;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Factory;\n+import org.testng.annotations.Test;\n+\n+@Test(groups = \"broker-impl\")\n+public class KeySharedSubscriptionDisabledBrokerCacheTest extends ProducerConsumerBase {\n+    private static final Logger log = LoggerFactory.getLogger(KeySharedSubscriptionDisabledBrokerCacheTest.class);\n+    private static final List<String> keys = Arrays.asList(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\");\n+    private static final String SUBSCRIPTION_NAME = \"key_shared\";\n+    private final KeySharedImplementationType implementationType;\n+\n+    // Comment out the next line (Factory annotation) to run tests manually in IntelliJ, one-by-one\n+    @Factory\n+    public static Object[] createTestInstances() {\n+        return KeySharedImplementationType.generateTestInstances(KeySharedSubscriptionDisabledBrokerCacheTest::new);\n+    }\n+\n+    public KeySharedSubscriptionDisabledBrokerCacheTest() {\n+        // set the default implementation type for manual running in IntelliJ\n+        this(KeySharedImplementationType.PIP379);\n+    }\n+\n+    public KeySharedSubscriptionDisabledBrokerCacheTest(KeySharedImplementationType implementationType) {\n+        this.implementationType = implementationType;\n+    }\n+\n+    @DataProvider(name = \"currentImplementationType\")\n+    public Object[] currentImplementationType() {\n+        return new Object[]{ implementationType };\n+    }\n+\n+    @BeforeClass(alwaysRun = true)\n+    @Override\n+    protected void setup() throws Exception {\n+        conf.setSubscriptionKeySharedUseClassicPersistentImplementation(implementationType.classic);\n+        conf.setSubscriptionSharedUseClassicPersistentImplementation(implementationType.classic);\n+        this.conf.setUnblockStuckSubscriptionEnabled(false);\n+        this.conf.setSubscriptionKeySharedUseConsistentHashing(true);\n+        conf.setManagedLedgerCacheSizeMB(0);\n+        conf.setManagedLedgerMaxReadsInFlightSizeInMB(0);\n+        conf.setDispatcherRetryBackoffInitialTimeInMs(0);\n+        conf.setDispatcherRetryBackoffMaxTimeInMs(0);\n+        conf.setKeySharedUnblockingIntervalMs(0);\n+        conf.setBrokerDeduplicationEnabled(true);\n+        super.internalSetup();\n+        super.producerBaseSetup();\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    @Override\n+    protected void cleanup() throws Exception {\n+        super.internalCleanup();\n+    }\n+\n+    @AfterMethod(alwaysRun = true)\n+    public void resetDefaultNamespace() throws Exception {\n+        List<String> list = admin.namespaces().getTopics(\"public/default\");\n+        for (String topicName : list){\n+            if (!pulsar.getBrokerService().isSystemTopic(topicName)) {\n+                admin.topics().delete(topicName, false);\n+            }\n+        }\n+        // reset read ahead limits to defaults\n+        ServiceConfiguration defaultConf = new ServiceConfiguration();\n+        conf.setKeySharedLookAheadMsgInReplayThresholdPerSubscription(\n+                defaultConf.getKeySharedLookAheadMsgInReplayThresholdPerSubscription());\n+        conf.setKeySharedLookAheadMsgInReplayThresholdPerConsumer(\n+                defaultConf.getKeySharedLookAheadMsgInReplayThresholdPerConsumer());\n+    }\n+\n+    // Use a fixed seed to make the tests using random values deterministic\n+    // When a test fails, it's possible to re-run it to reproduce the issue\n+    private static final Random random = new Random(1);\n+\n+    private Producer<Integer> createProducer(String topic, boolean enableBatch) throws PulsarClientException {\n+        Producer<Integer> producer = null;\n+        if (enableBatch) {\n+            producer = pulsarClient.newProducer(Schema.INT32)\n+                    .topic(topic)\n+                    .enableBatching(true)\n+                    .maxPendingMessages(2001)\n+                    .batcherBuilder(BatcherBuilder.KEY_BASED)\n+                    .create();\n+        } else {\n+            producer = pulsarClient.newProducer(Schema.INT32)\n+                    .topic(topic)\n+                    .maxPendingMessages(2001)\n+                    .enableBatching(false)\n+                    .create();\n+        }\n+        return producer;\n+    }\n+\n+    @SneakyThrows\n+    private StickyKeyConsumerSelector getSelector(String topic, String subscription) {\n+        Topic t = pulsar.getBrokerService().getTopicIfExists(topic).get().get();\n+        PersistentSubscription sub = (PersistentSubscription) t.getSubscription(subscription);\n+        StickyKeyDispatcher dispatcher = (StickyKeyDispatcher) sub.getDispatcher();\n+        return dispatcher.getSelector();\n+    }\n+\n+    @Test(dataProvider = \"currentImplementationType\", invocationCount = 1)\n+    public void testMessageOrderInSingleConsumerReconnect(KeySharedImplementationType impl) throws Exception {\n+        String topic = newUniqueName(\"testMessageOrderInSingleConsumerReconnect\");\n+        int numberOfKeys = 100;\n+        long pauseTime = 100L;\n+        // don't fail if duplicates are out-of-order\n+        // it's possible to change this setting while experimenting\n+        boolean failOnDuplicatesOutOfOrder = false;\n+\n+        @Cleanup\n+        PulsarClient pulsarClient2 = PulsarClient.builder()\n+                .serviceUrl(pulsar.getBrokerServiceUrl())\n+                .build();\n+\n+        @Cleanup\n+        PulsarClient pulsarClient3 = PulsarClient.builder()\n+                .serviceUrl(pulsar.getBrokerServiceUrl())\n+                .build();\n+\n+        @Cleanup\n+        Producer<Integer> producer = createProducer(topic, false);\n+\n+        // create a consumer and close it to create a subscription\n+        pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .subscribe()\n+                .close();\n+\n+        Set<Integer> remainingMessageValues = Collections.synchronizedSet(new HashSet<>());\n+        BlockingQueue<Pair<Consumer<Integer>, Message<Integer>>> unackedMessages = new LinkedBlockingQueue<>();\n+        AtomicBoolean c2MessagesShouldBeUnacked = new AtomicBoolean(true);\n+        Set<String> keysForC2 = new HashSet<>();\n+        AtomicLong lastMessageTimestamp = new AtomicLong(System.currentTimeMillis());\n+        List<Throwable> exceptionsInHandler = Collections.synchronizedList(new ArrayList<>());\n+\n+        Map<String, Pair<Position, String>> keyPositions = new HashMap<>();\n+        MessageListener<Integer> messageHandler = (consumer, msg) -> {\n+            lastMessageTimestamp.set(System.currentTimeMillis());\n+            synchronized (this) {\n+                try {\n+                    String key = msg.getKey();\n+                    if (c2MessagesShouldBeUnacked.get() && keysForC2.contains(key)) {\n+                        unackedMessages.add(Pair.of(consumer, msg));\n+                        return;\n+                    }\n+                    long delayMillis = ThreadLocalRandom.current().nextLong(25, 50);\n+                    CompletableFuture.delayedExecutor(delayMillis, TimeUnit.MILLISECONDS).execute(() ->\n+                            consumer.acknowledgeAsync(msg));\n+                    MessageIdAdv msgId = (MessageIdAdv) msg.getMessageId();\n+                    Position currentPosition = PositionFactory.create(msgId.getLedgerId(), msgId.getEntryId());\n+                    Pair<Position, String> prevPair = keyPositions.get(key);\n+                    if (prevPair != null && prevPair.getLeft().compareTo(currentPosition) > 0) {\n+                        boolean isDuplicate = !remainingMessageValues.contains(msg.getValue());\n+                        String errorMessage = String.format(\n+                                        \"out of order: key: %s value: %s prev: %s/%s current: %s/%s duplicate: %s\",\n+                                        key, msg.getValue(),\n+                                        prevPair.getLeft(), prevPair.getRight(),\n+                                        currentPosition, consumer.getConsumerName(), isDuplicate);\n+                        log.error(errorMessage);\n+                        if (!isDuplicate || failOnDuplicatesOutOfOrder) {\n+                            fail(errorMessage);\n+                        }\n+                    }\n+                    keyPositions.put(key, Pair.of(currentPosition, consumer.getConsumerName()));\n+                    boolean removed = remainingMessageValues.remove(msg.getValue());\n+                    if (!removed) {\n+                        // duplicates are possible during reconnects, this is not an error\n+                        log.warn(\"Duplicate message: {} value: {}\", msg.getMessageId(), msg.getValue());\n+                    }\n+                } catch (Throwable t) {\n+                    exceptionsInHandler.add(t);\n+                    if (!(t instanceof AssertionError)) {\n+                        log.error(\"Error in message handler\", t);\n+                    }\n+                }\n+            }\n+        };\n+\n+        // Adding a new consumer.\n+        @Cleanup\n+        Consumer<Integer> c1 = pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c1\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .messageListener(messageHandler)\n+                .subscribe();\n+\n+        @Cleanup\n+        Consumer<Integer> c2 = pulsarClient2.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c2\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .messageListener(messageHandler)\n+                .subscribe();\n+\n+        @Cleanup\n+        Consumer<Integer> c3 = pulsarClient3.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c3\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .messageListener(messageHandler)\n+                .subscribe();\n+\n+        StickyKeyConsumerSelector selector = getSelector(topic, SUBSCRIPTION_NAME);\n+\n+        // find keys that will be assigned to c2\n+        for (int i = 0; i < numberOfKeys; i++) {\n+            String key = String.valueOf(i);\n+            byte[] keyBytes = key.getBytes(UTF_8);\n+            int hash = selector.makeStickyKeyHash(keyBytes);\n+            if (selector.select(hash).consumerName().equals(\"c2\")) {\n+                keysForC2.add(key);\n+            }\n+        }\n+\n+        // close c2\n+        c2.close();\n+        Thread.sleep(pauseTime);\n+\n+        // produce messages with random keys\n+        for (int i = 0; i < 1000; i++) {\n+            String key = String.valueOf(random.nextInt(numberOfKeys));\n+            //log.info(\"Producing message with key: {} value: {}\", key, i);\n+            remainingMessageValues.add(i);\n+            producer.newMessage()\n+                    .key(key)\n+                    .value(i)\n+                    .send();\n+        }\n+\n+        // reconnect c2\n+        c2 = pulsarClient2.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c2\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .messageListener(messageHandler)\n+                .startPaused(true)\n+                .subscribe();\n+\n+        Thread.sleep(2 * pauseTime);\n+\n+        // produce messages with c2 keys so that possible race conditions would be more likely to happen\n+        List<String> keysForC2List=new ArrayList<>(keysForC2);\n+        for (int i = 1000; i < 1100; i++) {\n+            String key = keysForC2List.get(random.nextInt(keysForC2List.size()));\n+            log.info(\"Producing message with key: {} value: {}\", key, i);\n+            remainingMessageValues.add(i);\n+            producer.newMessage()\n+                    .key(key)\n+                    .value(i)\n+                    .send();\n+        }\n+\n+        Thread.sleep(2 * pauseTime);\n+\n+        log.info(\"Acking unacked messages to unblock c2 keys\");\n+        // ack the unacked messages to unblock c2 keys\n+        c2MessagesShouldBeUnacked.set(false);\n+        Pair<Consumer<Integer>, Message<Integer>> consumerMessagePair;\n+        while ((consumerMessagePair = unackedMessages.poll()) != null) {\n+            messageHandler.received(consumerMessagePair.getLeft(), consumerMessagePair.getRight());\n+        }\n+\n+        // resume c2 so that permits are while hashes are unblocked so that possible race conditions would\n+        // be more likely to happen\n+        log.info(\"Resuming c2\");\n+        c2.resume();\n+\n+        Awaitility.await().atMost(Duration.ofSeconds(10)).until(() -> {\n+            return remainingMessageValues.isEmpty()\n+                    || System.currentTimeMillis() - lastMessageTimestamp.get() > 50 * pauseTime;\n+        });\n+\n+        try {\n+            assertSoftly(softly -> {\n+                softly.assertThat(remainingMessageValues).as(\"remainingMessageValues\").isEmpty();\n+                softly.assertThat(exceptionsInHandler).as(\"exceptionsInHandler\").isEmpty();\n+            });\n+        } finally {\n+            logTopicStats(topic);\n+        }\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/test/resources/log4j2.xml b/pulsar-broker/src/test/resources/log4j2.xml\nindex a0732096f2845..7b3cd6a04fcca 100644\n--- a/pulsar-broker/src/test/resources/log4j2.xml\n+++ b/pulsar-broker/src/test/resources/log4j2.xml\n@@ -40,12 +40,18 @@\n     <Logger name=\"org.apache.pulsar.broker.service.persistent.PersistentStickyKeyDispatcherMultipleConsumers\" level=\"DEBUG\" additivity=\"false\">\n       <AppenderRef ref=\"CONSOLE\"/>\n     </Logger>\n+    <Logger name=\"org.apache.pulsar.broker.service.persistent.PersistentDispatcherMultipleConsumers\" level=\"DEBUG\" additivity=\"false\">\n+      <AppenderRef ref=\"CONSOLE\"/>\n+    </Logger>\n+    <Logger name=\"org.apache.pulsar.broker.service.Consumer\" level=\"DEBUG\" additivity=\"false\">\n+      <AppenderRef ref=\"CONSOLE\"/>\n+    </Logger>\n     <Logger name=\"org.apache.pulsar.broker.service.DrainingHashesTracker\" level=\"DEBUG\" additivity=\"false\">\n       <AppenderRef ref=\"CONSOLE\"/>\n     </Logger>\n     <Logger name=\"org.apache.pulsar.broker.service.persistent.RescheduleReadHandler\" level=\"DEBUG\" additivity=\"false\">\n       <AppenderRef ref=\"CONSOLE\"/>\n     </Logger>\n-    -->\n+     -->\n   </Loggers>\n </Configuration>\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23854",
    "pr_id": 23854,
    "issue_id": 23848,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Deadlock in DrainingHashesTracker due to synchronized methods\n### Search before asking\n\n- [x] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [x] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nPulsar 4.0.1\n\n### Minimal reproduce step\n\nExact steps to reproduce aren't yet confirmed.\n\nThis problem was faced in a test. The problem is that there isn't a `jstack -l <PID>` thread dump of the deadlocked state. I have a heap dump, but since heap dumps don't contain exactly the same information as a thread dump about threads, it's hard to find out the exact reason why the dead lock happens. There are multiple blocked threads which indicates a dead lock:\n\n<img width=\"1314\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/e0e94d2b-d61d-478a-b644-41dad2b93e65\" />\n\n<img width=\"1153\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/34da420d-33bb-4185-819e-96812a12910b\" />\n\n<img width=\"1011\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b7d02f4e-cc0a-4de6-b943-f18ff747d94d\" />\n\n<img width=\"1129\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/4715666f-f498-47a4-933c-b8e6a652ed85\" />\n\n<img width=\"1197\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/371366a4-938e-4994-8291-ca593389618f\" />\n\n<img width=\"1200\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/28c78430-0a79-46ff-bd4c-c356e3538424\" />\n\n<img width=\"1203\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/6a0a4f9f-2541-4584-a619-0a29105c53b9\" />\n\n<img width=\"1241\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f4ff8988-3d03-47e8-aa83-1263f13e530f\" />\n\n<img width=\"1244\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/13a3a20a-68db-4913-b502-2e3fdd5d5002\" />\n\n### What did you expect to see?\n\nNo dead locks.\n\n### What did you see instead?\n\nThere are multiple threads in blocked state which indicates a dead lock.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 342,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/DrainingHashesTracker.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java"
    ],
    "base_commit": "492a869b8dbdb65f394454754260548020ceac7e",
    "head_commit": "8289e320c119eeb7449ab616957864d048c179d4",
    "repo_url": "https://github.com/apache/pulsar/pull/23854",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23854",
    "dockerfile": "",
    "pr_merged_at": "2025-01-16T11:53:56.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/DrainingHashesTracker.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/DrainingHashesTracker.java\nindex 46762c844db6c..9bc5c5f1e44ec 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/DrainingHashesTracker.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/DrainingHashesTracker.java\n@@ -26,6 +26,8 @@\n import java.util.Map;\n import java.util.PrimitiveIterator;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n import lombok.ToString;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.common.policies.data.DrainingHash;\n@@ -35,6 +37,11 @@\n \n /**\n  * A thread-safe map to store draining hashes in the consumer.\n+ * The implementation uses read-write locks for ensuring thread-safe access. The high-level strategy to prevent\n+ * deadlocks is to perform side-effects (calls to other collaborators which could have other exclusive locks)\n+ * outside of the write lock. Early versions of this class had a problem where deadlocks could occur when\n+ * a consumer operations happened at the same time as another thread requested topic stats which include\n+ * the draining hashes state. This problem is avoided with the current implementation.\n  */\n @Slf4j\n public class DrainingHashesTracker {\n@@ -42,6 +49,7 @@ public class DrainingHashesTracker {\n     private final UnblockingHandler unblockingHandler;\n     // optimize the memory consumption of the map by using primitive int keys\n     private final Int2ObjectOpenHashMap<DrainingHashEntry> drainingHashes = new Int2ObjectOpenHashMap<>();\n+    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n     int batchLevel;\n     boolean unblockedWhileBatching;\n     private final Map<ConsumerIdentityWrapper, ConsumerDrainingHashesStats> consumerDrainingHashesStatsMap =\n@@ -52,9 +60,14 @@ public class DrainingHashesTracker {\n      */\n     @ToString\n     public static class DrainingHashEntry {\n+        private static final AtomicIntegerFieldUpdater<DrainingHashEntry> REF_COUNT_UPDATER =\n+                AtomicIntegerFieldUpdater.newUpdater(DrainingHashEntry.class, \"refCount\");\n+        private static final AtomicIntegerFieldUpdater<DrainingHashEntry> BLOCKED_COUNT_UPDATER =\n+                AtomicIntegerFieldUpdater.newUpdater(DrainingHashEntry.class, \"blockedCount\");\n+\n         private final Consumer consumer;\n-        private int refCount;\n-        private int blockedCount;\n+        private volatile int refCount;\n+        private volatile int blockedCount;\n \n         /**\n          * Constructs a new DrainingHashEntry with the specified Consumer.\n@@ -81,7 +94,7 @@ public Consumer getConsumer() {\n          * Increments the reference count.\n          */\n         void incrementRefCount() {\n-            refCount++;\n+            REF_COUNT_UPDATER.incrementAndGet(this);\n         }\n \n         /**\n@@ -90,14 +103,14 @@ void incrementRefCount() {\n          * @return true if the reference count is zero, false otherwise\n          */\n         boolean decrementRefCount() {\n-            return --refCount == 0;\n+            return REF_COUNT_UPDATER.decrementAndGet(this) == 0;\n         }\n \n         /**\n          * Increments the blocked count.\n          */\n         void incrementBlockedCount() {\n-            blockedCount++;\n+            BLOCKED_COUNT_UPDATER.incrementAndGet(this);\n         }\n \n         /**\n@@ -108,51 +121,89 @@ void incrementBlockedCount() {\n         boolean isBlocking() {\n             return blockedCount > 0;\n         }\n+\n+        /**\n+         * Gets the current reference count.\n+         *\n+         * @return the current reference count\n+         */\n+        int getRefCount() {\n+            return refCount;\n+        }\n+\n+        /**\n+         * Gets the current blocked count.\n+         *\n+         * @return the current blocked count\n+         */\n+        int getBlockedCount() {\n+            return blockedCount;\n+        }\n     }\n \n     private class ConsumerDrainingHashesStats {\n         private final RoaringBitmap drainingHashes = new RoaringBitmap();\n-        long drainingHashesClearedTotal;\n+        private long drainingHashesClearedTotal;\n+        private final ReentrantReadWriteLock statsLock = new ReentrantReadWriteLock();\n \n-        public synchronized void addHash(int stickyHash) {\n-            drainingHashes.add(stickyHash);\n+        public void addHash(int stickyHash) {\n+            statsLock.writeLock().lock();\n+            try {\n+                drainingHashes.add(stickyHash);\n+            } finally {\n+                statsLock.writeLock().unlock();\n+            }\n         }\n \n-        public synchronized boolean clearHash(int hash) {\n-            drainingHashes.remove(hash);\n-            drainingHashesClearedTotal++;\n-            boolean empty = drainingHashes.isEmpty();\n-            if (log.isDebugEnabled()) {\n-                log.debug(\"[{}] Cleared hash {} in stats. empty={} totalCleared={} hashes={}\",\n-                        dispatcherName, hash, empty, drainingHashesClearedTotal, drainingHashes.getCardinality());\n+        public boolean clearHash(int hash) {\n+            statsLock.writeLock().lock();\n+            try {\n+                drainingHashes.remove(hash);\n+                drainingHashesClearedTotal++;\n+                boolean empty = drainingHashes.isEmpty();\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"[{}] Cleared hash {} in stats. empty={} totalCleared={} hashes={}\",\n+                            dispatcherName, hash, empty, drainingHashesClearedTotal, drainingHashes.getCardinality());\n+                }\n+                if (empty) {\n+                    // reduce memory usage by trimming the bitmap when the RoaringBitmap instance is empty\n+                    drainingHashes.trim();\n+                }\n+                return empty;\n+            } finally {\n+                statsLock.writeLock().unlock();\n             }\n-            return empty;\n         }\n \n-        public synchronized void updateConsumerStats(Consumer consumer, ConsumerStatsImpl consumerStats) {\n-            int drainingHashesUnackedMessages = 0;\n-            List<DrainingHash> drainingHashesStats = new ArrayList<>();\n-            PrimitiveIterator.OfInt hashIterator = drainingHashes.stream().iterator();\n-            while (hashIterator.hasNext()) {\n-                int hash = hashIterator.nextInt();\n-                DrainingHashEntry entry = getEntry(hash);\n-                if (entry == null) {\n-                    log.warn(\"[{}] Draining hash {} not found in the tracker for consumer {}\", dispatcherName, hash,\n-                            consumer);\n-                    continue;\n+        public void updateConsumerStats(Consumer consumer, ConsumerStatsImpl consumerStats) {\n+            statsLock.readLock().lock();\n+            try {\n+                int drainingHashesUnackedMessages = 0;\n+                List<DrainingHash> drainingHashesStats = new ArrayList<>();\n+                PrimitiveIterator.OfInt hashIterator = drainingHashes.stream().iterator();\n+                while (hashIterator.hasNext()) {\n+                    int hash = hashIterator.nextInt();\n+                    DrainingHashEntry entry = getEntry(hash);\n+                    if (entry == null) {\n+                        log.warn(\"[{}] Draining hash {} not found in the tracker for consumer {}\", dispatcherName, hash,\n+                                consumer);\n+                        continue;\n+                    }\n+                    int unackedMessages = entry.getRefCount();\n+                    DrainingHashImpl drainingHash = new DrainingHashImpl();\n+                    drainingHash.hash = hash;\n+                    drainingHash.unackMsgs = unackedMessages;\n+                    drainingHash.blockedAttempts = entry.getBlockedCount();\n+                    drainingHashesStats.add(drainingHash);\n+                    drainingHashesUnackedMessages += unackedMessages;\n                 }\n-                int unackedMessages = entry.refCount;\n-                DrainingHashImpl drainingHash = new DrainingHashImpl();\n-                drainingHash.hash = hash;\n-                drainingHash.unackMsgs = unackedMessages;\n-                drainingHash.blockedAttempts = entry.blockedCount;\n-                drainingHashesStats.add(drainingHash);\n-                drainingHashesUnackedMessages += unackedMessages;\n+                consumerStats.drainingHashesCount = drainingHashesStats.size();\n+                consumerStats.drainingHashesClearedTotal = drainingHashesClearedTotal;\n+                consumerStats.drainingHashesUnackedMessages = drainingHashesUnackedMessages;\n+                consumerStats.drainingHashes = drainingHashesStats;\n+            } finally {\n+                statsLock.readLock().unlock();\n             }\n-            consumerStats.drainingHashesCount = drainingHashesStats.size();\n-            consumerStats.drainingHashesClearedTotal = drainingHashesClearedTotal;\n-            consumerStats.drainingHashesUnackedMessages = drainingHashesUnackedMessages;\n-            consumerStats.drainingHashes = drainingHashesStats;\n         }\n     }\n \n@@ -179,49 +230,79 @@ public DrainingHashesTracker(String dispatcherName, UnblockingHandler unblocking\n      * @param consumer the consumer\n      * @param stickyHash the sticky hash\n      */\n-    public synchronized void addEntry(Consumer consumer, int stickyHash) {\n+    public void addEntry(Consumer consumer, int stickyHash) {\n         if (stickyHash == 0) {\n             throw new IllegalArgumentException(\"Sticky hash cannot be 0\");\n         }\n-        DrainingHashEntry entry = drainingHashes.get(stickyHash);\n-        if (entry == null) {\n-            if (log.isDebugEnabled()) {\n-                log.debug(\"[{}] Adding and incrementing draining hash {} for consumer id:{} name:{}\", dispatcherName,\n-                        stickyHash, consumer.consumerId(), consumer.consumerName());\n-            }\n-            entry = new DrainingHashEntry(consumer);\n-            drainingHashes.put(stickyHash, entry);\n-            // update the consumer specific stats\n-            consumerDrainingHashesStatsMap.computeIfAbsent(new ConsumerIdentityWrapper(consumer),\n-                    k -> new ConsumerDrainingHashesStats()).addHash(stickyHash);\n-        } else if (entry.getConsumer() != consumer) {\n-            throw new IllegalStateException(\n-                    \"Consumer \" + entry.getConsumer() + \" is already draining hash \" + stickyHash\n-                            + \" in dispatcher \" + dispatcherName + \". Same hash being used for consumer \" + consumer\n-                            + \".\");\n-        } else {\n-            if (log.isDebugEnabled()) {\n-                log.debug(\"[{}] Draining hash {} incrementing {} consumer id:{} name:{}\", dispatcherName, stickyHash,\n-                        entry.refCount + 1, consumer.consumerId(), consumer.consumerName());\n+\n+        DrainingHashEntry entry;\n+        ConsumerDrainingHashesStats addedStatsForNewEntry = null;\n+        lock.writeLock().lock();\n+        try {\n+            entry = drainingHashes.get(stickyHash);\n+            if (entry == null) {\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"[{}] Adding and incrementing draining hash {} for consumer id:{} name:{}\",\n+                            dispatcherName, stickyHash, consumer.consumerId(), consumer.consumerName());\n+                }\n+                entry = new DrainingHashEntry(consumer);\n+                drainingHashes.put(stickyHash, entry);\n+                // add the consumer specific stats\n+                addedStatsForNewEntry = consumerDrainingHashesStatsMap\n+                        .computeIfAbsent(new ConsumerIdentityWrapper(consumer), k -> new ConsumerDrainingHashesStats());\n+            } else if (entry.getConsumer() != consumer) {\n+                throw new IllegalStateException(\n+                        \"Consumer \" + entry.getConsumer() + \" is already draining hash \" + stickyHash\n+                                + \" in dispatcher \" + dispatcherName + \". Same hash being used for consumer \" + consumer\n+                                + \".\");\n+            } else {\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"[{}] Draining hash {} incrementing {} consumer id:{} name:{}\", dispatcherName,\n+                            stickyHash, entry.getRefCount() + 1, consumer.consumerId(), consumer.consumerName());\n+                }\n             }\n+        } finally {\n+            lock.writeLock().unlock();\n         }\n+        // increment the reference count of the entry (applies to both new and existing entries)\n         entry.incrementRefCount();\n+\n+        // perform side-effects outside of the lock to reduce chances for deadlocks\n+        if (addedStatsForNewEntry != null) {\n+            // add hash to added stats\n+            addedStatsForNewEntry.addHash(stickyHash);\n+        }\n     }\n \n     /**\n      * Start a batch operation. There could be multiple nested batch operations.\n      * The unblocking of sticky key hashes will be done only when the last batch operation ends.\n      */\n-    public synchronized void startBatch() {\n-        batchLevel++;\n+    public void startBatch() {\n+        lock.writeLock().lock();\n+        try {\n+            batchLevel++;\n+        } finally {\n+            lock.writeLock().unlock();\n+        }\n     }\n \n     /**\n      * End a batch operation.\n      */\n-    public synchronized void endBatch() {\n-        if (--batchLevel == 0 && unblockedWhileBatching) {\n-            unblockedWhileBatching = false;\n+    public void endBatch() {\n+        boolean notifyUnblocking = false;\n+        lock.writeLock().lock();\n+        try {\n+            if (--batchLevel == 0 && unblockedWhileBatching) {\n+                unblockedWhileBatching = false;\n+                notifyUnblocking = true;\n+            }\n+        } finally {\n+            lock.writeLock().unlock();\n+        }\n+        // notify unblocking of the hash outside the lock\n+        if (notifyUnblocking) {\n             unblockingHandler.stickyKeyHashUnblocked(-1);\n         }\n     }\n@@ -231,13 +312,14 @@ public synchronized void endBatch() {\n      *\n      * @param consumer   the consumer\n      * @param stickyHash the sticky hash\n-     * @param closing\n+     * @param closing    whether the consumer is closing\n      */\n-    public synchronized void reduceRefCount(Consumer consumer, int stickyHash, boolean closing) {\n+    public void reduceRefCount(Consumer consumer, int stickyHash, boolean closing) {\n         if (stickyHash == 0) {\n             return;\n         }\n-        DrainingHashEntry entry = drainingHashes.get(stickyHash);\n+\n+        DrainingHashEntry entry = getEntry(stickyHash);\n         if (entry == null) {\n             return;\n         }\n@@ -252,24 +334,40 @@ public synchronized void reduceRefCount(Consumer consumer, int stickyHash, boole\n                 log.debug(\"[{}] Draining hash {} removing consumer id:{} name:{}\", dispatcherName, stickyHash,\n                         consumer.consumerId(), consumer.consumerName());\n             }\n-            DrainingHashEntry removed = drainingHashes.remove(stickyHash);\n+\n+            DrainingHashEntry removed;\n+            boolean notifyUnblocking = false;\n+            lock.writeLock().lock();\n+            try {\n+                removed = drainingHashes.remove(stickyHash);\n+                if (!closing && removed.isBlocking()) {\n+                    if (batchLevel > 0) {\n+                        unblockedWhileBatching = true;\n+                    } else {\n+                        notifyUnblocking = true;\n+                    }\n+                }\n+            } finally {\n+                lock.writeLock().unlock();\n+            }\n+\n+            // perform side-effects outside of the lock to reduce chances for deadlocks\n+\n             // update the consumer specific stats\n             ConsumerDrainingHashesStats drainingHashesStats =\n                     consumerDrainingHashesStatsMap.get(new ConsumerIdentityWrapper(consumer));\n             if (drainingHashesStats != null) {\n                 drainingHashesStats.clearHash(stickyHash);\n             }\n-            if (!closing && removed.isBlocking()) {\n-                if (batchLevel > 0) {\n-                    unblockedWhileBatching = true;\n-                } else {\n-                    unblockingHandler.stickyKeyHashUnblocked(stickyHash);\n-                }\n+\n+            // notify unblocking of the hash outside the lock\n+            if (notifyUnblocking) {\n+                unblockingHandler.stickyKeyHashUnblocked(stickyHash);\n             }\n         } else {\n             if (log.isDebugEnabled()) {\n-                log.debug(\"[{}] Draining hash {} decrementing {} consumer id:{} name:{}\", dispatcherName, stickyHash,\n-                        entry.refCount, consumer.consumerId(), consumer.consumerName());\n+                log.debug(\"[{}] Draining hash {} decrementing {} consumer id:{} name:{}\", dispatcherName,\n+                        stickyHash, entry.getRefCount(), consumer.consumerId(), consumer.consumerName());\n             }\n         }\n     }\n@@ -281,12 +379,12 @@ public synchronized void reduceRefCount(Consumer consumer, int stickyHash, boole\n      * @param stickyKeyHash the sticky key hash\n      * @return true if the sticky key hash should be blocked, false otherwise\n      */\n-    public synchronized boolean shouldBlockStickyKeyHash(Consumer consumer, int stickyKeyHash) {\n+    public boolean shouldBlockStickyKeyHash(Consumer consumer, int stickyKeyHash) {\n         if (stickyKeyHash == STICKY_KEY_HASH_NOT_SET) {\n             log.warn(\"[{}] Sticky key hash is not set. Allowing dispatching\", dispatcherName);\n             return false;\n         }\n-        DrainingHashEntry entry = drainingHashes.get(stickyKeyHash);\n+        DrainingHashEntry entry = getEntry(stickyKeyHash);\n         // if the entry is not found, the hash is not draining. Don't block the hash.\n         if (entry == null) {\n             return false;\n@@ -294,10 +392,14 @@ public synchronized boolean shouldBlockStickyKeyHash(Consumer consumer, int stic\n         // hash has been reassigned to the original consumer, remove the entry\n         // and don't block the hash\n         if (entry.getConsumer() == consumer) {\n-            log.info(\"[{}] Hash {} has been reassigned consumer {}. \"\n-                            + \"The draining hash entry with refCount={} will be removed.\",\n-                    dispatcherName, stickyKeyHash, entry.getConsumer(), entry.refCount);\n-            drainingHashes.remove(stickyKeyHash, entry);\n+            log.info(\"[{}] Hash {} has been reassigned consumer {}. The draining hash entry with refCount={} will \"\n+                    + \"be removed.\", dispatcherName, stickyKeyHash, entry.getConsumer(), entry.getRefCount());\n+            lock.writeLock().lock();\n+            try {\n+                drainingHashes.remove(stickyKeyHash, entry);\n+            } finally {\n+                lock.writeLock().unlock();\n+            }\n             return false;\n         }\n         // increment the blocked count which is used to determine if the hash is blocking\n@@ -313,16 +415,29 @@ public synchronized boolean shouldBlockStickyKeyHash(Consumer consumer, int stic\n      * @param stickyKeyHash the sticky key hash\n      * @return the draining hash entry, or null if not found\n      */\n-    public synchronized DrainingHashEntry getEntry(int stickyKeyHash) {\n-        return stickyKeyHash != 0 ? drainingHashes.get(stickyKeyHash) : null;\n+    public DrainingHashEntry getEntry(int stickyKeyHash) {\n+        if (stickyKeyHash == 0) {\n+            return null;\n+        }\n+        lock.readLock().lock();\n+        try {\n+            return drainingHashes.get(stickyKeyHash);\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     /**\n      * Clear all entries in the draining hashes tracker.\n      */\n-    public synchronized void clear() {\n-        drainingHashes.clear();\n-        consumerDrainingHashesStatsMap.clear();\n+    public void clear() {\n+        lock.writeLock().lock();\n+        try {\n+            drainingHashes.clear();\n+            consumerDrainingHashesStatsMap.clear();\n+        } finally {\n+            lock.writeLock().unlock();\n+        }\n     }\n \n     /**\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java\nindex 6a41e86f8934e..8364cae53b223 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/BrokerTestUtil.java\n@@ -224,7 +224,22 @@ public static String getJsonResourceAsString(String uri) {\n     public static <T> void receiveMessages(BiFunction<Consumer<T>, Message<T>, Boolean> messageHandler,\n                                        Duration quietTimeout,\n                                        Consumer<T>... consumers) {\n-        FutureUtil.waitForAll(Arrays.stream(consumers)\n+        receiveMessages(messageHandler, quietTimeout, Arrays.stream(consumers));\n+    }\n+\n+    /**\n+     * Receive messages concurrently from multiple consumers and handles them using the provided message handler.\n+     * The message handler should return true if it wants to continue receiving more messages, false otherwise.\n+     *\n+     * @param messageHandler the message handler\n+     * @param quietTimeout the duration of quiet time after which the method will stop waiting for more messages\n+     * @param consumers the consumers to receive messages from\n+     * @param <T> the message value type\n+     */\n+    public static <T> void receiveMessages(BiFunction<Consumer<T>, Message<T>, Boolean> messageHandler,\n+                                           Duration quietTimeout,\n+                                           Stream<Consumer<T>> consumers) {\n+        FutureUtil.waitForAll(consumers\n                 .map(consumer -> receiveMessagesAsync(consumer, quietTimeout, messageHandler)).toList()).join();\n     }\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\nindex 92257c1df53f8..b7f11b3764150 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n@@ -55,6 +55,7 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.function.BiFunction;\n import java.util.stream.Collectors;\n@@ -2359,4 +2360,174 @@ public void testOrderingAfterReconnects(KeySharedImplementationType impl) throws\n             logTopicStats(topic);\n         }\n     }\n+\n+    @Test(dataProvider = \"currentImplementationType\")\n+    public void testDeliveryOfRemainingMessagesWithoutDeadlock(KeySharedImplementationType impl) throws Exception {\n+        // don't set the unblock stuck subscription flag which is set to false by default, but for this test class\n+        // it is enabled in the setup method\n+        conf.setUnblockStuckSubscriptionEnabled(false);\n+\n+        // this was the way how reproduce the deadlock issue https://github.com/apache/pulsar/issues/23848\n+        @Cleanup(\"interrupt\")\n+        Thread updateRatesThread = new Thread(() -> {\n+            int count = 0;\n+            // the deadlock issue typically reproduced before 100000 iterations\n+            while (!Thread.currentThread().isInterrupted() && count++ < 200_000) {\n+                pulsar.getBrokerService().updateRates();\n+                Thread.yield();\n+                if (count % 10000 == 0) {\n+                    log.info(\"updateRatesThread count: {}\", count);\n+                }\n+            }\n+        }, \"update-rates-thread\");\n+        updateRatesThread.start();\n+\n+        String topic = newUniqueName(\"testDeliveryOfRemainingMessagesWithoutDeadlock\");\n+        int numberOfKeys = 100;\n+        long pauseTime = 100L;\n+\n+        @Cleanup\n+        Producer<Integer> producer = createProducer(topic, false);\n+\n+        // create a consumer and close it to create a subscription\n+        pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .subscribe()\n+                .close();\n+\n+        Set<Integer> remainingMessageValues = Collections.synchronizedSet(new HashSet<>());\n+        List<Pair<Consumer<Integer>, Message<Integer>>> unackedMessages = new ArrayList<>();\n+        AtomicBoolean c2MessagesShouldBeUnacked = new AtomicBoolean(true);\n+        Set<String> keysForC2 = new HashSet<>();\n+\n+        Map<String, Pair<Position, String>> keyPositions = new HashMap<>();\n+        BiFunction<Consumer<Integer>, Message<Integer>, Boolean> messageHandler = (consumer, msg) -> {\n+            synchronized (this) {\n+                String key = msg.getKey();\n+                if (c2MessagesShouldBeUnacked.get() && keysForC2.contains(key)) {\n+                    unackedMessages.add(Pair.of(consumer, msg));\n+                    return true;\n+                }\n+                consumer.acknowledgeAsync(msg);\n+                MessageIdAdv msgId = (MessageIdAdv) msg.getMessageId();\n+                Position currentPosition = PositionFactory.create(msgId.getLedgerId(), msgId.getEntryId());\n+                Pair<Position, String> prevPair = keyPositions.get(key);\n+                if (prevPair != null && prevPair.getLeft().compareTo(currentPosition) > 0) {\n+                    log.error(\"key: {} value: {} prev: {}/{} current: {}/{}\", key, msg.getValue(), prevPair.getLeft(),\n+                            prevPair.getRight(), currentPosition, consumer.getConsumerName());\n+                    fail(\"out of order\");\n+                }\n+                keyPositions.put(key, Pair.of(currentPosition, consumer.getConsumerName()));\n+                boolean removed = remainingMessageValues.remove(msg.getValue());\n+                if (!removed) {\n+                    // duplicates are possible during reconnects, this is not an error\n+                    log.warn(\"Duplicate message: {} value: {}\", msg.getMessageId(), msg.getValue());\n+                }\n+                return true;\n+            }\n+        };\n+\n+        // Adding a new consumer.\n+        @Cleanup\n+        Consumer<Integer> c1 = pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c1\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .subscribe();\n+\n+        @Cleanup\n+        Consumer<Integer> c2 = pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c2\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .subscribe();\n+\n+        @Cleanup\n+        Consumer<Integer> c3 = pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c3\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .subscribe();\n+\n+        StickyKeyConsumerSelector selector = getSelector(topic, SUBSCRIPTION_NAME);\n+\n+        // find keys that will be assigned to c2\n+        for (int i = 0; i < numberOfKeys; i++) {\n+            String key = String.valueOf(i);\n+            byte[] keyBytes = key.getBytes(UTF_8);\n+            int hash = selector.makeStickyKeyHash(keyBytes);\n+            if (selector.select(hash).consumerName().equals(\"c2\")) {\n+                keysForC2.add(key);\n+            }\n+        }\n+\n+        // close c2\n+        c2.close();\n+        Thread.sleep(pauseTime);\n+\n+        // produce messages with random keys\n+        for (int i = 0; i < 1000; i++) {\n+            String key = String.valueOf(random.nextInt(numberOfKeys));\n+            //log.info(\"Producing message with key: {} value: {}\", key, i);\n+            producer.newMessage()\n+                    .key(key)\n+                    .value(i)\n+                    .send();\n+            remainingMessageValues.add(i);\n+        }\n+\n+        // consume the messages\n+        receiveMessages(messageHandler, Duration.ofSeconds(1), c1, c3);\n+\n+        c2MessagesShouldBeUnacked.set(false);\n+\n+        // reconnect c2\n+        c2 = pulsarClient.newConsumer(Schema.INT32)\n+                .topic(topic)\n+                .consumerName(\"c2\")\n+                .subscriptionName(SUBSCRIPTION_NAME)\n+                .subscriptionType(SubscriptionType.Key_Shared)\n+                .startPaused(true)\n+                .subscribe();\n+\n+        Thread.sleep(2 * pauseTime);\n+\n+        // produce messages with c2 keys\n+        List<String> keysForC2List=new ArrayList<>(keysForC2);\n+        for (int i = 1000; i < 1100; i++) {\n+            String key = keysForC2List.get(random.nextInt(keysForC2List.size()));\n+            //log.info(\"Producing message with key: {} value: {}\", key, i);\n+            producer.newMessage()\n+                    .key(key)\n+                    .value(i)\n+                    .send();\n+            remainingMessageValues.add(i);\n+        }\n+\n+        Thread.sleep(2 * pauseTime);\n+\n+        // ack the unacked messages to unblock c2 keys\n+        unackedMessages.forEach(pair -> {\n+            messageHandler.apply(pair.getLeft(), pair.getRight());\n+        });\n+\n+        Thread.sleep(50 * pauseTime);\n+\n+        // resume c2\n+        c2.resume();\n+\n+        // consume the messages\n+        receiveMessages(messageHandler, Duration.ofSeconds(2), c1, c2, c3);\n+\n+        try {\n+            assertEquals(remainingMessageValues, Collections.emptySet());\n+        } finally {\n+            logTopicStats(topic);\n+        }\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23852",
    "pr_id": 23852,
    "issue_id": 23389,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11125404278/job/30955253737?pr=23327#step:11:1680\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 5, Failures: 1, Errors: 0, Skipped: 4, Time elapsed: 74.942 s <<< FAILURE! - in org.apache.pulsar.broker.service.ZkSessionExpireTest\r\n  Error:  org.apache.pulsar.broker.service.ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild[false, class org.apache.pulsar.broker.service.NetworkErrorTestBase$PreferBrokerModularLoadManager](4)  Time elapsed: 31.007 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition expected [2] but found [1] within 10 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.pulsar.broker.service.ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild(ZkSessionExpireTest.java:154)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  Caused by: java.lang.AssertionError: expected [2] but found [1]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n  \tat org.apache.pulsar.broker.service.ZkSessionExpireTest.lambda$testTopicUnloadAfterSessionRebuild$4(ZkSessionExpireTest.java:155)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 401,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java"
    ],
    "base_commit": "492a869b8dbdb65f394454754260548020ceac7e",
    "head_commit": "31bf3160efee29533d10e18cf64add460a02ad49",
    "repo_url": "https://github.com/apache/pulsar/pull/23852",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23852",
    "dockerfile": "",
    "pr_merged_at": "2025-01-16T08:40:31.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\nindex dd0d7c423b643..b05dae2c3c2d1 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\n@@ -26,6 +26,7 @@\n import java.util.Optional;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.broker.ServiceConfiguration;\n@@ -39,7 +40,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class ZkSessionExpireTest extends NetworkErrorTestBase {\n \n     private java.util.function.Consumer<ServiceConfiguration> settings;\n@@ -94,7 +95,7 @@ public void testTopicUnloadAfterSessionRebuild(boolean enableSystemTopic, Class\n         admin2.namespaces().unload(defaultNamespace);\n \n         // Confirm all brokers registered.\n-        Awaitility.await().untilAsserted(() -> {\n+        Awaitility.await().atMost(Duration.ofSeconds(20)).untilAsserted(() -> {\n             assertEquals(getAvailableBrokers(pulsar1).size(), 2);\n             assertEquals(getAvailableBrokers(pulsar2).size(), 2);\n         });\n@@ -160,7 +161,21 @@ public void testTopicUnloadAfterSessionRebuild(boolean enableSystemTopic, Class\n         // Verify: the topic on broker-2 is fine.\n         Awaitility.await().atMost(Duration.ofSeconds(10)).untilAsserted(() -> {\n             CompletableFuture<Optional<Topic>> future = pulsar1.getBrokerService().getTopic(topicName, false);\n-            assertTrue(future == null || future.isCompletedExceptionally());\n+            log.info(\"broker 1 topics {}\", pulsar1.getBrokerService().getTopics().keySet());\n+            log.info(\"broker 2 topics {}\", pulsar2.getBrokerService().getTopics().keySet());\n+            log.info(\"broker 1 bundles {}\", pulsar1.getNamespaceService().getOwnershipCache().getOwnedBundles()\n+                    .keySet().stream().map(k -> k.getNamespaceObject().toString() + \"/\" + k.getBundleRange())\n+                    .filter(s -> s.contains(defaultNamespace)).collect(Collectors.toList()));\n+            log.info(\"broker 2 bundles {}\", pulsar2.getNamespaceService().getOwnershipCache().getOwnedBundles()\n+                    .keySet().stream().map(k -> k.getNamespaceObject().toString() + \"/\" + k.getBundleRange())\n+                    .filter(s -> s.contains(defaultNamespace)).collect(Collectors.toList()));\n+            log.info(\"future: {}, isDone: {}, isCompletedExceptionally: {}\",\n+                    future, future == null ? \"null\" : future.isDone(),\n+                    future, future == null ? \"null\" : future.isCompletedExceptionally());\n+            assertTrue(future == null\n+                    || !pulsar1.getBrokerService().getTopics().containsKey(topicName)\n+                    || (future.isDone() && !future.isCompletedExceptionally() && future.get().isEmpty())\n+                    || future.isCompletedExceptionally());\n         });\n         Topic broker2Topic3 = pulsar2.getBrokerService().getTopic(topicName, false).join().get();\n         assertNotNull(broker2Topic3);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23824",
    "pr_id": 23824,
    "issue_id": 20635,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] pulsar keep creating dead letter queue producer and exceed the maximum limit\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Version\r\n2.11\r\n\r\n\r\n### Minimal reproduce step\r\nUse pulsar java client library to create a consumer with dlq prodcer. \r\n1. after application starts, stop bookie\r\n2. produce some message to the queue and trigger the consumer\r\n3.  check the log. \r\nIt seems keep creating dead letter queue producer, and eventually hit the maximum limit\r\n\r\n### What did you expect to see?\r\n\r\nextra producer should not be created if there is an issue on pulsar\r\n\r\n### What did you see instead?\r\n\r\ncreated over 10000 producers and eventually exceed the limits\r\n\r\n### Anything else?\r\nsee logs\r\n\r\n```\r\n--\r\nStarting Pulsar producer perf with config: {\"topicName\":\"persistent://public/default/my-topic\",\"producerName\":null,\"sendTimeoutMs\":30000,\"blockIfQueueFull\":false,\"maxPendingMessages\":0,\"maxPendingMessagesAcrossPartitions\":0,\"messageRoutingMode\":\"RoundRobinPartition\",\"hashingScheme\":\"JavaStringHash\",\"cryptoFailureAction\":\"FAIL\",\"batchingMaxPublishDelayMicros\":1000,\"batchingPartitionSwitchFrequencyByPublishDelay\":10,\"batchingMaxMessages\":1000,\"batchingMaxBytes\":131072,\"batchingEnabled\":true,\"chunkingEnabled\":false,\"chunkMaxMessageSize\":-1,\"compressionType\":\"NONE\",\"initialSequenceId\":null,\"autoUpdatePartitions\":true,\"autoUpdatePartitionsIntervalSeconds\":60,\"multiSchema\":true,\"accessMode\":\"Shared\",\"lazyStartPartitionedProducers\":false,\"properties\":{},\"initialSubscriptionName\":null}\r\n--\r\nPulsar client config: {\"serviceUrl\":\"pulsar://pulsar:6650\",\"authPluginClassName\":null,\"authParams\":null,\"authParamMap\":null,\"operationTimeoutMs\":30000,\"lookupTimeoutMs\":30000,\"statsIntervalSeconds\":60,\"numIoThreads\":1,\"numListenerThreads\":1,\"connectionsPerBroker\":1,\"connectionMaxIdleSeconds\":180,\"useTcpNoDelay\":true,\"useTls\":false,\"tlsKeyFilePath\":null,\"tlsCertificateFilePath\":null,\"tlsTrustCertsFilePath\":null,\"tlsAllowInsecureConnection\":false,\"tlsHostnameVerificationEnable\":false,\"concurrentLookupRequest\":5000,\"maxLookupRequest\":50000,\"maxLookupRedirects\":20,\"maxNumberOfRejectedRequestPerConnection\":50,\"keepAliveIntervalSeconds\":30,\"connectionTimeoutMs\":10000,\"requestTimeoutMs\":60000,\"initialBackoffIntervalNanos\":100000000,\"maxBackoffIntervalNanos\":60000000000,\"enableBusyWait\":false,\"listenerName\":null,\"useKeyStoreTls\":false,\"sslProvider\":null,\"tlsKeyStoreType\":\"JKS\",\"tlsKeyStorePath\":null,\"tlsKeyStorePassword\":null,\"tlsTrustStoreType\":\"JKS\",\"tlsTrustStorePath\":null,\"tlsTrustStorePassword\":null,\"tlsCiphers\":[],\"tlsProtocols\":[],\"memoryLimitBytes\":67108864,\"proxyServiceUrl\":null,\"proxyProtocol\":null,\"enableTransaction\":true,\"dnsLookupBindAddress\":null,\"dnsLookupBindPort\":0,\"socks5ProxyAddress\":null,\"socks5ProxyUsername\":null,\"socks5ProxyPassword\":null}\r\n[persistent://public/default/dlq] [null] Creating producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/dlq] [pulsar-dev-5-10032] Created producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/my-topic] failed to get schema : org.apache.pulsar.client.api.PulsarClientException: {\"errorMsg\":\"org.apache.pulsar.broker.service.schema.exceptions.SchemaException: Bookie handle is not available - ledger=35399 - operation=Failed to read entry - entry=0\",\"reqId\":4059106653410978868, \"remote\":\"pulsar/10.204.70.7:6650\", \"local\":\"/10.204.68.122:44372\"}\r\nDead letter producer exception with topic: persistent://public/default/dlq\r\nStarting Pulsar producer perf with config: {\"topicName\":\"persistent://public/default/dlq\",\"producerName\":null,\"sendTimeoutMs\":30000,\"blockIfQueueFull\":false,\"maxPendingMessages\":0,\"maxPendingMessagesAcrossPartitions\":0,\"messageRoutingMode\":\"RoundRobinPartition\",\"hashingScheme\":\"JavaStringHash\",\"cryptoFailureAction\":\"FAIL\",\"batchingMaxPublishDelayMicros\":1000,\"batchingPartitionSwitchFrequencyByPublishDelay\":10,\"batchingMaxMessages\":1000,\"batchingMaxBytes\":131072,\"batchingEnabled\":true,\"chunkingEnabled\":false,\"chunkMaxMessageSize\":-1,\"compressionType\":\"NONE\",\"initialSequenceId\":null,\"autoUpdatePartitions\":true,\"autoUpdatePartitionsIntervalSeconds\":60,\"multiSchema\":true,\"accessMode\":\"Shared\",\"lazyStartPartitionedProducers\":false,\"properties\":{},\"initialSubscriptionName\":null}\r\nPulsar client config: {\"serviceUrl\":\"pulsar://pulsar:6650\",\"authPluginClassName\":null,\"authParams\":null,\"authParamMap\":null,\"operationTimeoutMs\":30000,\"lookupTimeoutMs\":30000,\"statsIntervalSeconds\":60,\"numIoThreads\":1,\"numListenerThreads\":1,\"connectionsPerBroker\":1,\"connectionMaxIdleSeconds\":180,\"useTcpNoDelay\":true,\"useTls\":false,\"tlsKeyFilePath\":null,\"tlsCertificateFilePath\":null,\"tlsTrustCertsFilePath\":null,\"tlsAllowInsecureConnection\":false,\"tlsHostnameVerificationEnable\":false,\"concurrentLookupRequest\":5000,\"maxLookupRequest\":50000,\"maxLookupRedirects\":20,\"maxNumberOfRejectedRequestPerConnection\":50,\"keepAliveIntervalSeconds\":30,\"connectionTimeoutMs\":10000,\"requestTimeoutMs\":60000,\"initialBackoffIntervalNanos\":100000000,\"maxBackoffIntervalNanos\":60000000000,\"enableBusyWait\":false,\"listenerName\":null,\"useKeyStoreTls\":false,\"sslProvider\":null,\"tlsKeyStoreType\":\"JKS\",\"tlsKeyStorePath\":null,\"tlsKeyStorePassword\":null,\"tlsTrustStoreType\":\"JKS\",\"tlsTrustStorePath\":null,\"tlsTrustStorePassword\":null,\"tlsCiphers\":[],\"tlsProtocols\":[],\"memoryLimitBytes\":67108864,\"proxyServiceUrl\":null,\"proxyProtocol\":null,\"enableTransaction\":true,\"dnsLookupBindAddress\":null,\"dnsLookupBindPort\":0,\"socks5ProxyAddress\":null,\"socks5ProxyUsername\":null,\"socks5ProxyPassword\":null}\r\n[persistent://public/default/dlq] [null] Creating producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/dlq] [pulsar-dev-5-10033] Created producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/my-topic] failed to get schema : org.apache.pulsar.client.api.PulsarClientException: {\"errorMsg\":\"org.apache.pulsar.broker.service.schema.exceptions.SchemaException: Bookie handle is not available - ledger=35399 - operation=Failed to read entry - entry=0\",\"reqId\":4059106653410978872, \"remote\":\"pulsar/10.204.70.7:6650\", \"local\":\"/10.204.68.122:44372\"}\r\nDead letter producer exception with topic: persistent://public/default/dlq\r\nStarting Pulsar producer perf with config: {\"topicName\":\"persistent://public/default/dlq\",\"producerName\":null,\"sendTimeoutMs\":30000,\"blockIfQueueFull\":false,\"maxPendingMessages\":0,\"maxPendingMessagesAcrossPartitions\":0,\"messageRoutingMode\":\"RoundRobinPartition\",\"hashingScheme\":\"JavaStringHash\",\"cryptoFailureAction\":\"FAIL\",\"batchingMaxPublishDelayMicros\":1000,\"batchingPartitionSwitchFrequencyByPublishDelay\":10,\"batchingMaxMessages\":1000,\"batchingMaxBytes\":131072,\"batchingEnabled\":true,\"chunkingEnabled\":false,\"chunkMaxMessageSize\":-1,\"compressionType\":\"NONE\",\"initialSequenceId\":null,\"autoUpdatePartitions\":true,\"autoUpdatePartitionsIntervalSeconds\":60,\"multiSchema\":true,\"accessMode\":\"Shared\",\"lazyStartPartitionedProducers\":false,\"properties\":{},\"initialSubscriptionName\":null}\r\nPulsar client config: {\"serviceUrl\":\"pulsar://pulsar:6650\",\"authPluginClassName\":null,\"authParams\":null,\"authParamMap\":null,\"operationTimeoutMs\":30000,\"lookupTimeoutMs\":30000,\"statsIntervalSeconds\":60,\"numIoThreads\":1,\"numListenerThreads\":1,\"connectionsPerBroker\":1,\"connectionMaxIdleSeconds\":180,\"useTcpNoDelay\":true,\"useTls\":false,\"tlsKeyFilePath\":null,\"tlsCertificateFilePath\":null,\"tlsTrustCertsFilePath\":null,\"tlsAllowInsecureConnection\":false,\"tlsHostnameVerificationEnable\":false,\"concurrentLookupRequest\":5000,\"maxLookupRequest\":50000,\"maxLookupRedirects\":20,\"maxNumberOfRejectedRequestPerConnection\":50,\"keepAliveIntervalSeconds\":30,\"connectionTimeoutMs\":10000,\"requestTimeoutMs\":60000,\"initialBackoffIntervalNanos\":100000000,\"maxBackoffIntervalNanos\":60000000000,\"enableBusyWait\":false,\"listenerName\":null,\"useKeyStoreTls\":false,\"sslProvider\":null,\"tlsKeyStoreType\":\"JKS\",\"tlsKeyStorePath\":null,\"tlsKeyStorePassword\":null,\"tlsTrustStoreType\":\"JKS\",\"tlsTrustStorePath\":null,\"tlsTrustStorePassword\":null,\"tlsCiphers\":[],\"tlsProtocols\":[],\"memoryLimitBytes\":67108864,\"proxyServiceUrl\":null,\"proxyProtocol\":null,\"enableTransaction\":true,\"dnsLookupBindAddress\":null,\"dnsLookupBindPort\":0,\"socks5ProxyAddress\":null,\"socks5ProxyUsername\":null,\"socks5ProxyPassword\":null}\r\n[persistent://public/default/dlq] [null] Creating producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/dlq] [pulsar-dev-5-10034] Created producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/my-topic] failed to get schema : org.apache.pulsar.client.api.PulsarClientException: {\"errorMsg\":\"org.apache.pulsar.broker.service.schema.exceptions.SchemaException: Bookie handle is not available - ledger=35399 - operation=Failed to read entry - entry=0\",\"reqId\":4059106653410978876, \"remote\":\"pulsar/10.204.70.7:6650\", \"local\":\"/10.204.68.122:44372\"}\r\nDead letter producer exception with topic: persistent://public/default/dlq\r\nStarting Pulsar producer perf with config: {\"topicName\":\"persistent://public/default/dlq\",\"producerName\":null,\"sendTimeoutMs\":30000,\"blockIfQueueFull\":false,\"maxPendingMessages\":0,\"maxPendingMessagesAcrossPartitions\":0,\"messageRoutingMode\":\"RoundRobinPartition\",\"hashingScheme\":\"JavaStringHash\",\"cryptoFailureAction\":\"FAIL\",\"batchingMaxPublishDelayMicros\":1000,\"batchingPartitionSwitchFrequencyByPublishDelay\":10,\"batchingMaxMessages\":1000,\"batchingMaxBytes\":131072,\"batchingEnabled\":true,\"chunkingEnabled\":false,\"chunkMaxMessageSize\":-1,\"compressionType\":\"NONE\",\"initialSequenceId\":null,\"autoUpdatePartitions\":true,\"autoUpdatePartitionsIntervalSeconds\":60,\"multiSchema\":true,\"accessMode\":\"Shared\",\"lazyStartPartitionedProducers\":false,\"properties\":{},\"initialSubscriptionName\":null}\r\nPulsar client config: {\"serviceUrl\":\"pulsar://pulsar:6650\",\"authPluginClassName\":null,\"authParams\":null,\"authParamMap\":null,\"operationTimeoutMs\":30000,\"lookupTimeoutMs\":30000,\"statsIntervalSeconds\":60,\"numIoThreads\":1,\"numListenerThreads\":1,\"connectionsPerBroker\":1,\"connectionMaxIdleSeconds\":180,\"useTcpNoDelay\":true,\"useTls\":false,\"tlsKeyFilePath\":null,\"tlsCertificateFilePath\":null,\"tlsTrustCertsFilePath\":null,\"tlsAllowInsecureConnection\":false,\"tlsHostnameVerificationEnable\":false,\"concurrentLookupRequest\":5000,\"maxLookupRequest\":50000,\"maxLookupRedirects\":20,\"maxNumberOfRejectedRequestPerConnection\":50,\"keepAliveIntervalSeconds\":30,\"connectionTimeoutMs\":10000,\"requestTimeoutMs\":60000,\"initialBackoffIntervalNanos\":100000000,\"maxBackoffIntervalNanos\":60000000000,\"enableBusyWait\":false,\"listenerName\":null,\"useKeyStoreTls\":false,\"sslProvider\":null,\"tlsKeyStoreType\":\"JKS\",\"tlsKeyStorePath\":null,\"tlsKeyStorePassword\":null,\"tlsTrustStoreType\":\"JKS\",\"tlsTrustStorePath\":null,\"tlsTrustStorePassword\":null,\"tlsCiphers\":[],\"tlsProtocols\":[],\"memoryLimitBytes\":67108864,\"proxyServiceUrl\":null,\"proxyProtocol\":null,\"enableTransaction\":true,\"dnsLookupBindAddress\":null,\"dnsLookupBindPort\":0,\"socks5ProxyAddress\":null,\"socks5ProxyUsername\":null,\"socks5ProxyPassword\":null}\r\n[persistent://public/default/dlq] [null] Creating producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/dlq] [pulsar-dev-5-10035] Created producer on cnx [id: 0x910a07bb, L:/10.204.68.122:45104 - R:pulsar/10.204.67.17:6650]\r\n[persistent://public/default/my-topic] failed to get schema : org.apache.pulsar.client.api.PulsarClientException: {\"errorMsg\":\"org.apache.pulsar.broker.service.schema.exceptions.SchemaException: Bookie handle is not available - ledger=35399 - operation=Failed to read entry - entry=0\",\"reqId\":4059106653410978880, \"remote\":\"pulsar/10.204.70.7:6650\", \"local\":\"/10.204.68.122:44372\"}\r\nDead letter producer exception with topic: persistent://public/default/dlq\r\n\r\n```\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1221,
    "test_files_count": 2,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/MultiTopicsConsumerImpl.java",
      "pulsar-client/src/main/resources/findbugsExclude.xml"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java"
    ],
    "base_commit": "2eb4eabc84f68fef5b29d894631c7c23d06ec3af",
    "head_commit": "678aadf02586d8b3f7ad461bb385a04d37b43fc4",
    "repo_url": "https://github.com/apache/pulsar/pull/23824",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23824",
    "dockerfile": "",
    "pr_merged_at": "2025-01-09T19:10:49.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\nindex 86af4bdaf58c8..77a91a944ee6c 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n@@ -67,6 +67,7 @@\n import java.util.concurrent.locks.ReadWriteLock;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n import java.util.function.Function;\n+import java.util.function.Supplier;\n import java.util.stream.Collectors;\n import lombok.AccessLevel;\n import lombok.Getter;\n@@ -202,8 +203,9 @@ public class ConsumerImpl<T> extends ConsumerBase<T> implements ConnectionHandle\n     private final DeadLetterPolicy deadLetterPolicy;\n \n     private volatile CompletableFuture<Producer<byte[]>> deadLetterProducer;\n-\n+    private volatile int deadLetterProducerFailureCount;\n     private volatile CompletableFuture<Producer<byte[]>> retryLetterProducer;\n+    private volatile int retryLetterProducerFailureCount;\n     private final ReadWriteLock createProducerLock = new ReentrantReadWriteLock();\n \n     protected volatile boolean paused;\n@@ -682,9 +684,8 @@ protected CompletableFuture<Void> doReconsumeLater(Message<?> message, AckType a\n             return FutureUtil.failedFuture(exception);\n         }\n \n-        initRetryLetterProducerIfNeeded();\n         CompletableFuture<Void> result = new CompletableFuture<>();\n-        if (retryLetterProducer != null) {\n+        if (initRetryLetterProducerIfNeeded() != null) {\n             try {\n                 MessageImpl<T> retryMessage = (MessageImpl<T>) getMessageImpl(message);\n                 String originMessageIdStr = message.getMessageId().toString();\n@@ -707,52 +708,61 @@ protected CompletableFuture<Void> doReconsumeLater(Message<?> message, AckType a\n                 MessageId finalMessageId = messageId;\n                 if (reconsumeTimes > this.deadLetterPolicy.getMaxRedeliverCount()\n                         && StringUtils.isNotBlank(deadLetterPolicy.getDeadLetterTopic())) {\n-                    initDeadLetterProducerIfNeeded();\n-                    deadLetterProducer.thenAcceptAsync(dlqProducer -> {\n-                        TypedMessageBuilder<byte[]> typedMessageBuilderNew =\n-                                dlqProducer.newMessage(Schema.AUTO_PRODUCE_BYTES(retryMessage.getReaderSchema().get()))\n-                                        .value(retryMessage.getData())\n-                                        .properties(propertiesMap);\n-                        copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n-                        typedMessageBuilderNew.sendAsync().thenAccept(msgId -> {\n-                            consumerDlqMessagesCounter.increment();\n-\n-                            doAcknowledge(finalMessageId, ackType, Collections.emptyMap(), null).thenAccept(v -> {\n-                                result.complete(null);\n+                    initDeadLetterProducerIfNeeded().thenAcceptAsync(dlqProducer -> {\n+                        try {\n+                            TypedMessageBuilder<byte[]> typedMessageBuilderNew =\n+                                    dlqProducer.newMessage(\n+                                                    Schema.AUTO_PRODUCE_BYTES(retryMessage.getReaderSchema().get()))\n+                                            .value(retryMessage.getData())\n+                                            .properties(propertiesMap);\n+                            copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                            typedMessageBuilderNew.sendAsync().thenAccept(msgId -> {\n+                                consumerDlqMessagesCounter.increment();\n+\n+                                doAcknowledge(finalMessageId, ackType, Collections.emptyMap(), null).thenAccept(v -> {\n+                                    result.complete(null);\n+                                }).exceptionally(ex -> {\n+                                    result.completeExceptionally(ex);\n+                                    return null;\n+                                });\n                             }).exceptionally(ex -> {\n                                 result.completeExceptionally(ex);\n                                 return null;\n                             });\n-                        }).exceptionally(ex -> {\n-                            result.completeExceptionally(ex);\n-                            return null;\n-                        });\n+                        } catch (Exception e) {\n+                            result.completeExceptionally(e);\n+                        }\n                     }, internalPinnedExecutor).exceptionally(ex -> {\n                         result.completeExceptionally(ex);\n-                        deadLetterProducer = null;\n                         return null;\n                     });\n                 } else {\n                     assert retryMessage != null;\n-                    retryLetterProducer.thenAcceptAsync(rtlProducer -> {\n-                        TypedMessageBuilder<byte[]> typedMessageBuilderNew = rtlProducer\n-                                .newMessage(Schema.AUTO_PRODUCE_BYTES(message.getReaderSchema().get()))\n-                                .value(retryMessage.getData())\n-                                .properties(propertiesMap);\n-                        if (delayTime > 0) {\n-                            typedMessageBuilderNew.deliverAfter(delayTime, unit);\n+                    initRetryLetterProducerIfNeeded().thenAcceptAsync(rtlProducer -> {\n+                        try {\n+                            TypedMessageBuilder<byte[]> typedMessageBuilderNew = rtlProducer\n+                                    .newMessage(Schema.AUTO_PRODUCE_BYTES(message.getReaderSchema().get()))\n+                                    .value(retryMessage.getData())\n+                                    .properties(propertiesMap);\n+                            if (delayTime > 0) {\n+                                typedMessageBuilderNew.deliverAfter(delayTime, unit);\n+                            }\n+                            copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                            typedMessageBuilderNew.sendAsync()\n+                                    .thenCompose(\n+                                            __ -> doAcknowledge(finalMessageId, ackType, Collections.emptyMap(), null))\n+                                    .thenAccept(v -> {\n+                                        result.complete(null);\n+                                    })\n+                                    .exceptionally(ex -> {\n+                                        result.completeExceptionally(ex);\n+                                        return null;\n+                                    });\n+                        } catch (Exception e) {\n+                            result.completeExceptionally(e);\n                         }\n-                        copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n-                        typedMessageBuilderNew.sendAsync()\n-                                .thenCompose(__ -> doAcknowledge(finalMessageId, ackType, Collections.emptyMap(), null))\n-                                .thenAccept(v -> result.complete(null))\n-                                .exceptionally(ex -> {\n-                                    result.completeExceptionally(ex);\n-                                    return null;\n-                                });\n                     }, internalPinnedExecutor).exceptionally(ex -> {\n                         result.completeExceptionally(ex);\n-                        retryLetterProducer = null;\n                         return null;\n                     });\n                 }\n@@ -1099,10 +1109,29 @@ public void connectionFailed(PulsarClientException exception) {\n     public synchronized CompletableFuture<Void> closeAsync() {\n         CompletableFuture<Void> closeFuture = new CompletableFuture<>();\n \n+        ArrayList<CompletableFuture<Void>> closeFutures = new ArrayList<>(4);\n+        closeFutures.add(closeFuture);\n+        if (retryLetterProducer != null) {\n+            closeFutures.add(retryLetterProducer.thenCompose(p -> p.closeAsync()).whenComplete((ignore, ex) -> {\n+                if (ex != null) {\n+                    log.warn(\"Exception ignored in closing retryLetterProducer of consumer\", ex);\n+                }\n+            }));\n+        }\n+        if (deadLetterProducer != null) {\n+            closeFutures.add(deadLetterProducer.thenCompose(p -> p.closeAsync()).whenComplete((ignore, ex) -> {\n+                if (ex != null) {\n+                    log.warn(\"Exception ignored in closing deadLetterProducer of consumer\", ex);\n+                }\n+            }));\n+        }\n+        CompletableFuture<Void> compositeCloseFuture = FutureUtil.waitForAll(closeFutures);\n+\n+\n         if (getState() == State.Closing || getState() == State.Closed) {\n             closeConsumerTasks();\n             failPendingReceive().whenComplete((r, t) -> closeFuture.complete(null));\n-            return closeFuture;\n+            return compositeCloseFuture;\n         }\n \n         consumersClosedCounter.increment();\n@@ -1114,7 +1143,7 @@ public synchronized CompletableFuture<Void> closeAsync() {\n             deregisterFromClientCnx();\n             client.cleanupConsumer(this);\n             failPendingReceive().whenComplete((r, t) -> closeFuture.complete(null));\n-            return closeFuture;\n+            return compositeCloseFuture;\n         }\n \n         stats.getStatTimeout().ifPresent(Timeout::cancel);\n@@ -1141,23 +1170,7 @@ public synchronized CompletableFuture<Void> closeAsync() {\n             });\n         }\n \n-        ArrayList<CompletableFuture<Void>> closeFutures = new ArrayList<>(4);\n-        closeFutures.add(closeFuture);\n-        if (retryLetterProducer != null) {\n-            closeFutures.add(retryLetterProducer.thenCompose(p -> p.closeAsync()).whenComplete((ignore, ex) -> {\n-                if (ex != null) {\n-                    log.warn(\"Exception ignored in closing retryLetterProducer of consumer\", ex);\n-                }\n-            }));\n-        }\n-        if (deadLetterProducer != null) {\n-            closeFutures.add(deadLetterProducer.thenCompose(p -> p.closeAsync()).whenComplete((ignore, ex) -> {\n-                if (ex != null) {\n-                    log.warn(\"Exception ignored in closing deadLetterProducer of consumer\", ex);\n-                }\n-            }));\n-        }\n-        return FutureUtil.waitForAll(closeFutures);\n+        return compositeCloseFuture;\n     }\n \n     private void cleanupAtClose(CompletableFuture<Void> closeFuture, Throwable exception) {\n@@ -2216,47 +2229,54 @@ private CompletableFuture<Boolean> processPossibleToDLQ(MessageIdAdv messageId)\n         }\n         CompletableFuture<Boolean> result = new CompletableFuture<>();\n         if (deadLetterMessages != null) {\n-            initDeadLetterProducerIfNeeded();\n             List<MessageImpl<T>> finalDeadLetterMessages = deadLetterMessages;\n-            deadLetterProducer.thenAcceptAsync(producerDLQ -> {\n+            initDeadLetterProducerIfNeeded().thenAcceptAsync(producerDLQ -> {\n                 for (MessageImpl<T> message : finalDeadLetterMessages) {\n-                    String originMessageIdStr = message.getMessageId().toString();\n-                    String originTopicNameStr = getOriginTopicNameStr(message);\n-                    TypedMessageBuilder<byte[]> typedMessageBuilderNew =\n-                            producerDLQ.newMessage(Schema.AUTO_PRODUCE_BYTES(message.getReaderSchema().get()))\n-                            .value(message.getData())\n-                            .properties(getPropertiesMap(message, originMessageIdStr, originTopicNameStr));\n-                    copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n-                    typedMessageBuilderNew.sendAsync()\n-                            .thenAccept(messageIdInDLQ -> {\n-                                possibleSendToDeadLetterTopicMessages.remove(messageId);\n-                                acknowledgeAsync(messageId).whenComplete((v, ex) -> {\n-                                    if (ex != null) {\n-                                        log.warn(\"[{}] [{}] [{}] Failed to acknowledge the message {} of the original\"\n-                                                        + \" topic but send to the DLQ successfully.\",\n-                                                topicName, subscription, consumerName, messageId, ex);\n-                                        result.complete(false);\n+                    try {\n+                        String originMessageIdStr = message.getMessageId().toString();\n+                        String originTopicNameStr = getOriginTopicNameStr(message);\n+                        TypedMessageBuilder<byte[]> typedMessageBuilderNew =\n+                                producerDLQ.newMessage(Schema.AUTO_PRODUCE_BYTES(message.getReaderSchema().get()))\n+                                        .value(message.getData())\n+                                        .properties(getPropertiesMap(message, originMessageIdStr, originTopicNameStr));\n+                        copyMessageKeysIfNeeded(message, typedMessageBuilderNew);\n+                        typedMessageBuilderNew.sendAsync()\n+                                .thenAccept(messageIdInDLQ -> {\n+                                    possibleSendToDeadLetterTopicMessages.remove(messageId);\n+                                    acknowledgeAsync(messageId).whenComplete((v, ex) -> {\n+                                        if (ex != null) {\n+                                            log.warn(\n+                                                    \"[{}] [{}] [{}] Failed to acknowledge the message {} of the \"\n+                                                            + \"original topic but send to the DLQ successfully.\",\n+                                                    topicName, subscription, consumerName, messageId, ex);\n+                                            result.complete(false);\n+                                        } else {\n+                                            result.complete(true);\n+                                        }\n+                                    });\n+                                }).exceptionally(ex -> {\n+                                    if (ex instanceof PulsarClientException.ProducerQueueIsFullError) {\n+                                        log.warn(\n+                                                \"[{}] [{}] [{}] Failed to send DLQ message to {} for message id {}: {}\",\n+                                                topicName, subscription, consumerName,\n+                                                deadLetterPolicy.getDeadLetterTopic(), messageId, ex.getMessage());\n                                     } else {\n-                                        result.complete(true);\n+                                        log.warn(\"[{}] [{}] [{}] Failed to send DLQ message to {} for message id {}\",\n+                                                topicName, subscription, consumerName,\n+                                                deadLetterPolicy.getDeadLetterTopic(), messageId, ex);\n                                     }\n+                                    result.complete(false);\n+                                    return null;\n                                 });\n-                            }).exceptionally(ex -> {\n-                                if (ex instanceof PulsarClientException.ProducerQueueIsFullError) {\n-                                    log.warn(\"[{}] [{}] [{}] Failed to send DLQ message to {} for message id {}: {}\",\n-                                            topicName, subscription, consumerName,\n-                                            deadLetterPolicy.getDeadLetterTopic(), messageId, ex.getMessage());\n-                                } else {\n-                                    log.warn(\"[{}] [{}] [{}] Failed to send DLQ message to {} for message id {}\",\n-                                            topicName, subscription, consumerName,\n-                                            deadLetterPolicy.getDeadLetterTopic(), messageId, ex);\n-                                }\n-                                result.complete(false);\n-                                return null;\n-                    });\n+                    } catch (Exception e) {\n+                        log.warn(\"[{}] [{}] [{}] Failed to send DLQ message to {} for message id {}\",\n+                                topicName, subscription, consumerName, deadLetterPolicy.getDeadLetterTopic(), messageId,\n+                                e);\n+                        result.complete(false);\n+                    }\n                 }\n             }, internalPinnedExecutor).exceptionally(ex -> {\n                 log.error(\"Dead letter producer exception with topic: {}\", deadLetterPolicy.getDeadLetterTopic(), ex);\n-                deadLetterProducer = null;\n                 result.complete(false);\n                 return null;\n             });\n@@ -2266,51 +2286,112 @@ private CompletableFuture<Boolean> processPossibleToDLQ(MessageIdAdv messageId)\n         return result;\n     }\n \n-    private void initDeadLetterProducerIfNeeded() {\n-        if (deadLetterProducer == null) {\n+    private CompletableFuture<Producer<byte[]>> initDeadLetterProducerIfNeeded() {\n+        CompletableFuture<Producer<byte[]>> p = deadLetterProducer;\n+        if (p == null || p.isCompletedExceptionally()) {\n             createProducerLock.writeLock().lock();\n             try {\n-                if (deadLetterProducer == null) {\n-                    deadLetterProducer =\n-                            ((ProducerBuilderImpl<byte[]>) client.newProducer(Schema.AUTO_PRODUCE_BYTES(schema)))\n-                                    .initialSubscriptionName(this.deadLetterPolicy.getInitialSubscriptionName())\n-                                    .topic(this.deadLetterPolicy.getDeadLetterTopic())\n-                                    .producerName(String.format(\"%s-%s-%s-%s-DLQ\", this.topicName, this.subscription,\n-                                            this.consumerName, RandomStringUtils.randomAlphanumeric(5)))\n-                                    .blockIfQueueFull(false)\n-                                    .enableBatching(false)\n-                                    .enableChunking(true)\n-                                    .createAsync();\n-                    deadLetterProducer.thenAccept(dlqProducer -> {\n-                        stats.setDeadLetterProducerStats(dlqProducer.getStats());\n-                    });\n+                p = deadLetterProducer;\n+                if (p == null || p.isCompletedExceptionally()) {\n+                    p = createProducerWithBackOff(() -> {\n+                        CompletableFuture<Producer<byte[]>> newProducer =\n+                                ((ProducerBuilderImpl<byte[]>) client.newProducer(Schema.AUTO_PRODUCE_BYTES(schema)))\n+                                        .initialSubscriptionName(this.deadLetterPolicy.getInitialSubscriptionName())\n+                                        .topic(this.deadLetterPolicy.getDeadLetterTopic())\n+                                        .producerName(\n+                                                String.format(\"%s-%s-%s-%s-DLQ\", this.topicName, this.subscription,\n+                                                        this.consumerName, RandomStringUtils.randomAlphanumeric(5)))\n+                                        .blockIfQueueFull(false)\n+                                        .enableBatching(false)\n+                                        .enableChunking(true)\n+                                        .createAsync();\n+                        newProducer.whenComplete((producer, ex) -> {\n+                            if (ex != null) {\n+                                log.error(\"[{}] [{}] [{}] Failed to create dead letter producer for topic {}\",\n+                                        topicName, subscription, consumerName, deadLetterPolicy.getDeadLetterTopic(),\n+                                        ex);\n+                                deadLetterProducerFailureCount++;\n+                            } else {\n+                                deadLetterProducerFailureCount = 0;\n+                                stats.setDeadLetterProducerStats(producer.getStats());\n+                            }\n+                        });\n+                        return newProducer;\n+                    }, deadLetterProducerFailureCount, () -> \"dead letter producer (topic: \"\n+                            + deadLetterPolicy.getDeadLetterTopic() + \")\");\n+                    deadLetterProducer = p;\n                 }\n             } finally {\n                 createProducerLock.writeLock().unlock();\n             }\n         }\n+        return p;\n     }\n \n-    private void initRetryLetterProducerIfNeeded() {\n-        if (retryLetterProducer == null) {\n+    private CompletableFuture<Producer<byte[]>> createProducerWithBackOff(\n+            Supplier<CompletableFuture<Producer<byte[]>>> producerSupplier, int failureCount,\n+            Supplier<String> logDescription) {\n+        if (failureCount == 0) {\n+            return producerSupplier.get();\n+        } else {\n+            // calculate backoff time for given failure count\n+            Backoff backoff = new BackoffBuilder()\n+                    .setInitialTime(100, TimeUnit.MILLISECONDS)\n+                    .setMandatoryStop(client.getConfiguration().getOperationTimeoutMs() * 2,\n+                            TimeUnit.MILLISECONDS)\n+                    .setMax(1, TimeUnit.MINUTES)\n+                    .create();\n+            long backoffTimeMillis = 0;\n+            for (int i = 0; i < failureCount; i++) {\n+                backoffTimeMillis = backoff.next();\n+            }\n+            CompletableFuture<Producer<byte[]>> newProducer = new CompletableFuture<>();\n+            ScheduledExecutorService executor =\n+                    (ScheduledExecutorService) client.getScheduledExecutorProvider().getExecutor(this);\n+            log.info(\"Creating {} with backoff time of {} ms\", logDescription.get(), backoffTimeMillis);\n+            executor.schedule(() -> {\n+                FutureUtil.completeAfter(newProducer, producerSupplier.get());\n+            }, backoffTimeMillis, TimeUnit.MILLISECONDS);\n+            return newProducer;\n+        }\n+    }\n+\n+    private CompletableFuture<Producer<byte[]>> initRetryLetterProducerIfNeeded() {\n+        CompletableFuture<Producer<byte[]>> p = retryLetterProducer;\n+        if (p == null || p.isCompletedExceptionally()) {\n             createProducerLock.writeLock().lock();\n             try {\n-                if (retryLetterProducer == null) {\n-                    retryLetterProducer = client\n-                            .newProducer(Schema.AUTO_PRODUCE_BYTES(schema))\n-                            .topic(this.deadLetterPolicy.getRetryLetterTopic())\n-                            .enableBatching(false)\n-                            .enableChunking(true)\n-                            .blockIfQueueFull(false)\n-                            .createAsync();\n-                    retryLetterProducer.thenAccept(rtlProducer -> {\n-                        stats.setRetryLetterProducerStats(rtlProducer.getStats());\n-                    });\n+                p = retryLetterProducer;\n+                if (p == null || p.isCompletedExceptionally()) {\n+                    p = createProducerWithBackOff(() -> {\n+                        CompletableFuture<Producer<byte[]>> newProducer = client\n+                                .newProducer(Schema.AUTO_PRODUCE_BYTES(schema))\n+                                .topic(this.deadLetterPolicy.getRetryLetterTopic())\n+                                .enableBatching(false)\n+                                .enableChunking(true)\n+                                .blockIfQueueFull(false)\n+                                .createAsync();\n+                        newProducer.whenComplete((producer, ex) -> {\n+                            if (ex != null) {\n+                                log.error(\"[{}] [{}] [{}] Failed to create retry letter producer for topic {}\",\n+                                        topicName, subscription, consumerName, deadLetterPolicy.getRetryLetterTopic(),\n+                                        ex);\n+                                retryLetterProducerFailureCount++;\n+                            } else {\n+                                retryLetterProducerFailureCount = 0;\n+                                stats.setRetryLetterProducerStats(producer.getStats());\n+                            }\n+                        });\n+                        return newProducer;\n+                    }, retryLetterProducerFailureCount, () -> \"retry letter producer (topic: \"\n+                            + deadLetterPolicy.getRetryLetterTopic() + \")\");\n+                    retryLetterProducer = p;\n                 }\n             } finally {\n                 createProducerLock.writeLock().unlock();\n             }\n         }\n+        return p;\n     }\n \n     @Override\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/MultiTopicsConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/MultiTopicsConsumerImpl.java\nindex 6f9c5b47c55bb..341272cd69bf8 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/MultiTopicsConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/MultiTopicsConsumerImpl.java\n@@ -638,7 +638,14 @@ public CompletableFuture<Void> closeAsync() {\n \n         CompletableFuture<Void> closeFuture = new CompletableFuture<>();\n         List<CompletableFuture<Void>> futureList = consumers.values().stream()\n-            .map(ConsumerImpl::closeAsync).collect(Collectors.toList());\n+            .map(consumer -> consumer.closeAsync().exceptionally(t -> {\n+                Throwable cause = FutureUtil.unwrapCompletionException(t);\n+                if (!(cause instanceof PulsarClientException.AlreadyClosedException)) {\n+                    log.warn(\"[{}] [{}] Error closing individual consumer\", consumer.getTopic(),\n+                            consumer.getSubscription(), cause);\n+                }\n+                return null;\n+            })).collect(Collectors.toList());\n \n         FutureUtil.waitForAll(futureList)\n             .thenComposeAsync((r) -> {\n\ndiff --git a/pulsar-client/src/main/resources/findbugsExclude.xml b/pulsar-client/src/main/resources/findbugsExclude.xml\nindex 0e05d20cb9bb4..f7cf6b9cfd50e 100644\n--- a/pulsar-client/src/main/resources/findbugsExclude.xml\n+++ b/pulsar-client/src/main/resources/findbugsExclude.xml\n@@ -1043,4 +1043,8 @@\n         <Method name=\"getStats\"/>\n         <Bug pattern=\"EI_EXPOSE_REP\"/>\n     </Match>\n+    <Match>\n+        <Class name=\"org.apache.pulsar.client.impl.ConsumerImpl\"/>\n+        <Bug pattern=\"VO_VOLATILE_INCREMENT\"/>\n+    </Match>\n </FindBugsFilter>\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\nindex e46fddeacc117..ab26949c04fc6 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertNotNull;\n import static org.testng.Assert.assertNull;\n@@ -40,9 +41,11 @@\n import lombok.Cleanup;\n import lombok.Data;\n import org.apache.avro.reflect.Nullable;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.client.api.schema.GenericRecord;\n import org.apache.pulsar.client.impl.ConsumerBuilderImpl;\n import org.apache.pulsar.client.util.RetryMessageUtil;\n+import org.apache.pulsar.common.policies.data.SchemaCompatibilityStrategy;\n import org.awaitility.Awaitility;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -1167,4 +1170,94 @@ public void testDeadLetterPolicyDeserialize() throws Exception {\n         consumerBuilder.loadConf(config);\n         assertEquals(((ConsumerBuilderImpl)consumerBuilder).getConf().getDeadLetterPolicy(), policy);\n     }\n+\n+    @Data\n+    static class Payload {\n+        String number;\n+\n+        public Payload() {\n+\n+        }\n+\n+        public Payload(String number) {\n+            this.number = number;\n+        }\n+    }\n+\n+    @Data\n+    static class PayloadIncompatible {\n+        long number;\n+\n+        public PayloadIncompatible() {\n+\n+        }\n+\n+        public PayloadIncompatible(long number) {\n+            this.number = number;\n+        }\n+    }\n+\n+    // reproduce issue reported in https://github.com/apache/pulsar/issues/20635#issuecomment-1709616321\n+    @Test\n+    public void testCloseDeadLetterTopicProducerOnExceptionToPreventProducerLeak() throws Exception {\n+        String namespace = BrokerTestUtil.newUniqueName(\"my-property/my-ns\");\n+        admin.namespaces().createNamespace(namespace);\n+        // don't enforce schema validation\n+        admin.namespaces().setSchemaValidationEnforced(namespace, false);\n+        // set schema compatibility strategy to always compatible\n+        admin.namespaces().setSchemaCompatibilityStrategy(namespace, SchemaCompatibilityStrategy.ALWAYS_COMPATIBLE);\n+\n+        Schema<Payload> schema = Schema.AVRO(Payload.class);\n+        Schema<PayloadIncompatible> schemaIncompatible = Schema.AVRO(PayloadIncompatible.class);\n+        String topic = BrokerTestUtil.newUniqueName(\"persistent://\" + namespace\n+                        + \"/testCloseDeadLetterTopicProducerOnExceptionToPreventProducerLeak\");\n+        String dlqTopic = topic + \"-DLQ\";\n+\n+        // create topics\n+        admin.topics().createNonPartitionedTopic(topic);\n+        admin.topics().createNonPartitionedTopic(dlqTopic);\n+\n+        AtomicInteger nackCounter = new AtomicInteger(0);\n+        Consumer<Payload> payloadConsumer = null;\n+        try {\n+            payloadConsumer = pulsarClient.newConsumer(schema).topic(topic)\n+                    .subscriptionType(SubscriptionType.Shared).subscriptionName(\"sub\")\n+                    .ackTimeout(1, TimeUnit.SECONDS)\n+                    .negativeAckRedeliveryDelay(1, TimeUnit.MILLISECONDS)\n+                    .deadLetterPolicy(DeadLetterPolicy.builder().maxRedeliverCount(3).deadLetterTopic(dlqTopic).build())\n+                    .messageListener((c, msg) -> {\n+                        if (nackCounter.incrementAndGet() < 10) {\n+                            c.negativeAcknowledge(msg);\n+                        }\n+                    }).subscribe();\n+\n+            // send a message to the topic with the incompatible schema\n+            PayloadIncompatible payloadIncompatible = new PayloadIncompatible(123);\n+            try (Producer<PayloadIncompatible> producer = pulsarClient.newProducer(schemaIncompatible).topic(topic)\n+                    .create()) {\n+                producer.send(payloadIncompatible);\n+            }\n+\n+            Thread.sleep(2000L);\n+\n+            assertThat(pulsar.getBrokerService().getTopicReference(dlqTopic).get().getProducers().size())\n+                    .describedAs(\"producer count of dlq topic %s should be <= 1 so that it doesn't leak producers\",\n+                            dlqTopic)\n+                    .isLessThanOrEqualTo(1);\n+\n+        } finally {\n+            if (payloadConsumer != null) {\n+                try {\n+                    payloadConsumer.close();\n+                } catch (PulsarClientException e) {\n+                    // ignore\n+                }\n+            }\n+        }\n+\n+        assertThat(pulsar.getBrokerService().getTopicReference(dlqTopic).get().getProducers().size())\n+                .describedAs(\"producer count of dlq topic %s should be 0 here\",\n+                        dlqTopic)\n+                .isEqualTo(0);\n+    }\n }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\nindex cd598585c8e87..91b97fa475817 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/RetryTopicTest.java\n@@ -18,12 +18,12 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import static org.assertj.core.api.Assertions.assertThat;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertNull;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n-import java.lang.reflect.Field;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n@@ -36,11 +36,10 @@\n import lombok.Data;\n import org.apache.avro.AvroRuntimeException;\n import org.apache.avro.reflect.Nullable;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.client.api.schema.GenericRecord;\n-import org.apache.pulsar.client.impl.ConsumerImpl;\n-import org.apache.pulsar.client.impl.MultiTopicsConsumerImpl;\n import org.apache.pulsar.client.util.RetryMessageUtil;\n-import org.reflections.ReflectionUtils;\n+import org.apache.pulsar.common.policies.data.SchemaCompatibilityStrategy;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.testng.annotations.AfterMethod;\n@@ -617,10 +616,12 @@ public void testRetryTopicByCustomTopicName() throws Exception {\n \n     @Test(timeOut = 30000L)\n     public void testRetryTopicException() throws Exception {\n-        final String topic = \"persistent://my-property/my-ns/retry-topic\";\n+        String retryLetterTopic = BrokerTestUtil.newUniqueName(\"persistent://my-property/my-ns/retry-topic\");\n+        final String topic = BrokerTestUtil.newUniqueName(\"persistent://my-property/my-ns/input-topic\");\n         final int maxRedeliveryCount = 2;\n         final int sendMessages = 1;\n         // subscribe before publish\n+        @Cleanup\n         Consumer<byte[]> consumer = pulsarClient.newConsumer(Schema.BYTES)\n                 .topic(topic)\n                 .subscriptionName(\"my-subscription\")\n@@ -629,7 +630,7 @@ public void testRetryTopicException() throws Exception {\n                 .receiverQueueSize(100)\n                 .deadLetterPolicy(DeadLetterPolicy.builder()\n                         .maxRedeliverCount(maxRedeliveryCount)\n-                        .retryLetterTopic(\"persistent://my-property/my-ns/my-subscription-custom-Retry\")\n+                        .retryLetterTopic(retryLetterTopic)\n                         .build())\n                 .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n                 .subscribe();\n@@ -642,30 +643,16 @@ public void testRetryTopicException() throws Exception {\n         }\n         producer.close();\n \n-        // mock a retry producer exception when reconsumelater is called\n-        MultiTopicsConsumerImpl<byte[]> multiTopicsConsumer = (MultiTopicsConsumerImpl<byte[]>) consumer;\n-        List<ConsumerImpl<byte[]>> consumers = multiTopicsConsumer.getConsumers();\n-        for (ConsumerImpl<byte[]> c : consumers) {\n-            Set<Field> deadLetterPolicyField =\n-                    ReflectionUtils.getAllFields(c.getClass(), ReflectionUtils.withName(\"deadLetterPolicy\"));\n-\n-            if (deadLetterPolicyField.size() != 0) {\n-                Field field = deadLetterPolicyField.iterator().next();\n-                field.setAccessible(true);\n-                DeadLetterPolicy deadLetterPolicy = (DeadLetterPolicy) field.get(c);\n-                deadLetterPolicy.setRetryLetterTopic(\"#persistent://invlaid-topic#\");\n-            }\n-        }\n+        admin.topics().terminateTopic(retryLetterTopic);\n+\n         Message<byte[]> message = consumer.receive();\n         log.info(\"consumer received message : {} {}\", message.getMessageId(), new String(message.getData()));\n         try {\n             consumer.reconsumeLater(message, 1, TimeUnit.SECONDS);\n-        } catch (PulsarClientException.InvalidTopicNameException e) {\n-            assertEquals(e.getClass(), PulsarClientException.InvalidTopicNameException.class);\n-        } catch (Exception e) {\n-            fail(\"exception should be PulsarClientException.InvalidTopicNameException\");\n+            fail(\"exception should be PulsarClientException.TopicTerminatedException\");\n+        } catch (PulsarClientException.TopicTerminatedException e) {\n+            // ok\n         }\n-        consumer.close();\n     }\n \n \n@@ -718,10 +705,12 @@ public void testRetryProducerWillCloseByConsumer() throws Exception {\n \n     @Test(timeOut = 30000L)\n     public void testRetryTopicExceptionWithConcurrent() throws Exception {\n-        final String topic = \"persistent://my-property/my-ns/retry-topic\";\n+        String retryLetterTopic = BrokerTestUtil.newUniqueName(\"persistent://my-property/my-ns/retry-topic\");\n+        final String topic = BrokerTestUtil.newUniqueName(\"persistent://my-property/my-ns/input-topic\");\n         final int maxRedeliveryCount = 2;\n         final int sendMessages = 10;\n         // subscribe before publish\n+        @Cleanup\n         Consumer<byte[]> consumer = pulsarClient.newConsumer(Schema.BYTES)\n                 .topic(topic)\n                 .subscriptionName(\"my-subscription\")\n@@ -730,7 +719,7 @@ public void testRetryTopicExceptionWithConcurrent() throws Exception {\n                 .receiverQueueSize(100)\n                 .deadLetterPolicy(DeadLetterPolicy.builder()\n                         .maxRedeliverCount(maxRedeliveryCount)\n-                        .retryLetterTopic(\"persistent://my-property/my-ns/my-subscription-custom-Retry\")\n+                        .retryLetterTopic(retryLetterTopic)\n                         .build())\n                 .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n                 .subscribe();\n@@ -739,24 +728,11 @@ public void testRetryTopicExceptionWithConcurrent() throws Exception {\n                 .topic(topic)\n                 .create();\n         for (int i = 0; i < sendMessages; i++) {\n-            producer.newMessage().key(\"1\").value(String.format(\"Hello Pulsar [%d]\", i).getBytes()).send();\n+            producer.send(String.format(\"Hello Pulsar [%d]\", i).getBytes());\n         }\n         producer.close();\n \n-        // mock a retry producer exception when reconsumelater is called\n-        MultiTopicsConsumerImpl<byte[]> multiTopicsConsumer = (MultiTopicsConsumerImpl<byte[]>) consumer;\n-        List<ConsumerImpl<byte[]>> consumers = multiTopicsConsumer.getConsumers();\n-        for (ConsumerImpl<byte[]> c : consumers) {\n-            Set<Field> deadLetterPolicyField =\n-                    ReflectionUtils.getAllFields(c.getClass(), ReflectionUtils.withName(\"deadLetterPolicy\"));\n-\n-            if (deadLetterPolicyField.size() != 0) {\n-                Field field = deadLetterPolicyField.iterator().next();\n-                field.setAccessible(true);\n-                DeadLetterPolicy deadLetterPolicy = (DeadLetterPolicy) field.get(c);\n-                deadLetterPolicy.setRetryLetterTopic(\"#persistent://invalid-topic#\");\n-            }\n-        }\n+        admin.topics().terminateTopic(retryLetterTopic);\n \n         List<Message<byte[]>> messages = Lists.newArrayList();\n         for (int i = 0; i < sendMessages; i++) {\n@@ -769,16 +745,114 @@ public void testRetryTopicExceptionWithConcurrent() throws Exception {\n             new Thread(() -> {\n                 try {\n                     consumer.reconsumeLater(message, 1, TimeUnit.SECONDS);\n-                } catch (Exception ignore) {\n-\n-                } finally {\n+                } catch (PulsarClientException.TopicTerminatedException e) {\n+                    // ok\n                     latch.countDown();\n+                } catch (PulsarClientException e) {\n+                    // unexpected exception\n+                    fail(\"unexpected exception\", e);\n                 }\n             }).start();\n         }\n \n-        latch.await();\n+        latch.await(sendMessages, TimeUnit.SECONDS);\n         consumer.close();\n     }\n \n+    @Data\n+    static class Payload {\n+        String number;\n+\n+        public Payload() {\n+\n+        }\n+\n+        public Payload(String number) {\n+            this.number = number;\n+        }\n+    }\n+\n+    @Data\n+    static class PayloadIncompatible {\n+        long number;\n+\n+        public PayloadIncompatible() {\n+\n+        }\n+\n+        public PayloadIncompatible(long number) {\n+            this.number = number;\n+        }\n+    }\n+\n+    // reproduce similar issue as reported in https://github.com/apache/pulsar/issues/20635#issuecomment-1709616321\n+    // but for retry topic\n+    @Test\n+    public void testCloseRetryLetterTopicProducerOnExceptionToPreventProducerLeak() throws Exception {\n+        String namespace = BrokerTestUtil.newUniqueName(\"my-property/my-ns\");\n+        admin.namespaces().createNamespace(namespace);\n+        // don't enforce schema validation\n+        admin.namespaces().setSchemaValidationEnforced(namespace, false);\n+        // set schema compatibility strategy to always compatible\n+        admin.namespaces().setSchemaCompatibilityStrategy(namespace, SchemaCompatibilityStrategy.ALWAYS_COMPATIBLE);\n+\n+        Schema<Payload> schema = Schema.AVRO(Payload.class);\n+        Schema<PayloadIncompatible> schemaIncompatible = Schema.AVRO(\n+                PayloadIncompatible.class);\n+        String topic = BrokerTestUtil.newUniqueName(\"persistent://\" + namespace\n+                + \"/testCloseDeadLetterTopicProducerOnExceptionToPreventProducerLeak\");\n+        String dlqTopic = topic + \"-DLQ\";\n+        String retryTopic = topic + \"-RETRY\";\n+\n+        // create topics\n+        admin.topics().createNonPartitionedTopic(topic);\n+        admin.topics().createNonPartitionedTopic(dlqTopic);\n+        admin.topics().createNonPartitionedTopic(retryTopic);\n+\n+        Consumer<Payload> payloadConsumer = null;\n+        try {\n+            payloadConsumer = pulsarClient.newConsumer(schema).topic(topic)\n+                    .subscriptionType(SubscriptionType.Shared).subscriptionName(\"sub\")\n+                    .ackTimeout(1, TimeUnit.SECONDS)\n+                    .negativeAckRedeliveryDelay(1, TimeUnit.MILLISECONDS)\n+                    .enableRetry(true)\n+                    .deadLetterPolicy(DeadLetterPolicy.builder().retryLetterTopic(retryTopic).maxRedeliverCount(3)\n+                            .deadLetterTopic(dlqTopic).build())\n+                    .messageListener((c, msg) -> {\n+                        try {\n+                            c.reconsumeLater(msg, 1, TimeUnit.MILLISECONDS);\n+                        } catch (PulsarClientException e) {\n+                            throw new RuntimeException(e);\n+                        }\n+                    }).subscribe();\n+\n+            // send a message to the topic with the incompatible schema\n+            PayloadIncompatible payloadIncompatible = new PayloadIncompatible(123);\n+            try (Producer<PayloadIncompatible> producer = pulsarClient.newProducer(schemaIncompatible).topic(topic)\n+                    .create()) {\n+                producer.send(payloadIncompatible);\n+            }\n+\n+            Thread.sleep(2000L);\n+\n+            assertThat(pulsar.getBrokerService().getTopicReference(retryTopic).get().getProducers().size())\n+                    .describedAs(\"producer count of retry topic %s should be <= 1 so that it doesn't leak producers\",\n+                            retryTopic)\n+                    .isLessThanOrEqualTo(1);\n+\n+        } finally {\n+            if (payloadConsumer != null) {\n+                try {\n+                    payloadConsumer.close();\n+                } catch (PulsarClientException e) {\n+                    // ignore\n+                }\n+            }\n+        }\n+\n+        assertThat(pulsar.getBrokerService().getTopicReference(retryTopic).get().getProducers().size())\n+                .describedAs(\"producer count of retry topic %s should be 0 here\",\n+                        retryTopic)\n+                .isEqualTo(0);\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23811",
    "pr_id": 23811,
    "issue_id": 23705,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Pulsar Function processing time doesn't get properly recorded for asynchronous functions\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nany released version\r\n\r\n### Minimal reproduce step\r\n\r\nIn the code, it can be seen that asynchronous functions don't get handled properly. `stats.processTimeEnd()` gets called immediately when the result is returned:\r\nhttps://github.com/apache/pulsar/blob/6fe8100b1fd5d37a6e1bf33803a8904fa3879321/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java#L337-L355\r\n\r\n\r\n### What did you expect to see?\r\n\r\nasynchronous functions would also be handled\r\n\r\n### What did you see instead?\r\n\r\nasynchronous functions have invalid processing time stats\r\n\r\n### Anything else?\r\n\r\nThe current processing metric for async functions includes the time for doing the async calls and the waiting time when the concurrency limit is reached. The metric is useful for this purpose. \r\nIt doesn't tell the actual end-to-completion processing time which contains the async processing time.\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 206,
    "test_files_count": 2,
    "non_test_files_count": 8,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaExecutionResult.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstance.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/ComponentStatsManager.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/FunctionStatsManager.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SinkStatsManager.java",
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SourceStatsManager.java",
      "pulsar-functions/instance/src/main/resources/findbugsExclude.xml",
      "pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java",
      "pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java"
    ],
    "base_commit": "420f62eef20aaef49ae404a683f2d5466ccfdec3",
    "head_commit": "f771093987e948eefe482a0ac939411efeb6a300",
    "repo_url": "https://github.com/apache/pulsar/pull/23811",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23811",
    "dockerfile": "",
    "pr_merged_at": "2025-01-28T16:03:11.000Z",
    "patch": "diff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaExecutionResult.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaExecutionResult.java\nindex 5856600196b49..9ca9aa2a879d4 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaExecutionResult.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaExecutionResult.java\n@@ -29,9 +29,5 @@\n public class JavaExecutionResult {\n     private Throwable userException;\n     private Object result;\n-\n-    public void reset() {\n-        setUserException(null);\n-        setResult(null);\n-    }\n+    private final long startTime = System.nanoTime();\n }\n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstance.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstance.java\nindex 5946be9fe5be9..c5f82898f8251 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstance.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstance.java\n@@ -47,6 +47,7 @@ public class JavaInstance implements AutoCloseable {\n     public static class AsyncFuncRequest {\n         private final Record record;\n         private final CompletableFuture processResult;\n+        private final JavaExecutionResult result;\n     }\n \n     @Getter(AccessLevel.PACKAGE)\n@@ -136,7 +137,7 @@ public JavaExecutionResult handleMessage(Record<?> record, Object input,\n                 if (asyncPreserveInputOrderForOutputMessages) {\n                     // Function is in format: Function<I, CompletableFuture<O>>\n                     AsyncFuncRequest request = new AsyncFuncRequest(\n-                            record, (CompletableFuture) output\n+                            record, (CompletableFuture) output, executionResult\n                     );\n                     pendingAsyncRequests.put(request);\n                 } else {\n@@ -148,13 +149,12 @@ public JavaExecutionResult handleMessage(Record<?> record, Object input,\n                             processAsyncResultsInInputOrder(asyncResultConsumer);\n                         } else {\n                             try {\n-                                JavaExecutionResult execResult = new JavaExecutionResult();\n                                 if (cause != null) {\n-                                    execResult.setUserException(FutureUtil.unwrapCompletionException(cause));\n+                                    executionResult.setUserException(FutureUtil.unwrapCompletionException(cause));\n                                 } else {\n-                                    execResult.setResult(res);\n+                                    executionResult.setResult(res);\n                                 }\n-                                asyncResultConsumer.accept(record, execResult);\n+                                asyncResultConsumer.accept(record, executionResult);\n                             } finally {\n                                 asyncRequestsConcurrencyLimiter.release();\n                             }\n@@ -187,7 +187,7 @@ private void processAsyncResultsInInputOrder(JavaInstanceRunnable.AsyncResultCon\n         while (asyncResult != null && asyncResult.getProcessResult().isDone()) {\n             pendingAsyncRequests.remove(asyncResult);\n \n-            JavaExecutionResult execResult = new JavaExecutionResult();\n+            JavaExecutionResult execResult = asyncResult.getResult();\n             try {\n                 Object result = asyncResult.getProcessResult().get();\n                 execResult.setResult(result);\n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java\nindex 4f811c14704a0..cfb7e9536a3e6 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/JavaInstanceRunnable.java\n@@ -334,8 +334,6 @@ public void run() {\n                 // set last invocation time\n                 stats.setLastInvocation(System.currentTimeMillis());\n \n-                // start time for process latency stat\n-                stats.processTimeStart();\n \n                 // process the message\n                 Thread.currentThread().setContextClassLoader(functionClassLoader);\n@@ -346,9 +344,6 @@ public void run() {\n                         asyncErrorHandler);\n                 Thread.currentThread().setContextClassLoader(instanceClassLoader);\n \n-                // register end time\n-                stats.processTimeEnd();\n-\n                 if (result != null) {\n                     // process the synchronous results\n                     handleResult(currentRecord, result);\n@@ -448,6 +443,8 @@ void handleResult(Record srcRecord, JavaExecutionResult result) throws Exception\n             // increment total successfully processed\n             stats.incrTotalProcessedSuccessfully();\n         }\n+        // handle endTime here\n+        stats.processTimeEnd(result.getStartTime());\n     }\n \n     private void sendOutputMessage(Record srcRecord, Object output) throws Exception {\n@@ -631,6 +628,11 @@ public String getStatsAsString() throws IOException {\n         return \"\";\n     }\n \n+    @VisibleForTesting\n+    void setStats(ComponentStatsManager stats) {\n+        this.stats = stats;\n+    }\n+\n     public InstanceCommunication.MetricsData getAndResetMetrics() {\n         if (isInitialized) {\n             statsLock.writeLock().lock();\n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/ComponentStatsManager.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/ComponentStatsManager.java\nindex 6da3c082f78f4..17321735256eb 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/ComponentStatsManager.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/ComponentStatsManager.java\n@@ -100,9 +100,8 @@ public ComponentStatsManager(FunctionCollectorRegistry collectorRegistry,\n \n     public abstract void setLastInvocation(long ts);\n \n-    public abstract void processTimeStart();\n \n-    public abstract void processTimeEnd();\n+    public abstract void processTimeEnd(long startTime);\n \n     public abstract double getTotalProcessedSuccessfully();\n \n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/FunctionStatsManager.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/FunctionStatsManager.java\nindex 8737c8a4fa913..0009fcea6671a 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/FunctionStatsManager.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/FunctionStatsManager.java\n@@ -336,20 +336,13 @@ public void setLastInvocation(long ts) {\n         statlastInvocationChild.set(ts);\n     }\n \n-    private Long processTimeStart;\n \n-    @Override\n-    public void processTimeStart() {\n-        processTimeStart = System.nanoTime();\n-    }\n \n     @Override\n-    public void processTimeEnd() {\n-        if (processTimeStart != null) {\n-            double endTimeMs = ((double) System.nanoTime() - processTimeStart) / 1.0E6D;\n+    public void processTimeEnd(long startTime) {\n+            double endTimeMs = ((double) System.nanoTime() - startTime) / 1.0E6D;\n             statProcessLatencyChild.observe(endTimeMs);\n             statProcessLatency1minChild.observe(endTimeMs);\n-        }\n     }\n \n     @Override\n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SinkStatsManager.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SinkStatsManager.java\nindex c515ce6bc872c..4fae7f9c292d1 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SinkStatsManager.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SinkStatsManager.java\n@@ -279,13 +279,9 @@ public void setLastInvocation(long ts) {\n         statlastInvocationChild.set(ts);\n     }\n \n-    @Override\n-    public void processTimeStart() {\n-        //no-op\n-    }\n \n     @Override\n-    public void processTimeEnd() {\n+    public void processTimeEnd(long startTime) {\n         //no-op\n     }\n \n\ndiff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SourceStatsManager.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SourceStatsManager.java\nindex 1f7e159c4dcb5..b68e1d610f7d3 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SourceStatsManager.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/instance/stats/SourceStatsManager.java\n@@ -279,13 +279,9 @@ public void setLastInvocation(long ts) {\n         statlastInvocationChild.set(ts);\n     }\n \n-    @Override\n-    public void processTimeStart() {\n-        //no-op\n-    }\n \n     @Override\n-    public void processTimeEnd() {\n+    public void processTimeEnd(long startTime) {\n         //no-op\n     }\n \n\ndiff --git a/pulsar-functions/instance/src/main/resources/findbugsExclude.xml b/pulsar-functions/instance/src/main/resources/findbugsExclude.xml\nindex 40e3e91112328..ffe23993eb702 100644\n--- a/pulsar-functions/instance/src/main/resources/findbugsExclude.xml\n+++ b/pulsar-functions/instance/src/main/resources/findbugsExclude.xml\n@@ -557,4 +557,9 @@\n     <Method name=\"setSourceInputSpecs\"/>\n     <Bug pattern=\"EI_EXPOSE_REP2\"/>\n   </Match>\n+  <Match>\n+    <Class name=\"org.apache.pulsar.functions.instance.JavaInstance$AsyncFuncRequest\"/>\n+    <Method name=\"getResult\"/>\n+    <Bug pattern=\"EI_EXPOSE_REP\"/>\n+  </Match>\n </FindBugsFilter>\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java b/pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java\nindex 74c2a93b84e9f..aef75e5fc7efb 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/io/PulsarFunctionE2ETest.java\n@@ -64,6 +64,7 @@\n import org.apache.pulsar.common.policies.data.TopicStats;\n import org.apache.pulsar.compaction.PublishingOrderCompactor;\n import org.apache.pulsar.functions.api.Context;\n+import org.apache.pulsar.functions.api.examples.JavaNativeAsyncExclamationFunction;\n import org.apache.pulsar.functions.instance.InstanceUtils;\n import org.apache.pulsar.functions.utils.FunctionCommon;\n import org.apache.pulsar.functions.worker.FunctionRuntimeManager;\n@@ -296,6 +297,100 @@ public void testReadCompactedFunction() throws Exception {\n         producer.close();\n     }\n \n+    @Test(timeOut = 20000)\n+    public void testPulsarFunctionAsyncStatTime() throws Exception {\n+        final String namespacePortion = \"io\";\n+        final String replNamespace = tenant + \"/\" + namespacePortion;\n+        final String sourceTopic = \"persistent://\" + replNamespace + \"/my-topic1\";\n+        final String sinkTopic = \"persistent://\" + replNamespace + \"/output\";\n+        final String functionName = \"JavaNativeAsyncExclamationFunction\";\n+        final String subscriptionName = \"test-sub\";\n+        admin.namespaces().createNamespace(replNamespace);\n+        Set<String> clusters = Sets.newHashSet(Lists.newArrayList(\"use\"));\n+        admin.namespaces().setNamespaceReplicationClusters(replNamespace, clusters);\n+\n+        FunctionConfig functionConfig = new FunctionConfig();\n+        functionConfig.setTenant(tenant);\n+        functionConfig.setNamespace(namespacePortion);\n+        functionConfig.setName(functionName);\n+        functionConfig.setParallelism(1);\n+        functionConfig.setSubName(subscriptionName);\n+        functionConfig.setInputSpecs(Collections.singletonMap(sourceTopic,\n+                ConsumerConfig.builder().poolMessages(true).build()));\n+        functionConfig.setAutoAck(true);\n+        functionConfig.setClassName(JavaNativeAsyncExclamationFunction.class.getName());\n+        functionConfig.setRuntime(FunctionConfig.Runtime.JAVA);\n+        functionConfig.setOutput(sinkTopic);\n+        functionConfig.setCleanupSubscription(true);\n+        functionConfig.setProcessingGuarantees(FunctionConfig.ProcessingGuarantees.ATLEAST_ONCE);\n+\n+        admin.functions().createFunctionWithUrl(functionConfig,\n+                PulsarFunctionE2ETest.class.getProtectionDomain().getCodeSource().getLocation().toURI().toString());\n+\n+        // create a producer that creates a topic at broker\n+        Producer<String> producer = pulsarClient.newProducer(Schema.STRING).topic(sourceTopic).create();\n+        Consumer<String> consumer =\n+                pulsarClient.newConsumer(Schema.STRING).topic(sinkTopic).subscriptionName(subscriptionName).subscribe();\n+\n+        retryStrategically((test) -> {\n+            try {\n+                return admin.topics().getStats(sourceTopic).getSubscriptions().size() == 1;\n+            } catch (PulsarAdminException e) {\n+                return false;\n+            }\n+        }, 50, 150);\n+        retryStrategically((test) -> {\n+            try {\n+                return admin.topics().getStats(sinkTopic).getSubscriptions().size() == 1;\n+            } catch (PulsarAdminException e) {\n+                return false;\n+            }\n+        }, 50, 150);\n+        // validate pulsar sink consumer has started on the topic\n+        assertEquals(admin.topics().getStats(sourceTopic).getSubscriptions().size(), 1);\n+        assertEquals(admin.topics().getStats(sinkTopic).getSubscriptions().size(), 1);\n+\n+        int cntMsg = 5;\n+        for (int i = 0; i < cntMsg; i++) {\n+            producer.newMessage().value(\"it is the \" + i + \"th message , it will spend 500ms\").send();\n+        }\n+        Awaitility.await().ignoreExceptions().untilAsserted(() -> {\n+            SubscriptionStats subStats = admin.topics().getStats(sourceTopic).getSubscriptions().get(subscriptionName);\n+            assertEquals(subStats.getUnackedMessages(), 0);\n+        });\n+        int count = 0;\n+        while (true) {\n+            Message<String> message = consumer.receive(10, TimeUnit.SECONDS);\n+            if (message == null) {\n+                break;\n+            }\n+            consumer.acknowledge(message);\n+            count++;\n+        }\n+        Assert.assertEquals(count, cntMsg);\n+\n+        String prometheusMetrics = TestPulsarFunctionUtils.getPrometheusMetrics(pulsar.getListenPortHTTP().get());\n+        log.info(\"prometheus metrics: {}\", prometheusMetrics);\n+        Map<String, TestPulsarFunctionUtils.Metric> statsMetrics =\n+                TestPulsarFunctionUtils.parseMetrics(prometheusMetrics);\n+\n+        assertEquals(statsMetrics.get(\"pulsar_function_process_latency_ms\").value, 500.0, 100.0);\n+        admin.functions().deleteFunction(tenant, namespacePortion, functionName);\n+\n+        retryStrategically((test) -> {\n+            try {\n+                return admin.topics().getStats(sourceTopic).getSubscriptions().size() == 0;\n+            } catch (PulsarAdminException e) {\n+                return false;\n+            }\n+        }, 50, 150);\n+\n+        // make sure subscriptions are cleanup\n+        assertEquals(admin.topics().getStats(sourceTopic).getSubscriptions().size(), 0);\n+\n+        tempDirectory.assertThatFunctionDownloadTempFilesHaveBeenDeleted();\n+    }\n+\n     @Test(timeOut = 20000)\n     public void testPulsarFunctionStats() throws Exception {\n \n\ndiff --git a/pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java b/pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java\nindex c83648132d488..385d78e671727 100644\n--- a/pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java\n+++ b/pulsar-functions/instance/src/test/java/org/apache/pulsar/functions/instance/JavaInstanceRunnableTest.java\n@@ -24,7 +24,9 @@\n import static org.mockito.Mockito.times;\n import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.when;\n+\n import com.fasterxml.jackson.annotation.JsonIgnore;\n+\n import java.lang.reflect.Field;\n import java.lang.reflect.Method;\n import java.time.Duration;\n@@ -36,6 +38,7 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.atomic.AtomicReference;\n+\n import lombok.Getter;\n import lombok.Setter;\n import lombok.extern.slf4j.Slf4j;\n@@ -50,6 +53,7 @@\n import org.apache.pulsar.functions.api.Record;\n import org.apache.pulsar.functions.api.SerDe;\n import org.apache.pulsar.functions.instance.stats.ComponentStatsManager;\n+import org.apache.pulsar.functions.instance.stats.FunctionStatsManager;\n import org.apache.pulsar.functions.proto.Function.FunctionDetails;\n import org.apache.pulsar.functions.proto.Function.SinkSpec;\n import org.apache.pulsar.functions.proto.Function.SourceSpec;\n@@ -61,6 +65,7 @@\n import org.apache.pulsar.io.core.SourceContext;\n import org.awaitility.Awaitility;\n import org.jetbrains.annotations.NotNull;\n+import org.mockito.ArgumentCaptor;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.AfterMethod;\n@@ -173,6 +178,24 @@ public Void process(String input, Context context) throws Exception {\n         }\n     }\n \n+    @Test\n+    public void testFunctionAsyncTime() throws Exception {\n+        FunctionDetails functionDetails = FunctionDetails.newBuilder()\n+                .setAutoAck(true)\n+                .setProcessingGuarantees(org.apache.pulsar.functions.proto.Function.ProcessingGuarantees.MANUAL)\n+                .build();\n+        JavaInstanceRunnable javaInstanceRunnable = createRunnable(functionDetails);\n+        FunctionStatsManager manager = mock(FunctionStatsManager.class);\n+        javaInstanceRunnable.setStats(manager);\n+        JavaExecutionResult javaExecutionResult = new JavaExecutionResult();\n+        Thread.sleep(500);\n+        Record record = mock(Record.class);\n+        javaInstanceRunnable.handleResult(record, javaExecutionResult);\n+        ArgumentCaptor<Long> timeCaptor = ArgumentCaptor.forClass(Long.class);\n+        verify(manager).processTimeEnd(timeCaptor.capture());\n+        Assert.assertEquals(timeCaptor.getValue(), javaExecutionResult.getStartTime());\n+    }\n+\n     @Test\n     public void testFunctionResultNull() throws Exception {\n         JavaExecutionResult javaExecutionResult = new JavaExecutionResult();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23810",
    "pr_id": 23810,
    "issue_id": 23389,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11125404278/job/30955253737?pr=23327#step:11:1680\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 5, Failures: 1, Errors: 0, Skipped: 4, Time elapsed: 74.942 s <<< FAILURE! - in org.apache.pulsar.broker.service.ZkSessionExpireTest\r\n  Error:  org.apache.pulsar.broker.service.ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild[false, class org.apache.pulsar.broker.service.NetworkErrorTestBase$PreferBrokerModularLoadManager](4)  Time elapsed: 31.007 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition expected [2] but found [1] within 10 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.pulsar.broker.service.ZkSessionExpireTest.testTopicUnloadAfterSessionRebuild(ZkSessionExpireTest.java:154)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  Caused by: java.lang.AssertionError: expected [2] but found [1]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n  \tat org.apache.pulsar.broker.service.ZkSessionExpireTest.lambda$testTopicUnloadAfterSessionRebuild$4(ZkSessionExpireTest.java:155)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 401,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java"
    ],
    "base_commit": "1f7a79f4c240c8075c217ac417dffa5bc72a4d5f",
    "head_commit": "fef0d9c68dfe44d63d207cf82ef1ae7a57dc91a7",
    "repo_url": "https://github.com/apache/pulsar/pull/23810",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23810",
    "dockerfile": "",
    "pr_merged_at": "2025-01-03T21:50:07.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\nindex 143557b008b23..dd0d7c423b643 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ZkSessionExpireTest.java\n@@ -39,7 +39,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class ZkSessionExpireTest extends NetworkErrorTestBase {\n \n     private java.util.function.Consumer<ServiceConfiguration> settings;\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23796",
    "pr_id": 23796,
    "issue_id": 22657,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] consumers stops receiving new messages due to invalid blockedConsumerOnUnackedMsgs state\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\npulsar server: docker image [apachepulsar/pulsar:3.0.4](https://hub.docker.com/r/apachepulsar/pulsar/tags?page=&page_size=&ordering=&name=3.0.4) + helm chart [pulsar-helm-chart](https://github.com/apache/pulsar-helm-chart)\r\npulsar client: java client [org.apache.pulsar:pulsar-client:3.0.4](https://search.maven.org/artifact/org.apache.pulsar/pulsar-client/3.0.4/jar)\r\n\r\n### Minimal reproduce step\r\n\r\nAfter updating Apache Pulsar, we noticed that one of the consumers sometimes stops receiving new messages for some topics.\r\nThe last fully working version for us is 3.0.1. I have tested all later versions released so far and also built a branch-3.0.\r\n\r\nI looked through the commits and determined when our service stops working:\r\n- Last commit where our service works properly: https://github.com/apache/pulsar/commit/80a8f8d307ac2c023147410e31d567cfce8f17c5\r\n- Commit which breaks, our service no longer works properly: https://github.com/apache/pulsar/commit/6e5920879996de4f43dccb4809a910b227f931f5\r\n\r\nI performed a test using the last commit from branch 3.0 (https://github.com/apache/pulsar/commit/fd823f6cad40ed5a719cec6476563650a24c6986) and reverting the individualAckNormal method to the last version before the \"commit which breaks.\" The change looks as follows: https://github.com/180254/pulsar-issue-22657/commit/6dac4bf7200f332d2a7f7bf9cbfcf43f811f322e. I have no problem with the modified code.\r\n\r\nI found nothing in the logs that would inform me about the consumer suspension, etc. There are no unusual logs at all. Restarting the Kubernetes pod with consumers has helped for some time.\r\n\r\n### What did you expect to see?\r\n\r\nconsumer retrieves all messages\r\n\r\n### What did you see instead?\r\n\r\nconsumers stops receiving new messages for some topics\r\n\r\n### Anything else?\r\n\r\n\r\nThe configuration we use:\r\n- broker configuration:\r\n```\r\nbroker:\r\n    managedLedgerDefaultEnsembleSize: \"3\"\r\n    managedLedgerDefaultWriteQuorum: \"3\"\r\n    managedLedgerDefaultAckQuorum: \"2\"\r\n    brokerDeduplicationEnabled: \"true\"\r\n    bookkeeperClientTimeoutInSeconds: \"5\"\r\n    bookkeeperClientHealthCheckErrorThresholdPerInterval: \"3\"\r\n    bookkeeperClientHealthCheckQuarantineTimeInSeconds: \"600\"\r\n```\r\n- namespace configuration:\r\n```\r\nbin/pulsar-admin --admin-url \"${ADMIN_URL}\" namespaces create \"${TENANT}/service\"\r\nbin/pulsar-admin --admin-url \"${ADMIN_URL}\" namespaces set-max-unacked-messages-per-consumer -c 10 \"${TENANT}/service\"\r\nbin/pulsar-admin --admin-url \"${ADMIN_URL}\" namespaces set-max-unacked-messages-per-subscription -c 20 \"${TENANT}/service\"\r\n```\r\n- the topic is persistent:\r\n```\r\npersistent://public/service/service12_some_topic_someotherpart\r\n```\r\n- we use PatternMultiTopicsConsumerImpl\r\n```\r\n   return pulsarClient\r\n        .newConsumer(Schema.STRING)\r\n        .subscriptionName(pulsarServerBasename)\r\n        .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\r\n        .subscriptionType(SubscriptionType.Shared)\r\n        .topicsPattern(Pattern.compile(\"persistent://public/service/service12_.+\"))\r\n        .negativeAckRedeliveryDelay(1000, TimeUnit.MILLISECONDS)\r\n        .patternAutoDiscoveryPeriod(60, TimeUnit.SECONDS)\r\n        .receiverQueueSize(1)\r\n```\r\n\r\nWe can reproduce it on our service. Test scenario: serviced approximately 20 customers (== 20 topics), each with about 20 messages per second. 1 message is processed in approximately 200ms. The problem occurs for a certain number of topics in the test, not for all\r\n\r\nWhen a problem occurs:\r\n- pulsar_subscription_back_log metric shows that the backlog is growing\r\n- pulsar_subscription_unacked_messages metric shows 0\r\n- pulsar_subscription_blocked_on_unacked_messages metric shows 0\r\n- in the service metrics (consume & process pod), I do not see that any messages for the broken topic are being processed\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 535,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Consumer.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java"
    ],
    "base_commit": "d3ea0ee8515949808f2067c3cc2874ac379b5f28",
    "head_commit": "177c3b7d12f7415941ad38f2586aa7ca1b026579",
    "repo_url": "https://github.com/apache/pulsar/pull/23796",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23796",
    "dockerfile": "",
    "pr_merged_at": "2025-02-14T09:56:46.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Consumer.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Consumer.java\nindex b46e10a20fd34..61f9d5c86b32f 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Consumer.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Consumer.java\n@@ -595,6 +595,7 @@ private CompletableFuture<Long> individualAckNormal(CommandAck ack, Map<String,\n                 ackedCount = getAckedCountForMsgIdNoAckSets(batchSize, position, ackOwnerConsumer);\n                 if (checkCanRemovePendingAcksAndHandle(ackOwnerConsumer, position, msgId)) {\n                     addAndGetUnAckedMsgs(ackOwnerConsumer, -(int) ackedCount);\n+                    updateBlockedConsumerOnUnackedMsgs(ackOwnerConsumer);\n                 }\n             }\n \n@@ -1081,6 +1082,11 @@ private boolean removePendingAcks(Consumer ackOwnedConsumer, Position position)\n         if (log.isDebugEnabled()) {\n             log.debug(\"[{}-{}] consumer {} received ack {}\", topicName, subscription, consumerId, position);\n         }\n+        updateBlockedConsumerOnUnackedMsgs(ackOwnedConsumer);\n+        return true;\n+    }\n+\n+    public void updateBlockedConsumerOnUnackedMsgs(Consumer ackOwnedConsumer) {\n         // unblock consumer-throttling when limit check is disabled or receives half of maxUnackedMessages =>\n         // consumer can start again consuming messages\n         int unAckedMsgs = UNACKED_MESSAGES_UPDATER.get(ackOwnedConsumer);\n@@ -1090,7 +1096,6 @@ private boolean removePendingAcks(Consumer ackOwnedConsumer, Position position)\n             ackOwnedConsumer.blockedConsumerOnUnackedMsgs = false;\n             flowConsumerBlockedPermits(ackOwnedConsumer);\n         }\n-        return true;\n     }\n \n     public PendingAcksMap getPendingAcks() {\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\nindex 89727014be99e..fa76fdd5bf45c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n@@ -1790,6 +1790,47 @@ public void testDuplicateAcknowledgement() throws Exception {\n                 .get(\"sub-1\").getUnackedMessages(), 0);\n     }\n \n+    @Test\n+    public void testBlockedConsumerOnUnackedMsgs() throws Exception {\n+        final String ns = \"prop/ns-test\";\n+        admin.namespaces().createNamespace(ns, 2);\n+        admin.namespaces().setMaxUnackedMessagesPerConsumer(ns, 1);\n+\n+        final String topicName = \"persistent://prop/ns-test/testBlockedConsumerOnUnackedMsgs\";\n+        @Cleanup\n+        Producer<byte[]> producer = pulsarClient.newProducer()\n+                .topic(topicName)\n+                .create();\n+        @Cleanup\n+        Consumer<byte[]> consumer = pulsarClient.newConsumer()\n+                .topic(topicName)\n+                .subscriptionName(\"sub-test\")\n+                .acknowledgmentGroupTime(0, TimeUnit.SECONDS)\n+                .subscriptionType(SubscriptionType.Shared)\n+                .isAckReceiptEnabled(true)\n+                .receiverQueueSize(0)\n+                .subscribe();\n+\n+        producer.send(\"1\".getBytes(StandardCharsets.UTF_8));\n+        producer.send(\"2\".getBytes(StandardCharsets.UTF_8));\n+\n+        // 1. receive message\n+        Message<byte[]> message = consumer.receive();\n+        Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);\n+\n+        SubscriptionStats subscriptionStats = admin.topics().getStats(topicName).getSubscriptions().get(\"sub-test\");\n+        assertEquals(subscriptionStats.getUnackedMessages(), 1);\n+        assertTrue(subscriptionStats.getConsumers().get(0).isBlockedConsumerOnUnackedMsgs());\n+\n+        // 2ack this message\n+        consumer.acknowledge(message);\n+        Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);\n+\n+        subscriptionStats = admin.topics().getStats(topicName).getSubscriptions().get(\"sub-test\");\n+        assertEquals(subscriptionStats.getUnackedMessages(), 0);\n+        assertFalse(subscriptionStats.getConsumers().get(0).isBlockedConsumerOnUnackedMsgs());\n+    }\n+\n     @Test\n     public void testUnsubscribeNonDurableSub() throws Exception {\n         final String ns = \"prop/ns-test\";\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23766",
    "pr_id": 23766,
    "issue_id": 23765,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] TimeoutException encountered while accessing the admin's getMessageById API in version 3.0.7\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nOScentos7\r\nJdk17\r\nPulsar version3.0.7\n\n### Minimal reproduce step\n\n1. Add a test case to the testGetMessageById method in PersistentTopicsTest.java.\r\n\r\n2. Specifically, you can add the following code:\r\n`Assert.expectThrows(PulsarAdminException.ServerSideErrorException.class, () -> {\r\n    admin.topics().getMessageById(topicName1, id1.getLedgerId(), id1.getEntryId() + 10);\r\n});\r\n`\r\n\r\n3. Run this test case to reproduce the issue. You will encounter the following error:\r\n`Caused by: org.apache.pulsar.client.admin.PulsarAdminException$TimeoutException: java.util.concurrent.TimeoutException\r\n    at org.apache.pulsar.client.admin.internal.BaseResource.sync(BaseResource.java:347)\r\n    at org.apache.pulsar.client.admin.internal.TopicsImpl.getMessageById(TopicsImpl.java:1010)\r\n    at org.apache.pulsar.broker.admin.PersistentTopicsTest.lambda$testGetMessageById$11(PersistentTopicsTest.java:1385)\r\n    at org.testng.Assert.expectThrows(Assert.java:2440)\r\n    ... 29 more\r\n`\n\n### What did you expect to see?\n\nThe issue occurs when trying to query a non-existent message, which usually happens when a topic is newly created but hasn't received any traffic yet. In such cases, querying some information about the topic might invoke this API, leading to a timeout.\r\n\r\nFor this scenario, I would expect a fast failure, rather than being blocked until the timeout occurs.\n\n### What did you see instead?\n\nWhat I observed instead is that the getMessageById request gets blocked until the timeout occurs.\r\n\r\nThe hidden risk is that, since the timeout duration is uncertain, if the user has not configured a timeout (e.g., PulsarAdmin.builder().readTimeout(5, TimeUnit.SECONDS);) or if the timeout configuration is unreasonable, it can cause the TCP connection to enter a CLOSE_WAIT state. In extreme cases, this could potentially lead to a tcp.listenOverflow, which can affect other functionalities.\r\n\r\nThe following image shows a large number of connections in the CLOSE_WAIT state on the broker's 8080 port:\r\n![image](https://github.com/user-attachments/assets/ac845f7e-e62f-4f77-9def-e54f303dda28)\r\n\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 385,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java"
    ],
    "base_commit": "db892dd1f5f8c75155bd1bd7193a6144002cc77a",
    "head_commit": "d3bed6a77d0d3538ad7e3deceba24f05d8bde56b",
    "repo_url": "https://github.com/apache/pulsar/pull/23766",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23766",
    "dockerfile": "",
    "pr_merged_at": "2024-12-21T11:20:57.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\nindex 1300cd3449c27..4b9fea05cd885 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n@@ -2774,9 +2774,10 @@ protected CompletableFuture<Response> internalGetMessageById(long ledgerId, long\n                         public void readEntryFailed(ManagedLedgerException exception,\n                                                     Object ctx) {\n                             if (exception instanceof ManagedLedgerException.LedgerNotExistException) {\n-                                throw new RestException(Status.NOT_FOUND, \"Message id not found\");\n+                                results.completeExceptionally(\n+                                        new RestException(Status.NOT_FOUND, \"Message id not found\"));\n                             }\n-                            throw new RestException(exception);\n+                            results.completeExceptionally(new RestException(exception));\n                         }\n \n                         @Override\n@@ -2784,7 +2785,7 @@ public void readEntryComplete(Entry entry, Object ctx) {\n                             try {\n                                 results.complete(generateResponseWithEntry(entry, (PersistentTopic) topic));\n                             } catch (IOException exception) {\n-                                throw new RestException(exception);\n+                                results.completeExceptionally(new RestException(exception));\n                             } finally {\n                                 if (entry != null) {\n                                     entry.release();\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\nindex 302948903442c..258c0183114fd 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n@@ -1419,6 +1419,10 @@ public void testGetMessageById() throws Exception {\n         Assert.expectThrows(PulsarAdminException.NotFoundException.class, () -> {\n             admin.topics().getMessageById(topicName1, id2.getLedgerId(), id2.getEntryId());\n         });\n+\n+        Assert.expectThrows(PulsarAdminException.ServerSideErrorException.class, () -> {\n+            admin.topics().getMessageById(topicName1, id1.getLedgerId(), id1.getEntryId() + 10);\n+        });\n     }\n \n     @Test\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23747",
    "pr_id": 23747,
    "issue_id": 23746,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: KeySharedSubscriptionTest.testNoKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelector\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/12074341127/job/33672445502#step:10:1712\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\njava.lang.AssertionError: expected [33.333333333333336] but found [18.0]\r\n\tat org.testng.Assert.fail(Assert.java:110)\r\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n\tat org.testng.Assert.assertEquals(Assert.java:697)\r\n\tat org.testng.Assert.assertEquals(Assert.java:710)\r\n\tat org.apache.pulsar.client.api.KeySharedSubscriptionTest.receiveAndCheckDistribution(KeySharedSubscriptionTest.java:1478)\r\n\tat org.apache.pulsar.client.api.KeySharedSubscriptionTest.testNoKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelector(KeySharedSubscriptionTest.java:400)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 129,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java"
    ],
    "base_commit": "8d7d1fbb8e0d55bdd7a21f20f79247c22f20489d",
    "head_commit": "2cdf0ab66dd3da7350d2c64d7067459d96efa3f6",
    "repo_url": "https://github.com/apache/pulsar/pull/23747",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23747",
    "dockerfile": "",
    "pr_merged_at": "2024-12-20T11:39:05.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\nindex 08efb6d9583ef..92257c1df53f8 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n@@ -391,13 +391,14 @@ public void testNoKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelect\n         @Cleanup\n         Producer<Integer> producer = createProducer(topic, enableBatch);\n \n-        for (int i = 0; i < 100; i++) {\n+        int totalMessages = 300;\n+        for (int i = 0; i < totalMessages; i++) {\n             producer.newMessage()\n                     .value(i)\n                     .send();\n         }\n \n-        receiveAndCheckDistribution(Lists.newArrayList(consumer1, consumer2, consumer3), 100);\n+        receiveAndCheckDistribution(Lists.newArrayList(consumer1, consumer2, consumer3), totalMessages);\n     }\n \n     @Test(dataProvider = \"batch\")\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23730",
    "pr_id": 23730,
    "issue_id": 23715,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] validatePoliciesReadOnlyAccessAsync is missing from internalRevokePermissionsOnTopic\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nafter 62c6f0872f65a9861c07fb3555d0364ddcd2d0c1 / PR #20478\n\n### Minimal reproduce step\n\nvalidatePoliciesReadOnlyAccessAsync is missing from internalRevokePermissionsOnTopic\n\n### What did you expect to see?\n\nvalidatePoliciesReadOnlyAccessAsync to be called like it's the case for internalGrantPermissionsOnTopic\n\n### What did you see instead?\n\nThe method call is missing\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 114,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java"
    ],
    "base_commit": "1113153bd33a59b5997a1473514cc63f34d54991",
    "head_commit": "46998400c57c1847de3f9b7a8a8d49cc3ffd3ad0",
    "repo_url": "https://github.com/apache/pulsar/pull/23730",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23730",
    "dockerfile": "",
    "pr_merged_at": "2024-12-17T03:38:13.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\nindex 9a306f6b4fff7..1300cd3449c27 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n@@ -289,7 +289,8 @@ protected void internalGrantPermissionsOnTopic(final AsyncResponse asyncResponse\n     protected void internalRevokePermissionsOnTopic(AsyncResponse asyncResponse, String role) {\n         // This operation should be reading from zookeeper and it should be allowed without having admin privileges\n         CompletableFuture<Void> validateAccessForTenantCf =\n-                validateAdminAccessForTenantAsync(namespaceName.getTenant());\n+                validateAdminAccessForTenantAsync(namespaceName.getTenant())\n+                        .thenCompose(__ -> validatePoliciesReadOnlyAccessAsync());\n \n         var checkIfTopicExists = !pulsar().getConfiguration().isAllowAclChangesOnNonExistentTopics();\n         if (checkIfTopicExists) {\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\nindex cca5049ed50eb..302948903442c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n@@ -1030,6 +1030,36 @@ public void testRevokePartitionedTopic() {\n         }\n     }\n \n+    @Test\n+    public void testRevokePartitionedTopicWithReadonlyPolicies() throws Exception {\n+        final String partitionedTopicName = \"testRevokePartitionedTopicWithReadonlyPolicies-topic\";\n+        final int numPartitions = 5;\n+        AsyncResponse response = mock(AsyncResponse.class);\n+        ArgumentCaptor<Response> responseCaptor = ArgumentCaptor.forClass(Response.class);\n+        persistentTopics.createPartitionedTopic(\n+                response, testTenant, testNamespace, partitionedTopicName, numPartitions, true);\n+        verify(response, timeout(5000).times(1)).resume(responseCaptor.capture());\n+        Assert.assertEquals(responseCaptor.getValue().getStatus(), Response.Status.NO_CONTENT.getStatusCode());\n+        String role = \"role\";\n+        Set<AuthAction> expectActions = new HashSet<>();\n+        expectActions.add(AuthAction.produce);\n+        response = mock(AsyncResponse.class);\n+        responseCaptor = ArgumentCaptor.forClass(Response.class);\n+        persistentTopics.grantPermissionsOnTopic(response, testTenant, testNamespace, partitionedTopicName, role,\n+                expectActions);\n+        verify(response, timeout(5000).times(1)).resume(responseCaptor.capture());\n+        Assert.assertEquals(responseCaptor.getValue().getStatus(), Response.Status.NO_CONTENT.getStatusCode());\n+        response = mock(AsyncResponse.class);\n+        doReturn(CompletableFuture.failedFuture(\n+                new RestException(Response.Status.FORBIDDEN,  \"Broker is forbidden to do read-write operations\"))\n+        ).when(persistentTopics).validatePoliciesReadOnlyAccessAsync();\n+        persistentTopics.revokePermissionsOnTopic(response, testTenant, testNamespace, partitionedTopicName, role);\n+        ArgumentCaptor<RestException> exceptionCaptor = ArgumentCaptor.forClass(RestException.class);\n+        verify(response, timeout(5000).times(1)).resume(exceptionCaptor.capture());\n+        Assert.assertEquals(exceptionCaptor.getValue().getResponse().getStatus(),\n+                Response.Status.FORBIDDEN.getStatusCode());\n+    }\n+\n     @Test\n     public void testTriggerCompactionTopic() {\n         final String partitionTopicName = \"test-part\";\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23718",
    "pr_id": 23718,
    "issue_id": 23704,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] deadLetterPolicy attribute in the ConsumerConfigurationData class marked as transient\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nAll Java clients of version v2.8.0 and above\r\n\r\n### Minimal reproduce step\r\n\r\nCreate an instance of `ConsumerConfigurationData` class and set a `deadLetterPolicy` on it. Serialize it and de-serialize it back to get a new instance of the same. The `deadLetterPolicy` previously set will not be present after deserialization.\r\n\r\n### What did you expect to see?\r\n\r\nIdeally the `deadLetterPolicy` should have been preserved through serialization-deserialization.\r\n\r\n### What did you see instead?\r\n\r\nnull\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 152,
    "test_files_count": 2,
    "non_test_files_count": 5,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java",
      "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/DeadLetterPolicy.java",
      "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/KeySharedPolicy.java",
      "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationData.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ReaderConfigurationData.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java"
    ],
    "base_commit": "f571aa1e6c247bea54d7a10ed508991fee1ea71b",
    "head_commit": "11527439d6312764133dea8ff36aaf27b36f06d4",
    "repo_url": "https://github.com/apache/pulsar/pull/23718",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23718",
    "dockerfile": "",
    "pr_merged_at": "2024-12-24T06:41:42.000Z",
    "patch": "diff --git a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/DeadLetterPolicy.java b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/DeadLetterPolicy.java\nindex f0b75ff57dd7b..c2a172666b01d 100644\n--- a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/DeadLetterPolicy.java\n+++ b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/DeadLetterPolicy.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import java.io.Serializable;\n import lombok.AllArgsConstructor;\n import lombok.Builder;\n import lombok.Data;\n@@ -36,7 +37,8 @@\n @AllArgsConstructor\n @InterfaceAudience.Public\n @InterfaceStability.Stable\n-public class DeadLetterPolicy {\n+public class DeadLetterPolicy implements Serializable {\n+    private static final long serialVersionUID = 1L;\n \n     /**\n      * Maximum number of times that a message will be redelivered before being sent to the dead letter queue.\n\ndiff --git a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/KeySharedPolicy.java b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/KeySharedPolicy.java\nindex f5bc5b846b6db..ccaed04d75da3 100644\n--- a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/KeySharedPolicy.java\n+++ b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/KeySharedPolicy.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import java.io.Serializable;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.List;\n@@ -29,7 +30,7 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Stable\n-public abstract class KeySharedPolicy {\n+public abstract class KeySharedPolicy implements Serializable {\n \n     protected KeySharedMode keySharedMode;\n \n@@ -82,6 +83,7 @@ public int getHashRangeTotal() {\n      * for message, the cursor will rewind.\n      */\n     public static class KeySharedPolicySticky extends KeySharedPolicy {\n+        private static final long serialVersionUID = 1L;\n \n         protected final List<Range> ranges;\n \n@@ -129,6 +131,7 @@ public List<Range> getRanges() {\n      * Auto split hash range key shared policy.\n      */\n     public static class KeySharedPolicyAutoSplit extends KeySharedPolicy {\n+        private static final long serialVersionUID = 1L;\n \n         KeySharedPolicyAutoSplit() {\n             this.keySharedMode = KeySharedMode.AUTO_SPLIT;\n\ndiff --git a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\nindex 3db225330d0c7..14d9eec0e1b46 100644\n--- a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\n+++ b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.client.api;\n \n+import java.io.Serializable;\n import java.util.Objects;\n import org.apache.pulsar.common.classification.InterfaceAudience;\n import org.apache.pulsar.common.classification.InterfaceStability;\n@@ -27,7 +28,8 @@\n  */\n @InterfaceAudience.Public\n @InterfaceStability.Stable\n-public class Range implements Comparable<Range> {\n+public class Range implements Comparable<Range>, Serializable {\n+    private static final long serialVersionUID = 1L;\n \n     private final int start;\n     private final int end;\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationData.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationData.java\nindex f9ff5913f62da..f04d62228ae75 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationData.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationData.java\n@@ -358,7 +358,7 @@ public int getMaxPendingChuckedMessage() {\n                     + \"When specifying the dead letter policy while not specifying `ackTimeoutMillis`, you can set the\"\n                     + \" ack timeout to 30000 millisecond.\"\n     )\n-    private transient DeadLetterPolicy deadLetterPolicy;\n+    private DeadLetterPolicy deadLetterPolicy;\n \n     private boolean retryEnable = false;\n \n@@ -386,7 +386,7 @@ public int getMaxPendingChuckedMessage() {\n     private boolean resetIncludeHead = false;\n \n     @JsonIgnore\n-    private transient KeySharedPolicy keySharedPolicy;\n+    private KeySharedPolicy keySharedPolicy;\n \n     private boolean batchIndexAckEnabled = false;\n \n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ReaderConfigurationData.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ReaderConfigurationData.java\nindex 73d97f1f33607..cd5aa4c12f5c3 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ReaderConfigurationData.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ReaderConfigurationData.java\n@@ -144,7 +144,7 @@ public class ReaderConfigurationData<T> implements Serializable, Cloneable {\n     )\n     private boolean resetIncludeHead = false;\n \n-    private transient List<Range> keyHashRanges;\n+    private List<Range> keyHashRanges;\n \n     private boolean poolMessages = false;\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\nindex 2fd288239e362..e5f9e43b8bb4a 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BatchMessageTest.java\n@@ -991,8 +991,8 @@ public void testBatchMessageDispatchingAccordingToPermits() throws Exception {\n \n         int numMsgs = 1000;\n         int batchMessages = 10;\n-        final String topicName = \"persistent://prop/ns-abc/testRetrieveSequenceIdSpecify-\" + UUID.randomUUID();\n-        final String subscriptionName = \"sub-1\";\n+        final String topicName = \"persistent://prop/ns-abc/testBatchMessageDispatchingAccordingToPermits-\" + UUID.randomUUID();\n+        final String subscriptionName = \"bmdap-sub-1\";\n \n         ConsumerImpl<byte[]> consumer1 = (ConsumerImpl<byte[]>) pulsarClient.newConsumer().topic(topicName)\n                 .subscriptionName(subscriptionName).receiverQueueSize(10).subscriptionType(SubscriptionType.Shared)\n@@ -1017,6 +1017,7 @@ public void testBatchMessageDispatchingAccordingToPermits() throws Exception {\n \n         producer.close();\n         consumer1.close();\n+        consumer2.close();\n     }\n \n     @Test(dataProvider=\"testSubTypeAndEnableBatch\")\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java\nindex f47f83bcbce32..291583c306746 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/conf/ConsumerConfigurationDataTest.java\n@@ -19,7 +19,18 @@\n package org.apache.pulsar.client.impl.conf;\n \n import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.util.Collections;\n import java.util.regex.Pattern;\n+\n+import lombok.Cleanup;\n+import org.apache.pulsar.client.api.DeadLetterPolicy;\n+import org.apache.pulsar.client.api.SubscriptionType;\n+import org.testng.Assert;\n import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n@@ -45,4 +56,43 @@ public void testTopicConsumerConfigurationData(String topicName, int expectedPri\n \n         assertThat(topicConsumerConfigurationData.getPriorityLevel()).isEqualTo(expectedPriority);\n     }\n+\n+    @Test\n+    public void testSerializable() throws Exception {\n+        ConsumerConfigurationData<String> consumerConfigurationData = new ConsumerConfigurationData<>();\n+        consumerConfigurationData.setPriorityLevel(1);\n+        consumerConfigurationData.setSubscriptionName(\"my-sub\");\n+        consumerConfigurationData.setSubscriptionType(SubscriptionType.Shared);\n+        consumerConfigurationData.setReceiverQueueSize(100);\n+        consumerConfigurationData.setAckTimeoutMillis(1000);\n+        consumerConfigurationData.setTopicNames(Collections.singleton(\"my-topic\"));\n+\n+        DeadLetterPolicy deadLetterPolicy = DeadLetterPolicy.builder()\n+                .maxRedeliverCount(10)\n+                .retryLetterTopic(\"retry-topic\")\n+                .deadLetterTopic(\"dead-topic\")\n+                .build();\n+        consumerConfigurationData.setDeadLetterPolicy(deadLetterPolicy);\n+\n+        @Cleanup\n+        ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+        @Cleanup\n+        ObjectOutputStream oos = new ObjectOutputStream(bos);\n+        oos.writeObject(consumerConfigurationData);\n+        byte[] serialized = bos.toByteArray();\n+\n+        // Deserialize\n+        @Cleanup\n+        ByteArrayInputStream bis = new ByteArrayInputStream(serialized);\n+        @Cleanup\n+        ObjectInputStream ois = new ObjectInputStream(bis);\n+        Object object = ois.readObject();\n+\n+        Assert.assertEquals(object.getClass(), ConsumerConfigurationData.class);\n+        Assert.assertEquals(object, consumerConfigurationData);\n+\n+        DeadLetterPolicy deserialisedDeadLetterPolicy = ((ConsumerConfigurationData<?>) object).getDeadLetterPolicy();\n+        Assert.assertNotNull(deserialisedDeadLetterPolicy);\n+        Assert.assertEquals(deserialisedDeadLetterPolicy, deadLetterPolicy);\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23691",
    "pr_id": 23691,
    "issue_id": 23690,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] TopicName does not throw IllegalArgumentException if localName is whitespace only\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nPulsar master\r\n\r\n### Minimal reproduce step\r\n\r\nCall `TopicName.get(\" \")`.\r\n\r\n### What did you expect to see?\r\n\r\nThis is a test for the behavior I would expect:\r\n```java\r\ntry {\r\n    TopicName.get(\" \");\r\n    fail(\"Should have raised exception\");\r\n} catch (IllegalArgumentException e) {\r\n    // Ok\r\n}\r\n```\r\n\r\nWhen creating a consumer with the topic name only being a whitespace we get:\r\n\r\n> java.lang.IllegalArgumentException: topicNames cannot have blank topic\r\n\r\nThat's why I expect `TopicName.get(\" \")` to throw an exception too.\r\n\r\n### What did you see instead?\r\n\r\nNo exception is thrown.\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 161,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-common/src/main/java/org/apache/pulsar/common/naming/TopicName.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java"
    ],
    "base_commit": "9a7269a9cf98bd63f45cc48db85b70fb191fb054",
    "head_commit": "8b3da9bb2f12b9d2c2d313f8a549f95e5b01d320",
    "repo_url": "https://github.com/apache/pulsar/pull/23691",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23691",
    "dockerfile": "",
    "pr_merged_at": "2024-12-17T06:23:13.000Z",
    "patch": "diff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/naming/TopicName.java b/pulsar-common/src/main/java/org/apache/pulsar/common/naming/TopicName.java\nindex dd24c9a971210..b2f96bfe6e259 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/naming/TopicName.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/naming/TopicName.java\n@@ -170,9 +170,9 @@ private TopicName(String completeTopicName) {\n                 throw new IllegalArgumentException(\"Invalid topic name: \" + completeTopicName);\n             }\n \n-\n-            if (localName == null || localName.isEmpty()) {\n-                throw new IllegalArgumentException(\"Invalid topic name: \" + completeTopicName);\n+            if (StringUtils.isBlank(localName)) {\n+                throw new IllegalArgumentException(String.format(\"Invalid topic name: %s. Topic local name must not\"\n+                        + \" be blank.\", completeTopicName));\n             }\n \n         } catch (NullPointerException e) {\n",
    "test_patch": "diff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java\nindex 485bea3f1addb..27eb82d15af0d 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/naming/TopicNameTest.java\n@@ -177,6 +177,13 @@ public void topic() {\n             // Ok\n         }\n \n+        try {\n+            TopicName.get(\" \");\n+            fail(\"Should have raised exception\");\n+        } catch (IllegalArgumentException e) {\n+            // Ok\n+        }\n+\n         TopicName nameWithSlash = TopicName.get(\"persistent://tenant/cluster/namespace/ns-abc/table/1\");\n         assertEquals(nameWithSlash.getEncodedLocalName(), Codec.encode(\"ns-abc/table/1\"));\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23676",
    "pr_id": 23676,
    "issue_id": 23670,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] `onFilter` method in custom `BrokerInterceptor` doesn't get called\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nmaster(f27905560207eb2ade32f8086b4585dffb918b80)\n\n### Minimal reproduce step\n\n1. implement a simple `BrokerInterceptor` like below, and build a nar package for it:\r\n\r\n  ```\r\n  public class TestFilter implements BrokerInterceptor {\r\n      private static final Logger log = LoggerFactory.getLogger(TestFilter.class);\r\n      @Override\r\n      public void onPulsarCommand(BaseCommand command, ServerCnx cnx) {\r\n      }\r\n  \r\n      @Override\r\n      public void onConnectionClosed(ServerCnx cnx) {\r\n      }\r\n  \r\n      @Override\r\n      public void onWebserviceRequest(ServletRequest request) {\r\n      }\r\n  \r\n      @Override\r\n      public void onWebserviceResponse(ServletRequest request, ServletResponse response) {\r\n      }\r\n  \r\n      @Override\r\n      public void initialize(PulsarService pulsarService) {\r\n      }\r\n  \r\n      @Override\r\n      public void onFilter(ServletRequest request, ServletResponse response, FilterChain chain)\r\n              throws ServletException, IOException {\r\n          log.info(\"====test\");\r\n          chain.doFilter(request, response);\r\n      }\r\n  \r\n      @Override\r\n      public void close() {\r\n  \r\n      }\r\n  }\r\n  ```\r\n\r\n2. edit the `standalone.conf`, and update the `brokerInterceptors=` field to the `test-filter`\r\n3. start the pulsar service in standalone mode\r\n4. call `pulsar-admin tenants list` to fire a http request\n\n### What did you expect to see?\n\nthe pulsar process should printed below logs:\r\n\r\n```\r\n====test\r\n```\n\n### What did you see instead?\n\nthe `====test` logs doesn't get printed\n\n### Anything else?\n\nThe issue lies in the implementation:\r\n\r\nAlthough [PR #10489](https://github.com/apache/pulsar/pull/10489) introduced an `onFilter` method in the `BrokerInterceptor` interface, the `PulsarService` is hardcoded to use `BrokerInterceptors` as the entry interceptor. Custom interceptors configured via the `brokerInterceptors=` parameter are loaded into `BrokerInterceptors` and executed sequentially. However, `BrokerInterceptors` does not override the `onFilter` method, causing it to fall back to the default implementation:\r\n\r\n```java\r\ndefault void onFilter(ServletRequest request, ServletResponse response, FilterChain chain)\r\n        throws IOException, ServletException {\r\n    // Just continue the chain by default.\r\n    chain.doFilter(request, response);\r\n}\r\n```\r\n\r\nAs a result, even if a custom `BrokerInterceptor` implements the `onFilter` method, it is never invoked.\r\n\r\nThis issue exists in branch-3.0, 3.3, 4.0 too\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 345,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/intercept/BrokerInterceptorWithClassLoader.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/web/WebService.java",
      "tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java"
    ],
    "pr_changed_test_files": [
      "tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java"
    ],
    "base_commit": "f27905560207eb2ade32f8086b4585dffb918b80",
    "head_commit": "1ff6d0e76d4ec0f88266c8b07f2f293e96f43915",
    "repo_url": "https://github.com/apache/pulsar/pull/23676",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23676",
    "dockerfile": "",
    "pr_merged_at": "2024-12-04T10:13:51.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/intercept/BrokerInterceptorWithClassLoader.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/intercept/BrokerInterceptorWithClassLoader.java\nindex 3997e214f4316..849f7aa39f0ef 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/intercept/BrokerInterceptorWithClassLoader.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/intercept/BrokerInterceptorWithClassLoader.java\n@@ -22,6 +22,7 @@\n import io.netty.buffer.ByteBuf;\n import java.io.IOException;\n import java.util.Map;\n+import javax.servlet.FilterChain;\n import javax.servlet.ServletException;\n import javax.servlet.ServletRequest;\n import javax.servlet.ServletResponse;\n@@ -272,6 +273,18 @@ public void initialize(PulsarService pulsarService) throws Exception {\n         }\n     }\n \n+    @Override\n+    public void onFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n+            throws ServletException, IOException {\n+        final ClassLoader previousContext = Thread.currentThread().getContextClassLoader();\n+        try {\n+            Thread.currentThread().setContextClassLoader(narClassLoader);\n+            this.interceptor.onFilter(request, response, chain);\n+        } finally {\n+            Thread.currentThread().setContextClassLoader(previousContext);\n+        }\n+    }\n+\n     @Override\n     public void close() {\n         final ClassLoader previousContext = Thread.currentThread().getContextClassLoader();\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/web/WebService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/web/WebService.java\nindex 5f5e260890a02..7eb1f2fae09b6 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/web/WebService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/web/WebService.java\n@@ -41,6 +41,8 @@\n import org.apache.pulsar.broker.PulsarServerException;\n import org.apache.pulsar.broker.PulsarService;\n import org.apache.pulsar.broker.ServiceConfiguration;\n+import org.apache.pulsar.broker.intercept.BrokerInterceptor;\n+import org.apache.pulsar.broker.intercept.BrokerInterceptors;\n import org.apache.pulsar.common.util.PulsarSslConfiguration;\n import org.apache.pulsar.common.util.PulsarSslFactory;\n import org.apache.pulsar.jetty.tls.JettySslContextFactory;\n@@ -258,7 +260,17 @@ private static class FilterInitializer {\n                 // Enable PreInterceptFilter only when interceptors are enabled\n                 filterHolders.add(\n                         new FilterHolder(new PreInterceptFilter(pulsarService.getBrokerInterceptor(), handler)));\n-                filterHolders.add(new FilterHolder(new ProcessHandlerFilter(pulsarService.getBrokerInterceptor())));\n+                // The `ProcessHandlerFilter` is used to overwrite `doFilter` method, which cannot be called multiple\n+                // times inside one `Filter`, so we cannot use one `ProcessHandlerFilter` with a `BrokerInterceptors` to\n+                // hold all interceptors, instead we need to create a `ProcessHandlerFilter` for each `interceptor`.\n+                if (pulsarService.getBrokerInterceptor() instanceof BrokerInterceptors) {\n+                    for (BrokerInterceptor interceptor: ((BrokerInterceptors) pulsarService.getBrokerInterceptor())\n+                            .getInterceptors().values()) {\n+                        filterHolders.add(new FilterHolder(new ProcessHandlerFilter(interceptor)));\n+                    }\n+                } else {\n+                    filterHolders.add(new FilterHolder(new ProcessHandlerFilter(pulsarService.getBrokerInterceptor())));\n+                }\n             }\n \n             if (config.isAuthenticationEnabled()) {\n",
    "test_patch": "diff --git a/tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java b/tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java\nindex 992c6dd69a6b2..7e46ba18492d2 100644\n--- a/tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java\n+++ b/tests/docker-images/java-test-plugins/src/main/java/org/apache/pulsar/tests/integration/plugins/LoggingBrokerInterceptor.java\n@@ -19,8 +19,10 @@\n package org.apache.pulsar.tests.integration.plugins;\n \n import io.netty.buffer.ByteBuf;\n+import java.io.IOException;\n import java.util.Map;\n import javax.servlet.FilterChain;\n+import javax.servlet.ServletException;\n import javax.servlet.ServletRequest;\n import javax.servlet.ServletResponse;\n import org.apache.bookkeeper.mledger.Entry;\n@@ -122,7 +124,9 @@ public void txnEnded(String txnID, long txnAction) {\n     }\n \n     @Override\n-    public void onFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n+    public void onFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n+            throws ServletException, IOException {\n         log.info(\"onFilter\");\n+        chain.doFilter(request, response);\n     }\n }\n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java\nindex 98000c6f40636..b39339969e52c 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/plugins/TestBrokerInterceptors.java\n@@ -96,6 +96,7 @@ public void test(Supplier<String> serviceUrlSupplier) throws Exception {\n                 \"consumerCreated\",\n                 \"messageProduced\",\n                 \"beforeSendMessage: OK\",\n+                \"onFilter\",\n         }) {\n             assertTrue(log.contains(\"LoggingBrokerInterceptor - \" + line), \"Log did not contain line '\" + line + \"'\");\n         }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23666",
    "pr_id": 23666,
    "issue_id": 23416,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: GetPartitionMetadataMultiBrokerTest.testCompatibilityDifferentBrokersForNonPersistentTopic\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11232284277/job/31224135959?pr=23352#step:11:1732\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 50, Failures: 1, Errors: 0, Skipped: 10, Time elapsed: 65.967 s <<< FAILURE! - in org.apache.pulsar.broker.admin.GetPartitionMetadataMultiBrokerTest\r\n  Error:  org.apache.pulsar.broker.admin.GetPartitionMetadataMultiBrokerTest.testCompatibilityDifferentBrokersForNonPersistentTopic[true, true, false](8)  Time elapsed: 10.311 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition expected [99999] but found [100000] within 10 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.pulsar.broker.admin.GetPartitionMetadataMultiBrokerTest.testCompatibilityDifferentBrokersForNonPersistentTopic(GetPartitionMetadataMultiBrokerTest.java:296)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  Caused by: java.lang.AssertionError: expected [99999] but found [100000]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n  \tat org.apache.pulsar.broker.admin.GetPartitionMetadataMultiBrokerTest.lambda$testCompatibilityDifferentBrokersForNonPersistentTopic$0(GetPartitionMetadataMultiBrokerTest.java:297)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 395,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java"
    ],
    "base_commit": "46037229947c8031207eaed70dd937e6990de544",
    "head_commit": "37d4293fee41465acdfb2cf6356cc5400aea335e",
    "repo_url": "https://github.com/apache/pulsar/pull/23666",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23666",
    "dockerfile": "",
    "pr_merged_at": "2025-01-03T08:42:02.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java\nindex d1eeabdb3d7cc..1b4732f69d4d2 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/GetPartitionMetadataMultiBrokerTest.java\n@@ -253,6 +253,10 @@ public void testCompatibilityDifferentBrokersForNonPersistentTopic(boolean confi\n                                                   boolean isUsingHttpLookup) throws Exception {\n         modifyTopicAutoCreation(configAllowAutoTopicCreation, TopicType.PARTITIONED, 3);\n \n+        // Verify: the method \"getPartitionsForTopic(topic, false, true)\" will fallback\n+        //   to \"getPartitionsForTopic(topic, true)\" behavior.\n+        int lookupPermitsBefore = getLookupRequestPermits();\n+\n         // Initialize the connections of internal Pulsar Client.\n         PulsarClientImpl client1 = (PulsarClientImpl) pulsar1.getClient();\n         PulsarClientImpl client2 = (PulsarClientImpl) pulsar2.getClient();\n@@ -270,9 +274,6 @@ public void testCompatibilityDifferentBrokersForNonPersistentTopic(boolean confi\n                 field.set(clientCnx, false);\n             }\n         }\n-        // Verify: the method \"getPartitionsForTopic(topic, false, true)\" will fallback\n-        //   to \"getPartitionsForTopic(topic, true)\" behavior.\n-        int lookupPermitsBefore = getLookupRequestPermits();\n \n         // Verify: we will not get an un-support error.\n         PulsarClientImpl[] clientArray = getClientsToTest(isUsingHttpLookup);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23624",
    "pr_id": 23624,
    "issue_id": 23622,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug][client] Consumer incomingMessageSize and client memory usage is negative\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nmaster\n\n### Minimal reproduce step\n\nuse a simple demo to consume. Found that client memory usage is negative, and ConsumerBase#incomingMessagesSize is also negative.\r\n\r\n```\r\nConsumer<byte[]> consumer = client.newConsumer(Schema.BYTES)\r\n                .topic(\"persistent://test/normal/test\")\r\n                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\r\n                .subscriptionName(\"test\")\r\n                .subscriptionType(SubscriptionType.Shared)\r\n                .autoScaledReceiverQueueSizeEnabled(true)\r\n                .subscribe();\r\n\r\nwhile (true) {\r\n    Message msg = consumer.receive();\r\n}\r\n```\r\n\n\n### What did you expect to see?\n\nincomingMessageSize and client memory usage should not be negative\n\n### What did you see instead?\n\nincomingMessageSize and client memory usage is negative\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 159,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java"
    ],
    "base_commit": "949750fc080f3bee964dc839d16c9e215465d93a",
    "head_commit": "7d79851287f2613585744e0b7b6206dc0bb12a51",
    "repo_url": "https://github.com/apache/pulsar/pull/23624",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23624",
    "dockerfile": "",
    "pr_merged_at": "2024-11-22T01:51:03.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\nindex 3073f3a833487..38232c836b19e 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n@@ -1231,6 +1231,11 @@ protected void decreaseIncomingMessageSize(final Message<?> message) {\n         getMemoryLimitController().ifPresent(limiter -> limiter.releaseMemory(message.size()));\n     }\n \n+    protected void increaseIncomingMessageSize(final Message<?> message) {\n+        INCOMING_MESSAGES_SIZE_UPDATER.addAndGet(this, message.size());\n+        getMemoryLimitController().ifPresent(limiter -> limiter.forceReserveMemory(message.size()));\n+    }\n+\n     public long getIncomingMessageSize() {\n         return INCOMING_MESSAGES_SIZE_UPDATER.get(this);\n     }\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\nindex be01bd00eb300..f6e17ed906f80 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n@@ -1667,6 +1667,8 @@ void notifyPendingReceivedCallback(final Message<T> message, Exception exception\n             return;\n         }\n \n+        // increase incomingMessageSize here because the size would be decreased in messageProcessed() next step\n+        increaseIncomingMessageSize(message);\n         // increase permits for available message-queue\n         messageProcessed(message);\n         // call interceptor and complete received callback\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\nindex a867dc0cd3562..e75f0ace4d029 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n@@ -4252,6 +4252,62 @@ public void testIncomingMessageSize(boolean isPartitioned) throws Exception {\n         });\n     }\n \n+    @Test(timeOut = 100000)\n+    public void testNegativeIncomingMessageSize() throws Exception {\n+        final String topicName = \"persistent://my-property/my-ns/testIncomingMessageSize-\" +\n+                UUID.randomUUID().toString();\n+        final String subName = \"my-sub\";\n+\n+        admin.topics().createPartitionedTopic(topicName, 3);\n+\n+        @Cleanup\n+        Producer<byte[]> producer = pulsarClient.newProducer()\n+                .topic(topicName)\n+                .enableBatching(false)\n+                .create();\n+\n+        final int messages = 1000;\n+        List<CompletableFuture<MessageId>> messageIds = new ArrayList<>(messages);\n+        for (int i = 0; i < messages; i++) {\n+            messageIds.add(producer.newMessage().key(i + \"\").value((\"Message-\" + i).getBytes()).sendAsync());\n+        }\n+        FutureUtil.waitForAll(messageIds).get();\n+\n+        @Cleanup\n+        Consumer<byte[]> consumer = pulsarClient.newConsumer()\n+                .topic(topicName)\n+                .subscriptionName(subName)\n+                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n+                .subscribe();\n+\n+\n+        Awaitility.await().untilAsserted(() -> {\n+            long size = ((ConsumerBase<byte[]>) consumer).getIncomingMessageSize();\n+            log.info(\"Check the incoming message size should greater that 0, current size is {}\", size);\n+            Assert.assertTrue(size > 0);\n+        });\n+\n+\n+        for (int i = 0; i < messages; i++) {\n+            consumer.receive();\n+        }\n+\n+\n+        Awaitility.await().untilAsserted(() -> {\n+            long size = ((ConsumerBase<byte[]>) consumer).getIncomingMessageSize();\n+            log.info(\"Check the incoming message size should be 0, current size is {}\", size);\n+            Assert.assertEquals(size, 0);\n+        });\n+\n+\n+        MultiTopicsConsumerImpl multiTopicsConsumer = (MultiTopicsConsumerImpl) consumer;\n+        List<ConsumerImpl<byte[]>> list = multiTopicsConsumer.getConsumers();\n+        for (ConsumerImpl<byte[]> subConsumer : list) {\n+            long size = subConsumer.getIncomingMessageSize();\n+            log.info(\"Check the sub consumer incoming message size should be 0, current size is {}\", size);\n+            Assert.assertEquals(size, 0);\n+        }\n+    }\n \n     @Data\n     @EqualsAndHashCode\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java\nindex 858e43e84656f..5359158bf7214 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/AutoScaledReceiverQueueSizeTest.java\n@@ -20,14 +20,22 @@\n \n \n import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.TimeUnit;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.client.api.BatchReceivePolicy;\n+import org.apache.pulsar.client.api.Consumer;\n+import org.apache.pulsar.client.api.MessageId;\n import org.apache.pulsar.client.api.Producer;\n import org.apache.pulsar.client.api.PulsarClientException;\n+import org.apache.pulsar.client.api.SubscriptionInitialPosition;\n+import org.apache.pulsar.common.util.FutureUtil;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n@@ -257,4 +265,58 @@ public void testMultiConsumerImplBatchReceive() throws PulsarClientException, Pu\n         Awaitility.await().until(() -> consumer.getCurrentReceiverQueueSize() == currentSize * 2);\n         log.info(\"getCurrentReceiverQueueSize={}\", consumer.getCurrentReceiverQueueSize());\n     }\n+\n+    @Test\n+    public void testNegativeClientMemory() throws Exception {\n+        final String topicName = \"persistent://public/default/testMemory-\" +\n+                UUID.randomUUID().toString();\n+        final String subName = \"my-sub\";\n+\n+        admin.topics().createPartitionedTopic(topicName, 3);\n+\n+        @Cleanup\n+        Producer<byte[]> producer = pulsarClient.newProducer()\n+                .topic(topicName)\n+                .enableBatching(false)\n+                .create();\n+\n+        final int messages = 1000;\n+        List<CompletableFuture<MessageId>> messageIds = new ArrayList<>(messages);\n+        for (int i = 0; i < messages; i++) {\n+            messageIds.add(producer.newMessage().key(i + \"\").value((\"Message-\" + i).getBytes()).sendAsync());\n+        }\n+        FutureUtil.waitForAll(messageIds).get();\n+\n+\n+        @Cleanup\n+        Consumer<byte[]> consumer = pulsarClient.newConsumer()\n+                .topic(topicName)\n+                .subscriptionName(subName)\n+                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n+                .autoScaledReceiverQueueSizeEnabled(true)\n+                .subscribe();\n+\n+\n+        Awaitility.await().untilAsserted(() -> {\n+            long size = ((ConsumerBase<byte[]>) consumer).getIncomingMessageSize();\n+            log.info(\"Check the incoming message size should greater that 0, current size is {}\", size);\n+            Assert.assertTrue(size > 0);\n+        });\n+\n+\n+        for (int i = 0; i < messages; i++) {\n+            consumer.receive();\n+        }\n+\n+        Awaitility.await().untilAsserted(() -> {\n+            long size = ((ConsumerBase<byte[]>) consumer).getIncomingMessageSize();\n+            log.info(\"Check the incoming message size should be 0, current size is {}\", size);\n+            Assert.assertEquals(size, 0);\n+        });\n+\n+\n+        MemoryLimitController controller = ((PulsarClientImpl)pulsarClient).getMemoryLimitController();\n+        Assert.assertEquals(controller.currentUsage(), 0);\n+        Assert.assertEquals(controller.currentUsagePercent(), 0);\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23618",
    "pr_id": 23618,
    "issue_id": 23617,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] window functions ack messages directly when they comes, which is not expected\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nhttps://github.com/apache/pulsar/tree/v3.0.7\n\n### Minimal reproduce step\n\n1. deploy the pulsar cluster using v3.0.7\r\n2. create a window function\r\n```\r\nbin/pulsar-admin functions create --jar /pulsar/examples/api-examples.jar --name test-window-java --className org.apache.pulsar.functions.api.examples.window.LoggingWindowFunction --inputs persistent://public/default/api-java-fn-input --window-length-count 10 --sliding-interval-count 5\r\n```\r\n3. send 3 messages to the `persistent://public/default/api-java-fn-input` topic\r\n4. get the topic stats of `persistent://public/default/api-java-fn-input`, the backlog of subscription `public/default/test-window-java` should be 3, because the window is not triggered yet, so the 3 messages should not be acked\n\n### What did you expect to see?\n\nthe `msgBacklog` for subscription `public/default/test-window-java` should be 3\n\n### What did you see instead?\n\nthe `msgBacklog` for subscription `public/default/test-window-java` is 0\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 237,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/windowing/WindowFunctionExecutor.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java"
    ],
    "pr_changed_test_files": [
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java"
    ],
    "base_commit": "49aa3080d422994baa036ed0b743a2fa18a6d530",
    "head_commit": "a27e08dab6e8e952d2281f10ed34a2cff0961e40",
    "repo_url": "https://github.com/apache/pulsar/pull/23618",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23618",
    "dockerfile": "",
    "pr_merged_at": "2024-11-22T01:05:01.000Z",
    "patch": "diff --git a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/windowing/WindowFunctionExecutor.java b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/windowing/WindowFunctionExecutor.java\nindex c6ca4e65d33c0..1e492d74aa605 100644\n--- a/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/windowing/WindowFunctionExecutor.java\n+++ b/pulsar-functions/instance/src/main/java/org/apache/pulsar/functions/windowing/WindowFunctionExecutor.java\n@@ -238,6 +238,13 @@ private void processWindow(Context context, List<Record<T>> tuples, List<Record<\n                     }\n                 }\n             });\n+        } else {\n+            // When window function return null, needs to be acked directly.\n+            if (windowConfig.getProcessingGuarantees() == WindowConfig.ProcessingGuarantees.ATLEAST_ONCE) {\n+                for (Record<T> record : tuples) {\n+                    record.ack();\n+                }\n+            }\n         }\n     }\n \n",
    "test_patch": "diff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java\nindex b78a832f60933..694dcba5eaf61 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/functions/PulsarFunctionsTest.java\n@@ -22,6 +22,7 @@\n import static org.assertj.core.api.Assertions.assertThat;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertNotNull;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n import com.fasterxml.jackson.databind.JsonNode;\n@@ -322,7 +323,17 @@ protected void testWindowFunction(String type, String[] expectedResults) throws\n                 .enableBatching(false)\n                 .create();\n \n-        for (int i = 0; i < NUM_OF_MESSAGES; i++) {\n+        // send 3 messages first, and it won't trigger the window and so these 3 messages will not be acked\n+        for (int i = 0; i < 3; i++) {\n+            producer.send(String.format(\"%d\", i).getBytes());\n+        }\n+        TopicStats stats = pulsarAdmin.topics().getStats(inputTopicName, true);\n+        SubscriptionStats subStats = stats.getSubscriptions().get(\"public/default/\" + functionName);\n+        assertNotNull(subStats);\n+        assertEquals(3, subStats.getMsgBacklog());\n+        assertEquals(3, subStats.getUnackedMessages());\n+\n+        for (int i = 3; i < NUM_OF_MESSAGES; i++) {\n             producer.send(String.format(\"%d\", i).getBytes());\n         }\n \n@@ -348,6 +359,13 @@ protected void testWindowFunction(String type, String[] expectedResults) throws\n         // in case last commit is not updated\n         assertThat(i).isGreaterThanOrEqualTo(expectedResults.length - 1);\n \n+        // test that all messages are acked\n+        stats = pulsarAdmin.topics().getStats(inputTopicName, true);\n+        subStats = stats.getSubscriptions().get(\"public/default/\" + functionName);\n+        assertNotNull(subStats);\n+        assertEquals(0, subStats.getMsgBacklog());\n+        assertEquals(0, subStats.getUnackedMessages());\n+\n         deleteFunction(functionName);\n \n         getFunctionInfoNotFound(functionName);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23612",
    "pr_id": 23612,
    "issue_id": 2950,
    "repo": "apache/pulsar",
    "problem_statement": "is Authentication available in java client\n#### i'm newer for pulsar\r\ntoday I read pulsar java client in org.apache.pulsar.client.impl.conf.ClientConfigurationData\r\nin class ClientConfigurationData ,there's a field called authentication and type is Authentication.\r\nAuthentication is a interface,and I find 5 implements but theirs start method all empty.no implement in start method ,what i want to know is ,is  authentication feature  can be used now? Maybe I didn't find it, but I really didn't find his implementation.anyone can help me ?thank u\r\n\r\n\r\n#### System configuration\r\n**Pulsar version**: 2.2.0\r\n",
    "issue_word_count": 99,
    "test_files_count": 1,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "build/run_unit_group.sh",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGenerator.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGeneratorWithNoUnsafeTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGeneratorWithNoUnsafeTest.java"
    ],
    "base_commit": "387a96dcdd78509547b09f12092104620326aa9c",
    "head_commit": "cf31ebdceab417e2e22f7402e2fc2d4d40420256",
    "repo_url": "https://github.com/apache/pulsar/pull/23612",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23612",
    "dockerfile": "",
    "pr_merged_at": "2024-11-27T21:55:10.000Z",
    "patch": "diff --git a/build/run_unit_group.sh b/build/run_unit_group.sh\nindex cdaf69e351b6d..40f83efaf2fb9 100755\n--- a/build/run_unit_group.sh\n+++ b/build/run_unit_group.sh\n@@ -77,6 +77,8 @@ alias echo='{ [[ $- =~ .*x.* ]] && trace_enabled=1 || trace_enabled=0; set +x; }\n # Test Groups  -- start --\n function test_group_broker_group_1() {\n   mvn_test -pl pulsar-broker -Dgroups='broker' -DtestReuseFork=true\n+  # run tests in broker-isolated group individually (instead of with -Dgroups=broker-isolated) to avoid scanning all test classes\n+  mvn_test -pl pulsar-broker -Dtest=org.apache.pulsar.broker.stats.prometheus.PrometheusMetricsGeneratorWithNoUnsafeTest -DtestForkCount=1 -DtestReuseFork=false\n }\n \n function test_group_broker_group_2() {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGenerator.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGenerator.java\nindex 8c3cb39c925d7..97d5a7bc9538d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGenerator.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGenerator.java\n@@ -25,6 +25,7 @@\n import io.netty.buffer.CompositeByteBuf;\n import io.netty.buffer.PooledByteBufAllocator;\n import io.netty.buffer.Unpooled;\n+import io.netty.util.internal.PlatformDependent;\n import io.prometheus.client.Collector;\n import java.io.BufferedOutputStream;\n import java.io.IOException;\n@@ -364,19 +365,24 @@ protected ByteBuf generateMetrics(List<PrometheusRawMetricsProvider> metricsProv\n         }\n     }\n \n-    private ByteBuf allocateMultipartCompositeDirectBuffer() {\n+    ByteBuf allocateMultipartCompositeDirectBuffer() {\n         // use composite buffer with pre-allocated buffers to ensure that the pooled allocator can be used\n         // for allocating the buffers\n         ByteBufAllocator byteBufAllocator = PulsarByteBufAllocator.DEFAULT;\n-        int chunkSize = resolveChunkSize(byteBufAllocator);\n-        CompositeByteBuf buf = byteBufAllocator.compositeDirectBuffer(\n+        ByteBuf buf;\n+        if (PlatformDependent.hasUnsafe()) {\n+            int chunkSize = resolveChunkSize(byteBufAllocator);\n+            buf = byteBufAllocator.compositeDirectBuffer(\n                 Math.max(MINIMUM_FOR_MAX_COMPONENTS, (initialBufferSize / chunkSize) + 1));\n-        int totalLen = 0;\n-        while (totalLen < initialBufferSize) {\n-            totalLen += chunkSize;\n-            // increase the capacity in increments of chunkSize to preallocate the buffers\n-            // in the composite buffer\n-            buf.capacity(totalLen);\n+            int totalLen = 0;\n+            while (totalLen < initialBufferSize) {\n+                totalLen += chunkSize;\n+                // increase the capacity in increments of chunkSize to preallocate the buffers\n+                // in the composite buffer\n+                buf.capacity(totalLen);\n+            }\n+        } else {\n+            buf = byteBufAllocator.directBuffer(initialBufferSize);\n         }\n         return buf;\n     }\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGeneratorWithNoUnsafeTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGeneratorWithNoUnsafeTest.java\nnew file mode 100644\nindex 0000000000000..006428b4815f1\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/PrometheusMetricsGeneratorWithNoUnsafeTest.java\n@@ -0,0 +1,52 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.stats.prometheus;\n+\n+import static org.testng.Assert.assertFalse;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.util.internal.PlatformDependent;\n+import java.time.Clock;\n+import lombok.Cleanup;\n+import org.apache.pulsar.common.util.SimpleTextOutputStream;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+@Test(groups = \"broker-isolated\")\n+public class PrometheusMetricsGeneratorWithNoUnsafeTest {\n+\n+    @BeforeClass\n+    static void setup() {\n+        System.setProperty(\"io.netty.noUnsafe\", \"true\");\n+    }\n+\n+    @Test\n+    public void testWriteStringWithNoUnsafe() {\n+        assertFalse(PlatformDependent.hasUnsafe());\n+        @Cleanup\n+        PrometheusMetricsGenerator generator = new PrometheusMetricsGenerator(null, false, false, false, false,\n+            Clock.systemUTC());\n+        @Cleanup(\"release\")\n+        ByteBuf buf = generator.allocateMultipartCompositeDirectBuffer();\n+        for (int i = 0; i < 2; i++) {\n+            buf.writeBytes(new byte[1024 * 1024]);\n+        }\n+        SimpleTextOutputStream outputStream = new SimpleTextOutputStream(buf);\n+        outputStream.write(\"test\");\n+    }\n+}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23585",
    "pr_id": 23585,
    "issue_id": 23475,
    "repo": "apache/pulsar",
    "problem_statement": "pulsar-perf tool constant print WARNING: Failed to export metrics\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\n`pulsar-perf` is constant print warning message every minute during running perf testing, IMO, it's reasonable to disable openTelemetry by default in pulsar-perf tool.\r\n```\r\nOct 17, 2024 8:17:26 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\nWARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to localhost/127.0.0.1:4317\r\n...\r\nOct 17, 2024 8:18:26 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\nWARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to localhost/127.0.0.1:4317\r\n```\r\n\r\n### Solution\r\n\r\n_No response_\r\n\r\n### Alternatives\r\n\r\nWorkaround:\r\n\r\n`export OTEL_SDK_DISABLED=true` before start pulsar-perf script.\r\n\r\nAccording https://opentelemetry.io/docs/languages/java/configuration/#properties-general\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 172,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java"
    ],
    "pr_changed_test_files": [
      "pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java"
    ],
    "base_commit": "3e108da4f136e9c0013c8030e496d00ea94bfd2c",
    "head_commit": "55b8b364a55de2cc9a5274a261748610c5ceba4e",
    "repo_url": "https://github.com/apache/pulsar/pull/23585",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23585",
    "dockerfile": "",
    "pr_merged_at": "2024-11-27T20:34:07.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java b/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java\nindex 6bf73e705d16c..1e2f6231c6ed9 100644\n--- a/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java\n+++ b/pulsar-testclient/src/main/java/org/apache/pulsar/testclient/PerfClientUtils.java\n@@ -21,6 +21,7 @@\n import static org.apache.commons.lang3.StringUtils.isNotBlank;\n import io.opentelemetry.sdk.autoconfigure.AutoConfiguredOpenTelemetrySdk;\n import java.lang.management.ManagementFactory;\n+import java.util.Map;\n import java.util.Objects;\n import java.util.concurrent.TimeUnit;\n import java.util.function.Consumer;\n@@ -79,6 +80,9 @@ public static ClientBuilder createClientBuilderFromArguments(PerformanceBaseArgu\n                 .maxLookupRequests(arguments.maxLookupRequest)\n                 .proxyServiceUrl(arguments.proxyServiceURL, arguments.proxyProtocol)\n                 .openTelemetry(AutoConfiguredOpenTelemetrySdk.builder()\n+                        .addPropertiesSupplier(() -> Map.of(\n+                                \"otel.sdk.disabled\", \"true\"\n+                        ))\n                         .build().getOpenTelemetrySdk());\n \n         if (isNotBlank(arguments.authPluginClassName)) {\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23566",
    "pr_id": 23566,
    "issue_id": 23457,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: SchemaServiceTest.testSchemaRegistryMetrics\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11328656119/job/31502934109?pr=23442#step:11:1338\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 30, Failures: 1, Errors: 0, Skipped: 17, Time elapsed: 59.073 s <<< FAILURE! - in org.apache.pulsar.broker.service.schema.SchemaServiceTest\r\n  Error:  org.apache.pulsar.broker.service.schema.SchemaServiceTest.testSchemaRegistryMetrics  Time elapsed: 0.053 s  <<< FAILURE!\r\n  java.lang.AssertionError: expected [tenant/ns] but found [public/ns_73b1a31afce34671a5ddc48fe5ad7fc8]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:655)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:665)\r\n  \tat org.apache.pulsar.broker.service.schema.SchemaServiceTest.testSchemaRegistryMetrics(SchemaServiceTest.java:184)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 281,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java"
    ],
    "base_commit": "c4ee362f7e97b91549b7b13224315fe758b6e1b6",
    "head_commit": "e12ea92708ce80a576d8b96751eb86a39597f784",
    "repo_url": "https://github.com/apache/pulsar/pull/23566",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23566",
    "dockerfile": "",
    "pr_merged_at": "2024-11-06T11:41:32.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java\nindex 658ea268c644c..7e8aa72338024 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/schema/SchemaServiceTest.java\n@@ -180,22 +180,22 @@ public void testSchemaRegistryMetrics() throws Exception {\n         Assert.assertEquals(putMetrics.size(), 0);\n \n         Collection<Metric> deleteLatency = metrics.get(\"pulsar_schema_del_ops_latency_count\");\n-        for (Metric metric : deleteLatency) {\n+        assertThat(deleteLatency).anySatisfy(metric -> {\n             Assert.assertEquals(metric.tags.get(\"namespace\"), namespace);\n             Assert.assertTrue(metric.value > 0);\n-        }\n+        });\n \n         Collection<Metric> getLatency = metrics.get(\"pulsar_schema_get_ops_latency_count\");\n-        for (Metric metric : getLatency) {\n+        assertThat(getLatency).anySatisfy(metric -> {\n             Assert.assertEquals(metric.tags.get(\"namespace\"), namespace);\n             Assert.assertTrue(metric.value > 0);\n-        }\n+        });\n \n         Collection<Metric> putLatency = metrics.get(\"pulsar_schema_put_ops_latency_count\");\n-        for (Metric metric : putLatency) {\n+        assertThat(putLatency).anySatisfy(metric -> {\n             Assert.assertEquals(metric.tags.get(\"namespace\"), namespace);\n             Assert.assertTrue(metric.value > 0);\n-        }\n+        });\n     }\n \n     @Test\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23552",
    "pr_id": 23552,
    "issue_id": 23542,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: DeadLetterTopicTest.testDeadLetterTopicWithInitialSubscriptionAndMultiConsumers\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11631141771/job/32391999818?pr=23540#step:11:1029\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 39, Failures: 1, Errors: 0, Skipped: 29, Time elapsed: 128.442 s <<< FAILURE! - in org.apache.pulsar.client.api.DeadLetterTopicTest\r\n  Error:  org.apache.pulsar.client.api.DeadLetterTopicTest.testDeadLetterTopicWithInitialSubscriptionAndMultiConsumers  Time elapsed: 8.041 s  <<< FAILURE!\r\n  java.lang.AssertionError: expected [2] but found [1]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n  \tat org.apache.pulsar.client.api.DeadLetterTopicTest.testDeadLetterTopicWithInitialSubscriptionAndMultiConsumers(DeadLetterTopicTest.java:1055)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 284,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java"
    ],
    "base_commit": "570cb443eb220135861abf9e9de34ae65e5cdaaa",
    "head_commit": "e7dfcbf6bf2dc64b168389e2e31221b681c391dc",
    "repo_url": "https://github.com/apache/pulsar/pull/23552",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23552",
    "dockerfile": "",
    "pr_merged_at": "2024-11-06T12:56:57.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\nindex f5a74dcd1661b..7d34ce33e0a7f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DeadLetterTopicTest.java\n@@ -1010,7 +1010,7 @@ public void testDeadLetterTopicWithInitialSubscriptionAndMultiConsumers() throws\n                         .maxRedeliverCount(maxRedeliveryCount)\n                         .initialSubscriptionName(dlqInitialSub)\n                         .build())\n-                .receiverQueueSize(100)\n+                .receiverQueueSize(20)\n                 .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n                 .subscribe();\n \n@@ -1023,7 +1023,7 @@ public void testDeadLetterTopicWithInitialSubscriptionAndMultiConsumers() throws\n                         .maxRedeliverCount(maxRedeliveryCount)\n                         .initialSubscriptionName(dlqInitialSub)\n                         .build())\n-                .receiverQueueSize(100)\n+                .receiverQueueSize(20)\n                 .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n                 .subscribe();\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23548",
    "pr_id": 23548,
    "issue_id": 23547,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] package upload will timeout when the package size is big\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nuse the apachepulsar/pulsar:4.0.0 image, image index digest is: sha256:51e92bc45ba495b9753585b12625579ddaeea8e02d08aecd336ceff26e1099f1\r\n\r\n### Minimal reproduce step\r\n\r\n1. deploy pulsar using docker-compose, below is the compose yaml:\r\n\r\n```yaml\r\nversion: '3'\r\nnetworks:\r\n  pulsar:\r\n    driver: bridge\r\nservices:\r\n  # Start zookeeper\r\n  zookeeper:\r\n    image: apachepulsar/pulsar:4.0.0\r\n    container_name: zookeeper\r\n    restart: on-failure\r\n    networks:\r\n      - pulsar\r\n    volumes:\r\n      - ./data/zookeeper:/pulsar/data/zookeeper\r\n    environment:\r\n      - metadataStoreUrl=zk:zookeeper:2181\r\n      - PULSAR_MEM=-Xms256m -Xmx256m -XX:MaxDirectMemorySize=256m\r\n    command: >\r\n      bash -c \"bin/apply-config-from-env.py conf/zookeeper.conf && \\\r\n             bin/generate-zookeeper-config.sh conf/zookeeper.conf && \\\r\n             exec bin/pulsar zookeeper\"\r\n    healthcheck:\r\n      test: [\"CMD\", \"bin/pulsar-zookeeper-ruok.sh\"]\r\n      interval: 10s\r\n      timeout: 5s\r\n      retries: 30\r\n\r\n  # Init cluster metadata\r\n  pulsar-init:\r\n    container_name: pulsar-init\r\n    hostname: pulsar-init\r\n    image: apachepulsar/pulsar:4.0.0\r\n    networks:\r\n      - pulsar\r\n    command: >\r\n      bin/pulsar initialize-cluster-metadata --cluster cluster-a --zookeeper zookeeper:2181 --configuration-store zookeeper:2181 --web-service-url http://broker:8080 --broker-service-url pulsar://broker:6650\r\n    depends_on:\r\n      zookeeper:\r\n        condition: service_healthy\r\n\r\n  # Start bookie\r\n  bookie:\r\n    image: apachepulsar/pulsar:4.0.0\r\n    container_name: bookie\r\n    restart: on-failure\r\n    networks:\r\n      - pulsar\r\n    environment:\r\n      - clusterName=cluster-a\r\n      - zkServers=zookeeper:2181\r\n      - metadataServiceUri=metadata-store:zk:zookeeper:2181\r\n      # otherwise every time we run docker compose uo or down we fail to start due to Cookie\r\n      # See: https://github.com/apache/bookkeeper/blob/405e72acf42bb1104296447ea8840d805094c787/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Cookie.java#L57-68\r\n      - advertisedAddress=bookie\r\n      - BOOKIE_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m\r\n    depends_on:\r\n      zookeeper:\r\n        condition: service_healthy\r\n      pulsar-init:\r\n        condition: service_completed_successfully\r\n    # Map the local directory to the container to avoid bookie startup failure due to insufficient container disks.\r\n    volumes:\r\n      - ./data/bookkeeper:/pulsar/data/bookkeeper\r\n    command: bash -c \"bin/apply-config-from-env.py conf/bookkeeper.conf && exec bin/pulsar bookie\"\r\n\r\n  # Start broker\r\n  broker:\r\n    image: apachepulsar/pulsar:4.0.0\r\n    container_name: broker\r\n    hostname: broker\r\n    restart: on-failure\r\n    networks:\r\n      - pulsar\r\n    environment:\r\n      - metadataStoreUrl=zk:zookeeper:2181\r\n      - zookeeperServers=zookeeper:2181\r\n      - clusterName=cluster-a\r\n      - managedLedgerDefaultEnsembleSize=1\r\n      - managedLedgerDefaultWriteQuorum=1\r\n      - managedLedgerDefaultAckQuorum=1\r\n      - advertisedAddress=broker\r\n      - advertisedListeners=external:pulsar://127.0.0.1:6650\r\n      - enablePackagesManagement=true\r\n      - PULSAR_MEM=-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m\r\n    depends_on:\r\n      zookeeper:\r\n        condition: service_healthy\r\n      bookie:\r\n        condition: service_started\r\n    ports:\r\n      - \"6650:6650\"\r\n      - \"8080:8080\"\r\n    command: bash -c \"bin/apply-config-from-env.py conf/broker.conf && exec bin/pulsar broker\"\r\n```\r\n2. generate a 500MB file:\r\n```\r\ndd if=/dev/zero of=500MB_file bs=1M count=500\r\n```\r\n\r\n3. upload this file to package service:\r\n```\r\nazureuser@dev-machie:~/pulsar$ ./bin/pulsar-admin packages upload --path ~/500MB_file --description \"testing\" function://public/default/test500\r\n```\r\n\r\n### What did you expect to see?\r\n\r\n```\r\nThe package 'function://public/default/test500' uploaded from path '/home/azureuser/500MB_file' successfully\r\n```\r\n\r\n### What did you see instead?\r\n\r\n```\r\nnull\r\nReason: java.util.concurrent.CompletionException: java.util.concurrent.TimeoutException: Read timeout to localhost/127.0.0.1:8080 after 60000 ms\r\n```\r\n\r\n### Anything else?\r\n\r\nThe reason is that the `DLOutputStream` will read 8192 bytes each time, and write them to bk, so for a 500 MB file, it will write:\r\n\r\n500 * 1024 * 1024 / 8192.0 = 64000.0 times\r\n\r\nwhich leads to timeout\r\n\r\nThis error also happened in branch-3.0 and 3.3\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 574,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-package-management/bookkeeper-storage/src/main/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStream.java",
      "pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java"
    ],
    "base_commit": "570cb443eb220135861abf9e9de34ae65e5cdaaa",
    "head_commit": "01c962933b96e89faf70010ceb8271489c194b38",
    "repo_url": "https://github.com/apache/pulsar/pull/23548",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23548",
    "dockerfile": "",
    "pr_merged_at": "2024-11-05T00:19:23.000Z",
    "patch": "diff --git a/pulsar-package-management/bookkeeper-storage/src/main/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStream.java b/pulsar-package-management/bookkeeper-storage/src/main/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStream.java\nindex 67345ebd47e31..f446961c1d8fe 100644\n--- a/pulsar-package-management/bookkeeper-storage/src/main/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStream.java\n+++ b/pulsar-package-management/bookkeeper-storage/src/main/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStream.java\n@@ -36,7 +36,16 @@ class DLOutputStream {\n \n     private final DistributedLogManager distributedLogManager;\n     private final AsyncLogWriter writer;\n-    private final byte[] readBuffer = new byte[8192];\n+    /*\n+     * The LogRecord structure is:\n+     * -------------------\n+     * Bytes 0 - 7                      : Metadata (Long)\n+     * Bytes 8 - 15                     : TxId (Long)\n+     * Bytes 16 - 19                    : Payload length (Integer)\n+     * Bytes 20 - 20+payload.length-1   : Payload (Byte[])\n+     * So the max buffer size should be LogRecord.MAX_LOGRECORD_SIZE - 2 * (Long.SIZE / 8) - Integer.SIZE / 8\n+     */\n+    private final byte[] readBuffer = new byte[LogRecord.MAX_LOGRECORD_SIZE - 2 * (Long.SIZE / 8) - Integer.SIZE / 8];\n     private long offset = 0L;\n \n     private DLOutputStream(DistributedLogManager distributedLogManager, AsyncLogWriter writer) {\n@@ -51,9 +60,9 @@ static CompletableFuture<DLOutputStream> openWriterAsync(DistributedLogManager d\n \n     private void writeAsyncHelper(InputStream is, CompletableFuture<DLOutputStream> result) {\n         try {\n-            int read = is.read(readBuffer);\n-            if (read != -1) {\n-                log.info(\"write something into the ledgers offset: {}, length: {}\", offset, read);\n+            int read = is.readNBytes(readBuffer, 0, readBuffer.length);\n+            if (read > 0) {\n+                log.debug(\"write something into the ledgers offset: {}, length: {}\", offset, read);\n                 final ByteBuf writeBuf = Unpooled.wrappedBuffer(readBuffer, 0, read);\n                 offset += writeBuf.readableBytes();\n                 final LogRecord record = new LogRecord(offset, writeBuf);\n",
    "test_patch": "diff --git a/pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java b/pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java\nindex b55e0e0d34a4f..235cb4fefc0c3 100644\n--- a/pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java\n+++ b/pulsar-package-management/bookkeeper-storage/src/test/java/org/apache/pulsar/packages/management/storage/bookkeeper/DLOutputStreamTest.java\n@@ -99,7 +99,7 @@ public void writeBytesArrayData() throws ExecutionException, InterruptedExceptio\n \n     @Test\n     public void writeLongBytesArrayData() throws ExecutionException, InterruptedException {\n-        byte[] data = new byte[8192 * 3 + 4096];\n+        byte[] data = new byte[1040364 * 3 + 4096];\n         DLOutputStream.openWriterAsync(dlm)\n                 .thenCompose(w -> w.writeAsync(new ByteArrayInputStream(data))\n                         .thenCompose(DLOutputStream::closeAsync)).get();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23546",
    "pr_id": 23546,
    "issue_id": 23485,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: SimpleProducerConsumerTest.testMultiTopicsConsumerImplPauseForManualSubscription\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11407423480/job/31743771210?pr=23484#step:11:1686\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 294, Failures: 1, Errors: 0, Skipped: 231, Time elapsed: 352.306 s <<< FAILURE! - in org.apache.pulsar.client.api.SimpleProducerConsumerTest\r\n  Error:  org.apache.pulsar.client.api.SimpleProducerConsumerTest.testMultiTopicsConsumerImplPauseForManualSubscription  Time elapsed: 10.489 s  <<< FAILURE!\r\n  java.lang.AssertionError: expected [30] but found [29]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n  \tat org.apache.pulsar.client.api.SimpleProducerConsumerTest.testMultiTopicsConsumerImplPauseForManualSubscription(SimpleProducerConsumerTest.java:3580)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 284,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java"
    ],
    "base_commit": "570cb443eb220135861abf9e9de34ae65e5cdaaa",
    "head_commit": "2cd1dfbf1ff97f0dd99dd2044d4f2c6893e4cf5b",
    "repo_url": "https://github.com/apache/pulsar/pull/23546",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23546",
    "dockerfile": "",
    "pr_merged_at": "2024-11-06T03:24:08.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\nindex a867dc0cd3562..e99abac1ec40f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n@@ -3520,7 +3520,7 @@ public void testMultiTopicsConsumerImplPauseForManualSubscription() throws Excep\n             producer3.send(message.getBytes(UTF_8));\n         }\n \n-        int receiverQueueSize = 1;\n+        int receiverQueueSize = 6;\n         Consumer<byte[]> consumer = pulsarClient\n             .newConsumer()\n             .topics(Lists.newArrayList(topicNameBase + \"1\", topicNameBase + \"2\"))\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23534",
    "pr_id": 23534,
    "issue_id": 16551,
    "repo": "apache/pulsar",
    "problem_statement": "PIP-188: Cluster migration or Blue-Green cluster deployment support in Pulsar\n# Motivation\r\n\r\nCluster migration or Blue-Green cluster deployment is one of the proven solutions to migrate live traffic from one cluster to another. One of the examples is applications running on Kubernetes sometimes require a Kubernetes cluster upgrade which can cause downtime for the entire application during a Kubernetes cluster upgrade. Blue-green deployment is an application release model that gradually transfers user traffic from a previous version of an app or microservice to a nearly identical new releaseboth of which are running in production. \r\n \r\nThe old version can be called the blue environment while the new version can be known as the green environment. Once production traffic is fully transferred from blue to green, blue can standby in case of rollback or be pulled from production and updated to become the template upon which the next update is made.\r\n \r\nWe need such capability in Apache pulsar to migrate live traffic from the blue cluster to the green cluster so, eventually, the entire traffic moves from the blue cluster to the green cluster without causing downtime for the topics.\r\n\r\n# Goal\r\n\r\nThis PIP adds support to migrate and redirect the blue clusters traffic to the green cluster. Therefore, the Broker will support admin-API using which admin-user can mark migrate cluster along with redirection URLs where traffic should be redirected. Broker persists migration state and new redirected clusters URL as part of cluster metadata.\r\n\r\nOnce the cluster is marked as migrating, the broker asynchronously marks each topic owned by that broker as migrated by calling the  new managed-ledger API `asyncMigrate()`. Once, the topic is marked as migrated, broker notifies all the producers and consumers (which have drained the backlog for their subscriptions) with a new client-protocol command called Migrated-Topic which has redirection URLs to the green cluster. Producers and consumers for those topics cache the redirection URLs and retry to connect to the broker with that URL which redirects them to the green cluster. \r\n\r\nBroker can redirect only those consumers which have reached to end of a terminated topic or create a new subscription in the blue cluster. Therefore, the broker can determine the redirection of consumers in the consumer-creation phase and the pulsar client has to handle redirection after sending producer/consumer creation requests. \r\n\r\nBroker will unsubscribe the subscription once that subscription reaches end of topic and broker will also not allow creation of any new producer or subscription for the topics. Therefore, eventually, all the topics in the blue cluster will not have a subscription or producer attached and eventually, those topics will be deleted by the garbage collector. \r\n\r\nBroker marks the cluster state as migration-completed once all the topics are deleted and that cluster will not allow any new topic creation.\r\n\r\n# Broker/Client changes\r\n\r\n## Topic termination\r\nThis PIP depends on the recently added broker's feature to **terminate topic**. In case, if any user decides to terminate the topic then it can be done using admin API. Once, broker receives request to terminate the topic, broker \r\n1. Marks ledger with state : `Terminated` and doesn't allow any new writes on that managed-ledger.\r\n2. Broker immediately disconnects all the producers on that topic and fails new producer creation with error: `TopicTerminatedError`\r\n3. Broker allows dispatching messages for all types of subscriptions until they reach to end-of-topic. The broker sends end-of-topic message to all consumers as soon as that subscription reads and ack all messages on that topic.\r\n\r\nMigration of topic will have enhancement on top of topic-termination feature where migration process will \r\n1. first terminate the topic along with marking migration flag on managed-ledger.\r\n2. Instead of sending `TopicTerminatedError` error to the producer, the broker sends migration-response to producer so, producer can handle migration-response and manage redirection to the new cluster. We will discuss this step in detail in next section.\r\n3. Broker will continue dispatching messages to subscribers until they reach to end of the topic. Once, the subscriber reaches the end of topic, the broker will send a migration response to the consumer for further redirection.\r\n\r\n## Managed-Ledger Changes\r\n\r\nThis PIP will add API to managed-ledger to change ManagedLedger state as migrated. This API will terminate the topic and persist the status of managed-ledger as migrated. Broker triggers migrate API of managed-ledger once cluster becomes the blue cluster and traffic should redirect to the green cluster.\r\n\r\n1. Mark topic/ledger migration state\r\n```\r\nManagedLedger.java\r\n\r\nCompletableFuture<Position> asyncMigrate();\r\n```\r\n\r\n2. Persist topic/ledger migrated state\r\n\r\nIt will be persisted as a part of `ManagedLedgerInfo::properties` so, broker can recover migrated topic/ledger upon broker restart.\r\n\r\n\r\n## Broker changes\r\n\r\n\r\n\r\n#### 1. Broker provides pulsar-admin API to mark the cluster in migration state.\r\n\r\n**Pulsar Admin Change**\r\n```\r\npulsar-admin clusters set-cluster-migrated \\\r\nbrokerServiceUrl <> \\\r\nbrokerServiceUrlTls <>\r\n```\r\n\r\n#### 2. Broker stores cluster migration state and redirection urls in cluster-metadata.\r\n\r\nPulsar stores each regions url metadata into global zookeeper or configuration metadata store as a cluster metadata for that region where each clusters metadata stores that regions broker service urls. During the migration of a given blue region to its appropriate green region, blue region needs to store the migration-state flag and then appropriate green regions cluster metadata URL where blue region can redirect the traffic.\r\nBoth blue and green regions can share the same configuration metadata store or global zookeeper and the migration state of a blue region is attached to that blue region only. Therefore, blue region must store migration state and redirection url metadata locally in a local metadata store as this metadata configuration is only applicable to the blue region and not to be shared with green region.\r\nTherefore, pulsar broker will store the migration policies for the blue cluster at local metadata-store at path: `/admin/<cluster-name>/policies` and it will store below migration metadata info in that cluster policies.\r\n\r\n\r\n**Cluster-metadata change**\r\n```\r\nClusterPolicies.java\r\n\r\nboolean migrated;\r\nClusterUrl migratedClusterUrl;\r\n\r\n\r\nclass ClusterUrl {\r\n        String brokerServiceUrl;\r\n        String brokerServiceUrlTls;\r\n}\r\n```\r\n\r\n#### 3. Support migration per namespace level\r\n\r\nSometimes, we would like to start migration namespace by namespace, and admin requires a namespace level control for the migration so, it can start and test migration setup first with specific namespaces. Therefore, Pulsar should also allow controlling migration at the namespace level and Pulsar should provide admin API to enable migration for specific namespace. Pulsar broker will persist migration enable flag into namespace local policies. Therefore, the Pulsar broker will provide API to update and retrieve the namespace migration state.\r\n\r\n`Namespaces.java`\r\n\r\n```\r\nvoid updateMigrationState(String namespace, boolean migrated) throws PulsarAdminException;\r\n```\r\n\r\n#### 4. Show topic migration state into stats for monitoring\r\n\r\nIts really important to monitor the migration process and progress during blue-green cluster migration. Therefore, Pulsar will have a migration flag into existing topic stats so, we can monitor the migration state for each topic.\r\n\r\n\r\n#### 5. Broker runs periodic task to check cluster migration state and moves topic into migration state by calling managed-ledgers migration-api.\r\n\r\n```\r\nServiceConfiguration.java\r\n\r\nprivate long clusterMigrationCheckDurationSeconds = 0; //disable task with default value=0\r\n\r\n```\r\n\r\n#### 6. The broker sends topic migration message to client so, producer/consumer at client side can handle redirection accordingly.\r\n\r\n```\r\nPulsarApi.proto\r\n\r\nmessage CommandTopicMigrated {\r\n    enum ResourceType {\r\n        Producer = 0;\r\n        Consumer = 1;\r\n    }\r\n    required uint64 resource_id = 1;\r\n    required ResourceType resource_type = 2;\r\n    optional string brokerServiceUrl      = 2;\r\n    optional string brokerServiceUrlTls   = 3;    \r\n}\r\n\r\n```\r\n\r\n#### 7. Avoid data loss at green cluster with new incoming traffic by creating pulsar resources into green cluster\r\nOnce, topic is marked as migrated, broker will start redirecting producers to new cluster to publish new messages but if consumers are not yet redirected then messages at green cluster can be lost. Therefore, we can apply default retention policy at Green cluster until blue cluster is migrated. So, Green cluster will retain the messages until blue cluster is completely migrated to green cluster but that can make green cluster store large amount of retention data which might go beyond storage capacity of green cluster.\r\nTherefore, another option is to allow blue broker to create necessary resources of a topic such as tenant, namespace and list of existing subscription in a green cluster before starting migration and green cluster will persist newly published data until all consumers successfully migrated to green cluster and start catching up with the published messages.\r\n\r\n\r\n#### 8. Check client support before starting migration\r\n\r\nIn ordered to achieve cluster migration, all clients need to be upgraded to the version which handles cluster migration redirection. So, Broker can't complete migration if clients are not upgrade to the supported version. Therefore, it's really important to find out if any unsupported client is connected or don't allow any unsupported client to connect if we want to start the cluster migration process. Therefore, we will add a flag to allow the broker to reject all client connections which are initiated from unsupported clients. The broker will not allow connection from clients which don't support cluster migration redirection handling if the `clientMinVersionAllowed` broker flag is enabled.\r\n\r\n\r\n#### 9. Clean up topic resources once topic migration is completed\r\n\r\nOnce topic is successfully migrated from blue cluster to green cluster, brokers in a blue cluster should unsubscribe all subscription and garbage collector should be able to delete that topic successfully. Once, all the topics are migrated successfully to the green cluster, blue cluster will not have any single topic exist into the cluster which shows that blue green cluster migration is successfully finished. However, Pulsar broker should also makes sure that topic must not be recreated after migrating to green cluster successfully.\r\n\r\n\r\n### Replicator and message ordering handling\r\n\r\n**A. Incoming replication messages from other region's replicator producers to Blue cluster**\r\nThis will not impact ordering messages coming from the other regions to blue/green cluster. After marking blue cluster, blue cluster will reject replication writes from remote regions and redirects remote producers to the Green cluster where new messages will be written. Consumers of Blue clusters will only be redirected to green once they received all messages from blue. So, migration gives an ordering guarantee for messages replicating from remote regions.\r\n\r\n**B. Outgoing replication messages from Blue cluster's replicator producers to other regions**\r\nThe broker can give an ordering guarantee in this case with the trade-off of topic unavailability until the blue cluster replicates all existing published messages in the blue cluster before the topic gets terminated.\r\n1. Blue cluster marks topic terminated and migrated\r\n2. Topic will not redirect producers/consumers until all the replicators reaches end of topic and replicates all messages to remote regions. Topic will send `TOPIC_UNAVAILABLE` message to producers/consumers so, they can keep retrying until replicators reach to end of topics.\r\n3. Broker disconnects all the replicators and delete them once they reach end of topic.\r\n4. Broker start sending migrated-command to producer/consumers to redirect clients to green cluster.\r\n\r\n\r\n## Client Changes\r\nOnce producers and consumers receive the Migrated-Topic command with a list of redirect URLs, they will cache those URLs and try to reconnect with a broker by using those URLs. The client will add handling of the `CommandMigratedTopic`  protocol. \r\n\r\n## PIP supported feature\r\n1. Publish ordering guarantee\r\n2. Consumer ordering guarantee\r\n3. Incoming replicator ordering guarantee\r\n4. Outgoing replicator ordering guarantee with the topic unavailability tradeoff \r\n5. Auto resource creation (tenant, namespace, partitioned-topic, subscriptions) in a green cluster\r\n6. Auto topic deletion after migration successfully completed for a topic\r\n7. Enable migration at cluster level or per namespace level\r\n8. Stats to show topic's migration state ",
    "issue_word_count": 1932,
    "test_files_count": 1,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java"
    ],
    "base_commit": "f196e2c2e168b9a7a9550f69555ccf6af6369f3c",
    "head_commit": "78fc7fe896330d326584adc094b748c94b1f9dc4",
    "repo_url": "https://github.com/apache/pulsar/pull/23534",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23534",
    "dockerfile": "",
    "pr_merged_at": "2024-11-01T10:47:17.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\nindex 11f00fb28e34b..96ea2004be8d7 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\n@@ -1363,8 +1363,8 @@ public static CompletableFuture<Optional<ClusterUrl>> getMigratedClusterUrlAsync\n                 .getClusterPoliciesAsync(pulsar.getConfig().getClusterName())\n                 .thenCombine(isNamespaceMigrationEnabledAsync(pulsar, topic),\n                         ((clusterData, isNamespaceMigrationEnabled) -> {\n-                            Optional<ClusterUrl> url = ((clusterData.isPresent() && clusterData.get().isMigrated())\n-                                    || isNamespaceMigrationEnabled)\n+                            Optional<ClusterUrl> url = (clusterData.isPresent() && (clusterData.get().isMigrated()\n+                                    || isNamespaceMigrationEnabled))\n                                             ? Optional.ofNullable(clusterData.get().getMigratedClusterUrl())\n                                             : Optional.empty();\n                             return url;\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java\nindex 24163c631ffe9..35c41455e8987 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java\n@@ -710,9 +710,12 @@ protected void handleReachedEndOfTopic(CommandReachedEndOfTopic commandReachedEn\n     @Override\n     protected void handleTopicMigrated(CommandTopicMigrated commandTopicMigrated) {\n         final long resourceId = commandTopicMigrated.getResourceId();\n-        final String serviceUrl = commandTopicMigrated.getBrokerServiceUrl();\n-        final String serviceUrlTls = commandTopicMigrated.getBrokerServiceUrlTls();\n-\n+        final String serviceUrl = commandTopicMigrated.hasBrokerServiceUrl()\n+                ? commandTopicMigrated.getBrokerServiceUrl()\n+                : null;\n+        final String serviceUrlTls = commandTopicMigrated.hasBrokerServiceUrlTls()\n+                ? commandTopicMigrated.getBrokerServiceUrlTls()\n+                : null;\n         HandlerState resource = commandTopicMigrated.getResourceType() == ResourceType.Producer\n                 ? producers.get(resourceId)\n                 : consumers.get(resourceId);\n\ndiff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java b/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\nindex 8635368f00f0b..19aa9907549d9 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\n@@ -88,6 +88,7 @@\n import org.apache.pulsar.common.api.proto.CommandSubscribe.InitialPosition;\n import org.apache.pulsar.common.api.proto.CommandSubscribe.SubType;\n import org.apache.pulsar.common.api.proto.CommandTcClientConnectResponse;\n+import org.apache.pulsar.common.api.proto.CommandTopicMigrated;\n import org.apache.pulsar.common.api.proto.CommandTopicMigrated.ResourceType;\n import org.apache.pulsar.common.api.proto.FeatureFlags;\n import org.apache.pulsar.common.api.proto.IntRange;\n@@ -768,11 +769,14 @@ public static ByteBuf newReachedEndOfTopic(long consumerId) {\n \n     public static ByteBuf newTopicMigrated(ResourceType type, long resourceId, String brokerUrl, String brokerUrlTls) {\n         BaseCommand cmd = localCmd(Type.TOPIC_MIGRATED);\n-        cmd.setTopicMigrated()\n-            .setResourceType(type)\n-            .setResourceId(resourceId)\n-            .setBrokerServiceUrl(brokerUrl)\n-            .setBrokerServiceUrlTls(brokerUrlTls);\n+        CommandTopicMigrated migratedCmd = cmd.setTopicMigrated();\n+        migratedCmd.setResourceType(type).setResourceId(resourceId);\n+        if (StringUtils.isNotBlank(brokerUrl)) {\n+            migratedCmd.setBrokerServiceUrl(brokerUrl);\n+        }\n+        if (StringUtils.isNotBlank(brokerUrlTls)) {\n+            migratedCmd.setBrokerServiceUrlTls(brokerUrlTls);\n+        }\n         return serializeWithSize(cmd);\n     }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\nindex e56a3495600f0..e6a7d049366e4 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\n@@ -297,7 +297,7 @@ public void testClusterMigration() throws Exception {\n         assertFalse(topic2.getProducers().isEmpty());\n \n         ClusterUrl migratedUrl = new ClusterUrl(pulsar2.getWebServiceAddress(), pulsar2.getWebServiceAddressTls(),\n-                pulsar2.getBrokerServiceUrl(), pulsar2.getBrokerServiceUrlTls());\n+                pulsar2.getBrokerServiceUrl(), null);\n         admin1.clusters().updateClusterMigration(\"r1\", true, migratedUrl);\n         assertEquals(admin1.clusters().getClusterMigration(\"r1\").getMigratedClusterUrl(), migratedUrl);\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23522",
    "pr_id": 23522,
    "issue_id": 23474,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BadVersionExceptions in OneWayReplicatorUsingGlobalZKTest.cleanup \n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Example failure\r\n\r\nhttps://github.com/apache/pulsar/actions/runs/11368523712/job/31653376302?pr=23468#step:11:2008\r\n\r\nLogs: https://gist.github.com/lhotari/02be1e0d55026ca51730e6d932dfe1bc\r\n\r\n### Additional context\r\n\r\nThis seems to block all Pulsar CI PR build jobs from completing successfully at the moment (Thu Oct 17 09:26:11 UTC 2024).\r\n\r\n### Exception stacktrace\r\n\r\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Failures: \r\n  Error:    OneWayReplicatorUsingGlobalZKTest.cleanup  TestNGRuntime org.apache.pulsar.client.admin.PulsarAdminException$ServerSideErrorException: \r\n   --- An unexpected error occurred in the server ---\r\n  \r\n  Message: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n  \r\n  Stacktrace:\r\n  \r\n  org.apache.pulsar.broker.service.BrokerServiceException$PersistenceException: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n  \tat org.apache.pulsar.broker.service.persistent.PersistentTopic$6.deleteLedgerFailed(PersistentTopic.java:1546)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.lambda$asyncDelete$35(ManagedLedgerImpl.java:2978)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.lambda$asyncTruncate$58(ManagedLedgerImpl.java:4372)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:990)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:974)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl$26.clearBacklogFailed(ManagedLedgerImpl.java:4363)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$16.markDeleteFailed(ManagedCursorImpl.java:1767)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$28.operationFailed(ManagedCursorImpl.java:2940)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$31.lambda$operationFailed$0(ManagedCursorImpl.java:3317)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniRun.tryFire(CompletableFuture.java:787)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl.lambda$deleteLedgerAsync$39(ManagedCursorImpl.java:3051)\r\n  \tat org.apache.bookkeeper.client.LedgerDeleteOp.lambda$initiate$0(LedgerDeleteOp.java:86)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:482)\r\n  \tat org.apache.bookkeeper.common.util.SingleThreadExecutor.safeRunTask(SingleThreadExecutor.java:137)\r\n  \tat org.apache.bookkeeper.common.util.SingleThreadExecutor.run(SingleThreadExecutor.java:113)\r\n  \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  Caused by: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n```\r\n\r\n```\r\n2024-10-17T04:15:33,865 - INFO  - [broker-topic-workers-OrderedExecutor-2-0:AbstractMetadataStore] - Deleting path: /ledgers/00/0000/L0032 (v. Optional.empty)\r\n2024-10-17T04:15:33,865 - WARN  - [bookkeeper-ml-scheduler-OrderedScheduler-3-0:ManagedLedgerImpl] - [public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a] Failed to delete managed ledger\r\norg.apache.bookkeeper.mledger.ManagedLedgerException$MetaStoreException: java.util.concurrent.CompletionException: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\nCaused by: java.util.concurrent.CompletionException: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture$UniRun.tryFire(CompletableFuture.java:781) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194) ~[?:?]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) [?:?]\r\nCaused by: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:486) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) [?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) [?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) [?:?]\r\nCaused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:117) ~[zookeeper-3.9.2.jar:3.9.2]\r\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:53) ~[zookeeper-3.9.2.jar:3.9.2]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:480) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) ~[?:?]\r\n```\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1199,
    "test_files_count": 5,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/MetaStoreImpl.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java"
    ],
    "base_commit": "ebb3cb5384d188b3c9d6b3fe89c2f66254103bf7",
    "head_commit": "36cc57ff5d4fb02d189686ba368649fe3a402e9b",
    "repo_url": "https://github.com/apache/pulsar/pull/23522",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23522",
    "dockerfile": "",
    "pr_merged_at": "2024-10-29T08:01:58.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/MetaStoreImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/MetaStoreImpl.java\nindex d9269ec83b179..e47443e4e8f95 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/MetaStoreImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/MetaStoreImpl.java\n@@ -398,10 +398,13 @@ private static ManagedLedgerInfo updateMLInfoTimestamp(ManagedLedgerInfo info) {\n     }\n \n     private static MetaStoreException getException(Throwable t) {\n-        if (t.getCause() instanceof MetadataStoreException.BadVersionException) {\n-            return new ManagedLedgerException.BadVersionException(t.getMessage());\n+        Throwable actEx = FutureUtil.unwrapCompletionException(t);\n+        if (actEx instanceof MetadataStoreException.BadVersionException badVersionException) {\n+            return new ManagedLedgerException.BadVersionException(badVersionException);\n+        } else if (actEx instanceof MetaStoreException metaStoreException){\n+            return metaStoreException;\n         } else {\n-            return new MetaStoreException(t);\n+            return new MetaStoreException(actEx);\n         }\n     }\n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\nindex 9c86a99de0f14..541c8a7a225e8 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n@@ -1465,6 +1465,7 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions,\n             this.closeFutures =\n                     new CloseFutures(new CompletableFuture(), new CompletableFuture(), new CompletableFuture());\n \n+            AtomicBoolean alreadyUnFenced = new AtomicBoolean();\n             CompletableFuture<Void> res = getBrokerService().getPulsar().getPulsarResources().getNamespaceResources()\n                         .getPartitionedTopicResources().runWithMarkDeleteAsync(TopicName.get(topic), () -> {\n                 CompletableFuture<Void> deleteFuture = new CompletableFuture<>();\n@@ -1488,6 +1489,7 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions,\n                     }\n                 }).exceptionally(ex -> {\n                     log.error(\"[{}] Error closing clients\", topic, ex);\n+                    alreadyUnFenced.set(true);\n                     unfenceTopicToResume();\n                     closeClientFuture.completeExceptionally(ex);\n                     return null;\n@@ -1503,6 +1505,7 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions,\n                                 .whenComplete((v, ex) -> {\n                                     if (ex != null) {\n                                         log.error(\"[{}] Error deleting topic\", topic, ex);\n+                                        alreadyUnFenced.set(true);\n                                         unfenceTopicToResume();\n                                         deleteFuture.completeExceptionally(ex);\n                                     } else {\n@@ -1512,6 +1515,7 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions,\n                                     FutureUtil.waitForAll(subsDeleteFutures).whenComplete((f, e) -> {\n                                         if (e != null) {\n                                             log.error(\"[{}] Error deleting topic\", topic, e);\n+                                            alreadyUnFenced.set(true);\n                                             unfenceTopicToResume();\n                                             deleteFuture.completeExceptionally(e);\n                                         } else {\n@@ -1542,6 +1546,7 @@ public void deleteLedgerComplete(Object ctx) {\n                                                     } else {\n                                                         log.error(\"[{}] Error deleting topic\",\n                                                                 topic, exception);\n+                                                        alreadyUnFenced.set(true);\n                                                         unfenceTopicToResume();\n                                                         deleteFuture.completeExceptionally(\n                                                                 new PersistenceException(exception));\n@@ -1554,6 +1559,7 @@ public void deleteLedgerComplete(Object ctx) {\n                                 }\n                             });\n                 }).exceptionally(ex->{\n+                    alreadyUnFenced.set(true);\n                     unfenceTopicToResume();\n                     deleteFuture.completeExceptionally(\n                             new TopicBusyException(\"Failed to close clients before deleting topic.\",\n@@ -1565,7 +1571,9 @@ public void deleteLedgerComplete(Object ctx) {\n                 }).whenComplete((value, ex) -> {\n                     if (ex != null) {\n                         log.error(\"[{}] Error deleting topic\", topic, ex);\n-                        unfenceTopicToResume();\n+                        if (!alreadyUnFenced.get()) {\n+                            unfenceTopicToResume();\n+                        }\n                     }\n                 });\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\nindex fb19ed1ddbb6a..b39f8135e0e0c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\n@@ -42,7 +42,6 @@\n import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n-@Test(groups = \"flaky\")\n public class SameAuthParamsLookupAutoClusterFailoverTest extends OneWayReplicatorTestBase {\n \n     public void setup() throws Exception {\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\nindex 0246d16b23d0e..0f8db4aaa7316 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n@@ -44,7 +44,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class DisabledCreateTopicToRemoteClusterForReplicationTest extends OneWayReplicatorTestBase {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\nindex f2631f252ab0f..a8f8d7ecbbd47 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n@@ -104,7 +104,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class OneWayReplicatorTest extends OneWayReplicatorTestBase {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\nindex 827ad78fb26ff..ad877e8f947b7 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\n@@ -44,7 +44,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class OneWayReplicatorUsingGlobalZKTest extends OneWayReplicatorTest {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\nindex 9fe016176990b..bd4a0889c730f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\n@@ -59,7 +59,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class ReplicationTxnTest extends OneWayReplicatorTestBase {\n \n     private boolean transactionBufferSegmentedSnapshotEnabled = false;\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23518",
    "pr_id": 23518,
    "issue_id": 23417,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ManagedCursorTest.testForceCursorRecovery\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11232853373/job/31225793977?pr=23414#step:11:2927\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Tests run: 282, Failures: 1, Errors: 0, Skipped: 202, Time elapsed: 36.683 s <<< FAILURE! - in org.apache.bookkeeper.mledger.impl.ManagedCursorTest\r\n  Error:  org.apache.bookkeeper.mledger.impl.ManagedCursorTest.testForceCursorRecovery  Time elapsed: 0.031 s  <<< FAILURE!\r\n  java.lang.AssertionError: expected [true] but found [false]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertTrue(Assert.java:56)\r\n  \tat org.testng.Assert.assertTrue(Assert.java:66)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorTest.testForceCursorRecovery(ManagedCursorTest.java:4831)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 260,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java"
    ],
    "base_commit": "570cb443eb220135861abf9e9de34ae65e5cdaaa",
    "head_commit": "3dd817f728f02053ee8cbd07b1ce71b67ce971c1",
    "repo_url": "https://github.com/apache/pulsar/pull/23518",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23518",
    "dockerfile": "",
    "pr_merged_at": "2024-11-05T10:16:55.000Z",
    "patch": "",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\nindex 587f87a7d1d38..b4ab673facb26 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n@@ -4828,7 +4828,6 @@ public void operationFailed(ManagedLedgerException exception) {\n \n     @Test\n     void testForceCursorRecovery() throws Exception {\n-        ManagedLedgerFactoryConfig managedLedgerFactoryConfig = new ManagedLedgerFactoryConfig();\n         TestPulsarMockBookKeeper bk = new TestPulsarMockBookKeeper(executor);\n         factory = new ManagedLedgerFactoryImpl(metadataStore, bk);\n         ManagedLedgerConfig config = new ManagedLedgerConfig();\n@@ -4874,8 +4873,9 @@ public void asyncOpenLedger(final long lId, final DigestType digestType, final b\n                 final OpenCallback cb, final Object ctx) {\n             if (ledgerErrors.containsKey(lId)) {\n                 cb.openComplete(ledgerErrors.get(lId), null, ctx);\n+            } else {\n+                super.asyncOpenLedger(lId, digestType, passwd, cb, ctx);\n             }\n-            super.asyncOpenLedger(lId, digestType, passwd, cb, ctx);\n         }\n     }\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23502",
    "pr_id": 23502,
    "issue_id": 23501,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Reader.hasMessageAvailable return wrong value after seeking by timestamp with startMessageIdInclusive\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nmaster\n\n### Minimal reproduce step\n\n1. create new reader with startMessageIdInclusive\r\n2. seek to the current time  `reader.seek(System.currentTimeMillis());`\r\n3. call the `reader.hasMessageAvailable()`\r\n```java\r\n    @Test(dataProvider = \"initializeLastMessageIdInBroker\")\r\n    public void testHasMessageAvailableAfterSeekTimestampWithMessageIdInclusive(boolean initializeLastMessageIdInBroker)\r\n            throws Exception {\r\n        final String topic = \"persistent://my-property/my-ns/\" +\r\n                \"testHasMessageAvailableAfterSeekTimestampWithMessageInclusive\";\r\n\r\n        @Cleanup\r\n        Producer<String> producer = pulsarClient.newProducer(Schema.STRING).topic(topic).create();\r\n        final long timestampBeforeSend = System.currentTimeMillis();\r\n        final MessageId sentMsgId = producer.send(\"msg\");\r\n\r\n        final List<MessageId> messageIds = new ArrayList<>();\r\n        messageIds.add(MessageId.earliest);\r\n        messageIds.add(sentMsgId);\r\n        messageIds.add(MessageId.latest);\r\n\r\n        for (MessageId messageId : messageIds) {\r\n            @Cleanup\r\n            Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topic).receiverQueueSize(1)\r\n                    .startMessageIdInclusive()\r\n                    .startMessageId(messageId).create();\r\n            if (initializeLastMessageIdInBroker) {\r\n                assertTrue(reader.hasMessageAvailable());\r\n            }\r\n            reader.seek(System.currentTimeMillis());\r\n            assertFalse(reader.hasMessageAvailable());\r\n            Message<String> message = reader.readNext(10, TimeUnit.SECONDS);\r\n            assertNull(message);\r\n        }\r\n\r\n        for (MessageId messageId : messageIds) {\r\n            @Cleanup\r\n            Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topic).receiverQueueSize(1)\r\n                    .startMessageIdInclusive()\r\n                    .startMessageId(messageId).create();\r\n            if (initializeLastMessageIdInBroker) {\r\n                assertTrue(reader.hasMessageAvailable());\r\n            }\r\n            reader.seek(timestampBeforeSend);\r\n            assertTrue(reader.hasMessageAvailable());\r\n        }\r\n    }\r\n```\n\n### What did you expect to see?\n\nIn the step 3, `reader.hasMessageAvailable()` should return false cause there has no message to read\n\n### What did you see instead?\n\n`reader.hasMessageAvailable()` return true \r\n\r\n``` java.lang.AssertionError: \r\nExpected :false\r\nActual   :true\r\n<Click to see difference>\r\n\r\n\tat org.testng.Assert.fail(Assert.java:110)\r\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n\tat org.testng.Assert.assertFalse(Assert.java:78)\r\n\tat org.testng.Assert.assertFalse(Assert.java:88)\r\n\tat org.apache.pulsar.client.impl.ReaderTest.testHasMessageAvailableAfterSeekTimestampWithMessageIdInclusive(ReaderTest.java:934)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n\tat org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:677)\r\n\tat org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:221)\r\n\tat org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50)\r\n\tat org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:969)\r\n\tat org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:194)\r\n\tat org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:148)\r\n\tat org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128)\r\n\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\r\n\tat org.testng.TestRunner.privateRun(TestRunner.java:829)\r\n\tat org.testng.TestRunner.run(TestRunner.java:602)\r\n\tat org.testng.SuiteRunner.runTest(SuiteRunner.java:437)\r\n\tat org.testng.SuiteRunner.runSequentially(SuiteRunner.java:431)\r\n\tat org.testng.SuiteRunner.privateRun(SuiteRunner.java:391)\r\n\tat org.testng.SuiteRunner.run(SuiteRunner.java:330)\r\n\tat org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)\r\n\tat org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95)\r\n\tat org.testng.TestNG.runSuitesSequentially(TestNG.java:1256)\r\n\tat org.testng.TestNG.runSuitesLocally(TestNG.java:1176)\r\n\tat org.testng.TestNG.runSuites(TestNG.java:1099)\r\n\tat org.testng.TestNG.run(TestNG.java:1067)\r\n\tat com.intellij.rt.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:66)\r\n\tat com.intellij.rt.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:109)\r\n```\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 574,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java"
    ],
    "base_commit": "1344167328c31ea39054ec2a6019f003fb8bab50",
    "head_commit": "912c56f10cf5a60e3254d48d24352d77ed4dca84",
    "repo_url": "https://github.com/apache/pulsar/pull/23502",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23502",
    "dockerfile": "",
    "pr_merged_at": "2024-10-24T09:34:31.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\nindex b7010a1ddc7b4..be01bd00eb300 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n@@ -2515,6 +2515,8 @@ public CompletableFuture<Boolean> hasMessageAvailableAsync() {\n                                 .result();\n                         if (lastMessageId.getEntryId() < 0) {\n                             completehasMessageAvailableWithValue(booleanFuture, false);\n+                        } else if (hasSoughtByTimestamp) {\n+                            completehasMessageAvailableWithValue(booleanFuture, result < 0);\n                         } else {\n                             completehasMessageAvailableWithValue(booleanFuture,\n                                     resetIncludeHead ? result <= 0 : result < 0);\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\nindex 12228220b18bd..a6a3f83ebc37d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\n@@ -906,6 +906,46 @@ public void testHasMessageAvailableAfterSeekTimestamp(boolean initializeLastMess\n         }\n     }\n \n+    @Test\n+    public void testHasMessageAvailableAfterSeekTimestampWithMessageIdInclusive() throws Exception {\n+        final String topic = \"persistent://my-property/my-ns/\" +\n+                \"testHasMessageAvailableAfterSeekTimestampWithMessageInclusive\";\n+\n+        @Cleanup\n+        Producer<String> producer = pulsarClient.newProducer(Schema.STRING).topic(topic).create();\n+        final long timestampBeforeSend = System.currentTimeMillis();\n+        final MessageId sentMsgId = producer.send(\"msg\");\n+\n+        final List<MessageId> messageIds = new ArrayList<>();\n+        messageIds.add(MessageId.earliest);\n+        messageIds.add(sentMsgId);\n+        messageIds.add(MessageId.latest);\n+\n+        for (MessageId messageId : messageIds) {\n+            @Cleanup\n+            Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topic).receiverQueueSize(1)\n+                    .startMessageIdInclusive()\n+                    .startMessageId(messageId).create();\n+            assertTrue(reader.hasMessageAvailable());\n+\n+            reader.seek(System.currentTimeMillis());\n+            assertFalse(reader.hasMessageAvailable());\n+            Message<String> message = reader.readNext(10, TimeUnit.SECONDS);\n+            assertNull(message);\n+        }\n+\n+        for (MessageId messageId : messageIds) {\n+            @Cleanup\n+            Reader<String> reader = pulsarClient.newReader(Schema.STRING).topic(topic).receiverQueueSize(1)\n+                    .startMessageIdInclusive()\n+                    .startMessageId(messageId).create();\n+            assertTrue(reader.hasMessageAvailable());\n+\n+            reader.seek(timestampBeforeSend);\n+            assertTrue(reader.hasMessageAvailable());\n+        }\n+    }\n+\n     @Test\n     public void testReaderBuilderStateOnRetryFailure() throws Exception {\n         String ns = \"my-property/my-ns\";\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23478",
    "pr_id": 23478,
    "issue_id": 23474,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BadVersionExceptions in OneWayReplicatorUsingGlobalZKTest.cleanup \n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Example failure\r\n\r\nhttps://github.com/apache/pulsar/actions/runs/11368523712/job/31653376302?pr=23468#step:11:2008\r\n\r\nLogs: https://gist.github.com/lhotari/02be1e0d55026ca51730e6d932dfe1bc\r\n\r\n### Additional context\r\n\r\nThis seems to block all Pulsar CI PR build jobs from completing successfully at the moment (Thu Oct 17 09:26:11 UTC 2024).\r\n\r\n### Exception stacktrace\r\n\r\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  Failures: \r\n  Error:    OneWayReplicatorUsingGlobalZKTest.cleanup  TestNGRuntime org.apache.pulsar.client.admin.PulsarAdminException$ServerSideErrorException: \r\n   --- An unexpected error occurred in the server ---\r\n  \r\n  Message: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n  \r\n  Stacktrace:\r\n  \r\n  org.apache.pulsar.broker.service.BrokerServiceException$PersistenceException: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n  \tat org.apache.pulsar.broker.service.persistent.PersistentTopic$6.deleteLedgerFailed(PersistentTopic.java:1546)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.lambda$asyncDelete$35(ManagedLedgerImpl.java:2978)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl.lambda$asyncTruncate$58(ManagedLedgerImpl.java:4372)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:990)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:974)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl$26.clearBacklogFailed(ManagedLedgerImpl.java:4363)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$16.markDeleteFailed(ManagedCursorImpl.java:1767)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$28.operationFailed(ManagedCursorImpl.java:2940)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl$31.lambda$operationFailed$0(ManagedCursorImpl.java:3317)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniRun.tryFire(CompletableFuture.java:787)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\r\n  \tat org.apache.bookkeeper.mledger.impl.ManagedCursorImpl.lambda$deleteLedgerAsync$39(ManagedCursorImpl.java:3051)\r\n  \tat org.apache.bookkeeper.client.LedgerDeleteOp.lambda$initiate$0(LedgerDeleteOp.java:86)\r\n  \tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \tat java.base/java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:482)\r\n  \tat org.apache.bookkeeper.common.util.SingleThreadExecutor.safeRunTask(SingleThreadExecutor.java:137)\r\n  \tat org.apache.bookkeeper.common.util.SingleThreadExecutor.run(SingleThreadExecutor.java:113)\r\n  \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  Caused by: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/public/default/persistent/tp_-70132750-44af-4d14-817c-219034d2b7be-partition-0/pulsar.repl.r2\r\n```\r\n\r\n```\r\n2024-10-17T04:15:33,865 - INFO  - [broker-topic-workers-OrderedExecutor-2-0:AbstractMetadataStore] - Deleting path: /ledgers/00/0000/L0032 (v. Optional.empty)\r\n2024-10-17T04:15:33,865 - WARN  - [bookkeeper-ml-scheduler-OrderedScheduler-3-0:ManagedLedgerImpl] - [public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a] Failed to delete managed ledger\r\norg.apache.bookkeeper.mledger.ManagedLedgerException$MetaStoreException: java.util.concurrent.CompletionException: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\nCaused by: java.util.concurrent.CompletionException: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture$UniRun.tryFire(CompletableFuture.java:781) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]\r\n\tat java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194) ~[?:?]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) [?:?]\r\nCaused by: org.apache.pulsar.metadata.api.MetadataStoreException$NotFoundException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:486) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) [?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) [?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) [?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) [?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) [?:?]\r\nCaused by: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /managed-ledgers/public/ns_73b1a31afce34671a5ddc48fe5ad7fc8/persistent/___tp-5dd50794-7af8-4a34-8a0b-06188052c66a\r\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:117) ~[zookeeper-3.9.2.jar:3.9.2]\r\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:53) ~[zookeeper-3.9.2.jar:3.9.2]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.getException(ZKMetadataStore.java:480) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$internalStoreDelete$13(ZKMetadataStore.java:391) ~[pulsar-metadata-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.113.Final.jar:4.1.113.Final]\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583) ~[?:?]\r\n```\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1199,
    "test_files_count": 5,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java"
    ],
    "base_commit": "842f0ceb26217cdf9c110a47d2de45c0cf6ddff4",
    "head_commit": "251ed417b178321ad3f0f952f91252ac10ad98a4",
    "repo_url": "https://github.com/apache/pulsar/pull/23478",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23478",
    "dockerfile": "",
    "pr_merged_at": "2024-10-17T14:08:56.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\nindex b39f8135e0e0c..fb19ed1ddbb6a 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/SameAuthParamsLookupAutoClusterFailoverTest.java\n@@ -42,6 +42,7 @@\n import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n+@Test(groups = \"flaky\")\n public class SameAuthParamsLookupAutoClusterFailoverTest extends OneWayReplicatorTestBase {\n \n     public void setup() throws Exception {\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\nindex 0f8db4aaa7316..0246d16b23d0e 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/DisabledCreateTopicToRemoteClusterForReplicationTest.java\n@@ -44,7 +44,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class DisabledCreateTopicToRemoteClusterForReplicationTest extends OneWayReplicatorTestBase {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\nindex a8f8d7ecbbd47..f2631f252ab0f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n@@ -104,7 +104,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class OneWayReplicatorTest extends OneWayReplicatorTestBase {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\nindex ad877e8f947b7..827ad78fb26ff 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorUsingGlobalZKTest.java\n@@ -44,7 +44,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class OneWayReplicatorUsingGlobalZKTest extends OneWayReplicatorTest {\n \n     @Override\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\nindex bd4a0889c730f..9fe016176990b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicationTxnTest.java\n@@ -59,7 +59,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class ReplicationTxnTest extends OneWayReplicatorTestBase {\n \n     private boolean transactionBufferSegmentedSnapshotEnabled = false;\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23449",
    "pr_id": 23449,
    "issue_id": 23272,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Dispatcher will be closing and reopening when Key_shared consumers have different policies (AUTO_SPLIT/STICKY, allowOutOfOrderDelivery true/false)\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nall released versions including master branch\n\n### Minimal reproduce step\n\nThe conclusion is currently based on the source code:\r\nhttps://github.com/apache/pulsar/blob/766d2a407196533832184447c25498c6a82f7a86/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java#L287-L309\r\n\n\n### What did you expect to see?\n\nWhen multiple consumers are using different policies, this should be properly handled.\r\nOne possibility is to keep the policy of the connected consumers and reject any other consumers and return a proper error message.\n\n### What did you see instead?\n\nBased on the source code, it looks like the solution cannot work:\r\n- a new dispatcher is created while the existing dispatcher is active\r\n- the existing dispatcher is closed asynchronously\r\n- no proper errors messages are logged or logged that could help resolving the situation\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 215,
    "test_files_count": 2,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractSubscription.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionConsumerCompatibilityTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionConsumerCompatibilityTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java"
    ],
    "base_commit": "7367f1c6553c83d7d335977b86ed38494c9485b7",
    "head_commit": "6f80b55d9d54fe18d5148c00691fa91c86caeba2",
    "repo_url": "https://github.com/apache/pulsar/pull/23449",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23449",
    "dockerfile": "",
    "pr_merged_at": "2024-10-21T21:32:31.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractSubscription.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractSubscription.java\nindex 10e6b79609721..ae108646532dc 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractSubscription.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractSubscription.java\n@@ -19,8 +19,12 @@\n package org.apache.pulsar.broker.service;\n \n import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.atomic.LongAdder;\n import java.util.function.ToLongFunction;\n+import org.apache.pulsar.common.api.proto.CommandSubscribe;\n+import org.apache.pulsar.common.api.proto.KeySharedMeta;\n+import org.apache.pulsar.common.util.FutureUtil;\n \n public abstract class AbstractSubscription implements Subscription {\n     protected final LongAdder bytesOutFromRemovedConsumers = new LongAdder();\n@@ -39,4 +43,46 @@ private long sumConsumers(ToLongFunction<Consumer> toCounter) {\n                 .map(dispatcher -> dispatcher.getConsumers().stream().mapToLong(toCounter).sum())\n                 .orElse(0L);\n     }\n+\n+    /**\n+     * Checks if the given consumer is compatible with the given dispatcher. They are incompatible if\n+     * <ul>\n+     * <li>the subscription type of the consumer differs from the subscription type of the dispatcher or</li>\n+     * <li>if both the consumer and dispatcher are of {@link CommandSubscribe.SubType#Key_Shared} type but\n+     * their policies differ ({@link org.apache.pulsar.common.api.proto.KeySharedMode#AUTO_SPLIT}/\n+     * {@link org.apache.pulsar.common.api.proto.KeySharedMode#STICKY} or allowOutOfOrderDelivery true/false).</li>\n+     * </ul>\n+     * @param dispatcher The dispatcher of the subscription\n+     * @param consumer New consumer to be added to the subscription\n+     * @return Optional containing failed future with {@link BrokerServiceException.SubscriptionBusyException} if\n+     * consumer and dispatcher are incompatible or empty optional otherwise.\n+     */\n+    protected Optional<CompletableFuture<Void>> checkForConsumerCompatibilityErrorWithDispatcher(Dispatcher dispatcher,\n+                                                                                                 Consumer consumer) {\n+        if (consumer.subType() != dispatcher.getType()) {\n+            return Optional.of(FutureUtil.failedFuture(new BrokerServiceException.SubscriptionBusyException(\n+                    String.format(\"Subscription is of different type. Active subscription type of '%s' is different \"\n+                                    + \"than the connecting consumer's type '%s'.\",\n+                            dispatcher.getType(), consumer.subType()))));\n+        } else if (dispatcher.getType() == CommandSubscribe.SubType.Key_Shared) {\n+            KeySharedMeta dispatcherKsm = dispatcher.getConsumers().get(0).getKeySharedMeta();\n+            KeySharedMeta consumerKsm = consumer.getKeySharedMeta();\n+            if (dispatcherKsm.getKeySharedMode() != consumerKsm.getKeySharedMode()) {\n+                return Optional.of(FutureUtil.failedFuture(new BrokerServiceException.SubscriptionBusyException(\n+                        String.format(\"Subscription is of different type. Active subscription key_shared mode of '%s' \"\n+                                        + \"is different than the connecting consumer's key_shared mode '%s'.\",\n+                                dispatcherKsm.getKeySharedMode(), consumerKsm.getKeySharedMode()))));\n+            }\n+            if (dispatcherKsm.isAllowOutOfOrderDelivery() != consumerKsm.isAllowOutOfOrderDelivery()) {\n+                return Optional.of(FutureUtil.failedFuture(new BrokerServiceException.SubscriptionBusyException(\n+                        String.format(\"Subscription is of different type. %s\",\n+                                dispatcherKsm.isAllowOutOfOrderDelivery()\n+                                        ? \"Active subscription allows out of order delivery while the connecting \"\n+                                        + \"consumer does not allow it.\" :\n+                                        \"Active subscription does not allow out of order delivery while the connecting \"\n+                                                + \"consumer allows it.\"))));\n+            }\n+        }\n+        return Optional.empty();\n+    }\n }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\nindex e92eef5cb7bff..55639868e0ac1 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentSubscription.java\n@@ -34,7 +34,6 @@\n import org.apache.pulsar.broker.service.AnalyzeBacklogResult;\n import org.apache.pulsar.broker.service.BrokerServiceException;\n import org.apache.pulsar.broker.service.BrokerServiceException.ServerMetadataException;\n-import org.apache.pulsar.broker.service.BrokerServiceException.SubscriptionBusyException;\n import org.apache.pulsar.broker.service.BrokerServiceException.SubscriptionFencedException;\n import org.apache.pulsar.broker.service.Consumer;\n import org.apache.pulsar.broker.service.Dispatcher;\n@@ -159,8 +158,10 @@ public synchronized CompletableFuture<Void> addConsumer(Consumer consumer) {\n                 });\n             }\n         } else {\n-            if (consumer.subType() != dispatcher.getType()) {\n-                return FutureUtil.failedFuture(new SubscriptionBusyException(\"Subscription is of different type\"));\n+            Optional<CompletableFuture<Void>> compatibilityError =\n+                    checkForConsumerCompatibilityErrorWithDispatcher(dispatcher, consumer);\n+            if (compatibilityError.isPresent()) {\n+                return compatibilityError.get();\n             }\n         }\n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\nindex df1c23cbbcb30..0096f398ada91 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\n@@ -307,9 +307,10 @@ private CompletableFuture<Void> addConsumerInternal(Consumer consumer) {\n                         });\n                     }\n                 } else {\n-                    if (consumer.subType() != dispatcher.getType()) {\n-                        return FutureUtil.failedFuture(\n-                                new SubscriptionBusyException(\"Subscription is of different type\"));\n+                    Optional<CompletableFuture<Void>> compatibilityError =\n+                            checkForConsumerCompatibilityErrorWithDispatcher(dispatcher, consumer);\n+                    if (compatibilityError.isPresent()) {\n+                        return compatibilityError.get();\n                     }\n                 }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionConsumerCompatibilityTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionConsumerCompatibilityTest.java\nnew file mode 100644\nindex 0000000000000..dc1d0170f9d72\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/SubscriptionConsumerCompatibilityTest.java\n@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.service;\n+\n+import static org.mockito.Mockito.doReturn;\n+import static org.mockito.Mockito.mock;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+import static org.testng.Assert.fail;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.bookkeeper.mledger.ManagedLedger;\n+import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n+import org.apache.bookkeeper.mledger.impl.ManagedCursorImpl;\n+import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n+import org.apache.pulsar.broker.service.nonpersistent.NonPersistentSubscription;\n+import org.apache.pulsar.broker.service.nonpersistent.NonPersistentTopic;\n+import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n+import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n+import org.apache.pulsar.broker.testcontext.PulsarTestContext;\n+import org.apache.pulsar.common.api.proto.CommandSubscribe;\n+import org.apache.pulsar.common.api.proto.KeySharedMeta;\n+import org.apache.pulsar.common.api.proto.KeySharedMode;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+@Test(groups = \"broker\")\n+public class SubscriptionConsumerCompatibilityTest {\n+\n+    private PulsarTestContext pulsarTestContext;\n+    private ManagedLedger ledgerMock;\n+    private ManagedCursorImpl cursorMock;\n+    private final String successTopicName = \"persistent://prop/use/ns-abc/successTopic\";\n+    private final String subName = \"subscriptionName\";\n+\n+    @BeforeMethod\n+    public void setup() throws Exception {\n+        pulsarTestContext = PulsarTestContext.builderForNonStartableContext().build();\n+\n+        ledgerMock = mock(ManagedLedgerImpl.class);\n+        ManagedLedgerConfig managedLedgerConfigMock = mock(ManagedLedgerConfig.class);\n+        doReturn(managedLedgerConfigMock).when(ledgerMock).getConfig();\n+\n+        cursorMock = mock(ManagedCursorImpl.class);\n+        doReturn(\"mockCursor\").when(cursorMock).getName();\n+    }\n+\n+    @AfterMethod(alwaysRun = true)\n+    public void teardown() throws Exception {\n+        if (pulsarTestContext != null) {\n+            pulsarTestContext.close();\n+            pulsarTestContext = null;\n+        }\n+    }\n+\n+    @DataProvider(name = \"incompatibleKeySharedPolicies\")\n+    public Object[][] incompatibleKeySharedPolicies() {\n+        KeySharedMeta ksmSticky = new KeySharedMeta().setKeySharedMode(KeySharedMode.STICKY);\n+        ksmSticky.addHashRange().setStart(0).setEnd(2);\n+\n+        KeySharedMeta ksmStickyAllowOutOfOrder = new KeySharedMeta().setKeySharedMode(KeySharedMode.STICKY)\n+                .setAllowOutOfOrderDelivery(true);\n+        ksmStickyAllowOutOfOrder.addHashRange().setStart(3).setEnd(5);\n+\n+        KeySharedMeta ksmAutoSplit = new KeySharedMeta().setKeySharedMode(KeySharedMode.AUTO_SPLIT);\n+        KeySharedMeta ksmAutoSplitAllowOutOfOrder = new KeySharedMeta().setKeySharedMode(KeySharedMode.AUTO_SPLIT)\n+                .setAllowOutOfOrderDelivery(true);\n+\n+        String errorMessagePrefix = \"Subscription is of different type. \";\n+        String errorMessageSubscriptionModeSticky = errorMessagePrefix + \"Active subscription key_shared mode of \"\n+                + \"'STICKY' is different than the connecting consumer's key_shared mode 'AUTO_SPLIT'.\";\n+        String errorMessageSubscriptionModeAutoSplit = errorMessagePrefix + \"Active subscription key_shared mode of \"\n+                + \"'AUTO_SPLIT' is different than the connecting consumer's key_shared mode 'STICKY'.\";\n+        String errorMessageOutOfOrderNotAllowed = errorMessagePrefix + \"Active subscription does not allow out of \"\n+                + \"order delivery while the connecting consumer allows it.\";\n+        String errorMessageOutOfOrderAllowed = errorMessagePrefix + \"Active subscription allows out of order delivery \"\n+                + \"while the connecting consumer does not allow it.\";\n+\n+        return new Object[][] {\n+                { ksmAutoSplit, ksmSticky, errorMessageSubscriptionModeAutoSplit },\n+                { ksmAutoSplit, ksmStickyAllowOutOfOrder, errorMessageSubscriptionModeAutoSplit },\n+                { ksmAutoSplit, ksmAutoSplitAllowOutOfOrder, errorMessageOutOfOrderNotAllowed },\n+\n+                { ksmAutoSplitAllowOutOfOrder, ksmSticky, errorMessageSubscriptionModeAutoSplit },\n+                { ksmAutoSplitAllowOutOfOrder, ksmStickyAllowOutOfOrder, errorMessageSubscriptionModeAutoSplit },\n+                { ksmAutoSplitAllowOutOfOrder, ksmAutoSplit, errorMessageOutOfOrderAllowed },\n+\n+                { ksmSticky, ksmStickyAllowOutOfOrder, errorMessageOutOfOrderNotAllowed },\n+                { ksmSticky, ksmAutoSplit, errorMessageSubscriptionModeSticky },\n+                { ksmSticky, ksmAutoSplitAllowOutOfOrder, errorMessageSubscriptionModeSticky },\n+\n+                { ksmStickyAllowOutOfOrder, ksmSticky, errorMessageOutOfOrderAllowed },\n+                { ksmStickyAllowOutOfOrder, ksmAutoSplit, errorMessageSubscriptionModeSticky },\n+                { ksmStickyAllowOutOfOrder, ksmAutoSplitAllowOutOfOrder, errorMessageSubscriptionModeSticky }\n+        };\n+    }\n+\n+    @Test(dataProvider = \"incompatibleKeySharedPolicies\")\n+    public void testIncompatibleKeySharedPoliciesNotAllowedInNonPersistentSub(KeySharedMeta consumer1Ksm, KeySharedMeta consumer2Ksm,\n+                                                                              String expectedErrorMessage) throws Exception {\n+        NonPersistentTopic topic = new NonPersistentTopic(successTopicName, pulsarTestContext.getBrokerService());\n+        NonPersistentSubscription sub = new NonPersistentSubscription(topic, subName, Map.of());\n+\n+        // two consumers with incompatible key_shared policies\n+        Consumer keySharedConsumerMock1 = createKeySharedMockConsumer(\"consumer-1\", consumer1Ksm);\n+        Consumer keySharedConsumerMock2 = createKeySharedMockConsumer(\"consumer-2\", consumer2Ksm);\n+\n+        // first consumer defines key_shared mode of subscription and whether out of order delivery is allowed\n+        sub.addConsumer(keySharedConsumerMock1).get(5, TimeUnit.SECONDS);\n+\n+        try {\n+            // add second consumer with incompatible key_shared policy\n+            sub.addConsumer(keySharedConsumerMock2).get(5, TimeUnit.SECONDS);\n+            fail(BrokerServiceException.SubscriptionBusyException.class.getSimpleName() + \" not thrown\");\n+        } catch (Exception e) {\n+            // subscription throws exception when consumer with incompatible key_shared policy is added\n+            Throwable cause = e.getCause();\n+            assertTrue(cause instanceof BrokerServiceException.SubscriptionBusyException);\n+            assertEquals(cause.getMessage(), expectedErrorMessage);\n+        }\n+    }\n+\n+    @Test(dataProvider = \"incompatibleKeySharedPolicies\")\n+    public void testIncompatibleKeySharedPoliciesNotAllowedInPersistentSub(KeySharedMeta consumer1Ksm, KeySharedMeta consumer2Ksm,\n+                                                            String expectedErrorMessage) throws Exception {\n+        PersistentTopic topic = new PersistentTopic(successTopicName, ledgerMock, pulsarTestContext.getBrokerService());\n+        PersistentSubscription sub = new PersistentSubscription(topic, subName, cursorMock, false);\n+\n+        // two consumers with incompatible key_shared policies\n+        Consumer keySharedConsumerMock1 = createKeySharedMockConsumer(\"consumer-1\", consumer1Ksm);\n+        Consumer keySharedConsumerMock2 = createKeySharedMockConsumer(\"consumer-2\", consumer2Ksm);\n+\n+        // first consumer defines key_shared mode of subscription and whether out of order delivery is allowed\n+        sub.addConsumer(keySharedConsumerMock1).get(5, TimeUnit.SECONDS);\n+\n+        try {\n+            // add second consumer with incompatible key_shared policy\n+            sub.addConsumer(keySharedConsumerMock2).get(5, TimeUnit.SECONDS);\n+            fail(BrokerServiceException.SubscriptionBusyException.class.getSimpleName() + \" not thrown\");\n+        } catch (Exception e) {\n+            // subscription throws exception when consumer with incompatible key_shared policy is added\n+            Throwable cause = e.getCause();\n+            assertTrue(cause instanceof BrokerServiceException.SubscriptionBusyException);\n+            assertEquals(cause.getMessage(), expectedErrorMessage);\n+        }\n+    }\n+\n+    protected Consumer createKeySharedMockConsumer(String name, KeySharedMeta ksm) {\n+        Consumer consumer = BrokerTestUtil.createMockConsumer(name);\n+        doReturn(CommandSubscribe.SubType.Key_Shared).when(consumer).subType();\n+        doReturn(ksm).when(consumer).getKeySharedMeta();\n+        doReturn(mock(PendingAcksMap.class)).when(consumer).getPendingAcks();\n+        return consumer;\n+    }\n+\n+}\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java\nindex 309cd7b55ac0c..9a46a2919d12a 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentSubscriptionTest.java\n@@ -26,7 +26,6 @@\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n-import io.netty.channel.EventLoopGroup;\n import java.lang.reflect.Field;\n import java.util.ArrayList;\n import java.util.Collections;\n@@ -35,7 +34,6 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n-import org.apache.bookkeeper.common.util.OrderedExecutor;\n import org.apache.bookkeeper.mledger.AsyncCallbacks;\n import org.apache.bookkeeper.mledger.ManagedLedger;\n import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n@@ -60,8 +58,6 @@\n import org.apache.pulsar.common.policies.data.Policies;\n import org.apache.pulsar.transaction.common.exception.TransactionConflictException;\n import org.awaitility.Awaitility;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n import org.testng.annotations.AfterMethod;\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n@@ -83,11 +79,6 @@ public class PersistentSubscriptionTest {\n     final TxnID txnID1 = new TxnID(1,1);\n     final TxnID txnID2 = new TxnID(1,2);\n \n-    private static final Logger log = LoggerFactory.getLogger(PersistentTopicTest.class);\n-\n-    private OrderedExecutor executor;\n-    private EventLoopGroup eventLoopGroup;\n-\n     @BeforeMethod\n     public void setup() throws Exception {\n         pulsarTestContext = PulsarTestContext.builderForNonStartableContext()\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23447",
    "pr_id": 23447,
    "issue_id": 23443,
    "repo": "apache/pulsar",
    "problem_statement": "[Enhancement][PIP-379] Improve collision handling so that a consumer that collided can restore a hash ring point when another one leaves\nfrom discussion: https://github.com/apache/pulsar/pull/23441#discussion_r1797140960\r\n\r\n> One problem is that the hash points don't get restored for a collided consumer if an earlier consumer leaves. A solution where there's a list and the first entry is used would be a solution to this. That's one reason to restore the list in the hash ring entry. I'll create an issue to track it.",
    "issue_word_count": 92,
    "test_files_count": 2,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/RemovedHashRanges.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java",
      "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java"
    ],
    "base_commit": "390d7d92734538b7fa431044f25ad3c6c5574e78",
    "head_commit": "97f7eb8f368dbd7749f452ab0601e7d0bd692ceb",
    "repo_url": "https://github.com/apache/pulsar/pull/23447",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23447",
    "dockerfile": "",
    "pr_merged_at": "2024-10-14T06:52:31.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\nindex 2559a02f87df0..06bac02782eff 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\n@@ -19,6 +19,7 @@\n package org.apache.pulsar.broker.service;\n \n import java.util.ArrayList;\n+import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n import java.util.NavigableMap;\n@@ -27,6 +28,7 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.locks.ReadWriteLock;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import lombok.ToString;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.client.api.Range;\n \n@@ -40,8 +42,66 @@ public class ConsistentHashingStickyKeyConsumerSelector implements StickyKeyCons\n     private static final String KEY_SEPARATOR = \"\\0\";\n     private final ReadWriteLock rwLock = new ReentrantReadWriteLock();\n \n+    /**\n+     * Represents a hash ring point entry.\n+     */\n+    @ToString\n+    private static class HashRingPointEntry {\n+        Consumer selectedConsumer;\n+        private List<Consumer> collidingConsumers;\n+\n+        /**\n+         * Create a hash ring entry with a selected consumer.\n+         * @param selectedConsumer the selected consumer\n+         */\n+        HashRingPointEntry(Consumer selectedConsumer) {\n+            this.selectedConsumer = selectedConsumer;\n+            this.collidingConsumers = null;\n+        }\n+\n+        /**\n+         * Add a colliding consumer to the hash ring entry. Colliding consumers are consumers that have the same hash\n+         * ring point. A colliding consumer is selected when the selected consumer is removed from the hash ring.\n+         * @param consumer the consumer to add\n+         */\n+        void addCollidingConsumer(Consumer consumer) {\n+            if (collidingConsumers == null) {\n+                collidingConsumers = new LinkedList<>();\n+            }\n+            collidingConsumers.add(consumer);\n+        }\n+\n+        /**\n+         * Remove a consumer from the hash ring entry. When the selected consumer is removed, the first colliding\n+         * consumer is selected as the new selected consumer and removed from the colliding consumers list.\n+         * @param consumer the consumer to remove\n+         * @return true if the entry is empty and should be removed from the hash ring\n+         */\n+        boolean removeConsumer(Consumer consumer) {\n+            if (selectedConsumer == consumer) {\n+                if (collidingConsumers != null) {\n+                    selectedConsumer = collidingConsumers.remove(0);\n+                    if (collidingConsumers.isEmpty()) {\n+                        collidingConsumers = null;\n+                    }\n+                } else {\n+                    selectedConsumer = null;\n+                }\n+            } else if (collidingConsumers != null) {\n+                // remove using identity comparison\n+                collidingConsumers.removeIf(c -> c == consumer);\n+                if (collidingConsumers.isEmpty()) {\n+                    // remove the list instance when there are no more colliding consumers\n+                    collidingConsumers = null;\n+                }\n+            }\n+            // return true when the entry is empty and should be removed from the hash ring\n+            return selectedConsumer == null;\n+        }\n+    }\n+\n     // Consistent-Hash ring\n-    private final NavigableMap<Integer, ConsumerIdentityWrapper> hashRing;\n+    private final NavigableMap<Integer, HashRingPointEntry> hashRing;\n     // Tracks the used consumer name indexes for each consumer name\n     private final ConsumerNameIndexTracker consumerNameIndexTracker = new ConsumerNameIndexTracker();\n \n@@ -84,15 +144,16 @@ public CompletableFuture<Optional<ImpactedConsumersResult>> addConsumer(Consumer\n                 int consumerNameIndex =\n                         consumerNameIndexTracker.increaseConsumerRefCountAndReturnIndex(consumerIdentityWrapper);\n                 int hash = calculateHashForConsumerAndIndex(consumer, consumerNameIndex, i);\n-                // When there's a collision, the entry won't be added to the hash ring.\n+                // When there's a collision, the entry won't be selected in the hash ring.\n                 // This isn't a problem with the consumerNameIndexTracker solution since the collisions won't align\n                 // for all hash ring points when using the same consumer name. This won't affect the overall\n                 // distribution significantly when the number of hash ring points is sufficiently large (>100).\n-                ConsumerIdentityWrapper existing = hashRing.putIfAbsent(hash, consumerIdentityWrapper);\n+                HashRingPointEntry existing = hashRing.putIfAbsent(hash, new HashRingPointEntry(consumer));\n                 if (existing != null) {\n                     hashPointCollisions++;\n-                    // reduce the ref count which was increased before adding since the consumer was not added\n-                    consumerNameIndexTracker.decreaseConsumerRefCount(consumerIdentityWrapper);\n+                    // Add the consumer to the colliding consumers list. The first colliding consumer is selected\n+                    // when the selected consumer is removed from the hash ring.\n+                    existing.addCollidingConsumer(consumer);\n                 } else {\n                     hashPointsAdded++;\n                 }\n@@ -147,9 +208,15 @@ public Optional<ImpactedConsumersResult> removeConsumer(Consumer consumer) {\n                 // Remove all the points that were added for this consumer\n                 for (int i = 0; i < numberOfPoints; i++) {\n                     int hash = calculateHashForConsumerAndIndex(consumer, consumerNameIndex, i);\n-                    if (hashRing.remove(hash, consumerIdentityWrapper)) {\n-                        consumerNameIndexTracker.decreaseConsumerRefCount(consumerIdentityWrapper);\n-                    }\n+                    hashRing.compute(hash, (k, hashRingPointEntry) -> {\n+                        assert hashRingPointEntry != null : \"hash ring entry wasn't found for hash \" + hash;\n+                        if (hashRingPointEntry.removeConsumer(consumer)) {\n+                            // Remove the entry from the hash ring when there are no more consumers\n+                            return null;\n+                        }\n+                        return hashRingPointEntry;\n+                    });\n+                    consumerNameIndexTracker.decreaseConsumerRefCount(consumerIdentityWrapper);\n                 }\n             }\n             if (!addOrRemoveReturnsImpactedConsumersResult) {\n@@ -172,12 +239,12 @@ public Consumer select(int hash) {\n             if (hashRing.isEmpty()) {\n                 return null;\n             }\n-            Map.Entry<Integer, ConsumerIdentityWrapper> ceilingEntry = hashRing.ceilingEntry(hash);\n+            Map.Entry<Integer, HashRingPointEntry> ceilingEntry = hashRing.ceilingEntry(hash);\n             if (ceilingEntry != null) {\n-                return ceilingEntry.getValue().consumer;\n+                return ceilingEntry.getValue().selectedConsumer;\n             } else {\n                 // Handle wrap-around in the hash ring, return the first consumer\n-                return hashRing.firstEntry().getValue().consumer;\n+                return hashRing.firstEntry().getValue().selectedConsumer;\n             }\n         } finally {\n             rwLock.readLock().unlock();\n@@ -209,8 +276,8 @@ private ConsumerHashAssignmentsSnapshot internalGetConsumerHashAssignmentsSnapsh\n         int lastKey = -1;\n         Consumer previousConsumer = null;\n         Range previousRange = null;\n-        for (Map.Entry<Integer, ConsumerIdentityWrapper> entry: hashRing.entrySet()) {\n-            Consumer consumer = entry.getValue().consumer;\n+        for (Map.Entry<Integer, HashRingPointEntry> entry: hashRing.entrySet()) {\n+            Consumer consumer = entry.getValue().selectedConsumer;\n             Range range;\n             if (consumer == previousConsumer) {\n                 // join ranges\n@@ -226,7 +293,7 @@ private ConsumerHashAssignmentsSnapshot internalGetConsumerHashAssignmentsSnapsh\n             previousRange = range;\n         }\n         // Handle wrap-around\n-        Consumer firstConsumer = hashRing.firstEntry().getValue().consumer;\n+        Consumer firstConsumer = hashRing.firstEntry().getValue().selectedConsumer;\n         if (lastKey != getKeyHashRange().getEnd()) {\n             Range range;\n             if (firstConsumer == previousConsumer && previousRange.getEnd() == lastKey) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/RemovedHashRanges.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/RemovedHashRanges.java\nindex 1833c243f8955..d9bd502255b5b 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/RemovedHashRanges.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/RemovedHashRanges.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.broker.service;\n \n+import java.util.Arrays;\n import java.util.List;\n import lombok.EqualsAndHashCode;\n import lombok.ToString;\n@@ -71,4 +72,20 @@ public boolean containsStickyKey(int stickyKeyHash) {\n         }\n         return false;\n     }\n+\n+    /**\n+     * Checks if all removed ranges are fully contained in the provided list of ranges.\n+     */\n+    public boolean isFullyContainedInRanges(List<Range> otherRanges) {\n+        return Arrays.stream(sortedRanges).allMatch(range ->\n+                otherRanges.stream().anyMatch(otherRange -> otherRange.contains(range))\n+        );\n+    }\n+\n+    /**\n+     * Returns the removed hash ranges as a list of ranges.\n+     */\n+    public List<Range> asRanges() {\n+        return Arrays.asList(sortedRanges);\n+    }\n }\n\ndiff --git a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\nindex cbca1ef8f06bd..3db225330d0c7 100644\n--- a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\n+++ b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/Range.java\n@@ -94,10 +94,28 @@ public int compareTo(Range o) {\n         return result;\n     }\n \n+    /**\n+     * Check if the value is in the range.\n+     * @param value\n+     * @return true if the value is in the range.\n+     */\n     public boolean contains(int value) {\n         return value >= start && value <= end;\n     }\n \n+    /**\n+     * Check if the range is fully contained in the other range.\n+     * @param otherRange\n+     * @return true if the range is fully contained in the other range.\n+     */\n+    public boolean contains(Range otherRange) {\n+        return start <= otherRange.start && end >= otherRange.end;\n+    }\n+\n+    /**\n+     * Get the size of the range.\n+     * @return the size of the range.\n+     */\n     public int size() {\n         return end - start + 1;\n     }\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\nindex 6752cd7cfab45..24e14ca3c9c5d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\n@@ -31,6 +31,7 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.TreeSet;\n import java.util.UUID;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n@@ -475,11 +476,11 @@ public void testShouldNotChangeSelectedConsumerWhenConsumerIsAdded() {\n     }\n \n     @Test\n-    public void testShouldNotContainMappingChangesWhenConsumersLeaveAndRejoinInSameOrder() {\n+    public void testShouldContainMinimalMappingChangesWhenConsumerLeavesAndRejoins() {\n         final ConsistentHashingStickyKeyConsumerSelector selector =\n-                new ConsistentHashingStickyKeyConsumerSelector(200, true);\n+                new ConsistentHashingStickyKeyConsumerSelector(100, true);\n         final String consumerName = \"consumer\";\n-        final int numOfInitialConsumers = 200;\n+        final int numOfInitialConsumers = 10;\n         List<Consumer> consumers = new ArrayList<>();\n         for (int i = 0; i < numOfInitialConsumers; i++) {\n             final Consumer consumer = createMockConsumer(consumerName, \"index \" + i, i);\n@@ -498,8 +499,73 @@ public void testShouldNotContainMappingChangesWhenConsumersLeaveAndRejoinInSameO\n         selector.addConsumer(consumers.get(numOfInitialConsumers / 2));\n \n         ConsumerHashAssignmentsSnapshot assignmentsAfter = selector.getConsumerHashAssignmentsSnapshot();\n+        int removedRangesSize = assignmentsBefore.diffRanges(assignmentsAfter).keySet().stream()\n+                .mapToInt(Range::size)\n+                .sum();\n+        double allowedremovedRangesPercentage = 1; // 1%\n+        int hashRangeSize = selector.getKeyHashRange().size();\n+        int allowedremovedRanges = (int) (hashRangeSize * (allowedremovedRangesPercentage / 100.0d));\n+        assertThat(removedRangesSize).describedAs(\"Allow up to %d%% of total hash range size to be impacted\",\n+                allowedremovedRangesPercentage).isLessThan(allowedremovedRanges);\n+    }\n \n-        assertThat(assignmentsBefore.resolveImpactedConsumers(assignmentsAfter).getRemovedHashRanges()).isEmpty();\n+    @Test\n+    public void testShouldNotSwapExistingConsumers() {\n+        final ConsistentHashingStickyKeyConsumerSelector selector =\n+                new ConsistentHashingStickyKeyConsumerSelector(200, true);\n+        final String consumerName = \"consumer\";\n+        final int consumerCount = 100;\n+        List<Consumer> consumers = new ArrayList<>();\n+        for (int i = 0; i < consumerCount; i++) {\n+            final Consumer consumer = createMockConsumer(consumerName + i, \"index \" + i, i);\n+            consumers.add(consumer);\n+            selector.addConsumer(consumer);\n+        }\n+        ConsumerHashAssignmentsSnapshot assignmentsBefore = selector.getConsumerHashAssignmentsSnapshot();\n+        for (int i = 0; i < consumerCount; i++) {\n+            Consumer consumer = consumers.get(i);\n+\n+            // remove consumer\n+            selector.removeConsumer(consumer);\n+\n+            ConsumerHashAssignmentsSnapshot assignmentsAfter = selector.getConsumerHashAssignmentsSnapshot();\n+            assertThat(assignmentsBefore.resolveImpactedConsumers(assignmentsAfter).getRemovedHashRanges())\n+                    .describedAs(\n+                            \"when a consumer is removed, the removed hash ranges should only be from \"\n+                                    + \"the removed consumer\")\n+                    .containsOnlyKeys(consumer);\n+            assignmentsBefore = assignmentsAfter;\n+\n+            // add consumer back\n+            selector.addConsumer(consumer);\n+\n+            assignmentsAfter = selector.getConsumerHashAssignmentsSnapshot();\n+            List<Range> addedConsumerRanges = assignmentsAfter.getRangesByConsumer().get(consumer);\n+\n+            Map<Consumer, RemovedHashRanges> removedHashRanges =\n+                    assignmentsBefore.resolveImpactedConsumers(assignmentsAfter).getRemovedHashRanges();\n+            ConsumerHashAssignmentsSnapshot finalAssignmentsBefore = assignmentsBefore;\n+            assertThat(removedHashRanges).allSatisfy((c, removedHashRange) -> {\n+                assertThat(removedHashRange\n+                        .isFullyContainedInRanges(finalAssignmentsBefore.getRangesByConsumer().get(c)))\n+                        .isTrue();\n+                assertThat(removedHashRange\n+                        .isFullyContainedInRanges(addedConsumerRanges))\n+                        .isTrue();\n+            }).describedAs(\"when a consumer is added back, all removed hash ranges should be ones \"\n+                    + \"that are moved from existing consumers to the new consumer.\");\n+\n+            List<Range> allRemovedRanges =\n+                    ConsumerHashAssignmentsSnapshot.mergeOverlappingRanges(\n+                            removedHashRanges.entrySet().stream().map(Map.Entry::getValue)\n+                                    .map(RemovedHashRanges::asRanges)\n+                                    .flatMap(List::stream).collect(Collectors.toCollection(TreeSet::new)));\n+            assertThat(allRemovedRanges)\n+                    .describedAs(\"all removed ranges should be the same as the ranges of the added consumer\")\n+                    .containsExactlyElementsOf(addedConsumerRanges);\n+\n+            assignmentsBefore = assignmentsAfter;\n+        }\n     }\n \n     @Test\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java\nindex 50168221fea37..bb443498a16bd 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/api/RangeTest.java\n@@ -87,6 +87,38 @@ public void testContains() {\n         Assert.assertFalse(range.contains(6));\n     }\n \n+    @Test\n+    public void testContainsRange() {\n+        Range range = Range.of(5, 10);\n+\n+        // Test ranges that are fully contained\n+        Assert.assertTrue(range.contains(Range.of(6, 8)));\n+\n+        Assert.assertTrue(range.contains(Range.of(5, 10)));\n+\n+        Assert.assertTrue(range.contains(Range.of(5, 5)));\n+\n+        Assert.assertTrue(range.contains(Range.of(5, 8)));\n+\n+        Assert.assertTrue(range.contains(Range.of(10, 10)));\n+\n+        Assert.assertTrue(range.contains(Range.of(8, 10)));\n+\n+        // Test ranges that are not fully contained\n+        Assert.assertFalse(range.contains(Range.of(1, 5)));\n+\n+        Assert.assertFalse(range.contains(Range.of(1, 4)));\n+\n+        Assert.assertFalse(range.contains(Range.of(1, 10)));\n+\n+        Assert.assertFalse(range.contains(Range.of(1, 11)));\n+\n+        Assert.assertFalse(range.contains(Range.of(10, 12)));\n+\n+        Assert.assertFalse(range.contains(Range.of(11, 20)));\n+    }\n+\n+\n     @Test\n     public void testSize() {\n         Range range = Range.of(0, 0);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23441",
    "pr_id": 23441,
    "issue_id": 23439,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug][PIP-379] Hash ranges should not move from one consumer to another when a consumer joins\n              > What happens if a hash is moved between existing consumers? Is it handled?\r\n\r\nYes. All removed ranges are processed in both when a consumer is added and when it's removed. In some experimental testing I noticed that it actually could happen also when a consumer is added, due to how hash range conflicts are resolved. There's a need to make an improvement that when there are conflicts that the first assigned consumer is preserved instead of replacing it. I'll make a PR for that since hash range conflicts are fairly likely to happen with the reduced hash range of 65535 and 100 hash points when there's a large amount of consumers. I'll address that.\r\n\r\n_Originally posted by @lhotari in https://github.com/apache/pulsar/pull/23352#discussion_r1797026999_\r\n            ",
    "issue_word_count": 149,
    "test_files_count": 1,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsumerHashAssignmentsSnapshot.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java"
    ],
    "base_commit": "2dace760b03bd679dae5ea682e1e23fd93c15f78",
    "head_commit": "cc54bf8983d9a2cb25df359e9d0ea5ca13d9f818",
    "repo_url": "https://github.com/apache/pulsar/pull/23441",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23441",
    "dockerfile": "",
    "pr_merged_at": "2024-10-11T17:54:52.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\nindex fde140a299c27..2559a02f87df0 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelector.java\n@@ -27,12 +27,14 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.locks.ReadWriteLock;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.client.api.Range;\n \n /**\n  * This is a consumer selector using consistent hashing to evenly split\n  * the number of keys assigned to each consumer.\n  */\n+@Slf4j\n public class ConsistentHashingStickyKeyConsumerSelector implements StickyKeyConsumerSelector {\n     // use NUL character as field separator for hash key calculation\n     private static final String KEY_SEPARATOR = \"\\0\";\n@@ -76,18 +78,36 @@ public CompletableFuture<Optional<ImpactedConsumersResult>> addConsumer(Consumer\n             ConsumerIdentityWrapper consumerIdentityWrapper = new ConsumerIdentityWrapper(consumer);\n             // Insert multiple points on the hash ring for every consumer\n             // The points are deterministically added based on the hash of the consumer name\n+            int hashPointsAdded = 0;\n+            int hashPointCollisions = 0;\n             for (int i = 0; i < numberOfPoints; i++) {\n                 int consumerNameIndex =\n                         consumerNameIndexTracker.increaseConsumerRefCountAndReturnIndex(consumerIdentityWrapper);\n                 int hash = calculateHashForConsumerAndIndex(consumer, consumerNameIndex, i);\n-                // When there's a collision, the new consumer will replace the old one.\n-                // This is a rare case, and it is acceptable to replace the old consumer since there\n-                // are multiple points for each consumer. This won't affect the overall distribution significantly.\n-                ConsumerIdentityWrapper removed = hashRing.put(hash, consumerIdentityWrapper);\n-                if (removed != null) {\n-                    consumerNameIndexTracker.decreaseConsumerRefCount(removed);\n+                // When there's a collision, the entry won't be added to the hash ring.\n+                // This isn't a problem with the consumerNameIndexTracker solution since the collisions won't align\n+                // for all hash ring points when using the same consumer name. This won't affect the overall\n+                // distribution significantly when the number of hash ring points is sufficiently large (>100).\n+                ConsumerIdentityWrapper existing = hashRing.putIfAbsent(hash, consumerIdentityWrapper);\n+                if (existing != null) {\n+                    hashPointCollisions++;\n+                    // reduce the ref count which was increased before adding since the consumer was not added\n+                    consumerNameIndexTracker.decreaseConsumerRefCount(consumerIdentityWrapper);\n+                } else {\n+                    hashPointsAdded++;\n                 }\n             }\n+            if (hashPointsAdded == 0) {\n+                log.error(\"Failed to add consumer '{}' to the hash ring. There were {} collisions. Consider increasing \"\n+                                + \"the number of points ({}) per consumer by setting \"\n+                                + \"subscriptionKeySharedConsistentHashingReplicaPoints={}\",\n+                        consumer, hashPointCollisions, numberOfPoints,\n+                        Math.max((int) (numberOfPoints * 1.5d), numberOfPoints + 1));\n+            }\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"Added consumer '{}' with {} points, {} collisions\", consumer, hashPointsAdded,\n+                        hashPointCollisions);\n+            }\n             if (!addOrRemoveReturnsImpactedConsumersResult) {\n                 return CompletableFuture.completedFuture(Optional.empty());\n             }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsumerHashAssignmentsSnapshot.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsumerHashAssignmentsSnapshot.java\nindex d2bd113e69d1e..b4add79294cc4 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsumerHashAssignmentsSnapshot.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ConsumerHashAssignmentsSnapshot.java\n@@ -71,8 +71,8 @@ public static ConsumerHashAssignmentsSnapshot empty() {\n         return new ConsumerHashAssignmentsSnapshot(Collections.emptyList());\n     }\n \n-    public ImpactedConsumersResult resolveImpactedConsumers(ConsumerHashAssignmentsSnapshot other) {\n-        return resolveConsumerRemovedHashRanges(this.hashRangeAssignments, other.hashRangeAssignments);\n+    public ImpactedConsumersResult resolveImpactedConsumers(ConsumerHashAssignmentsSnapshot assignmentsAfter) {\n+        return resolveConsumerRemovedHashRanges(this.hashRangeAssignments, assignmentsAfter.hashRangeAssignments);\n     }\n \n     /**\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\nindex 2b01256611b01..6752cd7cfab45 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ConsistentHashingStickyKeyConsumerSelectorTest.java\n@@ -475,11 +475,11 @@ public void testShouldNotChangeSelectedConsumerWhenConsumerIsAdded() {\n     }\n \n     @Test\n-    public void testShouldContainMinimalMappingChangesWhenConsumerLeavesAndRejoins() {\n+    public void testShouldNotContainMappingChangesWhenConsumersLeaveAndRejoinInSameOrder() {\n         final ConsistentHashingStickyKeyConsumerSelector selector =\n-                new ConsistentHashingStickyKeyConsumerSelector(100, true);\n+                new ConsistentHashingStickyKeyConsumerSelector(200, true);\n         final String consumerName = \"consumer\";\n-        final int numOfInitialConsumers = 10;\n+        final int numOfInitialConsumers = 200;\n         List<Consumer> consumers = new ArrayList<>();\n         for (int i = 0; i < numOfInitialConsumers; i++) {\n             final Consumer consumer = createMockConsumer(consumerName, \"index \" + i, i);\n@@ -498,14 +498,8 @@ public void testShouldContainMinimalMappingChangesWhenConsumerLeavesAndRejoins()\n         selector.addConsumer(consumers.get(numOfInitialConsumers / 2));\n \n         ConsumerHashAssignmentsSnapshot assignmentsAfter = selector.getConsumerHashAssignmentsSnapshot();\n-        int removedRangesSize = assignmentsBefore.diffRanges(assignmentsAfter).keySet().stream()\n-                .mapToInt(Range::size)\n-                .sum();\n-        double allowedremovedRangesPercentage = 1; // 1%\n-        int hashRangeSize = selector.getKeyHashRange().size();\n-        int allowedremovedRanges = (int) (hashRangeSize * (allowedremovedRangesPercentage / 100.0d));\n-        assertThat(removedRangesSize).describedAs(\"Allow up to %d%% of total hash range size to be impacted\",\n-                allowedremovedRangesPercentage).isLessThan(allowedremovedRanges);\n+\n+        assertThat(assignmentsBefore.resolveImpactedConsumers(assignmentsAfter).getRemovedHashRanges()).isEmpty();\n     }\n \n     @Test\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23437",
    "pr_id": 23437,
    "issue_id": 23164,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ManagedLedgerTest.testDeleteCurrentLedgerWhenItIsClosed\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n### Example failures\r\n\r\n- [2024-08-07T22:14:33.5197682Z](https://github.com/apache/pulsar/actions/runs/10291342248/job/28486280269#step:11:90) \r\n- [2024-08-07T21:07:35.1097748Z](https://github.com/apache/pulsar/actions/runs/10291342248/job/28483793177#step:11:90) \r\n\r\n\r\n### Exception stacktrace\r\n\r\n```\r\norg.awaitility.core.ConditionTimeoutException: Assertion condition defined as a org.apache.bookkeeper.mledger.impl.ManagedLedgerTest expected [1] but found [2] within 10 seconds.\r\n\tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n\tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n\tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n\tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n\tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n\tat org.apache.bookkeeper.mledger.impl.ManagedLedgerTest.testDeleteCurrentLedgerWhenItIsClosed(ManagedLedgerTest.java:4368)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\nCaused by: java.lang.AssertionError: expected [1] but found [2]\r\n\tat org.testng.Assert.fail(Assert.java:110)\r\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n\tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n\tat org.testng.Assert.assertEquals(Assert.java:131)\r\n\tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n\tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n\tat org.testng.Assert.assertEquals(Assert.java:1428)\r\n\tat org.apache.bookkeeper.mledger.impl.ManagedLedgerTest.lambda$testDeleteCurrentLedgerWhenItIsClosed$52(ManagedLedgerTest.java:4370)\r\n\tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n\tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n```\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!\r\n",
    "issue_word_count": 385,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java"
    ],
    "base_commit": "2dace760b03bd679dae5ea682e1e23fd93c15f78",
    "head_commit": "3990f7a9807412d1c295344e126ec07daa4fad1a",
    "repo_url": "https://github.com/apache/pulsar/pull/23437",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23437",
    "dockerfile": "",
    "pr_merged_at": "2024-10-13T14:56:56.000Z",
    "patch": "",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\nindex 83a6c771513a9..67c928c8a5617 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerTest.java\n@@ -4361,9 +4361,10 @@ public void testDeleteCurrentLedgerWhenItIsClosed(boolean closeLedgerByAddEntry)\n             // Detect the current ledger is full by the timed task. (Imitate: the timed task `checkLedgerRollTask` call\n             // `rollCurrentLedgerIfFull` periodically).\n             ml.rollCurrentLedgerIfFull();\n-            // the ledger closing in the `rollCurrentLedgerIfFull` is async, so the wait is needed.\n-            Awaitility.await().untilAsserted(() -> assertEquals(ml.ledgers.size(), 2));\n         }\n+        // wait the new ledger create\n+        Awaitility.await().untilAsserted(() -> assertEquals(ml.ledgers.size(), 2));\n+\n         // Act: Trigger trimming to delete the previous current ledger.\n         ml.internalTrimLedgers(false, Futures.NULL_PROMISE);\n         // Verify: A new ledger will be opened after the current ledger is closed and the previous current ledger can be\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23433",
    "pr_id": 23433,
    "issue_id": 23412,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ExtensibleLoadManagerCloseTest.testCloseAfterLoadingBundles  \n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Example failure\r\n\r\nhttps://github.com/apache/pulsar/actions/runs/11231028428/job/31220046001?pr=23410#step:11:1598\r\n\r\nLogs at https://gist.github.com/lhotari/768dc7942175bdc25be4fc76e918ec49\r\n\r\n### Exception stacktrace\r\n\r\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerCloseTest.testCloseAfterLoadingBundles  Time elapsed: 2.395 s  <<< FAILURE!\r\n  org.apache.pulsar.client.admin.PulsarAdminException$ConflictException: This topic already exists\r\n  \tat org.apache.pulsar.client.admin.PulsarAdminException.wrap(PulsarAdminException.java:252)\r\n  \tat org.apache.pulsar.client.admin.internal.BaseResource.sync(BaseResource.java:352)\r\n  \tat org.apache.pulsar.client.admin.internal.TopicsImpl.createPartitionedTopic(TopicsImpl.java:307)\r\n  \tat org.apache.pulsar.client.admin.Topics.createPartitionedTopic(Topics.java:475)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerCloseTest.testCloseAfterLoadingBundles(ExtensibleLoadManagerCloseTest.java:100)\r\n  \tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n  \tSuppressed: org.apache.pulsar.client.admin.PulsarAdminException$ConflictException: This topic already exists\r\n  \t\tat org.apache.pulsar.client.admin.internal.BaseResource.getApiException(BaseResource.java:287)\r\n  \t\tat org.apache.pulsar.client.admin.internal.BaseResource$1.failed(BaseResource.java:136)\r\n  \t\tat org.glassfish.jersey.client.JerseyInvocation$1.failed(JerseyInvocation.java:898)\r\n  \t\tat org.glassfish.jersey.client.JerseyInvocation$1.completed(JerseyInvocation.java:879)\r\n  \t\tat org.glassfish.jersey.client.ClientRuntime.processResponse(ClientRuntime.java:232)\r\n  \t\tat org.glassfish.jersey.client.ClientRuntime.access$200(ClientRuntime.java:62)\r\n  \t\tat org.glassfish.jersey.client.ClientRuntime$2.lambda$response$0(ClientRuntime.java:176)\r\n  \t\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\r\n  \t\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\r\n  \t\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\r\n  \t\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\r\n  \t\tat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\r\n  \t\tat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:288)\r\n  \t\tat org.glassfish.jersey.client.ClientRuntime$2.response(ClientRuntime.java:176)\r\n  \t\tat org.apache.pulsar.client.admin.internal.http.AsyncHttpConnector.lambda$apply$1(AsyncHttpConnector.java:275)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\r\n  \t\tat org.apache.pulsar.client.admin.internal.http.AsyncHttpConnector.lambda$retryOperation$4(AsyncHttpConnector.java:331)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.cancel(CompletableFuture.java:2512)\r\n  \t\tat org.apache.pulsar.client.admin.internal.http.AsyncHttpConnector.lambda$executeRequest$10(AsyncHttpConnector.java:400)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\r\n  \t\tat com.spotify.futures.ConcurrencyReducer.lambda$invoke$0(ConcurrencyReducer.java:173)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n  \t\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\r\n  \t\tat org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222)\r\n  \t\tat org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257)\r\n  \t\tat org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241)\r\n  \t\tat org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:114)\r\n  \t\tat org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:143)\r\n  \t\tat org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n  \t\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n  \t\tat io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)\r\n  \t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\r\n  \t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)\r\n  \t\tat io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n  \t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\r\n  \t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n  \t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\r\n  \t\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\r\n  \t\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\r\n  \t\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\r\n  \t\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\r\n  \t\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\r\n  \t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n  \t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n  \t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n  \t\t... 1 more\r\n  \tCaused by: javax.ws.rs.ClientErrorException: HTTP 409 {\"reason\":\"This topic already exists\"}\r\n  \t\tat org.glassfish.jersey.client.JerseyInvocation.createExceptionForFamily(JerseyInvocation.java:1002)\r\n  \t\tat org.glassfish.jersey.client.JerseyInvocation.convertToException(JerseyInvocation.java:984)\r\n  \t\tat org.glassfish.jersey.client.JerseyInvocation.access$700(JerseyInvocation.java:82)\r\n  \t\t... 64 more\r\n  Caused by: [CIRCULAR REFERENCE: javax.ws.rs.ClientErrorException: HTTP 409 {\"reason\":\"This topic already exists\"}]\r\n```\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1038,
    "test_files_count": 1,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/channel/ServiceUnitStateChannelImpl.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java"
    ],
    "base_commit": "b334c4f637bdd32787494c16e9d34169f1a25812",
    "head_commit": "35fd689ef5248812ac19587587ecf2636fca87fc",
    "repo_url": "https://github.com/apache/pulsar/pull/23433",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23433",
    "dockerfile": "",
    "pr_merged_at": "2024-10-10T16:14:27.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\nindex da4cee7b4651c..e397dbb64a075 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/BrokersBase.java\n@@ -388,7 +388,11 @@ public void healthCheck(@Suspended AsyncResponse asyncResponse,\n                     asyncResponse.resume(Response.ok(\"ok\").build());\n                 }).exceptionally(ex -> {\n                     if (!isRedirectException(ex)) {\n-                        LOG.error(\"[{}] Fail to run health check.\", clientAppId(), ex);\n+                        if (isNotFoundException(ex)) {\n+                            LOG.warn(\"[{}] Failed to run health check: {}\", clientAppId(), ex.getMessage());\n+                        } else {\n+                            LOG.error(\"[{}] Failed to run health check.\", clientAppId(), ex);\n+                        }\n                     }\n                     resumeAsyncResponseExceptionally(asyncResponse, ex);\n                     return null;\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/channel/ServiceUnitStateChannelImpl.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/channel/ServiceUnitStateChannelImpl.java\nindex 49d038d512e59..ea1bf01be5b54 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/channel/ServiceUnitStateChannelImpl.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/channel/ServiceUnitStateChannelImpl.java\n@@ -87,6 +87,7 @@\n import org.apache.pulsar.broker.namespace.NamespaceService;\n import org.apache.pulsar.broker.service.BrokerServiceException;\n import org.apache.pulsar.client.admin.PulsarAdmin;\n+import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.common.naming.NamespaceBundle;\n import org.apache.pulsar.common.naming.NamespaceBundleFactory;\n@@ -1291,6 +1292,14 @@ private void handleBrokerCreationEvent(String broker) {\n                                         broker, cleanupJobs.size());\n                             }\n                         }\n+                    })\n+                    .exceptionally(e -> {\n+                        if (FutureUtil.unwrapCompletionException(e) instanceof PulsarAdminException.NotFoundException) {\n+                            log.warn(\"{} Failed to run health check: {}\", broker, e.getMessage());\n+                        } else {\n+                            log.error(\"{} Failed to run health check\", broker, e);\n+                        }\n+                        return null;\n                     });\n         }\n     }\n@@ -1323,12 +1332,19 @@ private void handleBrokerDeletionEvent(String broker) {\n         }\n     }\n \n+    private boolean channelDisabled() {\n+        final var channelState = this.channelState;\n+        if (channelState == Disabled || channelState == Closed) {\n+            log.warn(\"[{}] Skip scheduleCleanup because the state is {} now\", brokerId, channelState);\n+            return true;\n+        }\n+        return false;\n+    }\n+\n     private void scheduleCleanup(String broker, long delayInSecs) {\n         var scheduled = new MutableObject<CompletableFuture<Void>>();\n         try {\n-            final var channelState = this.channelState;\n-            if (channelState == Disabled || channelState == Closed) {\n-                log.warn(\"[{}] Skip scheduleCleanup because the state is {} now\", brokerId, channelState);\n+            if (channelDisabled()) {\n                 return;\n             }\n             cleanupJobs.computeIfAbsent(broker, k -> {\n@@ -1462,6 +1478,10 @@ private CompletableFuture<Void> healthCheckBrokerAsync(String brokerId) {\n     }\n \n     private void doHealthCheckBrokerAsyncWithRetries(String brokerId, int retry, CompletableFuture<Void> future) {\n+        if (channelDisabled()) {\n+            future.complete(null);\n+            return;\n+        }\n         try {\n             var admin = getPulsarAdmin();\n             admin.brokers().healthcheckAsync(TopicVersion.V2, Optional.of(brokerId))\n@@ -1472,7 +1492,6 @@ private void doHealthCheckBrokerAsyncWithRetries(String brokerId, int retry, Com\n                             return;\n                         }\n                         if (retry == MAX_BROKER_HEALTH_CHECK_RETRY) {\n-                            log.error(\"Failed health-check broker :{}\", brokerId, e);\n                             future.completeExceptionally(FutureUtil.unwrapCompletionException(e));\n                         } else {\n                             pulsar.getExecutor()\n@@ -1509,7 +1528,12 @@ private synchronized void doCleanup(String broker, boolean gracefully) {\n                 return;\n             } catch (Exception e) {\n                 if (debug()) {\n-                    log.info(\"Failed to check broker:{} health\", broker, e);\n+                    if (e instanceof ExecutionException\n+                            && e.getCause() instanceof PulsarAdminException.NotFoundException) {\n+                        log.info(\"The broker {} is not healthy because it's not found\", broker);\n+                    } else {\n+                        log.info(\"Failed to check broker:{} health\", broker, e);\n+                    }\n                 }\n                 log.info(\"Checked the broker:{} health. Continue the orphan bundle cleanup\", broker);\n             }\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java\nindex ca44f6bc4d6d9..c8427d1a66d53 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java\n@@ -38,7 +38,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class ExtensibleLoadManagerCloseTest {\n \n     private static final String clusterName = \"test\";\n@@ -88,14 +88,18 @@ private ServiceConfiguration brokerConfig() {\n         config.setLoadManagerClassName(ExtensibleLoadManagerImpl.class.getName());\n         config.setLoadBalancerDebugModeEnabled(true);\n         config.setBrokerShutdownTimeoutMs(100);\n+\n+        // Reduce these timeout configs to avoid failed tests being blocked too long\n+        config.setMetadataStoreOperationTimeoutSeconds(5);\n+        config.setNamespaceBundleUnloadingTimeoutMs(5000);\n         return config;\n     }\n \n \n-    @Test\n+    @Test(invocationCount = 10)\n     public void testCloseAfterLoadingBundles() throws Exception {\n         setupBrokers(3);\n-        final var topic = \"test\";\n+        final var topic = \"test-\" + System.currentTimeMillis();\n         final var admin = brokers.get(0).getAdminClient();\n         admin.topics().createPartitionedTopic(topic, 20);\n         admin.lookups().lookupPartitionedTopic(topic);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23426",
    "pr_id": 23426,
    "issue_id": 23425,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] recover from ledger incorrect when set config ledgerForceRecovery true\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nmaster\r\n\r\n### Minimal reproduce step\r\n\r\nManagedCursorTest\r\n```java\r\n    @Test(timeOut = 20000)\r\n    public void cursorPersistenceWithLedgerForceRecovery() throws Exception {\r\n        ManagedLedgerConfig config = new ManagedLedgerConfig();\r\n        config.setLedgerForceRecovery(true);\r\n\r\n        ManagedLedger ledger = factory.open(\"my_test_ledger\", config);\r\n        ManagedCursor c1 = ledger.openCursor(\"c1\");\r\n        ledger.addEntry(\"dummy-entry-1\".getBytes(Encoding));\r\n        ledger.addEntry(\"dummy-entry-2\".getBytes(Encoding));\r\n        ledger.addEntry(\"dummy-entry-3\".getBytes(Encoding));\r\n\r\n        List<Entry> entries = c1.readEntries(2);\r\n        Position p1 = entries.get(1).getPosition();\r\n        c1.markDelete(p1);\r\n        entries.forEach(Entry::release);\r\n\r\n        entries = c1.readEntries(1);\r\n        entries.forEach(Entry::release);\r\n\r\n        // Reopen\r\n        @Cleanup(\"shutdown\")\r\n        ManagedLedgerFactory factory2 = new ManagedLedgerFactoryImpl(metadataStore, bkc);\r\n        ledger = factory2.open(\"my_test_ledger\", config);\r\n        c1 = ledger.openCursor(\"c1\");\r\n\r\n        assertEquals(c1.getMarkDeletedPosition(), p1);\r\n    }\r\n```\r\n\r\n### What did you expect to see?\r\n\r\ntest pass\r\n\r\n### What did you see instead?\r\n\r\nThis test failed.\r\n```2024-10-09T16:03:34,448 - INFO  - [bookkeeper-ml-scheduler-OrderedScheduler-3-0:ManagedLedgerImpl@1496] - [my_test_ledger] Closing managed ledger\r\n\r\njava.lang.AssertionError: \r\nExpected :3:1\r\nActual   :3:-1\r\n<Click to see difference>\r\n\r\n\tat org.testng.Assert.fail(Assert.java:110)\r\n\tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n\tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n\tat org.testng.Assert.assertEquals(Assert.java:131)\r\n\tat org.testng.Assert.assertEquals(Assert.java:643)\r\n\tat org.apache.bookkeeper.mledger.impl.ManagedCursorTest.cursorPersistenceWithLedgerForceRecovery(ManagedCursorTest.java:1283)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n\tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n```\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 408,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java",
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java"
    ],
    "base_commit": "676fdb1ffb4392bb7b10b8d1e8ba94b379b25166",
    "head_commit": "79321b42e7e563365576d315d6a3f9b8e013e93a",
    "repo_url": "https://github.com/apache/pulsar/pull/23426",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23426",
    "dockerfile": "",
    "pr_merged_at": "2024-10-09T14:17:27.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\nindex f469b88cae8e6..7c0d13108b1c4 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n@@ -549,10 +549,10 @@ protected void recoverFromLedger(final ManagedCursorInfo info, final VoidCallbac\n             if (log.isInfoEnabled()) {\n                 log.info(\"[{}] Opened ledger {} for cursor {}. rc={}\", ledger.getName(), ledgerId, name, rc);\n             }\n-            if (isBkErrorNotRecoverable(rc) || ledgerForceRecovery) {\n+            if (isBkErrorNotRecoverable(rc) || (rc != BKException.Code.OK && ledgerForceRecovery)) {\n                 log.error(\"[{}] Error opening metadata ledger {} for cursor {}: {}\", ledger.getName(), ledgerId, name,\n                         BKException.getMessage(rc));\n-                // Rewind to oldest entry available\n+                // Rewind to the oldest entry available\n                 initialize(getRollbackPosition(info), Collections.emptyMap(), cursorProperties, callback);\n                 return;\n             } else if (rc != BKException.Code.OK) {\n@@ -577,10 +577,10 @@ protected void recoverFromLedger(final ManagedCursorInfo info, final VoidCallbac\n                 if (log.isDebugEnabled()) {\n                     log.debug(\"[{}} readComplete rc={} entryId={}\", ledger.getName(), rc1, lh1.getLastAddConfirmed());\n                 }\n-                if (isBkErrorNotRecoverable(rc1) || ledgerForceRecovery) {\n+                if (isBkErrorNotRecoverable(rc1) || (rc1 != BKException.Code.OK && ledgerForceRecovery)) {\n                     log.error(\"[{}] Error reading from metadata ledger {} for cursor {}: {}\", ledger.getName(),\n                             ledgerId, name, BKException.getMessage(rc1));\n-                    // Rewind to oldest entry available\n+                    // Rewind to the oldest entry available\n                     initialize(getRollbackPosition(info), Collections.emptyMap(), cursorProperties, callback);\n                     return;\n                 } else if (rc1 != BKException.Code.OK) {\n",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\nindex 8ae5a04a507b1..587f87a7d1d38 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n@@ -1255,6 +1255,34 @@ void cursorPersistence() throws Exception {\n         assertEquals(c2.getMarkDeletedPosition(), p2);\n     }\n \n+    @Test(timeOut = 20000)\n+    public void cursorPersistenceWithLedgerForceRecovery() throws Exception {\n+        ManagedLedgerConfig config = new ManagedLedgerConfig();\n+        config.setLedgerForceRecovery(true);\n+\n+        ManagedLedger ledger = factory.open(\"my_test_ledger\", config);\n+        ManagedCursor c1 = ledger.openCursor(\"c1\");\n+        ledger.addEntry(\"dummy-entry-1\".getBytes(Encoding));\n+        ledger.addEntry(\"dummy-entry-2\".getBytes(Encoding));\n+        ledger.addEntry(\"dummy-entry-3\".getBytes(Encoding));\n+\n+        List<Entry> entries = c1.readEntries(2);\n+        Position p1 = entries.get(1).getPosition();\n+        c1.markDelete(p1);\n+        entries.forEach(Entry::release);\n+\n+        entries = c1.readEntries(1);\n+        entries.forEach(Entry::release);\n+\n+        // Reopen\n+        @Cleanup(\"shutdown\")\n+        ManagedLedgerFactory factory2 = new ManagedLedgerFactoryImpl(metadataStore, bkc);\n+        ledger = factory2.open(\"my_test_ledger\", config);\n+        c1 = ledger.openCursor(\"c1\");\n+\n+        assertEquals(c1.getMarkDeletedPosition(), p1);\n+    }\n+\n     @Test(timeOut = 20000)\n     void cursorPersistence2() throws Exception {\n         ManagedLedger ledger = factory.open(\"my_test_ledger\",\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23371",
    "pr_id": 23371,
    "issue_id": 23365,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11074101345/job/30796634094?pr=23362#step:11:1686\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion  Time elapsed: 5.037 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition defined as a org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest lists don't have the same size expected [1] but found [0] within 3 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion(BrokerRegistryIntegrationTest.java:78)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:840)\r\n  Caused by: java.lang.AssertionError: lists don't have the same size expected [1] but found [0]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1629)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1605)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.lambda$testRecoverFromNodeDeletion$1(BrokerRegistryIntegrationTest.java:78)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 424,
    "test_files_count": 3,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/TableViewImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java"
    ],
    "base_commit": "5e832a1cc1441eaf8d64fe72c1a2af8829030d3d",
    "head_commit": "26edb49e7a51f26690a46869e90918c1e2d745ba",
    "repo_url": "https://github.com/apache/pulsar/pull/23371",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23371",
    "dockerfile": "",
    "pr_merged_at": "2024-09-30T06:20:33.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java\nindex 9fd0518a054cc..a13b332e6eb5f 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryImpl.java\n@@ -83,13 +83,6 @@ public BrokerRegistryImpl(PulsarService pulsar) {\n         this.brokerLookupDataMetadataCache = pulsar.getLocalMetadataStore().getMetadataCache(BrokerLookupData.class);\n         this.scheduler = pulsar.getLoadManagerExecutor();\n         this.listeners = new ArrayList<>();\n-        // The registered node is an ephemeral node that could be deleted when the metadata store client's session\n-        // is expired. In this case, we should register again.\n-        this.listeners.add((broker, notificationType) -> {\n-            if (notificationType == NotificationType.Deleted && getBrokerId().equals(broker)) {\n-                registerAsync();\n-            }\n-        });\n         this.brokerIdKeyPath = keyPath(pulsar.getBrokerId());\n         this.brokerLookupData = new BrokerLookupData(\n                 pulsar.getWebServiceAddress(),\n@@ -223,11 +216,16 @@ private void handleMetadataStoreNotification(Notification t) {\n             if (log.isDebugEnabled()) {\n                 log.debug(\"Handle notification: [{}]\", t);\n             }\n+            // The registered node is an ephemeral node that could be deleted when the metadata store client's session\n+            // is expired. In this case, we should register again.\n+            final var brokerId = t.getPath().substring(LOADBALANCE_BROKERS_ROOT.length() + 1);\n+            if (t.getType() == NotificationType.Deleted && getBrokerId().equals(brokerId)) {\n+                registerAsync();\n+            }\n             if (listeners.isEmpty()) {\n                 return;\n             }\n             this.scheduler.submit(() -> {\n-                String brokerId = t.getPath().substring(LOADBALANCE_BROKERS_ROOT.length() + 1);\n                 for (BiConsumer<String, NotificationType> listener : listeners) {\n                     listener.accept(brokerId, t.getType());\n                 }\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TableViewImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TableViewImpl.java\nindex 4f52060497864..17b49828eeced 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TableViewImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/TableViewImpl.java\n@@ -36,6 +36,7 @@\n import org.apache.pulsar.client.api.CryptoKeyReader;\n import org.apache.pulsar.client.api.Message;\n import org.apache.pulsar.client.api.MessageId;\n+import org.apache.pulsar.client.api.MessageIdAdv;\n import org.apache.pulsar.client.api.PulsarClientException;\n import org.apache.pulsar.client.api.Reader;\n import org.apache.pulsar.client.api.ReaderBuilder;\n@@ -259,7 +260,11 @@ private void handleMessage(Message<T> msg) {\n     @Override\n     public CompletableFuture<Void> refreshAsync() {\n         CompletableFuture<Void> completableFuture = new CompletableFuture<>();\n-        reader.thenCompose(reader -> getLastMessageIds(reader).thenAccept(lastMessageIds -> {\n+        reader.thenCompose(reader -> getLastMessageIdOfNonEmptyTopics(reader).thenAccept(lastMessageIds -> {\n+            if (lastMessageIds.isEmpty()) {\n+                completableFuture.complete(null);\n+                return;\n+            }\n             // After get the response of lastMessageIds, put the future and result into `refreshMap`\n             // and then filter out partitions that has been read to the lastMessageID.\n             pendingRefreshRequests.put(completableFuture, lastMessageIds);\n@@ -291,8 +296,12 @@ private CompletableFuture<Void> readAllExistingMessages(Reader<T> reader) {\n         AtomicLong messagesRead = new AtomicLong();\n \n         CompletableFuture<Void> future = new CompletableFuture<>();\n-        getLastMessageIds(reader).thenAccept(maxMessageIds -> {\n-            readAllExistingMessages(reader, future, startTime, messagesRead, maxMessageIds);\n+        getLastMessageIdOfNonEmptyTopics(reader).thenAccept(lastMessageIds -> {\n+            if (lastMessageIds.isEmpty()) {\n+                future.complete(null);\n+                return;\n+            }\n+            readAllExistingMessages(reader, future, startTime, messagesRead, lastMessageIds);\n         }).exceptionally(ex -> {\n             future.completeExceptionally(ex);\n             return null;\n@@ -300,13 +309,15 @@ private CompletableFuture<Void> readAllExistingMessages(Reader<T> reader) {\n         return future;\n     }\n \n-    private CompletableFuture<Map<String, TopicMessageId>> getLastMessageIds(Reader<T> reader) {\n+    private CompletableFuture<Map<String, TopicMessageId>> getLastMessageIdOfNonEmptyTopics(Reader<T> reader) {\n         return reader.getLastMessageIdsAsync().thenApply(lastMessageIds -> {\n-            Map<String, TopicMessageId> maxMessageIds = new ConcurrentHashMap<>();\n+            Map<String, TopicMessageId> lastMessageIdMap = new ConcurrentHashMap<>();\n             lastMessageIds.forEach(topicMessageId -> {\n-                maxMessageIds.put(topicMessageId.getOwnerTopic(), topicMessageId);\n+                if (((MessageIdAdv) topicMessageId).getEntryId() >= 0) {\n+                    lastMessageIdMap.put(topicMessageId.getOwnerTopic(), topicMessageId);\n+                } // else: a negative entry id represents an empty topic so that we don't have to read messages from it\n             });\n-            return maxMessageIds;\n+            return lastMessageIdMap;\n         });\n     }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\nindex d6615a8a5b49b..232088afb94fe 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n@@ -37,7 +37,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"flaky\")\n+@Test(groups = \"broker\")\n public class BrokerRegistryIntegrationTest {\n \n     private static final String clusterName = \"test\";\n@@ -63,13 +63,18 @@ protected void setup() throws Exception {\n \n     @AfterClass(alwaysRun = true)\n     protected void cleanup() throws Exception {\n+        final var startMs = System.currentTimeMillis();\n         if (pulsar != null) {\n             pulsar.close();\n         }\n+        final var elapsedMs = System.currentTimeMillis() - startMs;\n         bk.stop();\n+        if (elapsedMs > 5000) {\n+            throw new RuntimeException(\"Broker took \" + elapsedMs + \"ms to close\");\n+        }\n     }\n \n-    @Test(enabled = false)\n+    @Test\n     public void testRecoverFromNodeDeletion() throws Exception {\n         // Simulate the case that the node was somehow deleted (e.g. by session timeout)\n         Awaitility.await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> Assert.assertEquals(\n@@ -88,7 +93,7 @@ public void testRecoverFromNodeDeletion() throws Exception {\n         Assert.assertEquals(brokerRegistry.getAvailableBrokersAsync().get(), List.of(pulsar.getBrokerId()));\n     }\n \n-    @Test(enabled = false)\n+    @Test\n     public void testRegisterAgain() throws Exception {\n         Awaitility.await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> Assert.assertEquals(\n                 brokerRegistry.getAvailableBrokersAsync().join(), List.of(pulsar.getBrokerId())));\n@@ -105,7 +110,7 @@ public void testRegisterAgain() throws Exception {\n         });\n     }\n \n-    private ServiceConfiguration brokerConfig() {\n+    protected ServiceConfiguration brokerConfig() {\n         final var config = new ServiceConfiguration();\n         config.setClusterName(clusterName);\n         config.setAdvertisedAddress(\"localhost\");\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java\nnew file mode 100644\nindex 0000000000000..3e01b1fad0f21\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryMetadataStoreIntegrationTest.java\n@@ -0,0 +1,35 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.loadbalance.extensions;\n+\n+import org.apache.pulsar.broker.ServiceConfiguration;\n+import org.apache.pulsar.broker.loadbalance.extensions.channel.ServiceUnitStateMetadataStoreTableViewImpl;\n+import org.testng.annotations.Test;\n+\n+@Test(groups = \"broker\")\n+public class BrokerRegistryMetadataStoreIntegrationTest extends BrokerRegistryIntegrationTest {\n+\n+    @Override\n+    protected ServiceConfiguration brokerConfig() {\n+        final var config = super.brokerConfig();\n+        config.setLoadManagerServiceUnitStateTableViewClassName(\n+                ServiceUnitStateMetadataStoreTableViewImpl.class.getName());\n+        return config;\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java\nindex 61ab4de8a3294..5448751160a9c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TableViewTest.java\n@@ -173,6 +173,9 @@ public void testRefreshAPI(int partition) throws Exception {\n         TableView<byte[]> tv = pulsarClient.newTableView(Schema.BYTES)\n                 .topic(topic)\n                 .create();\n+        // Verify refresh can handle the case when the topic is empty\n+        tv.refreshAsync().get(3, TimeUnit.SECONDS);\n+\n         // 2. Add a listen action to provide the test environment.\n         // The listen action will be triggered when there are incoming messages every time.\n         // This is a sync operation, so sleep in the listen action can slow down the reading rate of messages.\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23367",
    "pr_id": 23367,
    "issue_id": 23365,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/11074101345/job/30796634094?pr=23362#step:11:1686\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n  Error:  org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion  Time elapsed: 5.037 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition defined as a org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest lists don't have the same size expected [1] but found [0] within 3 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.testRecoverFromNodeDeletion(BrokerRegistryIntegrationTest.java:78)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:840)\r\n  Caused by: java.lang.AssertionError: lists don't have the same size expected [1] but found [0]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1418)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1382)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1629)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1605)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.BrokerRegistryIntegrationTest.lambda$testRecoverFromNodeDeletion$1(BrokerRegistryIntegrationTest.java:78)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 424,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java"
    ],
    "base_commit": "95bd1d1dd3d447f0705a96092afbc9d6bd6cd1dc",
    "head_commit": "738981e9c837b29f0a942304a893b202a66993fb",
    "repo_url": "https://github.com/apache/pulsar/pull/23367",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23367",
    "dockerfile": "",
    "pr_merged_at": "2024-09-28T17:10:54.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\nindex 162ea50829d40..d6615a8a5b49b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/BrokerRegistryIntegrationTest.java\n@@ -37,7 +37,7 @@\n import org.testng.annotations.Test;\n \n @Slf4j\n-@Test(groups = \"broker\")\n+@Test(groups = \"flaky\")\n public class BrokerRegistryIntegrationTest {\n \n     private static final String clusterName = \"test\";\n@@ -69,7 +69,7 @@ protected void cleanup() throws Exception {\n         bk.stop();\n     }\n \n-    @Test\n+    @Test(enabled = false)\n     public void testRecoverFromNodeDeletion() throws Exception {\n         // Simulate the case that the node was somehow deleted (e.g. by session timeout)\n         Awaitility.await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> Assert.assertEquals(\n@@ -88,7 +88,7 @@ public void testRecoverFromNodeDeletion() throws Exception {\n         Assert.assertEquals(brokerRegistry.getAvailableBrokersAsync().get(), List.of(pulsar.getBrokerId()));\n     }\n \n-    @Test\n+    @Test(enabled = false)\n     public void testRegisterAgain() throws Exception {\n         Awaitility.await().atMost(Duration.ofSeconds(3)).untilAsserted(() -> Assert.assertEquals(\n                 brokerRegistry.getAvailableBrokersAsync().join(), List.of(pulsar.getBrokerId())));\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23329",
    "pr_id": 23329,
    "issue_id": 23215,
    "repo": "apache/pulsar",
    "problem_statement": "Replace the ConcurrentOpenHashMap as much as possible\n### PR list\r\n- [x] https://github.com/apache/pulsar/pull/23217\r\n- [x] https://github.com/apache/pulsar/pull/23320\r\n- [x] https://github.com/apache/pulsar/pull/23322\r\n- [x] https://github.com/apache/pulsar/pull/23329\r\n\r\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\nThere was a discussion at Sep. 2023 before to replace Customized Map with ConcurrentOpenHashMap. In this issue, I'd focus on the `ConcurrentOpenHashMap`.\r\n\r\nHere is the only advantage of this map.\r\n\r\n> Provides similar methods as a {@code ConcurrentMap<K,V>} but since it's an open hash map with linear probing,  no node allocations are required to store the values.\r\n\r\nLet me count the disadvantages.\r\n\r\n### 1. Bad performance\r\n\r\nThis map was aded in the initial commit (on 2016). However, this implementation was just based on the Java 7 implementation of the `ConcurrentHashMap`, which uses a segment based lock. Actually, this solution was discarded by the Java team since Java 8.\r\n\r\nhttps://github.com/apache/pulsar/pull/20647/#issuecomment-1607257960 did a benchmark and found the performance was much worse than the current `ConcurrentHashMap` provided by Java library. We can also search the PROs of the Java 8 design in network, or just ask for ChatGPT.\r\n\r\nBesides, the frequently used `keys()` and `values()` methods just copy the keys and values to a new list. While the `ConcurrentHashMap` just returns a thread-safe internal view that users can choose whether to make a copy.\r\n\r\nAnyway, to prove the performance is worse than `ConcurrentHashMap`, we need to have more tests and research. So it's the least important reason.\r\n\r\n### 2. Lack of the updates\r\n\r\nThis class was rarely updated. What I can remember is the shrink support two years ago. https://github.com/apache/pulsar/pull/14663\r\n\r\nFrom https://github.com/apache/bookkeeper/pull/3061, we can see the motivation is the frequently appeared Full GC caused by this implementation. However, adding a `shrink` method makes it harder to use. There are already many parameters to tune, see it's builder:\r\n\r\n```java\r\n    public static class Builder<K, V> {\r\n        int expectedItems = DefaultExpectedItems;\r\n        int concurrencyLevel = DefaultConcurrencyLevel;\r\n        float mapFillFactor = DefaultMapFillFactor;\r\n        float mapIdleFactor = DefaultMapIdleFactor;\r\n        float expandFactor = DefaultExpandFactor;\r\n        float shrinkFactor = DefaultShrinkFactor;\r\n        boolean autoShrink = DefaultAutoShrink;\r\n```\r\n\r\nMany `xxxFactor`s and the concurrency level. It's hard to determine a proper value by default. However, it makes new developers hard to modify it.\r\n\r\n### 3. Bad debug experience\r\n\r\nWhen I debugged the topics maintained in a `BrokerService`.\r\n\r\n<img width=\"1031\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5dfb13d9-7897-429e-ab06-4888595a06c1\">\r\n\r\nAs you can see. There are 16 sections. And I have to iterate over all these sections and expand the `table` array to find the target topic.\r\n\r\nLet's compare it with the official `ConcurrentHashMap` (I replaced it locally)\r\n\r\n<img width=\"1211\" alt=\"image\" src=\"https://github.com/user-attachments/assets/49fbb5ba-7cb0-4225-922f-737af90ef5a7\">\r\n\r\nBesides, it's even harder to analyze in the heap dump.\r\n\r\n### 4. Not friendly to new developers\r\n\r\nMany places just use it as a concurrent hash map. **What's the reason for new developers to not use the official `ConcurrentHashMap`, which is developed and consistently improved by a professional team?** Just to reduce the node allocation? With the improving JVM GC?\r\n\r\nAs I've mentioned, this class might be introduced at the Java 7 era. Now the minimum required Java version of broker side is 17. We have ZGC. We have Shenandoah GC. We have many more JVM developers developing better GC. I'm suspecting if the advantage makes sense.\r\n\r\nI cannot think of a reason to choose this hard-to-maintain class rather than well-maintained official `ConcurrentHashMap`.\r\n\r\nFor example, when I maintained KoP, I encountered the deadlock of `ConcurrentLongHashMap` (maybe the similar implementation). https://github.com/streamnative/kop/pull/620 And it's hard to know if this case is fixed. So I have to switch to the official `ConcurrentHashMap`.\r\n\r\n### Solution\r\n\r\nReplace `ConcurrentOpenHashMap` with the official Java `ConcurrentHashMap`.\r\n\r\n### Alternatives\r\n\r\nN/A\r\n\r\n### Anything else?\r\n\r\nJava Concurrent HashMap Improvements over the years https://medium.com/@vikas.taank_40391/java-concurrent-hashmap-improvements-over-the-years-8d8b7be6ce37\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 709,
    "test_files_count": 5,
    "non_test_files_count": 12,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerFactoryImpl.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/ClusterReplicationMetrics.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PartitionedProducerImpl.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerBase.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMap.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSet.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMapTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSetTest.java",
      "pulsar-websocket/src/main/java/org/apache/pulsar/websocket/WebSocketService.java",
      "pulsar-websocket/src/main/java/org/apache/pulsar/websocket/stats/ProxyStats.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMapTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSetTest.java"
    ],
    "base_commit": "1ce7855c9424b23ac357cfd1cfe89bdb6e22ea57",
    "head_commit": "5f4bfa47c07617ec4c6a0110b34c6039e4c4784c",
    "repo_url": "https://github.com/apache/pulsar/pull/23329",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23329",
    "dockerfile": "",
    "pr_merged_at": "2024-09-23T02:44:48.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerFactoryImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerFactoryImpl.java\nindex 586beb412d297..34dd3610d4ec9 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerFactoryImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerFactoryImpl.java\n@@ -104,7 +104,6 @@\n import org.apache.pulsar.common.util.DateFormatter;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.Runnables;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.metadata.api.MetadataStore;\n import org.apache.pulsar.metadata.api.Stat;\n import org.apache.pulsar.metadata.api.extended.MetadataStoreExtended;\n@@ -1207,8 +1206,7 @@ public void calculateCursorBacklogs(final TopicName topicName,\n         BookKeeper bk = getBookKeeper().get();\n         final CountDownLatch allCursorsCounter = new CountDownLatch(1);\n         final long errorInReadingCursor = -1;\n-        ConcurrentOpenHashMap<String, Long> ledgerRetryMap =\n-                ConcurrentOpenHashMap.<String, Long>newBuilder().build();\n+        final var ledgerRetryMap = new ConcurrentHashMap<String, Long>();\n \n         final MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo = ledgers.lastEntry().getValue();\n         final Position lastLedgerPosition =\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\nindex 0b1661fb9540a..b2ee299bb030e 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\n@@ -109,7 +109,6 @@\n import org.apache.pulsar.common.stats.MetricsUtil;\n import org.apache.pulsar.common.topics.TopicList;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.metadata.api.MetadataCache;\n import org.apache.pulsar.metadata.api.MetadataStoreException;\n import org.apache.pulsar.opentelemetry.annotations.PulsarDeprecatedMetric;\n@@ -150,7 +149,7 @@ public class NamespaceService implements AutoCloseable {\n     public static final String HEARTBEAT_NAMESPACE_FMT_V2 = \"pulsar/%s\";\n     public static final String SLA_NAMESPACE_FMT = SLA_NAMESPACE_PROPERTY + \"/%s/%s\";\n \n-    private final ConcurrentOpenHashMap<ClusterDataImpl, PulsarClientImpl> namespaceClients;\n+    private final Map<ClusterDataImpl, PulsarClientImpl> namespaceClients = new ConcurrentHashMap<>();\n \n     private final List<NamespaceBundleOwnershipListener> bundleOwnershipListeners;\n \n@@ -204,8 +203,6 @@ public NamespaceService(PulsarService pulsar) {\n         this.loadManager = pulsar.getLoadManager();\n         this.bundleFactory = new NamespaceBundleFactory(pulsar, Hashing.crc32());\n         this.ownershipCache = new OwnershipCache(pulsar, this);\n-        this.namespaceClients =\n-                ConcurrentOpenHashMap.<ClusterDataImpl, PulsarClientImpl>newBuilder().build();\n         this.bundleOwnershipListeners = new CopyOnWriteArrayList<>();\n         this.bundleSplitListeners = new CopyOnWriteArrayList<>();\n         this.localBrokerDataCache = pulsar.getLocalMetadataStore().getMetadataCache(LocalBrokerData.class);\n@@ -461,16 +458,10 @@ public boolean registerNamespace(NamespaceName nsname, boolean ensureOwned) thro\n         }\n     }\n \n-    private final ConcurrentOpenHashMap<NamespaceBundle, CompletableFuture<Optional<LookupResult>>>\n-            findingBundlesAuthoritative =\n-            ConcurrentOpenHashMap.<NamespaceBundle,\n-                    CompletableFuture<Optional<LookupResult>>>newBuilder()\n-                    .build();\n-    private final ConcurrentOpenHashMap<NamespaceBundle, CompletableFuture<Optional<LookupResult>>>\n-            findingBundlesNotAuthoritative =\n-            ConcurrentOpenHashMap.<NamespaceBundle,\n-                    CompletableFuture<Optional<LookupResult>>>newBuilder()\n-                    .build();\n+    private final Map<NamespaceBundle, CompletableFuture<Optional<LookupResult>>>\n+            findingBundlesAuthoritative = new ConcurrentHashMap<>();\n+    private final Map<NamespaceBundle, CompletableFuture<Optional<LookupResult>>>\n+            findingBundlesNotAuthoritative = new ConcurrentHashMap<>();\n \n     /**\n      * Main internal method to lookup and setup ownership of service unit to a broker.\n@@ -485,7 +476,7 @@ private CompletableFuture<Optional<LookupResult>> findBrokerServiceUrl(\n             LOG.debug(\"findBrokerServiceUrl: {} - options: {}\", bundle, options);\n         }\n \n-        ConcurrentOpenHashMap<NamespaceBundle, CompletableFuture<Optional<LookupResult>>> targetMap;\n+        Map<NamespaceBundle, CompletableFuture<Optional<LookupResult>>> targetMap;\n         if (options.isAuthoritative()) {\n             targetMap = findingBundlesAuthoritative;\n         } else {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\nindex e8d19d2e2eca1..dfb8b9d2edb12 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\n@@ -42,7 +42,6 @@\n import org.apache.pulsar.broker.service.Topic.PublishContext;\n import org.apache.pulsar.common.api.proto.MessageMetadata;\n import org.apache.pulsar.common.protocol.Commands;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -101,20 +100,12 @@ public MessageDupUnknownException() {\n     // Map that contains the highest sequenceId that have been sent by each producers. The map will be updated before\n     // the messages are persisted\n     @VisibleForTesting\n-    final ConcurrentOpenHashMap<String, Long> highestSequencedPushed =\n-            ConcurrentOpenHashMap.<String, Long>newBuilder()\n-                    .expectedItems(16)\n-                    .concurrencyLevel(1)\n-                    .build();\n+    final Map<String, Long> highestSequencedPushed = new ConcurrentHashMap<>();\n \n     // Map that contains the highest sequenceId that have been persistent by each producers. The map will be updated\n     // after the messages are persisted\n     @VisibleForTesting\n-    final ConcurrentOpenHashMap<String, Long> highestSequencedPersisted =\n-            ConcurrentOpenHashMap.<String, Long>newBuilder()\n-            .expectedItems(16)\n-            .concurrencyLevel(1)\n-            .build();\n+    final Map<String, Long> highestSequencedPersisted = new ConcurrentHashMap<>();\n \n     // Number of persisted entries after which to store a snapshot of the sequence ids map\n     private final int snapshotInterval;\n@@ -434,7 +425,7 @@ public void resetHighestSequenceIdPushed() {\n         }\n \n         highestSequencedPushed.clear();\n-        for (String producer : highestSequencedPersisted.keys()) {\n+        for (String producer : highestSequencedPersisted.keySet()) {\n             highestSequencedPushed.put(producer, highestSequencedPersisted.get(producer));\n         }\n     }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/ClusterReplicationMetrics.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/ClusterReplicationMetrics.java\nindex 6b274b26b57fb..828cb48be429d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/ClusterReplicationMetrics.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/ClusterReplicationMetrics.java\n@@ -20,23 +20,22 @@\n \n import java.util.ArrayList;\n import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import org.apache.pulsar.common.stats.Metrics;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n \n /**\n  */\n public class ClusterReplicationMetrics {\n     private final List<Metrics> metricsList;\n     private final String localCluster;\n-    private final ConcurrentOpenHashMap<String, ReplicationMetrics> metricsMap;\n+    private final Map<String, ReplicationMetrics> metricsMap = new ConcurrentHashMap<>();\n     public static final String SEPARATOR = \"_\";\n     public final boolean metricsEnabled;\n \n     public ClusterReplicationMetrics(String localCluster, boolean metricsEnabled) {\n         metricsList = new ArrayList<>();\n         this.localCluster = localCluster;\n-        metricsMap = ConcurrentOpenHashMap.<String, ReplicationMetrics>newBuilder()\n-                .build();\n         this.metricsEnabled = metricsEnabled;\n     }\n \n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\nindex 03256a3e139b6..111cbdb8a8ef3 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n@@ -31,6 +31,7 @@\n import java.util.Optional;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentLinkedQueue;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n@@ -67,7 +68,6 @@\n import org.apache.pulsar.common.api.proto.CommandSubscribe.SubType;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.collections.BitSetRecyclable;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.common.util.collections.GrowableArrayBlockingQueue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -88,7 +88,7 @@ public abstract class ConsumerBase<T> extends HandlerState implements Consumer<T\n     protected final ExecutorService internalPinnedExecutor;\n     protected UnAckedMessageTracker unAckedMessageTracker;\n     final GrowableArrayBlockingQueue<Message<T>> incomingMessages;\n-    protected ConcurrentOpenHashMap<MessageIdAdv, MessageIdImpl[]> unAckedChunkedMessageIdSequenceMap;\n+    protected Map<MessageIdAdv, MessageIdImpl[]> unAckedChunkedMessageIdSequenceMap = new ConcurrentHashMap<>();\n     protected final ConcurrentLinkedQueue<CompletableFuture<Message<T>>> pendingReceives;\n     protected final int maxReceiverQueueSize;\n     private volatile int currentReceiverQueueSize;\n@@ -138,8 +138,6 @@ protected ConsumerBase(PulsarClientImpl client, String topic, ConsumerConfigurat\n         this.consumerEventListener = conf.getConsumerEventListener();\n         // Always use growable queue since items can exceed the advertised size\n         this.incomingMessages = new GrowableArrayBlockingQueue<>();\n-        this.unAckedChunkedMessageIdSequenceMap =\n-                ConcurrentOpenHashMap.<MessageIdAdv, MessageIdImpl[]>newBuilder().build();\n         this.executorProvider = executorProvider;\n         this.messageListenerExecutor = conf.getMessageListenerExecutor() == null\n                 ? (conf.getSubscriptionType() == SubscriptionType.Key_Shared\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\nindex 60b9d145c4897..03ccbae01c276 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerImpl.java\n@@ -130,7 +130,6 @@\n import org.apache.pulsar.common.util.SafeCollectionUtils;\n import org.apache.pulsar.common.util.collections.BitSetRecyclable;\n import org.apache.pulsar.common.util.collections.ConcurrentBitSetRecyclable;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.common.util.collections.GrowableArrayBlockingQueue;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -207,8 +206,7 @@ public class ConsumerImpl<T> extends ConsumerBase<T> implements ConnectionHandle\n \n     protected volatile boolean paused;\n \n-    protected ConcurrentOpenHashMap<String, ChunkedMessageCtx> chunkedMessagesMap =\n-            ConcurrentOpenHashMap.<String, ChunkedMessageCtx>newBuilder().build();\n+    protected Map<String, ChunkedMessageCtx> chunkedMessagesMap = new ConcurrentHashMap<>();\n     private int pendingChunkedMessageCount = 0;\n     protected long expireTimeOfIncompleteChunkedMessageMillis = 0;\n     private final AtomicBoolean expireChunkMessageTaskScheduled = new AtomicBoolean(false);\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/PartitionedProducerImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/PartitionedProducerImpl.java\nindex bf7f1066173f6..2dc826d9e3af3 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/PartitionedProducerImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/PartitionedProducerImpl.java\n@@ -27,9 +27,11 @@\n import java.util.Collections;\n import java.util.Comparator;\n import java.util.List;\n+import java.util.Map;\n import java.util.Objects;\n import java.util.Optional;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ThreadLocalRandom;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n@@ -52,7 +54,6 @@\n import org.apache.pulsar.client.impl.transaction.TransactionImpl;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -60,7 +61,7 @@ public class PartitionedProducerImpl<T> extends ProducerBase<T> {\n \n     private static final Logger log = LoggerFactory.getLogger(PartitionedProducerImpl.class);\n \n-    private final ConcurrentOpenHashMap<Integer, ProducerImpl<T>> producers;\n+    private final Map<Integer, ProducerImpl<T>> producers = new ConcurrentHashMap<>();\n     private final MessageRouter routerPolicy;\n     private final PartitionedTopicProducerStatsRecorderImpl stats;\n     private TopicMetadata topicMetadata;\n@@ -76,8 +77,6 @@ public PartitionedProducerImpl(PulsarClientImpl client, String topic, ProducerCo\n                                    int numPartitions, CompletableFuture<Producer<T>> producerCreatedFuture,\n                                    Schema<T> schema, ProducerInterceptors interceptors) {\n         super(client, topic, conf, producerCreatedFuture, schema, interceptors);\n-        this.producers =\n-                ConcurrentOpenHashMap.<Integer, ProducerImpl<T>>newBuilder().build();\n         this.topicMetadata = new TopicMetadataImpl(numPartitions);\n         this.routerPolicy = getMessageRouter();\n         stats = client.getConfiguration().getStatsIntervalSeconds() > 0\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerBase.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerBase.java\nindex 7dc5f78398434..12e380fdd510c 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerBase.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerBase.java\n@@ -19,7 +19,9 @@\n package org.apache.pulsar.client.impl;\n \n import static com.google.common.base.Preconditions.checkArgument;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import org.apache.pulsar.client.api.Message;\n import org.apache.pulsar.client.api.MessageId;\n import org.apache.pulsar.client.api.Producer;\n@@ -32,7 +34,6 @@\n import org.apache.pulsar.client.impl.transaction.TransactionImpl;\n import org.apache.pulsar.common.protocol.schema.SchemaHash;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n \n public abstract class ProducerBase<T> extends HandlerState implements Producer<T> {\n \n@@ -40,7 +41,7 @@ public abstract class ProducerBase<T> extends HandlerState implements Producer<T\n     protected final ProducerConfigurationData conf;\n     protected final Schema<T> schema;\n     protected final ProducerInterceptors interceptors;\n-    protected final ConcurrentOpenHashMap<SchemaHash, byte[]> schemaCache;\n+    protected final Map<SchemaHash, byte[]> schemaCache = new ConcurrentHashMap<>();\n     protected volatile MultiSchemaMode multiSchemaMode = MultiSchemaMode.Auto;\n \n     protected ProducerBase(PulsarClientImpl client, String topic, ProducerConfigurationData conf,\n@@ -50,8 +51,6 @@ protected ProducerBase(PulsarClientImpl client, String topic, ProducerConfigurat\n         this.conf = conf;\n         this.schema = schema;\n         this.interceptors = interceptors;\n-        this.schemaCache =\n-                ConcurrentOpenHashMap.<SchemaHash, byte[]>newBuilder().build();\n         if (!conf.isMultiSchema()) {\n             multiSchemaMode = MultiSchemaMode.Disabled;\n         }\n\ndiff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMap.java b/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMap.java\ndeleted file mode 100644\nindex 7f0dbb4379265..0000000000000\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMap.java\n+++ /dev/null\n@@ -1,658 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-package org.apache.pulsar.common.util.collections;\n-\n-import static com.google.common.base.Preconditions.checkArgument;\n-import static java.util.Objects.requireNonNull;\n-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.List;\n-import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n-import java.util.concurrent.locks.StampedLock;\n-import java.util.function.BiConsumer;\n-import java.util.function.Function;\n-\n-/**\n- * Concurrent hash map.\n- *\n- * <p>Provides similar methods as a {@code ConcurrentMap<K,V>} but since it's an open hash map with linear probing,\n- * no node allocations are required to store the values.\n- *\n- * <br>\n- * <b>WARN: method forEach do not guarantee thread safety, nor do the keys and values method.</b>\n- * <br>\n- * The forEach method is specifically designed for single-threaded usage. When iterating over a map\n- * with concurrent writes, it becomes possible for new values to be either observed or not observed.\n- * There is no guarantee that if we write value1 and value2, and are able to see value2, then we will also see value1.\n- * In some cases, it is even possible to encounter two mappings with the same key,\n- * leading the keys method to return a List containing two identical keys.\n- *\n- * <br>\n- * It is crucial to understand that the results obtained from aggregate status methods such as keys and values\n- * are typically reliable only when the map is not undergoing concurrent updates from other threads.\n- * When concurrent updates are involved, the results of these methods reflect transient states\n- * that may be suitable for monitoring or estimation purposes, but not for program control.\n- * @param <V>\n- */\n-@SuppressWarnings(\"unchecked\")\n-public class ConcurrentOpenHashMap<K, V> {\n-\n-    private static final Object EmptyKey = null;\n-    private static final Object DeletedKey = new Object();\n-    private static final ConcurrentOpenHashMap EmptyMap = new ConcurrentOpenHashMap<>(1, 1);\n-\n-    /**\n-     * This object is used to delete empty value in this map.\n-     * EmptyValue.equals(null) = true.\n-     */\n-    private static final Object EmptyValue = new Object() {\n-\n-        @SuppressFBWarnings\n-        @Override\n-        public boolean equals(Object obj) {\n-            return obj == null;\n-        }\n-\n-        /**\n-         * This is just for avoiding spotbugs errors\n-         */\n-        @Override\n-        public int hashCode() {\n-            return super.hashCode();\n-        }\n-    };\n-\n-    private static final int DefaultExpectedItems = 256;\n-    private static final int DefaultConcurrencyLevel = 16;\n-\n-    private static final float DefaultMapFillFactor = 0.66f;\n-    private static final float DefaultMapIdleFactor = 0.15f;\n-\n-    private static final float DefaultExpandFactor = 2;\n-    private static final float DefaultShrinkFactor = 2;\n-\n-    private static final boolean DefaultAutoShrink = false;\n-\n-    private final Section<K, V>[] sections;\n-\n-    public static <K, V> Builder<K, V> newBuilder() {\n-        return new Builder<>();\n-    }\n-\n-    /**\n-     * Builder of ConcurrentOpenHashMap.\n-     */\n-    public static class Builder<K, V> {\n-        int expectedItems = DefaultExpectedItems;\n-        int concurrencyLevel = DefaultConcurrencyLevel;\n-        float mapFillFactor = DefaultMapFillFactor;\n-        float mapIdleFactor = DefaultMapIdleFactor;\n-        float expandFactor = DefaultExpandFactor;\n-        float shrinkFactor = DefaultShrinkFactor;\n-        boolean autoShrink = DefaultAutoShrink;\n-\n-        public Builder<K, V> expectedItems(int expectedItems) {\n-            this.expectedItems = expectedItems;\n-            return this;\n-        }\n-\n-        public Builder<K, V> concurrencyLevel(int concurrencyLevel) {\n-            this.concurrencyLevel = concurrencyLevel;\n-            return this;\n-        }\n-\n-        public Builder<K, V> mapFillFactor(float mapFillFactor) {\n-            this.mapFillFactor = mapFillFactor;\n-            return this;\n-        }\n-\n-        public Builder<K, V> mapIdleFactor(float mapIdleFactor) {\n-            this.mapIdleFactor = mapIdleFactor;\n-            return this;\n-        }\n-\n-        public Builder<K, V> expandFactor(float expandFactor) {\n-            this.expandFactor = expandFactor;\n-            return this;\n-        }\n-\n-        public Builder<K, V> shrinkFactor(float shrinkFactor) {\n-            this.shrinkFactor = shrinkFactor;\n-            return this;\n-        }\n-\n-        public Builder<K, V> autoShrink(boolean autoShrink) {\n-            this.autoShrink = autoShrink;\n-            return this;\n-        }\n-\n-        public ConcurrentOpenHashMap<K, V> build() {\n-            return new ConcurrentOpenHashMap<>(expectedItems, concurrencyLevel,\n-                    mapFillFactor, mapIdleFactor, autoShrink, expandFactor, shrinkFactor);\n-        }\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashMap() {\n-        this(DefaultExpectedItems);\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashMap(int expectedItems) {\n-        this(expectedItems, DefaultConcurrencyLevel);\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashMap(int expectedItems, int concurrencyLevel) {\n-        this(expectedItems, concurrencyLevel, DefaultMapFillFactor, DefaultMapIdleFactor,\n-                DefaultAutoShrink, DefaultExpandFactor, DefaultShrinkFactor);\n-    }\n-\n-    public ConcurrentOpenHashMap(int expectedItems, int concurrencyLevel,\n-                                 float mapFillFactor, float mapIdleFactor,\n-                                 boolean autoShrink, float expandFactor, float shrinkFactor) {\n-        checkArgument(expectedItems > 0);\n-        checkArgument(concurrencyLevel > 0);\n-        checkArgument(expectedItems >= concurrencyLevel);\n-        checkArgument(mapFillFactor > 0 && mapFillFactor < 1);\n-        checkArgument(mapIdleFactor > 0 && mapIdleFactor < 1);\n-        checkArgument(mapFillFactor > mapIdleFactor);\n-        checkArgument(expandFactor > 1);\n-        checkArgument(shrinkFactor > 1);\n-\n-        int numSections = concurrencyLevel;\n-        int perSectionExpectedItems = expectedItems / numSections;\n-        int perSectionCapacity = (int) (perSectionExpectedItems / mapFillFactor);\n-        this.sections = (Section<K, V>[]) new Section[numSections];\n-\n-        for (int i = 0; i < numSections; i++) {\n-            sections[i] = new Section<>(perSectionCapacity, mapFillFactor, mapIdleFactor,\n-                    autoShrink, expandFactor, shrinkFactor);\n-        }\n-    }\n-\n-    public static <K, V> ConcurrentOpenHashMap<K, V> emptyMap() {\n-        return (ConcurrentOpenHashMap<K, V>) EmptyMap;\n-    }\n-\n-    long getUsedBucketCount() {\n-        long usedBucketCount = 0;\n-        for (Section<K, V> s : sections) {\n-            usedBucketCount += s.usedBuckets;\n-        }\n-        return usedBucketCount;\n-    }\n-\n-    public long size() {\n-        long size = 0;\n-        for (Section<K, V> s : sections) {\n-            size += s.size;\n-        }\n-        return size;\n-    }\n-\n-    public long capacity() {\n-        long capacity = 0;\n-        for (Section<K, V> s : sections) {\n-            capacity += s.capacity;\n-        }\n-        return capacity;\n-    }\n-\n-    public boolean isEmpty() {\n-        for (Section<K, V> s : sections) {\n-            if (s.size != 0) {\n-                return false;\n-            }\n-        }\n-\n-        return true;\n-    }\n-\n-    public V get(K key) {\n-        requireNonNull(key);\n-        long h = hash(key);\n-        return getSection(h).get(key, (int) h);\n-    }\n-\n-    public boolean containsKey(K key) {\n-        return get(key) != null;\n-    }\n-\n-    public V put(K key, V value) {\n-        requireNonNull(key);\n-        requireNonNull(value);\n-        long h = hash(key);\n-        return getSection(h).put(key, value, (int) h, false, null);\n-    }\n-\n-    public V putIfAbsent(K key, V value) {\n-        requireNonNull(key);\n-        requireNonNull(value);\n-        long h = hash(key);\n-        return getSection(h).put(key, value, (int) h, true, null);\n-    }\n-\n-    public V computeIfAbsent(K key, Function<K, V> provider) {\n-        requireNonNull(key);\n-        requireNonNull(provider);\n-        long h = hash(key);\n-        return getSection(h).put(key, null, (int) h, true, provider);\n-    }\n-\n-    public V remove(K key) {\n-        requireNonNull(key);\n-        long h = hash(key);\n-        return getSection(h).remove(key, null, (int) h);\n-    }\n-\n-    public boolean remove(K key, Object value) {\n-        requireNonNull(key);\n-        requireNonNull(value);\n-        long h = hash(key);\n-        return getSection(h).remove(key, value, (int) h) != null;\n-    }\n-\n-    public void removeNullValue(K key) {\n-        remove(key, EmptyValue);\n-    }\n-\n-    private Section<K, V> getSection(long hash) {\n-        // Use 32 msb out of long to get the section\n-        final int sectionIdx = (int) (hash >>> 32) & (sections.length - 1);\n-        return sections[sectionIdx];\n-    }\n-\n-    public void clear() {\n-        for (int i = 0; i < sections.length; i++) {\n-            sections[i].clear();\n-        }\n-    }\n-\n-    /**\n-     * Iterate over all the entries in the map and apply the processor function to each of them.\n-     * <p>\n-     * <b>Warning: Do Not Guarantee Thread-Safety.</b>\n-     * @param processor the function to apply to each entry\n-     */\n-    public void forEach(BiConsumer<? super K, ? super V> processor) {\n-        for (int i = 0; i < sections.length; i++) {\n-            sections[i].forEach(processor);\n-        }\n-    }\n-\n-    /**\n-     * @return a new list of all keys (makes a copy)\n-     */\n-    public List<K> keys() {\n-        List<K> keys = new ArrayList<>((int) size());\n-        forEach((key, value) -> keys.add(key));\n-        return keys;\n-    }\n-\n-    public List<V> values() {\n-        List<V> values = new ArrayList<>((int) size());\n-        forEach((key, value) -> values.add(value));\n-        return values;\n-    }\n-\n-    // A section is a portion of the hash map that is covered by a single\n-    @SuppressWarnings(\"serial\")\n-    private static final class Section<K, V> extends StampedLock {\n-        // Each item take up 2 continuous array space.\n-        private static final int ITEM_SIZE = 2;\n-\n-        // Keys and values are stored interleaved in the table array\n-        private volatile Object[] table;\n-\n-        private volatile int capacity;\n-        private final int initCapacity;\n-        private static final AtomicIntegerFieldUpdater<Section> SIZE_UPDATER =\n-                AtomicIntegerFieldUpdater.newUpdater(Section.class, \"size\");\n-        private volatile int size;\n-        private int usedBuckets;\n-        private int resizeThresholdUp;\n-        private int resizeThresholdBelow;\n-        private final float mapFillFactor;\n-        private final float mapIdleFactor;\n-        private final float expandFactor;\n-        private final float shrinkFactor;\n-        private final boolean autoShrink;\n-\n-        Section(int capacity, float mapFillFactor, float mapIdleFactor, boolean autoShrink,\n-                float expandFactor, float shrinkFactor) {\n-            this.capacity = alignToPowerOfTwo(capacity);\n-            this.initCapacity = this.capacity;\n-            this.table = new Object[ITEM_SIZE * this.capacity];\n-            this.size = 0;\n-            this.usedBuckets = 0;\n-            this.autoShrink = autoShrink;\n-            this.mapFillFactor = mapFillFactor;\n-            this.mapIdleFactor = mapIdleFactor;\n-            this.expandFactor = expandFactor;\n-            this.shrinkFactor = shrinkFactor;\n-            this.resizeThresholdUp = (int) (this.capacity * mapFillFactor);\n-            this.resizeThresholdBelow = (int) (this.capacity * mapIdleFactor);\n-        }\n-\n-        V get(K key, int keyHash) {\n-            long stamp = tryOptimisticRead();\n-            boolean acquiredLock = false;\n-\n-            // add local variable here, so OutOfBound won't happen\n-            Object[] table = this.table;\n-            // calculate table.length / 2 as capacity to avoid rehash changing capacity\n-            int bucket = signSafeMod(keyHash, table.length / ITEM_SIZE);\n-\n-            try {\n-                while (true) {\n-                    // First try optimistic locking\n-                    K storedKey = (K) table[bucket];\n-                    V storedValue = (V) table[bucket + 1];\n-\n-                    if (!acquiredLock && validate(stamp)) {\n-                        // The values we have read are consistent\n-                        if (key.equals(storedKey)) {\n-                            return storedValue;\n-                        } else if (storedKey == EmptyKey) {\n-                            // Not found\n-                            return null;\n-                        }\n-                    } else {\n-                        // Fallback to acquiring read lock\n-                        if (!acquiredLock) {\n-                            stamp = readLock();\n-                            acquiredLock = true;\n-\n-                            // update local variable\n-                            table = this.table;\n-                            bucket = signSafeMod(keyHash, table.length / ITEM_SIZE);\n-                            storedKey = (K) table[bucket];\n-                            storedValue = (V) table[bucket + 1];\n-                        }\n-\n-                        if (key.equals(storedKey)) {\n-                            return storedValue;\n-                        } else if (storedKey == EmptyKey) {\n-                            // Not found\n-                            return null;\n-                        }\n-                    }\n-\n-                    bucket = (bucket + ITEM_SIZE) & (table.length - 1);\n-                }\n-            } finally {\n-                if (acquiredLock) {\n-                    unlockRead(stamp);\n-                }\n-            }\n-        }\n-\n-        V put(K key, V value, int keyHash, boolean onlyIfAbsent, Function<K, V> valueProvider) {\n-            long stamp = writeLock();\n-            int bucket = signSafeMod(keyHash, capacity);\n-\n-            // Remember where we find the first available spot\n-            int firstDeletedKey = -1;\n-\n-            try {\n-                while (true) {\n-                    K storedKey = (K) table[bucket];\n-                    V storedValue = (V) table[bucket + 1];\n-\n-                    if (key.equals(storedKey)) {\n-                        if (!onlyIfAbsent) {\n-                            // Over written an old value for same key\n-                            table[bucket + 1] = value;\n-                            return storedValue;\n-                        } else {\n-                            return storedValue;\n-                        }\n-                    } else if (storedKey == EmptyKey) {\n-                        // Found an empty bucket. This means the key is not in the map. If we've already seen a deleted\n-                        // key, we should write at that position\n-                        if (firstDeletedKey != -1) {\n-                            bucket = firstDeletedKey;\n-                        } else {\n-                            ++usedBuckets;\n-                        }\n-\n-                        if (value == null) {\n-                            value = valueProvider.apply(key);\n-                        }\n-\n-                        table[bucket] = key;\n-                        table[bucket + 1] = value;\n-                        SIZE_UPDATER.incrementAndGet(this);\n-                        return valueProvider != null ? value : null;\n-                    } else if (storedKey == DeletedKey) {\n-                        // The bucket contained a different deleted key\n-                        if (firstDeletedKey == -1) {\n-                            firstDeletedKey = bucket;\n-                        }\n-                    }\n-\n-                    bucket = (bucket + ITEM_SIZE) & (table.length - 1);\n-                }\n-            } finally {\n-                if (usedBuckets > resizeThresholdUp) {\n-                    try {\n-                        // Expand the hashmap\n-                        int newCapacity = alignToPowerOfTwo((int) (capacity * expandFactor));\n-                        rehash(newCapacity);\n-                    } finally {\n-                        unlockWrite(stamp);\n-                    }\n-                } else {\n-                    unlockWrite(stamp);\n-                }\n-            }\n-        }\n-\n-        private V remove(K key, Object value, int keyHash) {\n-            long stamp = writeLock();\n-            int bucket = signSafeMod(keyHash, capacity);\n-\n-            try {\n-                while (true) {\n-                    K storedKey = (K) table[bucket];\n-                    V storedValue = (V) table[bucket + 1];\n-                    if (key.equals(storedKey)) {\n-                        if (value == null || value.equals(storedValue)) {\n-                            SIZE_UPDATER.decrementAndGet(this);\n-\n-                            int nextInArray = (bucket + ITEM_SIZE) & (table.length - 1);\n-                            if (table[nextInArray] == EmptyKey) {\n-                                table[bucket] = EmptyKey;\n-                                table[bucket + 1] = null;\n-                                --usedBuckets;\n-\n-                                // Cleanup all the buckets that were in `DeletedKey` state,\n-                                // so that we can reduce unnecessary expansions\n-                                int lastBucket = (bucket - ITEM_SIZE) & (table.length - 1);\n-                                while (table[lastBucket] == DeletedKey) {\n-                                    table[lastBucket] = EmptyKey;\n-                                    table[lastBucket + 1] = null;\n-                                    --usedBuckets;\n-\n-                                    lastBucket = (lastBucket - ITEM_SIZE) & (table.length - 1);\n-                                }\n-                            } else {\n-                                table[bucket] = DeletedKey;\n-                                table[bucket + 1] = null;\n-                            }\n-\n-                            return storedValue;\n-                        } else {\n-                            return null;\n-                        }\n-                    } else if (storedKey == EmptyKey) {\n-                        // Key wasn't found\n-                        return null;\n-                    }\n-\n-                    bucket = (bucket + ITEM_SIZE) & (table.length - 1);\n-                }\n-\n-            } finally {\n-                if (autoShrink && size < resizeThresholdBelow) {\n-                    try {\n-                        // Shrinking must at least ensure initCapacity,\n-                        // so as to avoid frequent shrinking and expansion near initCapacity,\n-                        // frequent shrinking and expansion,\n-                        // additionally opened arrays will consume more memory and affect GC\n-                        int newCapacity = Math.max(alignToPowerOfTwo((int) (capacity / shrinkFactor)), initCapacity);\n-                        int newResizeThresholdUp = (int) (newCapacity * mapFillFactor);\n-                        if (newCapacity < capacity && newResizeThresholdUp > size) {\n-                            // shrink the hashmap\n-                            rehash(newCapacity);\n-                        }\n-                    } finally {\n-                        unlockWrite(stamp);\n-                    }\n-                } else {\n-                    unlockWrite(stamp);\n-                }\n-            }\n-        }\n-\n-        void clear() {\n-            long stamp = writeLock();\n-\n-            try {\n-                if (autoShrink && capacity > initCapacity) {\n-                    shrinkToInitCapacity();\n-                } else {\n-                    Arrays.fill(table, EmptyKey);\n-                    this.size = 0;\n-                    this.usedBuckets = 0;\n-                }\n-            } finally {\n-                unlockWrite(stamp);\n-            }\n-        }\n-\n-        public void forEach(BiConsumer<? super K, ? super V> processor) {\n-            // Take a reference to the data table, if there is a rehashing event, we'll be\n-            // simply iterating over a snapshot of the data.\n-            Object[] table = this.table;\n-\n-            // Go through all the buckets for this section. We try to renew the stamp only after a validation\n-            // error, otherwise we keep going with the same.\n-            long stamp = 0;\n-            for (int bucket = 0; bucket < table.length; bucket += ITEM_SIZE) {\n-                if (stamp == 0) {\n-                    stamp = tryOptimisticRead();\n-                }\n-\n-                K storedKey = (K) table[bucket];\n-                V storedValue = (V) table[bucket + 1];\n-\n-                if (!validate(stamp)) {\n-                    // Fallback to acquiring read lock\n-                    stamp = readLock();\n-\n-                    try {\n-                        storedKey = (K) table[bucket];\n-                        storedValue = (V) table[bucket + 1];\n-                    } finally {\n-                        unlockRead(stamp);\n-                    }\n-\n-                    stamp = 0;\n-                }\n-\n-                if (storedKey != DeletedKey && storedKey != EmptyKey) {\n-                    processor.accept(storedKey, storedValue);\n-                }\n-            }\n-        }\n-\n-        private void rehash(int newCapacity) {\n-            // Expand the hashmap\n-            Object[] newTable = new Object[ITEM_SIZE * newCapacity];\n-\n-            // Re-hash table\n-            for (int i = 0; i < table.length; i += ITEM_SIZE) {\n-                K storedKey = (K) table[i];\n-                V storedValue = (V) table[i + 1];\n-                if (storedKey != EmptyKey && storedKey != DeletedKey) {\n-                    insertKeyValueNoLock(newTable, newCapacity, storedKey, storedValue);\n-                }\n-            }\n-\n-            table = newTable;\n-            capacity = newCapacity;\n-            usedBuckets = size;\n-            resizeThresholdUp = (int) (capacity * mapFillFactor);\n-            resizeThresholdBelow = (int) (capacity * mapIdleFactor);\n-        }\n-\n-        private void shrinkToInitCapacity() {\n-            Object[] newTable = new Object[ITEM_SIZE * initCapacity];\n-\n-            table = newTable;\n-            size = 0;\n-            usedBuckets = 0;\n-            // Capacity needs to be updated after the values, so that we won't see\n-            // a capacity value bigger than the actual array size\n-            capacity = initCapacity;\n-            resizeThresholdUp = (int) (capacity * mapFillFactor);\n-            resizeThresholdBelow = (int) (capacity * mapIdleFactor);\n-        }\n-\n-        private static <K, V> void insertKeyValueNoLock(Object[] table, int capacity, K key, V value) {\n-            int bucket = signSafeMod(hash(key), capacity);\n-\n-            while (true) {\n-                K storedKey = (K) table[bucket];\n-\n-                if (storedKey == EmptyKey) {\n-                    // The bucket is empty, so we can use it\n-                    table[bucket] = key;\n-                    table[bucket + 1] = value;\n-                    return;\n-                }\n-\n-                bucket = (bucket + ITEM_SIZE) & (table.length - 1);\n-            }\n-        }\n-    }\n-\n-    private static final long HashMixer = 0xc6a4a7935bd1e995L;\n-    private static final int R = 47;\n-\n-    static final <K> long hash(K key) {\n-        long hash = key.hashCode() * HashMixer;\n-        hash ^= hash >>> R;\n-        hash *= HashMixer;\n-        return hash;\n-    }\n-\n-    static final int signSafeMod(long n, int max) {\n-        // as the ITEM_SIZE of Section is 2, so the index is the multiple of 2\n-        // that is to left shift 1 bit\n-        return (int) (n & (max - 1)) << 1;\n-    }\n-\n-    private static int alignToPowerOfTwo(int n) {\n-        return (int) Math.pow(2, 32 - Integer.numberOfLeadingZeros(n - 1));\n-    }\n-}\n\ndiff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSet.java b/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSet.java\ndeleted file mode 100644\nindex 0a9f802037bce..0000000000000\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSet.java\n+++ /dev/null\n@@ -1,622 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-package org.apache.pulsar.common.util.collections;\n-\n-import static com.google.common.base.Preconditions.checkArgument;\n-import static java.util.Objects.requireNonNull;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.List;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n-import java.util.concurrent.locks.StampedLock;\n-import java.util.function.Consumer;\n-import java.util.function.Predicate;\n-\n-/**\n- * Concurrent hash set.\n- *\n- * <p>Provides similar methods as a {@code ConcurrentMap<K,V>} but since it's an open hash map with linear probing,\n- * no node allocations are required to store the values.\n- *\n- * <br>\n- * <b>WARN: method forEach do not guarantee thread safety, nor does the values method.</b>\n- * <br>\n- * The forEach method is specifically designed for single-threaded usage. When iterating over a set\n- * with concurrent writes, it becomes possible for new values to be either observed or not observed.\n- * There is no guarantee that if we write value1 and value2, and are able to see value2, then we will also see value1.\n- *\n- * <br>\n- * It is crucial to understand that the results obtained from aggregate status methods such as values\n- * are typically reliable only when the map is not undergoing concurrent updates from other threads.\n- * When concurrent updates are involved, the results of these methods reflect transient states\n- * that may be suitable for monitoring or estimation purposes, but not for program control.\n- * @param <V>\n- */\n-@SuppressWarnings(\"unchecked\")\n-public class ConcurrentOpenHashSet<V> {\n-\n-    private static final Object EmptyValue = null;\n-    private static final Object DeletedValue = new Object();\n-\n-    private static final int DefaultExpectedItems = 256;\n-    private static final int DefaultConcurrencyLevel = 16;\n-\n-    private static final float DefaultMapFillFactor = 0.66f;\n-    private static final float DefaultMapIdleFactor = 0.15f;\n-\n-    private static final float DefaultExpandFactor = 2;\n-    private static final float DefaultShrinkFactor = 2;\n-\n-    private static final boolean DefaultAutoShrink = false;\n-\n-    private final Section<V>[] sections;\n-\n-    public static <V> Builder<V> newBuilder() {\n-        return new Builder<>();\n-    }\n-\n-    /**\n-     * Builder of ConcurrentOpenHashSet.\n-     */\n-    public static class Builder<V> {\n-        int expectedItems = DefaultExpectedItems;\n-        int concurrencyLevel = DefaultConcurrencyLevel;\n-        float mapFillFactor = DefaultMapFillFactor;\n-        float mapIdleFactor = DefaultMapIdleFactor;\n-        float expandFactor = DefaultExpandFactor;\n-        float shrinkFactor = DefaultShrinkFactor;\n-        boolean autoShrink = DefaultAutoShrink;\n-\n-        public Builder<V> expectedItems(int expectedItems) {\n-            this.expectedItems = expectedItems;\n-            return this;\n-        }\n-\n-        public Builder<V> concurrencyLevel(int concurrencyLevel) {\n-            this.concurrencyLevel = concurrencyLevel;\n-            return this;\n-        }\n-\n-        public Builder<V> mapFillFactor(float mapFillFactor) {\n-            this.mapFillFactor = mapFillFactor;\n-            return this;\n-        }\n-\n-        public Builder<V> mapIdleFactor(float mapIdleFactor) {\n-            this.mapIdleFactor = mapIdleFactor;\n-            return this;\n-        }\n-\n-        public Builder<V> expandFactor(float expandFactor) {\n-            this.expandFactor = expandFactor;\n-            return this;\n-        }\n-\n-        public Builder<V> shrinkFactor(float shrinkFactor) {\n-            this.shrinkFactor = shrinkFactor;\n-            return this;\n-        }\n-\n-        public Builder<V> autoShrink(boolean autoShrink) {\n-            this.autoShrink = autoShrink;\n-            return this;\n-        }\n-\n-        public ConcurrentOpenHashSet<V> build() {\n-            return new ConcurrentOpenHashSet<>(expectedItems, concurrencyLevel,\n-                    mapFillFactor, mapIdleFactor, autoShrink, expandFactor, shrinkFactor);\n-        }\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashSet() {\n-        this(DefaultExpectedItems);\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashSet(int expectedItems) {\n-        this(expectedItems, DefaultConcurrencyLevel);\n-    }\n-\n-    @Deprecated\n-    public ConcurrentOpenHashSet(int expectedItems, int concurrencyLevel) {\n-        this(expectedItems, concurrencyLevel, DefaultMapFillFactor, DefaultMapIdleFactor,\n-                DefaultAutoShrink, DefaultExpandFactor, DefaultShrinkFactor);\n-    }\n-\n-    public ConcurrentOpenHashSet(int expectedItems, int concurrencyLevel,\n-                                 float mapFillFactor, float mapIdleFactor,\n-                                 boolean autoShrink, float expandFactor, float shrinkFactor) {\n-        checkArgument(expectedItems > 0);\n-        checkArgument(concurrencyLevel > 0);\n-        checkArgument(expectedItems >= concurrencyLevel);\n-        checkArgument(mapFillFactor > 0 && mapFillFactor < 1);\n-        checkArgument(mapIdleFactor > 0 && mapIdleFactor < 1);\n-        checkArgument(mapFillFactor > mapIdleFactor);\n-        checkArgument(expandFactor > 1);\n-        checkArgument(shrinkFactor > 1);\n-\n-        int numSections = concurrencyLevel;\n-        int perSectionExpectedItems = expectedItems / numSections;\n-        int perSectionCapacity = (int) (perSectionExpectedItems / mapFillFactor);\n-        this.sections = (Section<V>[]) new Section[numSections];\n-\n-        for (int i = 0; i < numSections; i++) {\n-            sections[i] = new Section<>(perSectionCapacity, mapFillFactor, mapIdleFactor,\n-                    autoShrink, expandFactor, shrinkFactor);\n-        }\n-    }\n-\n-    long getUsedBucketCount() {\n-        long usedBucketCount = 0;\n-        for (Section<V> s : sections) {\n-            usedBucketCount += s.usedBuckets;\n-        }\n-        return usedBucketCount;\n-    }\n-\n-    public long size() {\n-        long size = 0;\n-        for (int i = 0; i < sections.length; i++) {\n-            size += sections[i].size;\n-        }\n-        return size;\n-    }\n-\n-    public long capacity() {\n-        long capacity = 0;\n-        for (int i = 0; i < sections.length; i++) {\n-            capacity += sections[i].capacity;\n-        }\n-        return capacity;\n-    }\n-\n-    public boolean isEmpty() {\n-        for (int i = 0; i < sections.length; i++) {\n-            if (sections[i].size != 0) {\n-                return false;\n-            }\n-        }\n-\n-        return true;\n-    }\n-\n-    public boolean contains(V value) {\n-        requireNonNull(value);\n-        long h = hash(value);\n-        return getSection(h).contains(value, (int) h);\n-    }\n-\n-    public boolean add(V value) {\n-        requireNonNull(value);\n-        long h = hash(value);\n-        return getSection(h).add(value, (int) h);\n-    }\n-\n-    public boolean remove(V value) {\n-        requireNonNull(value);\n-        long h = hash(value);\n-        return getSection(h).remove(value, (int) h);\n-    }\n-\n-    private Section<V> getSection(long hash) {\n-        // Use 32 msb out of long to get the section\n-        final int sectionIdx = (int) (hash >>> 32) & (sections.length - 1);\n-        return sections[sectionIdx];\n-    }\n-\n-    public void clear() {\n-        for (int i = 0; i < sections.length; i++) {\n-            sections[i].clear();\n-        }\n-    }\n-\n-    /**\n-     * Iterate over all the elements in the set and apply the provided function.\n-     * <p>\n-     * <b>Warning: Do Not Guarantee Thread-Safety.</b>\n-     * @param processor the function to apply to each element\n-     */\n-    public void forEach(Consumer<? super V> processor) {\n-        for (int i = 0; i < sections.length; i++) {\n-            sections[i].forEach(processor);\n-        }\n-    }\n-\n-    public int removeIf(Predicate<V> filter) {\n-        requireNonNull(filter);\n-\n-        int removedCount = 0;\n-        for (int i = 0; i < sections.length; i++) {\n-            removedCount += sections[i].removeIf(filter);\n-        }\n-\n-        return removedCount;\n-    }\n-\n-    /**\n-     * @return a new list of all values (makes a copy)\n-     */\n-    public List<V> values() {\n-        List<V> values = new ArrayList<>();\n-        forEach(value -> values.add(value));\n-        return values;\n-    }\n-\n-    @Override\n-    public String toString() {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append('{');\n-        final AtomicBoolean first = new AtomicBoolean(true);\n-        forEach(value -> {\n-            if (!first.getAndSet(false)) {\n-                sb.append(\", \");\n-            }\n-\n-            sb.append(value.toString());\n-        });\n-        sb.append('}');\n-        return sb.toString();\n-    }\n-\n-    // A section is a portion of the hash map that is covered by a single\n-    @SuppressWarnings(\"serial\")\n-    private static final class Section<V> extends StampedLock {\n-        private volatile V[] values;\n-\n-        private volatile int capacity;\n-        private final int initCapacity;\n-        private static final AtomicIntegerFieldUpdater<Section> SIZE_UPDATER =\n-                AtomicIntegerFieldUpdater.newUpdater(Section.class, \"size\");\n-        private volatile int size;\n-        private int usedBuckets;\n-        private int resizeThresholdUp;\n-        private int resizeThresholdBelow;\n-        private final float mapFillFactor;\n-        private final float mapIdleFactor;\n-        private final float expandFactor;\n-        private final float shrinkFactor;\n-        private final boolean autoShrink;\n-\n-        Section(int capacity, float mapFillFactor, float mapIdleFactor, boolean autoShrink,\n-                float expandFactor, float shrinkFactor) {\n-            this.capacity = alignToPowerOfTwo(capacity);\n-            this.initCapacity = this.capacity;\n-            this.values = (V[]) new Object[this.capacity];\n-            this.size = 0;\n-            this.usedBuckets = 0;\n-            this.autoShrink = autoShrink;\n-            this.mapFillFactor = mapFillFactor;\n-            this.mapIdleFactor = mapIdleFactor;\n-            this.expandFactor = expandFactor;\n-            this.shrinkFactor = shrinkFactor;\n-            this.resizeThresholdUp = (int) (this.capacity * mapFillFactor);\n-            this.resizeThresholdBelow = (int) (this.capacity * mapIdleFactor);\n-        }\n-\n-        boolean contains(V value, int keyHash) {\n-            long stamp = tryOptimisticRead();\n-            boolean acquiredLock = false;\n-\n-            // add local variable here, so OutOfBound won't happen\n-            V[] values = this.values;\n-            // calculate table.length as capacity to avoid rehash changing capacity\n-            int bucket = signSafeMod(keyHash, values.length);\n-\n-            try {\n-                while (true) {\n-                    // First try optimistic locking\n-                    V storedValue = values[bucket];\n-\n-                    if (!acquiredLock && validate(stamp)) {\n-                        // The values we have read are consistent\n-                        if (value.equals(storedValue)) {\n-                            return true;\n-                        } else if (storedValue == EmptyValue) {\n-                            // Not found\n-                            return false;\n-                        }\n-                    } else {\n-                        // Fallback to acquiring read lock\n-                        if (!acquiredLock) {\n-                            stamp = readLock();\n-                            acquiredLock = true;\n-\n-                            // update local variable\n-                            values = this.values;\n-                            bucket = signSafeMod(keyHash, values.length);\n-                            storedValue = values[bucket];\n-                        }\n-\n-                        if (value.equals(storedValue)) {\n-                            return true;\n-                        } else if (storedValue == EmptyValue) {\n-                            // Not found\n-                            return false;\n-                        }\n-                    }\n-                    bucket = (bucket + 1) & (values.length - 1);\n-                }\n-            } finally {\n-                if (acquiredLock) {\n-                    unlockRead(stamp);\n-                }\n-            }\n-        }\n-\n-        boolean add(V value, int keyHash) {\n-            int bucket = keyHash;\n-\n-            long stamp = writeLock();\n-            int capacity = this.capacity;\n-\n-            // Remember where we find the first available spot\n-            int firstDeletedValue = -1;\n-\n-            try {\n-                while (true) {\n-                    bucket = signSafeMod(bucket, capacity);\n-\n-                    V storedValue = values[bucket];\n-\n-                    if (value.equals(storedValue)) {\n-                        return false;\n-                    } else if (storedValue == EmptyValue) {\n-                        // Found an empty bucket. This means the value is not in the set. If we've already seen a\n-                        // deleted value, we should write at that position\n-                        if (firstDeletedValue != -1) {\n-                            bucket = firstDeletedValue;\n-                        } else {\n-                            ++usedBuckets;\n-                        }\n-\n-                        values[bucket] = value;\n-                        SIZE_UPDATER.incrementAndGet(this);\n-                        return true;\n-                    } else if (storedValue == DeletedValue) {\n-                        // The bucket contained a different deleted key\n-                        if (firstDeletedValue == -1) {\n-                            firstDeletedValue = bucket;\n-                        }\n-                    }\n-\n-                    ++bucket;\n-                }\n-            } finally {\n-                if (usedBuckets > resizeThresholdUp) {\n-                    try {\n-                        // Expand the hashmap\n-                        int newCapacity = alignToPowerOfTwo((int) (capacity * expandFactor));\n-                        rehash(newCapacity);\n-                    } finally {\n-                        unlockWrite(stamp);\n-                    }\n-                } else {\n-                    unlockWrite(stamp);\n-                }\n-            }\n-        }\n-\n-        private boolean remove(V value, int keyHash) {\n-            int bucket = keyHash;\n-            long stamp = writeLock();\n-\n-            try {\n-                while (true) {\n-                    int capacity = this.capacity;\n-                    bucket = signSafeMod(bucket, capacity);\n-\n-                    V storedValue = values[bucket];\n-                    if (value.equals(storedValue)) {\n-                        SIZE_UPDATER.decrementAndGet(this);\n-                        cleanBucket(bucket);\n-                        return true;\n-                    } else if (storedValue == EmptyValue) {\n-                        // Value wasn't found\n-                        return false;\n-                    }\n-\n-                    ++bucket;\n-                }\n-\n-            } finally {\n-                if (autoShrink && size < resizeThresholdBelow) {\n-                    try {\n-                        // Shrinking must at least ensure initCapacity,\n-                        // so as to avoid frequent shrinking and expansion near initCapacity,\n-                        // frequent shrinking and expansion,\n-                        // additionally opened arrays will consume more memory and affect GC\n-                        int newCapacity = Math.max(alignToPowerOfTwo((int) (capacity / shrinkFactor)), initCapacity);\n-                        int newResizeThresholdUp = (int) (newCapacity * mapFillFactor);\n-                        if (newCapacity < capacity && newResizeThresholdUp > size) {\n-                            // shrink the hashmap\n-                            rehash(newCapacity);\n-                        }\n-                    } finally {\n-                        unlockWrite(stamp);\n-                    }\n-                } else {\n-                    unlockWrite(stamp);\n-                }\n-            }\n-        }\n-\n-        void clear() {\n-            long stamp = writeLock();\n-\n-            try {\n-                if (autoShrink && capacity > initCapacity) {\n-                    shrinkToInitCapacity();\n-                } else {\n-                    Arrays.fill(values, EmptyValue);\n-                    this.size = 0;\n-                    this.usedBuckets = 0;\n-                }\n-            } finally {\n-                unlockWrite(stamp);\n-            }\n-        }\n-\n-        int removeIf(Predicate<V> filter) {\n-            long stamp = writeLock();\n-\n-            int removedCount = 0;\n-            try {\n-                // Go through all the buckets for this section\n-                for (int bucket = capacity - 1; bucket >= 0; bucket--) {\n-                    V storedValue = values[bucket];\n-\n-                    if (storedValue != DeletedValue && storedValue != EmptyValue) {\n-                        if (filter.test(storedValue)) {\n-                            // Removing item\n-                            SIZE_UPDATER.decrementAndGet(this);\n-                            ++removedCount;\n-                            cleanBucket(bucket);\n-                        }\n-                    }\n-                }\n-\n-                return removedCount;\n-            } finally {\n-                unlockWrite(stamp);\n-            }\n-        }\n-\n-        private void cleanBucket(int bucket) {\n-            int nextInArray = signSafeMod(bucket + 1, capacity);\n-            if (values[nextInArray] == EmptyValue) {\n-                values[bucket] = (V) EmptyValue;\n-                --usedBuckets;\n-\n-                // Cleanup all the buckets that were in `DeletedValue` state,\n-                // so that we can reduce unnecessary expansions\n-                int lastBucket = signSafeMod(bucket - 1, capacity);\n-                while (values[lastBucket] == DeletedValue) {\n-                    values[lastBucket] = (V) EmptyValue;\n-                    --usedBuckets;\n-\n-                    lastBucket = signSafeMod(lastBucket - 1, capacity);\n-                }\n-            } else {\n-                values[bucket] = (V) DeletedValue;\n-            }\n-        }\n-\n-        public void forEach(Consumer<? super V> processor) {\n-            V[] values = this.values;\n-\n-            // Go through all the buckets for this section. We try to renew the stamp only after a validation\n-            // error, otherwise we keep going with the same.\n-            long stamp = 0;\n-            for (int bucket = 0; bucket < capacity; bucket++) {\n-                if (stamp == 0) {\n-                    stamp = tryOptimisticRead();\n-                }\n-\n-                V storedValue = values[bucket];\n-\n-                if (!validate(stamp)) {\n-                    // Fallback to acquiring read lock\n-                    stamp = readLock();\n-\n-                    try {\n-                        storedValue = values[bucket];\n-                    } finally {\n-                        unlockRead(stamp);\n-                    }\n-\n-                    stamp = 0;\n-                }\n-\n-                if (storedValue != DeletedValue && storedValue != EmptyValue) {\n-                    processor.accept(storedValue);\n-                }\n-            }\n-        }\n-\n-        private void rehash(int newCapacity) {\n-            // Expand the hashmap\n-            V[] newValues = (V[]) new Object[newCapacity];\n-\n-            // Re-hash table\n-            for (int i = 0; i < values.length; i++) {\n-                V storedValue = values[i];\n-                if (storedValue != EmptyValue && storedValue != DeletedValue) {\n-                    insertValueNoLock(newValues, storedValue);\n-                }\n-            }\n-\n-            values = newValues;\n-            capacity = newCapacity;\n-            usedBuckets = size;\n-            resizeThresholdUp = (int) (capacity * mapFillFactor);\n-            resizeThresholdBelow = (int) (capacity * mapIdleFactor);\n-        }\n-\n-        private void shrinkToInitCapacity() {\n-            V[] newValues = (V[]) new Object[initCapacity];\n-\n-            values = newValues;\n-            size = 0;\n-            usedBuckets = 0;\n-            // Capacity needs to be updated after the values, so that we won't see\n-            // a capacity value bigger than the actual array size\n-            capacity = initCapacity;\n-            resizeThresholdUp = (int) (capacity * mapFillFactor);\n-            resizeThresholdBelow = (int) (capacity * mapIdleFactor);\n-        }\n-\n-        private static <V> void insertValueNoLock(V[] values, V value) {\n-            int bucket = (int) hash(value);\n-\n-            while (true) {\n-                bucket = signSafeMod(bucket, values.length);\n-\n-                V storedValue = values[bucket];\n-\n-                if (storedValue == EmptyValue) {\n-                    // The bucket is empty, so we can use it\n-                    values[bucket] = value;\n-                    return;\n-                }\n-\n-                ++bucket;\n-            }\n-        }\n-    }\n-\n-    private static final long HashMixer = 0xc6a4a7935bd1e995L;\n-    private static final int R = 47;\n-\n-    static final <K> long hash(K key) {\n-        long hash = key.hashCode() * HashMixer;\n-        hash ^= hash >>> R;\n-        hash *= HashMixer;\n-        return hash;\n-    }\n-\n-    static final int signSafeMod(long n, int max) {\n-        return (int) n & (max - 1);\n-    }\n-\n-    private static int alignToPowerOfTwo(int n) {\n-        return (int) Math.pow(2, 32 - Integer.numberOfLeadingZeros(n - 1));\n-    }\n-}\n\ndiff --git a/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/WebSocketService.java b/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/WebSocketService.java\nindex 889f4431cc35b..7bb4df7baa533 100644\n--- a/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/WebSocketService.java\n+++ b/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/WebSocketService.java\n@@ -23,7 +23,10 @@\n import java.io.Closeable;\n import java.io.IOException;\n import java.net.MalformedURLException;\n+import java.util.Map;\n import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.Executors;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n@@ -44,8 +47,6 @@\n import org.apache.pulsar.client.internal.PropertiesUtils;\n import org.apache.pulsar.common.configuration.PulsarConfigurationLoader;\n import org.apache.pulsar.common.policies.data.ClusterData;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashSet;\n import org.apache.pulsar.metadata.api.MetadataStoreException;\n import org.apache.pulsar.metadata.api.MetadataStoreException.NotFoundException;\n import org.apache.pulsar.metadata.api.extended.MetadataStoreExtended;\n@@ -73,9 +74,9 @@ public class WebSocketService implements Closeable {\n     private Optional<CryptoKeyReader> cryptoKeyReader = Optional.empty();\n \n     private ClusterData localCluster;\n-    private final ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ProducerHandler>> topicProducerMap;\n-    private final ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ConsumerHandler>> topicConsumerMap;\n-    private final ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ReaderHandler>> topicReaderMap;\n+    private final Map<String, Set<ProducerHandler>> topicProducerMap = new ConcurrentHashMap<>();\n+    private final Map<String, Set<ConsumerHandler>> topicConsumerMap = new ConcurrentHashMap<>();\n+    private final Map<String, Set<ReaderHandler>> topicReaderMap = new ConcurrentHashMap<>();\n     private final ProxyStats proxyStats;\n \n     public WebSocketService(WebSocketProxyConfiguration config) {\n@@ -88,17 +89,6 @@ public WebSocketService(ClusterData localCluster, ServiceConfiguration config) {\n                 .newScheduledThreadPool(config.getWebSocketNumServiceThreads(),\n                         new DefaultThreadFactory(\"pulsar-websocket\"));\n         this.localCluster = localCluster;\n-        this.topicProducerMap =\n-                ConcurrentOpenHashMap.<String,\n-                        ConcurrentOpenHashSet<ProducerHandler>>newBuilder()\n-                        .build();\n-        this.topicConsumerMap =\n-                ConcurrentOpenHashMap.<String,\n-                        ConcurrentOpenHashSet<ConsumerHandler>>newBuilder()\n-                        .build();\n-        this.topicReaderMap =\n-                ConcurrentOpenHashMap.<String, ConcurrentOpenHashSet<ReaderHandler>>newBuilder()\n-                        .build();\n         this.proxyStats = new ProxyStats(this);\n     }\n \n@@ -288,11 +278,11 @@ public boolean isAuthorizationEnabled() {\n     public boolean addProducer(ProducerHandler producer) {\n         return topicProducerMap\n                 .computeIfAbsent(producer.getProducer().getTopic(),\n-                        topic -> ConcurrentOpenHashSet.<ProducerHandler>newBuilder().build())\n+                        topic -> ConcurrentHashMap.newKeySet())\n                 .add(producer);\n     }\n \n-    public ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ProducerHandler>> getProducers() {\n+    public Map<String, Set<ProducerHandler>> getProducers() {\n         return topicProducerMap;\n     }\n \n@@ -306,12 +296,11 @@ public boolean removeProducer(ProducerHandler producer) {\n \n     public boolean addConsumer(ConsumerHandler consumer) {\n         return topicConsumerMap\n-                .computeIfAbsent(consumer.getConsumer().getTopic(), topic ->\n-                        ConcurrentOpenHashSet.<ConsumerHandler>newBuilder().build())\n+                .computeIfAbsent(consumer.getConsumer().getTopic(), topic -> ConcurrentHashMap.newKeySet())\n                 .add(consumer);\n     }\n \n-    public ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ConsumerHandler>> getConsumers() {\n+    public Map<String, Set<ConsumerHandler>> getConsumers() {\n         return topicConsumerMap;\n     }\n \n@@ -324,12 +313,11 @@ public boolean removeConsumer(ConsumerHandler consumer) {\n     }\n \n     public boolean addReader(ReaderHandler reader) {\n-        return topicReaderMap.computeIfAbsent(reader.getConsumer().getTopic(), topic ->\n-                ConcurrentOpenHashSet.<ReaderHandler>newBuilder().build())\n+        return topicReaderMap.computeIfAbsent(reader.getConsumer().getTopic(), topic -> ConcurrentHashMap.newKeySet())\n                 .add(reader);\n     }\n \n-    public ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<ReaderHandler>> getReaders() {\n+    public Map<String, Set<ReaderHandler>> getReaders() {\n         return topicReaderMap;\n     }\n \n\ndiff --git a/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/stats/ProxyStats.java b/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/stats/ProxyStats.java\nindex eb1566ef7d412..4660340e9cc54 100644\n--- a/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/stats/ProxyStats.java\n+++ b/pulsar-websocket/src/main/java/org/apache/pulsar/websocket/stats/ProxyStats.java\n@@ -24,11 +24,11 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.TimeUnit;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.stats.JvmMetrics;\n import org.apache.pulsar.common.stats.Metrics;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.websocket.WebSocketService;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -41,7 +41,7 @@ public class ProxyStats {\n \n     private final WebSocketService service;\n     private final JvmMetrics jvmMetrics;\n-    private ConcurrentOpenHashMap<String, ProxyNamespaceStats> topicStats;\n+    private final Map<String, ProxyNamespaceStats> topicStats = new ConcurrentHashMap<>();\n     private List<Metrics> metricsCollection;\n     private List<Metrics> tempMetricsCollection;\n \n@@ -50,9 +50,6 @@ public ProxyStats(WebSocketService service) {\n         this.service = service;\n         this.jvmMetrics = JvmMetrics.create(\n                 service.getExecutor(), \"prx\", service.getConfig().getJvmGCMetricsLoggerClassName());\n-        this.topicStats =\n-                ConcurrentOpenHashMap.<String, ProxyNamespaceStats>newBuilder()\n-                        .build();\n         this.metricsCollection = new ArrayList<>();\n         this.tempMetricsCollection = new ArrayList<>();\n         // schedule stat generation task every 1 minute\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java\nindex e7dcbc602134c..5b1c78574b462 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/MessageDuplicationTest.java\n@@ -60,7 +60,6 @@\n import org.apache.pulsar.common.naming.SystemTopicNames;\n import org.apache.pulsar.common.protocol.Commands;\n import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.compaction.CompactionServiceFactory;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n@@ -230,9 +229,7 @@ public void testInactiveProducerRemove() throws Exception {\n         messageDeduplication.purgeInactiveProducers();\n         assertFalse(inactiveProducers.containsKey(producerName2));\n         assertFalse(inactiveProducers.containsKey(producerName3));\n-        field = MessageDeduplication.class.getDeclaredField(\"highestSequencedPushed\");\n-        field.setAccessible(true);\n-        ConcurrentOpenHashMap<String, Long> highestSequencedPushed = (ConcurrentOpenHashMap<String, Long>) field.get(messageDeduplication);\n+        final var highestSequencedPushed = messageDeduplication.highestSequencedPushed;\n \n         assertEquals((long) highestSequencedPushed.get(producerName1), 2L);\n         assertFalse(highestSequencedPushed.containsKey(producerName2));\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java\nindex 514e3dde14070..a62d9e7479852 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java\n@@ -45,7 +45,6 @@\n import org.apache.pulsar.client.util.TimedCompletableFuture;\n import org.apache.pulsar.common.api.proto.CommandAck.AckType;\n import org.apache.pulsar.common.util.collections.ConcurrentBitSetRecyclable;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.common.api.proto.ProtocolVersion;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.BeforeClass;\n@@ -62,8 +61,7 @@ public class AcknowledgementsGroupingTrackerTest {\n     public void setup() throws NoSuchFieldException, IllegalAccessException {\n         eventLoopGroup = new NioEventLoopGroup(1);\n         consumer = mock(ConsumerImpl.class);\n-        consumer.unAckedChunkedMessageIdSequenceMap =\n-                ConcurrentOpenHashMap.<MessageIdAdv, MessageIdImpl[]>newBuilder().build();\n+        consumer.unAckedChunkedMessageIdSequenceMap = new ConcurrentHashMap<>();\n         cnx = spy(new ClientCnxTest(new ClientConfigurationData(), eventLoopGroup));\n         PulsarClientImpl client = mock(PulsarClientImpl.class);\n         ConnectionPool connectionPool = mock(ConnectionPool.class);\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java\nindex b01fbcb879f80..eaac165818a56 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/UnAckedMessageTrackerTest.java\n@@ -31,13 +31,11 @@\n import io.netty.util.concurrent.DefaultThreadFactory;\n import java.time.Duration;\n import java.util.HashSet;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.TimeUnit;\n-\n import org.apache.pulsar.client.api.MessageId;\n-import org.apache.pulsar.client.api.MessageIdAdv;\n import org.apache.pulsar.client.impl.conf.ConsumerConfigurationData;\n import org.apache.pulsar.client.impl.metrics.InstrumentProvider;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.testng.annotations.Test;\n \n@@ -113,8 +111,7 @@ public void testTrackChunkedMessageId() {\n         ChunkMessageIdImpl chunkedMessageId =\n                 new ChunkMessageIdImpl(chunkMsgIds[0], chunkMsgIds[chunkMsgIds.length - 1]);\n \n-        consumer.unAckedChunkedMessageIdSequenceMap =\n-                ConcurrentOpenHashMap.<MessageIdAdv, MessageIdImpl[]>newBuilder().build();\n+        consumer.unAckedChunkedMessageIdSequenceMap = new ConcurrentHashMap<>();\n         consumer.unAckedChunkedMessageIdSequenceMap.put(chunkedMessageId, chunkMsgIds);\n \n         // Redeliver chunked message\n\ndiff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMapTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMapTest.java\ndeleted file mode 100644\nindex 48a1a705a3202..0000000000000\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashMapTest.java\n+++ /dev/null\n@@ -1,700 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-package org.apache.pulsar.common.util.collections;\n-\n-import static org.testng.Assert.assertEquals;\n-import static org.testng.Assert.assertFalse;\n-import static org.testng.Assert.assertNotEquals;\n-import static org.testng.Assert.assertNull;\n-import static org.testng.Assert.assertThrows;\n-import static org.testng.Assert.assertTrue;\n-import static org.testng.Assert.fail;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Random;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.CyclicBarrier;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicReference;\n-import java.util.function.Function;\n-\n-import lombok.Cleanup;\n-import org.testng.annotations.Test;\n-\n-import com.google.common.collect.Lists;\n-\n-public class ConcurrentOpenHashMapTest {\n-\n-    @Test\n-    public void testConstructor() {\n-        try {\n-            ConcurrentOpenHashMap.<String, String>newBuilder()\n-                    .expectedItems(0)\n-                    .build();\n-            fail(\"should have thrown exception\");\n-        } catch (IllegalArgumentException e) {\n-            // ok\n-        }\n-\n-        try {\n-            ConcurrentOpenHashMap.<String, String>newBuilder()\n-                    .expectedItems(16)\n-                    .concurrencyLevel(0)\n-                    .build();\n-            fail(\"should have thrown exception\");\n-        } catch (IllegalArgumentException e) {\n-            // ok\n-        }\n-\n-        try {\n-            ConcurrentOpenHashMap.<String, String>newBuilder()\n-                    .expectedItems(4)\n-                    .concurrencyLevel(8)\n-                    .build();\n-            fail(\"should have thrown exception\");\n-        } catch (IllegalArgumentException e) {\n-            // ok\n-        }\n-    }\n-\n-    @Test\n-    public void simpleInsertions() {\n-        ConcurrentOpenHashMap<String, String> map =\n-                ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(16)\n-                .build();\n-\n-        assertTrue(map.isEmpty());\n-        assertNull(map.put(\"1\", \"one\"));\n-        assertFalse(map.isEmpty());\n-\n-        assertNull(map.put(\"2\", \"two\"));\n-        assertNull(map.put(\"3\", \"three\"));\n-\n-        assertEquals(map.size(), 3);\n-\n-        assertEquals(map.get(\"1\"), \"one\");\n-        assertEquals(map.size(), 3);\n-\n-        assertEquals(map.remove(\"1\"), \"one\");\n-        assertEquals(map.size(), 2);\n-        assertNull(map.get(\"1\"));\n-        assertNull(map.get(\"5\"));\n-        assertEquals(map.size(), 2);\n-\n-        assertNull(map.put(\"1\", \"one\"));\n-        assertEquals(map.size(), 3);\n-        assertEquals(map.put(\"1\", \"uno\"), \"one\");\n-        assertEquals(map.size(), 3);\n-    }\n-\n-    @Test\n-    public void testReduceUnnecessaryExpansions() {\n-        ConcurrentOpenHashMap<String, String> map = ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .build();\n-        assertNull(map.put(\"1\", \"1\"));\n-        assertNull(map.put(\"2\", \"2\"));\n-        assertNull(map.put(\"3\", \"3\"));\n-        assertNull(map.put(\"4\", \"4\"));\n-\n-        assertEquals(map.remove(\"1\"), \"1\");\n-        assertEquals(map.remove(\"2\"), \"2\");\n-        assertEquals(map.remove(\"3\"), \"3\");\n-        assertEquals(map.remove(\"4\"), \"4\");\n-\n-        assertEquals(0, map.getUsedBucketCount());\n-    }\n-\n-    @Test\n-    public void testClear() {\n-        ConcurrentOpenHashMap<String, String> map = ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertTrue(map.capacity() == 4);\n-\n-        assertNull(map.put(\"k1\", \"v1\"));\n-        assertNull(map.put(\"k2\", \"v2\"));\n-        assertNull(map.put(\"k3\", \"v3\"));\n-\n-        assertTrue(map.capacity() == 8);\n-        map.clear();\n-        assertTrue(map.capacity() == 4);\n-    }\n-\n-    @Test\n-    public void testExpandAndShrink() {\n-        ConcurrentOpenHashMap<String, String> map = ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertTrue(map.capacity() == 4);\n-\n-        assertNull(map.put(\"k1\", \"v1\"));\n-        assertNull(map.put(\"k2\", \"v2\"));\n-        assertNull(map.put(\"k3\", \"v3\"));\n-\n-        // expand hashmap\n-        assertTrue(map.capacity() == 8);\n-\n-        assertTrue(map.remove(\"k1\", \"v1\"));\n-        // not shrink\n-        assertTrue(map.capacity() == 8);\n-        assertTrue(map.remove(\"k2\", \"v2\"));\n-        // shrink hashmap\n-        assertTrue(map.capacity() == 4);\n-\n-        // expand hashmap\n-        assertNull(map.put(\"k4\", \"v4\"));\n-        assertNull(map.put(\"k5\", \"v5\"));\n-        assertTrue(map.capacity() == 8);\n-\n-        //verify that the map does not keep shrinking at every remove() operation\n-        assertNull(map.put(\"k6\", \"v6\"));\n-        assertTrue(map.remove(\"k6\", \"v6\"));\n-        assertTrue(map.capacity() == 8);\n-    }\n-\n-    @Test\n-    public void testExpandShrinkAndClear() {\n-        ConcurrentOpenHashMap<String, String> map = ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        final long initCapacity = map.capacity();\n-        assertTrue(map.capacity() == 4);\n-        assertNull(map.put(\"k1\", \"v1\"));\n-        assertNull(map.put(\"k2\", \"v2\"));\n-        assertNull(map.put(\"k3\", \"v3\"));\n-\n-        // expand hashmap\n-        assertTrue(map.capacity() == 8);\n-\n-        assertTrue(map.remove(\"k1\", \"v1\"));\n-        // not shrink\n-        assertTrue(map.capacity() == 8);\n-        assertTrue(map.remove(\"k2\", \"v2\"));\n-        // shrink hashmap\n-        assertTrue(map.capacity() == 4);\n-\n-        assertTrue(map.remove(\"k3\", \"v3\"));\n-        // Will not shrink the hashmap again because shrink capacity is less than initCapacity\n-        // current capacity is equal than the initial capacity\n-        assertTrue(map.capacity() == initCapacity);\n-        map.clear();\n-        // after clear, because current capacity is equal than the initial capacity, so not shrinkToInitCapacity\n-        assertTrue(map.capacity() == initCapacity);\n-    }\n-\n-    @Test\n-    public void testConcurrentExpandAndShrinkAndGet()  throws Throwable {\n-        ConcurrentOpenHashMap<String, String> map = ConcurrentOpenHashMap.<String, String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertEquals(map.capacity(), 4);\n-\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-        final int readThreads = 16;\n-        final int writeThreads = 1;\n-        final int n = 1_000;\n-        CyclicBarrier barrier = new CyclicBarrier(writeThreads + readThreads);\n-        Future<?> future = null;\n-        AtomicReference<Exception> ex = new AtomicReference<>();\n-\n-        for (int i = 0; i < readThreads; i++) {\n-            executor.submit(() -> {\n-                try {\n-                    barrier.await();\n-                } catch (Exception e) {\n-                    throw new RuntimeException(e);\n-                }\n-                while (!Thread.currentThread().isInterrupted()) {\n-                    try {\n-                        map.get(\"k2\");\n-                    } catch (Exception e) {\n-                        ex.set(e);\n-                    }\n-                }\n-            });\n-        }\n-\n-        assertNull(map.put(\"k1\",\"v1\"));\n-        future = executor.submit(() -> {\n-            try {\n-                barrier.await();\n-            } catch (Exception e) {\n-                throw new RuntimeException(e);\n-            }\n-\n-            for (int i = 0; i < n; i++) {\n-                // expand hashmap\n-                assertNull(map.put(\"k2\", \"v2\"));\n-                assertNull(map.put(\"k3\", \"v3\"));\n-                assertEquals(map.capacity(), 8);\n-\n-                // shrink hashmap\n-                assertTrue(map.remove(\"k2\", \"v2\"));\n-                assertTrue(map.remove(\"k3\", \"v3\"));\n-                assertEquals(map.capacity(), 4);\n-            }\n-        });\n-\n-        future.get();\n-        assertTrue(ex.get() == null);\n-        // shut down pool\n-        executor.shutdown();\n-    }\n-\n-    @Test\n-    public void testRemove() {\n-        ConcurrentOpenHashMap<String, String> map =\n-                ConcurrentOpenHashMap.<String, String>newBuilder().build();\n-\n-        assertTrue(map.isEmpty());\n-        assertNull(map.put(\"1\", \"one\"));\n-        assertFalse(map.isEmpty());\n-\n-        assertFalse(map.remove(\"0\", \"zero\"));\n-        assertFalse(map.remove(\"1\", \"uno\"));\n-\n-        assertFalse(map.isEmpty());\n-        assertTrue(map.remove(\"1\", \"one\"));\n-        assertTrue(map.isEmpty());\n-    }\n-\n-    @Test\n-    public void testRehashing() {\n-        int n = 16;\n-        ConcurrentOpenHashMap<String, Integer> map = ConcurrentOpenHashMap.<String, Integer>newBuilder()\n-                        .expectedItems(n / 2)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        assertEquals(map.capacity(), n);\n-        assertEquals(map.size(), 0);\n-\n-        for (int i = 0; i < n; i++) {\n-            map.put(Integer.toString(i), i);\n-        }\n-\n-        assertEquals(map.capacity(), 2 * n);\n-        assertEquals(map.size(), n);\n-    }\n-\n-    @Test\n-    public void testRehashingWithDeletes() {\n-        int n = 16;\n-        ConcurrentOpenHashMap<Integer, Integer> map =\n-                ConcurrentOpenHashMap.<Integer, Integer>newBuilder()\n-                        .expectedItems(n / 2)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        assertEquals(map.capacity(), n);\n-        assertEquals(map.size(), 0);\n-\n-        for (int i = 0; i < n / 2; i++) {\n-            map.put(i, i);\n-        }\n-\n-        for (int i = 0; i < n / 2; i++) {\n-            map.remove(i);\n-        }\n-\n-        for (int i = n; i < (2 * n); i++) {\n-            map.put(i, i);\n-        }\n-\n-        assertEquals(map.capacity(), 2 * n);\n-        assertEquals(map.size(), n);\n-    }\n-\n-    @Test\n-    public void concurrentInsertions() throws Throwable {\n-        ConcurrentOpenHashMap<Long, String> map = ConcurrentOpenHashMap.<Long, String>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-\n-        final int nThreads = 16;\n-        final int N = 100_000;\n-        String value = \"value\";\n-\n-        List<Future<?>> futures = new ArrayList<>();\n-        for (int i = 0; i < nThreads; i++) {\n-            final int threadIdx = i;\n-\n-            futures.add(executor.submit(() -> {\n-                Random random = new Random();\n-\n-                for (int j = 0; j < N; j++) {\n-                    long key = random.nextLong();\n-                    // Ensure keys are uniques\n-                    key -= key % (threadIdx + 1);\n-\n-                    map.put(key, value);\n-                }\n-            }));\n-        }\n-\n-        for (Future<?> future : futures) {\n-            future.get();\n-        }\n-\n-        assertEquals(map.size(), N * nThreads);\n-    }\n-\n-    @Test\n-    public void concurrentInsertionsAndReads() throws Throwable {\n-        ConcurrentOpenHashMap<Long, String> map =\n-                ConcurrentOpenHashMap.<Long, String>newBuilder().build();\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-\n-        final int nThreads = 16;\n-        final int N = 100_000;\n-        String value = \"value\";\n-\n-        List<Future<?>> futures = new ArrayList<>();\n-        for (int i = 0; i < nThreads; i++) {\n-            final int threadIdx = i;\n-\n-            futures.add(executor.submit(() -> {\n-                Random random = new Random();\n-\n-                for (int j = 0; j < N; j++) {\n-                    long key = random.nextLong();\n-                    // Ensure keys are uniques\n-                    key -= key % (threadIdx + 1);\n-\n-                    map.put(key, value);\n-                }\n-            }));\n-        }\n-\n-        for (Future<?> future : futures) {\n-            future.get();\n-        }\n-\n-        assertEquals(map.size(), N * nThreads);\n-    }\n-\n-    @Test\n-    public void testIteration() {\n-        ConcurrentOpenHashMap<Long, String> map =\n-                ConcurrentOpenHashMap.<Long, String>newBuilder().build();\n-\n-        assertEquals(map.keys(), Collections.emptyList());\n-        assertEquals(map.values(), Collections.emptyList());\n-\n-        map.put(0l, \"zero\");\n-\n-        assertEquals(map.keys(), Lists.newArrayList(0l));\n-        assertEquals(map.values(), Lists.newArrayList(\"zero\"));\n-\n-        map.remove(0l);\n-\n-        assertEquals(map.keys(), Collections.emptyList());\n-        assertEquals(map.values(), Collections.emptyList());\n-\n-        map.put(0l, \"zero\");\n-        map.put(1l, \"one\");\n-        map.put(2l, \"two\");\n-\n-        List<Long> keys = map.keys();\n-        keys.sort(null);\n-        assertEquals(keys, Lists.newArrayList(0l, 1l, 2l));\n-\n-        List<String> values = map.values();\n-        values.sort(null);\n-        assertEquals(values, Lists.newArrayList(\"one\", \"two\", \"zero\"));\n-\n-        map.put(1l, \"uno\");\n-\n-        keys = map.keys();\n-        keys.sort(null);\n-        assertEquals(keys, Lists.newArrayList(0l, 1l, 2l));\n-\n-        values = map.values();\n-        values.sort(null);\n-        assertEquals(values, Lists.newArrayList(\"two\", \"uno\", \"zero\"));\n-\n-        map.clear();\n-        assertTrue(map.isEmpty());\n-    }\n-\n-    @Test\n-    public void testHashConflictWithDeletion() {\n-        final int Buckets = 16;\n-        ConcurrentOpenHashMap<Long, String> map = ConcurrentOpenHashMap.<Long, String>newBuilder()\n-                .expectedItems(Buckets)\n-                .concurrencyLevel(1)\n-                .build();\n-\n-        // Pick 2 keys that fall into the same bucket\n-        long key1 = 1;\n-        long key2 = 27;\n-\n-        int bucket1 = ConcurrentOpenHashMap.signSafeMod(ConcurrentOpenHashMap.hash(key1), Buckets);\n-        int bucket2 = ConcurrentOpenHashMap.signSafeMod(ConcurrentOpenHashMap.hash(key2), Buckets);\n-        assertEquals(bucket1, bucket2);\n-\n-        assertNull(map.put(key1, \"value-1\"));\n-        assertNull(map.put(key2, \"value-2\"));\n-        assertEquals(map.size(), 2);\n-\n-        assertEquals(map.remove(key1), \"value-1\");\n-        assertEquals(map.size(), 1);\n-\n-        assertNull(map.put(key1, \"value-1-overwrite\"));\n-        assertEquals(map.size(), 2);\n-\n-        assertEquals(map.remove(key1), \"value-1-overwrite\");\n-        assertEquals(map.size(), 1);\n-\n-        assertEquals(map.put(key2, \"value-2-overwrite\"), \"value-2\");\n-        assertEquals(map.get(key2), \"value-2-overwrite\");\n-\n-        assertEquals(map.size(), 1);\n-        assertEquals(map.remove(key2), \"value-2-overwrite\");\n-        assertTrue(map.isEmpty());\n-    }\n-\n-    @Test\n-    public void testPutIfAbsent() {\n-        ConcurrentOpenHashMap<Long, String> map =\n-                ConcurrentOpenHashMap.<Long, String>newBuilder().build();\n-        assertNull(map.putIfAbsent(1l, \"one\"));\n-        assertEquals(map.get(1l), \"one\");\n-\n-        assertEquals(map.putIfAbsent(1l, \"uno\"), \"one\");\n-        assertEquals(map.get(1l), \"one\");\n-    }\n-\n-    @Test\n-    public void testComputeIfAbsent() {\n-        ConcurrentOpenHashMap<Integer, Integer> map = ConcurrentOpenHashMap.<Integer, Integer>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n-        AtomicInteger counter = new AtomicInteger();\n-        Function<Integer, Integer> provider = key -> counter.getAndIncrement();\n-\n-        assertEquals(map.computeIfAbsent(0, provider).intValue(), 0);\n-        assertEquals(map.get(0).intValue(), 0);\n-\n-        assertEquals(map.computeIfAbsent(1, provider).intValue(), 1);\n-        assertEquals(map.get(1).intValue(), 1);\n-\n-        assertEquals(map.computeIfAbsent(1, provider).intValue(), 1);\n-        assertEquals(map.get(1).intValue(), 1);\n-\n-        assertEquals(map.computeIfAbsent(2, provider).intValue(), 2);\n-        assertEquals(map.get(2).intValue(), 2);\n-    }\n-\n-    @Test\n-    public void testEqualsKeys() {\n-        class T {\n-            int value;\n-\n-            T(int value) {\n-                this.value = value;\n-            }\n-\n-            @Override\n-            public int hashCode() {\n-                return Integer.hashCode(value);\n-            }\n-\n-            @Override\n-            public boolean equals(Object obj) {\n-                if (obj instanceof T) {\n-                    return value == ((T) obj).value;\n-                }\n-\n-                return false;\n-            }\n-        }\n-\n-        ConcurrentOpenHashMap<T, String> map =\n-                ConcurrentOpenHashMap.<T, String>newBuilder().build();\n-\n-        T t1 = new T(1);\n-        T t1_b = new T(1);\n-        T t2 = new T(2);\n-\n-        assertEquals(t1, t1_b);\n-        assertNotEquals(t2, t1);\n-        assertNotEquals(t2, t1_b);\n-\n-        assertNull(map.put(t1, \"t1\"));\n-        assertEquals(map.get(t1), \"t1\");\n-        assertEquals(map.get(t1_b), \"t1\");\n-        assertNull(map.get(t2));\n-\n-        assertEquals(map.remove(t1_b), \"t1\");\n-        assertNull(map.get(t1));\n-        assertNull(map.get(t1_b));\n-    }\n-\n-    @Test\n-    public void testNullValue() {\n-        ConcurrentOpenHashMap<String, String> map =\n-                ConcurrentOpenHashMap.<String, String>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        String key = \"a\";\n-        assertThrows(NullPointerException.class, () -> map.put(key, null));\n-\n-        //put a null value.\n-        assertNull(map.computeIfAbsent(key, k -> null));\n-        assertEquals(1, map.size());\n-        assertEquals(1, map.keys().size());\n-        assertEquals(1, map.values().size());\n-        assertNull(map.get(key));\n-        assertFalse(map.containsKey(key));\n-\n-        //test remove null value\n-        map.removeNullValue(key);\n-        assertTrue(map.isEmpty());\n-        assertEquals(0, map.keys().size());\n-        assertEquals(0, map.values().size());\n-        assertNull(map.get(key));\n-        assertFalse(map.containsKey(key));\n-\n-\n-        //test not remove non-null value\n-        map.put(key, \"V\");\n-        assertEquals(1, map.size());\n-        map.removeNullValue(key);\n-        assertEquals(1, map.size());\n-\n-    }\n-\n-    static final int Iterations = 1;\n-    static final int ReadIterations = 1000;\n-    static final int N = 1_000_000;\n-\n-    public void benchConcurrentOpenHashMap() throws Exception {\n-        ConcurrentOpenHashMap<Long, String> map = ConcurrentOpenHashMap.<Long, String>newBuilder()\n-                .expectedItems(N)\n-                .concurrencyLevel(1)\n-                .build();\n-\n-        for (long i = 0; i < Iterations; i++) {\n-            for (int j = 0; j < N; j++) {\n-                map.put(i, \"value\");\n-            }\n-\n-            for (long h = 0; h < ReadIterations; h++) {\n-                for (int j = 0; j < N; j++) {\n-                    map.get(i);\n-                }\n-            }\n-\n-            for (long j = 0; j < N; j++) {\n-                map.remove(i);\n-            }\n-        }\n-    }\n-\n-    public void benchConcurrentHashMap() throws Exception {\n-        ConcurrentHashMap<Long, String> map = new ConcurrentHashMap<Long, String>(N, 0.66f, 1);\n-\n-        for (long i = 0; i < Iterations; i++) {\n-            for (int j = 0; j < N; j++) {\n-                map.put(i, \"value\");\n-            }\n-\n-            for (long h = 0; h < ReadIterations; h++) {\n-                for (int j = 0; j < N; j++) {\n-                    map.get(i);\n-                }\n-            }\n-\n-            for (int j = 0; j < N; j++) {\n-                map.remove(i);\n-            }\n-        }\n-    }\n-\n-    void benchHashMap() {\n-        HashMap<Long, String> map = new HashMap<>(N, 0.66f);\n-\n-        for (long i = 0; i < Iterations; i++) {\n-            for (int j = 0; j < N; j++) {\n-                map.put(i, \"value\");\n-            }\n-\n-            for (long h = 0; h < ReadIterations; h++) {\n-                for (int j = 0; j < N; j++) {\n-                    map.get(i);\n-                }\n-            }\n-\n-            for (int j = 0; j < N; j++) {\n-                map.remove(i);\n-            }\n-        }\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        ConcurrentOpenHashMapTest t = new ConcurrentOpenHashMapTest();\n-\n-        long start = System.nanoTime();\n-        t.benchHashMap();\n-        long end = System.nanoTime();\n-\n-        System.out.println(\"HM:   \" + TimeUnit.NANOSECONDS.toMillis(end - start) + \" ms\");\n-\n-        start = System.nanoTime();\n-        t.benchConcurrentHashMap();\n-        end = System.nanoTime();\n-\n-        System.out.println(\"CHM:  \" + TimeUnit.NANOSECONDS.toMillis(end - start) + \" ms\");\n-\n-        start = System.nanoTime();\n-        t.benchConcurrentOpenHashMap();\n-        end = System.nanoTime();\n-\n-        System.out.println(\"CLHM: \" + TimeUnit.NANOSECONDS.toMillis(end - start) + \" ms\");\n-\n-    }\n-}\n\ndiff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSetTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSetTest.java\ndeleted file mode 100644\nindex d509002e21998..0000000000000\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenHashSetTest.java\n+++ /dev/null\n@@ -1,503 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- */\n-package org.apache.pulsar.common.util.collections;\n-\n-import static org.testng.Assert.assertEquals;\n-import static org.testng.Assert.assertFalse;\n-import static org.testng.Assert.assertNotEquals;\n-import static org.testng.Assert.assertThrows;\n-import static org.testng.Assert.assertTrue;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Random;\n-import java.util.concurrent.CyclicBarrier;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.atomic.AtomicReference;\n-\n-import lombok.Cleanup;\n-import org.testng.annotations.Test;\n-\n-import com.google.common.collect.Lists;\n-\n-// Deprecation warning suppressed as this test targets deprecated class\n-@SuppressWarnings(\"deprecation\")\n-public class ConcurrentOpenHashSetTest {\n-\n-    @Test\n-    public void testConstructor() {\n-        assertThrows(IllegalArgumentException.class, () -> new ConcurrentOpenHashSet<String>(0));\n-        assertThrows(IllegalArgumentException.class, () -> new ConcurrentOpenHashSet<String>(16, 0));\n-        assertThrows(IllegalArgumentException.class, () -> new ConcurrentOpenHashSet<String>(4, 8));\n-    }\n-\n-    @Test\n-    public void simpleInsertions() {\n-        ConcurrentOpenHashSet<String> set = new ConcurrentOpenHashSet<>(16);\n-\n-        assertTrue(set.isEmpty());\n-        assertTrue(set.add(\"1\"));\n-        assertFalse(set.isEmpty());\n-\n-        assertTrue(set.add(\"2\"));\n-        assertTrue(set.add(\"3\"));\n-\n-        assertEquals(set.size(), 3);\n-\n-        assertTrue(set.contains(\"1\"));\n-        assertEquals(set.size(), 3);\n-\n-        assertTrue(set.remove(\"1\"));\n-        assertEquals(set.size(), 2);\n-        assertFalse(set.contains(\"1\"));\n-        assertFalse(set.contains(\"5\"));\n-        assertEquals(set.size(), 2);\n-\n-        assertTrue(set.add(\"1\"));\n-        assertEquals(set.size(), 3);\n-        assertFalse(set.add(\"1\"));\n-        assertEquals(set.size(), 3);\n-    }\n-\n-    @Test\n-    public void testReduceUnnecessaryExpansions() {\n-        ConcurrentOpenHashSet<String> set =\n-                ConcurrentOpenHashSet.<String>newBuilder()\n-                        .expectedItems(2)\n-                        .concurrencyLevel(1)\n-                        .build();\n-\n-        assertTrue(set.add(\"1\"));\n-        assertTrue(set.add(\"2\"));\n-        assertTrue(set.add(\"3\"));\n-        assertTrue(set.add(\"4\"));\n-\n-        assertTrue(set.remove(\"1\"));\n-        assertTrue(set.remove(\"2\"));\n-        assertTrue(set.remove(\"3\"));\n-        assertTrue(set.remove(\"4\"));\n-        assertEquals(0, set.getUsedBucketCount());\n-    }\n-\n-    @Test\n-    public void testClear() {\n-        ConcurrentOpenHashSet<String> set =\n-                ConcurrentOpenHashSet.<String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertEquals(set.capacity(), 4);\n-\n-        assertTrue(set.add(\"k1\"));\n-        assertTrue(set.add(\"k2\"));\n-        assertTrue(set.add(\"k3\"));\n-\n-        assertEquals(set.capacity(), 8);\n-        set.clear();\n-        assertEquals(set.capacity(), 4);\n-    }\n-\n-    @Test\n-    public void testExpandAndShrink() {\n-        ConcurrentOpenHashSet<String> map =\n-                ConcurrentOpenHashSet.<String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertEquals(map.capacity(), 4);\n-\n-        assertTrue(map.add(\"k1\"));\n-        assertTrue(map.add(\"k2\"));\n-        assertTrue(map.add(\"k3\"));\n-\n-        // expand hashmap\n-        assertEquals(map.capacity(), 8);\n-\n-        assertTrue(map.remove(\"k1\"));\n-        // not shrink\n-        assertEquals(map.capacity(), 8);\n-        assertTrue(map.remove(\"k2\"));\n-        // shrink hashmap\n-        assertEquals(map.capacity(), 4);\n-\n-        // expand hashmap\n-        assertTrue(map.add(\"k4\"));\n-        assertTrue(map.add(\"k5\"));\n-        assertEquals(map.capacity(), 8);\n-\n-        //verify that the map does not keep shrinking at every remove() operation\n-        assertTrue(map.add(\"k6\"));\n-        assertTrue(map.remove(\"k6\"));\n-        assertEquals(map.capacity(), 8);\n-    }\n-\n-    @Test\n-    public void testExpandShrinkAndClear() {\n-        ConcurrentOpenHashSet<String> map = ConcurrentOpenHashSet.<String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        final long initCapacity = map.capacity();\n-        assertTrue(map.capacity() == 4);\n-\n-        assertTrue(map.add(\"k1\"));\n-        assertTrue(map.add(\"k2\"));\n-        assertTrue(map.add(\"k3\"));\n-\n-        // expand hashmap\n-        assertTrue(map.capacity() == 8);\n-\n-        assertTrue(map.remove(\"k1\"));\n-        // not shrink\n-        assertTrue(map.capacity() == 8);\n-        assertTrue(map.remove(\"k2\"));\n-        // shrink hashmap\n-        assertTrue(map.capacity() == 4);\n-\n-        assertTrue(map.remove(\"k3\"));\n-        // Will not shrink the hashmap again because shrink capacity is less than initCapacity\n-        // current capacity is equal than the initial capacity\n-        assertTrue(map.capacity() == initCapacity);\n-        map.clear();\n-        // after clear, because current capacity is equal than the initial capacity, so not shrinkToInitCapacity\n-        assertTrue(map.capacity() == initCapacity);\n-    }\n-\n-    @Test\n-    public void testConcurrentExpandAndShrinkAndGet()  throws Throwable {\n-        ConcurrentOpenHashSet<String> set = ConcurrentOpenHashSet.<String>newBuilder()\n-                .expectedItems(2)\n-                .concurrencyLevel(1)\n-                .autoShrink(true)\n-                .mapIdleFactor(0.25f)\n-                .build();\n-        assertEquals(set.capacity(), 4);\n-\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-        final int readThreads = 16;\n-        final int writeThreads = 1;\n-        final int n = 1_000;\n-        CyclicBarrier barrier = new CyclicBarrier(writeThreads + readThreads);\n-        Future<?> future = null;\n-        AtomicReference<Exception> ex = new AtomicReference<>();\n-\n-        for (int i = 0; i < readThreads; i++) {\n-            executor.submit(() -> {\n-                try {\n-                    barrier.await();\n-                } catch (Exception e) {\n-                    throw new RuntimeException(e);\n-                }\n-                while (!Thread.currentThread().isInterrupted()) {\n-                    try {\n-                        set.contains(\"k2\");\n-                    } catch (Exception e) {\n-                        ex.set(e);\n-                    }\n-                }\n-            });\n-        }\n-\n-        assertTrue(set.add(\"k1\"));\n-        future = executor.submit(() -> {\n-            try {\n-                barrier.await();\n-            } catch (Exception e) {\n-                throw new RuntimeException(e);\n-            }\n-\n-            for (int i = 0; i < n; i++) {\n-                // expand hashmap\n-                assertTrue(set.add(\"k2\"));\n-                assertTrue(set.add(\"k3\"));\n-                assertEquals(set.capacity(), 8);\n-\n-                // shrink hashmap\n-                assertTrue(set.remove(\"k2\"));\n-                assertTrue(set.remove(\"k3\"));\n-                assertEquals(set.capacity(), 4);\n-            }\n-        });\n-\n-        future.get();\n-        assertTrue(ex.get() == null);\n-        // shut down pool\n-        executor.shutdown();\n-    }\n-\n-    @Test\n-    public void testRemove() {\n-        ConcurrentOpenHashSet<String> set =\n-                ConcurrentOpenHashSet.<String>newBuilder().build();\n-\n-        assertTrue(set.isEmpty());\n-        assertTrue(set.add(\"1\"));\n-        assertFalse(set.isEmpty());\n-\n-        assertFalse(set.remove(\"0\"));\n-        assertFalse(set.isEmpty());\n-        assertTrue(set.remove(\"1\"));\n-        assertTrue(set.isEmpty());\n-    }\n-\n-    @Test\n-    public void testRehashing() {\n-        int n = 16;\n-        ConcurrentOpenHashSet<Integer> set = new ConcurrentOpenHashSet<>(n / 2, 1);\n-        assertEquals(set.capacity(), n);\n-        assertEquals(set.size(), 0);\n-\n-        for (int i = 0; i < n; i++) {\n-            set.add(i);\n-        }\n-\n-        assertEquals(set.capacity(), 2 * n);\n-        assertEquals(set.size(), n);\n-    }\n-\n-    @Test\n-    public void testRehashingWithDeletes() {\n-        int n = 16;\n-        ConcurrentOpenHashSet<Integer> set = new ConcurrentOpenHashSet<>(n / 2, 1);\n-        assertEquals(set.capacity(), n);\n-        assertEquals(set.size(), 0);\n-\n-        for (int i = 0; i < n / 2; i++) {\n-            set.add(i);\n-        }\n-\n-        for (int i = 0; i < n / 2; i++) {\n-            set.remove(i);\n-        }\n-\n-        for (int i = n; i < (2 * n); i++) {\n-            set.add(i);\n-        }\n-\n-        assertEquals(set.capacity(), 2 * n);\n-        assertEquals(set.size(), n);\n-    }\n-\n-    @Test\n-    public void concurrentInsertions() throws Throwable {\n-        ConcurrentOpenHashSet<Long> set =\n-                ConcurrentOpenHashSet.<Long>newBuilder().build();\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-\n-        final int nThreads = 16;\n-        final int N = 100_000;\n-\n-        List<Future<?>> futures = new ArrayList<>();\n-        for (int i = 0; i < nThreads; i++) {\n-            final int threadIdx = i;\n-\n-            futures.add(executor.submit(() -> {\n-                Random random = new Random();\n-\n-                for (int j = 0; j < N; j++) {\n-                    long key = random.nextLong();\n-                    // Ensure keys are unique\n-                    key -= key % (threadIdx + 1);\n-\n-                    set.add(key);\n-                }\n-            }));\n-        }\n-\n-        for (Future<?> future : futures) {\n-            future.get();\n-        }\n-\n-        assertEquals(set.size(), N * nThreads);\n-    }\n-\n-    @Test\n-    public void concurrentInsertionsAndReads() throws Throwable {\n-        ConcurrentOpenHashSet<Long> map =\n-                ConcurrentOpenHashSet.<Long>newBuilder().build();\n-        @Cleanup(\"shutdownNow\")\n-        ExecutorService executor = Executors.newCachedThreadPool();\n-\n-        final int nThreads = 16;\n-        final int N = 100_000;\n-\n-        List<Future<?>> futures = new ArrayList<>();\n-        for (int i = 0; i < nThreads; i++) {\n-            final int threadIdx = i;\n-\n-            futures.add(executor.submit(() -> {\n-                Random random = new Random();\n-\n-                for (int j = 0; j < N; j++) {\n-                    long key = random.nextLong();\n-                    // Ensure keys are unique\n-                    key -= key % (threadIdx + 1);\n-\n-                    map.add(key);\n-                }\n-            }));\n-        }\n-\n-        for (Future<?> future : futures) {\n-            future.get();\n-        }\n-\n-        assertEquals(map.size(), N * nThreads);\n-    }\n-\n-    @Test\n-    public void testIteration() {\n-        ConcurrentOpenHashSet<Long> set = ConcurrentOpenHashSet.<Long>newBuilder().build();\n-\n-        assertEquals(set.values(), Collections.emptyList());\n-\n-        set.add(0l);\n-\n-        assertEquals(set.values(), Lists.newArrayList(0l));\n-\n-        set.remove(0l);\n-\n-        assertEquals(set.values(), Collections.emptyList());\n-\n-        set.add(0l);\n-        set.add(1l);\n-        set.add(2l);\n-\n-        List<Long> values = set.values();\n-        values.sort(null);\n-        assertEquals(values, Lists.newArrayList(0l, 1l, 2l));\n-\n-        set.clear();\n-        assertTrue(set.isEmpty());\n-    }\n-\n-    @Test\n-    public void testRemoval() {\n-        ConcurrentOpenHashSet<Integer> set =\n-                ConcurrentOpenHashSet.<Integer>newBuilder().build();\n-\n-        set.add(0);\n-        set.add(1);\n-        set.add(3);\n-        set.add(6);\n-        set.add(7);\n-\n-        List<Integer> values = set.values();\n-        values.sort(null);\n-        assertEquals(values, Lists.newArrayList(0, 1, 3, 6, 7));\n-\n-        int numOfItemsDeleted = set.removeIf(i -> i < 5);\n-        assertEquals(numOfItemsDeleted, 3);\n-        assertEquals(set.size(), values.size() - numOfItemsDeleted);\n-        values = set.values();\n-        values.sort(null);\n-        assertEquals(values, Lists.newArrayList(6, 7));\n-    }\n-\n-    @Test\n-    public void testHashConflictWithDeletion() {\n-        final int Buckets = 16;\n-        ConcurrentOpenHashSet<Long> set = new ConcurrentOpenHashSet<>(Buckets, 1);\n-\n-        // Pick 2 keys that fall into the same bucket\n-        long key1 = 1;\n-        long key2 = 27;\n-\n-        int bucket1 = ConcurrentOpenHashSet.signSafeMod(ConcurrentOpenHashSet.hash(key1), Buckets);\n-        int bucket2 = ConcurrentOpenHashSet.signSafeMod(ConcurrentOpenHashSet.hash(key2), Buckets);\n-        assertEquals(bucket1, bucket2);\n-\n-        assertTrue(set.add(key1));\n-        assertTrue(set.add(key2));\n-        assertEquals(set.size(), 2);\n-\n-        assertTrue(set.remove(key1));\n-        assertEquals(set.size(), 1);\n-\n-        assertTrue(set.add(key1));\n-        assertEquals(set.size(), 2);\n-\n-        assertTrue(set.remove(key1));\n-        assertEquals(set.size(), 1);\n-\n-        assertFalse(set.add(key2));\n-        assertTrue(set.contains(key2));\n-\n-        assertEquals(set.size(), 1);\n-        assertTrue(set.remove(key2));\n-        assertTrue(set.isEmpty());\n-    }\n-\n-    @Test\n-    public void testEqualsObjects() {\n-        class T {\n-            int value;\n-\n-            T(int value) {\n-                this.value = value;\n-            }\n-\n-            @Override\n-            public int hashCode() {\n-                return Integer.hashCode(value);\n-            }\n-\n-            @Override\n-            public boolean equals(Object obj) {\n-                if (obj instanceof T) {\n-                    return value == ((T) obj).value;\n-                }\n-\n-                return false;\n-            }\n-        }\n-\n-        ConcurrentOpenHashSet<T> set =\n-                ConcurrentOpenHashSet.<T>newBuilder().build();\n-\n-        T t1 = new T(1);\n-        T t1_b = new T(1);\n-        T t2 = new T(2);\n-\n-        assertEquals(t1, t1_b);\n-        assertNotEquals(t2, t1);\n-        assertNotEquals(t2, t1_b);\n-\n-        set.add(t1);\n-        assertTrue(set.contains(t1));\n-        assertTrue(set.contains(t1_b));\n-        assertFalse(set.contains(t2));\n-\n-        assertTrue(set.remove(t1_b));\n-        assertFalse(set.contains(t1));\n-        assertFalse(set.contains(t1_b));\n-    }\n-\n-}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23322",
    "pr_id": 23322,
    "issue_id": 23215,
    "repo": "apache/pulsar",
    "problem_statement": "Replace the ConcurrentOpenHashMap as much as possible\n### PR list\r\n- [x] https://github.com/apache/pulsar/pull/23217\r\n- [x] https://github.com/apache/pulsar/pull/23320\r\n- [x] https://github.com/apache/pulsar/pull/23322\r\n- [x] https://github.com/apache/pulsar/pull/23329\r\n\r\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\nThere was a discussion at Sep. 2023 before to replace Customized Map with ConcurrentOpenHashMap. In this issue, I'd focus on the `ConcurrentOpenHashMap`.\r\n\r\nHere is the only advantage of this map.\r\n\r\n> Provides similar methods as a {@code ConcurrentMap<K,V>} but since it's an open hash map with linear probing,  no node allocations are required to store the values.\r\n\r\nLet me count the disadvantages.\r\n\r\n### 1. Bad performance\r\n\r\nThis map was aded in the initial commit (on 2016). However, this implementation was just based on the Java 7 implementation of the `ConcurrentHashMap`, which uses a segment based lock. Actually, this solution was discarded by the Java team since Java 8.\r\n\r\nhttps://github.com/apache/pulsar/pull/20647/#issuecomment-1607257960 did a benchmark and found the performance was much worse than the current `ConcurrentHashMap` provided by Java library. We can also search the PROs of the Java 8 design in network, or just ask for ChatGPT.\r\n\r\nBesides, the frequently used `keys()` and `values()` methods just copy the keys and values to a new list. While the `ConcurrentHashMap` just returns a thread-safe internal view that users can choose whether to make a copy.\r\n\r\nAnyway, to prove the performance is worse than `ConcurrentHashMap`, we need to have more tests and research. So it's the least important reason.\r\n\r\n### 2. Lack of the updates\r\n\r\nThis class was rarely updated. What I can remember is the shrink support two years ago. https://github.com/apache/pulsar/pull/14663\r\n\r\nFrom https://github.com/apache/bookkeeper/pull/3061, we can see the motivation is the frequently appeared Full GC caused by this implementation. However, adding a `shrink` method makes it harder to use. There are already many parameters to tune, see it's builder:\r\n\r\n```java\r\n    public static class Builder<K, V> {\r\n        int expectedItems = DefaultExpectedItems;\r\n        int concurrencyLevel = DefaultConcurrencyLevel;\r\n        float mapFillFactor = DefaultMapFillFactor;\r\n        float mapIdleFactor = DefaultMapIdleFactor;\r\n        float expandFactor = DefaultExpandFactor;\r\n        float shrinkFactor = DefaultShrinkFactor;\r\n        boolean autoShrink = DefaultAutoShrink;\r\n```\r\n\r\nMany `xxxFactor`s and the concurrency level. It's hard to determine a proper value by default. However, it makes new developers hard to modify it.\r\n\r\n### 3. Bad debug experience\r\n\r\nWhen I debugged the topics maintained in a `BrokerService`.\r\n\r\n<img width=\"1031\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5dfb13d9-7897-429e-ab06-4888595a06c1\">\r\n\r\nAs you can see. There are 16 sections. And I have to iterate over all these sections and expand the `table` array to find the target topic.\r\n\r\nLet's compare it with the official `ConcurrentHashMap` (I replaced it locally)\r\n\r\n<img width=\"1211\" alt=\"image\" src=\"https://github.com/user-attachments/assets/49fbb5ba-7cb0-4225-922f-737af90ef5a7\">\r\n\r\nBesides, it's even harder to analyze in the heap dump.\r\n\r\n### 4. Not friendly to new developers\r\n\r\nMany places just use it as a concurrent hash map. **What's the reason for new developers to not use the official `ConcurrentHashMap`, which is developed and consistently improved by a professional team?** Just to reduce the node allocation? With the improving JVM GC?\r\n\r\nAs I've mentioned, this class might be introduced at the Java 7 era. Now the minimum required Java version of broker side is 17. We have ZGC. We have Shenandoah GC. We have many more JVM developers developing better GC. I'm suspecting if the advantage makes sense.\r\n\r\nI cannot think of a reason to choose this hard-to-maintain class rather than well-maintained official `ConcurrentHashMap`.\r\n\r\nFor example, when I maintained KoP, I encountered the deadlock of `ConcurrentLongHashMap` (maybe the similar implementation). https://github.com/streamnative/kop/pull/620 And it's hard to know if this case is fixed. So I have to switch to the official `ConcurrentHashMap`.\r\n\r\n### Solution\r\n\r\nReplace `ConcurrentOpenHashMap` with the official Java `ConcurrentHashMap`.\r\n\r\n### Alternatives\r\n\r\nN/A\r\n\r\n### Anything else?\r\n\r\nJava Concurrent HashMap Improvements over the years https://medium.com/@vikas.taank_40391/java-concurrent-hashmap-improvements-over-the-years-8d8b7be6ce37\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 709,
    "test_files_count": 17,
    "non_test_files_count": 8,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsController.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilder.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java"
    ],
    "base_commit": "f5c1ad24d7753eb203da3c7f3e4912b005b76044",
    "head_commit": "dbc8a651a87e275816e40ce5a7467e084815fe86",
    "repo_url": "https://github.com/apache/pulsar/pull/23322",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23322",
    "dockerfile": "",
    "pr_merged_at": "2024-09-21T11:48:21.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\nindex bdbd70afbaeac..8860c9bb06d4d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n@@ -1265,14 +1265,14 @@ private void resumeAsyncResponse(AsyncResponse asyncResponse, Set<String> subscr\n                     return;\n                 }\n             } else {\n-                asyncResponse.resume(new ArrayList<>(subscriptions));\n+                asyncResponse.resume(subscriptions);\n             }\n         });\n     }\n \n     private void internalGetSubscriptionsForNonPartitionedTopic(AsyncResponse asyncResponse) {\n         getTopicReferenceAsync(topicName)\n-                .thenAccept(topic -> asyncResponse.resume(new ArrayList<>(topic.getSubscriptions().keys())))\n+                .thenAccept(topic -> asyncResponse.resume(topic.getSubscriptions().keySet()))\n                 .exceptionally(ex -> {\n                     // If the exception is not redirect exception we need to log it.\n                     if (isNot307And404Exception(ex)) {\n@@ -2024,7 +2024,7 @@ private void internalExpireMessagesForAllSubscriptionsForNonPartitionedTopic(Asy\n                             new ArrayList<>((int) topic.getReplicators().size());\n                     List<String> subNames =\n                             new ArrayList<>((int) topic.getSubscriptions().size());\n-                    subNames.addAll(topic.getSubscriptions().keys().stream().filter(\n+                    subNames.addAll(topic.getSubscriptions().keySet().stream().filter(\n                             subName -> !subName.equals(Compactor.COMPACTION_SUBSCRIPTION)).toList());\n                     for (int i = 0; i < subNames.size(); i++) {\n                         try {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\nindex 3fdfeeee6e152..dce50a54db1f6 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/AbstractTopic.java\n@@ -26,6 +26,7 @@\n import java.time.Clock;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collection;\n import java.util.Collections;\n import java.util.EnumSet;\n import java.util.List;\n@@ -576,7 +577,7 @@ && getNumberOfSameAddressConsumers(consumer.getClientAddress()) >= maxSameAddres\n     public abstract int getNumberOfSameAddressConsumers(String clientAddress);\n \n     protected int getNumberOfSameAddressConsumers(final String clientAddress,\n-            final List<? extends Subscription> subscriptions) {\n+            final Collection<? extends Subscription> subscriptions) {\n         int count = 0;\n         if (clientAddress != null) {\n             for (Subscription subscription : subscriptions) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex 6b0be07c8f7a8..09f04d878c4e5 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -1176,7 +1176,7 @@ private CompletableFuture<Void> deleteTopicInternal(String topic, boolean forceD\n             // v2 topics have a global name so check if the topic is replicated.\n             if (t.isReplicated()) {\n                 // Delete is disallowed on global topic\n-                final List<String> clusters = t.getReplicators().keys();\n+                final var clusters = t.getReplicators().keySet();\n                 log.error(\"Delete forbidden topic {} is replicated on clusters {}\", topic, clusters);\n                 return FutureUtil.failedFuture(\n                         new IllegalStateException(\"Delete forbidden topic is replicated on clusters \" + clusters));\n@@ -1184,7 +1184,7 @@ private CompletableFuture<Void> deleteTopicInternal(String topic, boolean forceD\n \n             // shadow topic should be deleted first.\n             if (t.isShadowReplicated()) {\n-                final List<String> shadowTopics = t.getShadowReplicators().keys();\n+                final var shadowTopics = t.getShadowReplicators().keySet();\n                 log.error(\"Delete forbidden. Topic {} is replicated to shadow topics: {}\", topic, shadowTopics);\n                 return FutureUtil.failedFuture(new IllegalStateException(\n                         \"Delete forbidden. Topic \" + topic + \" is replicated to shadow topics.\"));\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\nindex 3ec09e9bfcd28..ec7889af6bbbe 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\n@@ -44,7 +44,6 @@\n import org.apache.pulsar.common.policies.data.stats.TopicStatsImpl;\n import org.apache.pulsar.common.protocol.schema.SchemaData;\n import org.apache.pulsar.common.protocol.schema.SchemaVersion;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.policies.data.loadbalancer.NamespaceBundleStats;\n import org.apache.pulsar.utils.StatsOutputStream;\n \n@@ -183,7 +182,7 @@ CompletableFuture<Subscription> createSubscription(String subscriptionName, Init\n \n     CompletableFuture<Void> unsubscribe(String subName);\n \n-    ConcurrentOpenHashMap<String, ? extends Subscription> getSubscriptions();\n+    Map<String, ? extends Subscription> getSubscriptions();\n \n     CompletableFuture<Void> delete();\n \n@@ -265,9 +264,9 @@ void updateRates(NamespaceStats nsStats, NamespaceBundleStats currentBundleStats\n \n     Subscription getSubscription(String subscription);\n \n-    ConcurrentOpenHashMap<String, ? extends Replicator> getReplicators();\n+    Map<String, ? extends Replicator> getReplicators();\n \n-    ConcurrentOpenHashMap<String, ? extends Replicator> getShadowReplicators();\n+    Map<String, ? extends Replicator> getShadowReplicators();\n \n     TopicStatsImpl getStats(boolean getPreciseBacklog, boolean subscriptionBacklogSize,\n                             boolean getEarliestTimeInBacklog);\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\nindex 2abd505d527cc..34c2678f847a5 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\n@@ -33,6 +33,7 @@\n import java.util.Set;\n import java.util.TreeMap;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicLongFieldUpdater;\n@@ -96,7 +97,6 @@\n import org.apache.pulsar.common.protocol.schema.SchemaData;\n import org.apache.pulsar.common.schema.SchemaType;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.policies.data.loadbalancer.NamespaceBundleStats;\n import org.apache.pulsar.utils.StatsOutputStream;\n import org.slf4j.Logger;\n@@ -105,9 +105,9 @@\n public class NonPersistentTopic extends AbstractTopic implements Topic, TopicPolicyListener {\n \n     // Subscriptions to this topic\n-    private final ConcurrentOpenHashMap<String, NonPersistentSubscription> subscriptions;\n+    private final Map<String, NonPersistentSubscription> subscriptions = new ConcurrentHashMap<>();\n \n-    private final ConcurrentOpenHashMap<String, NonPersistentReplicator> replicators;\n+    private final Map<String, NonPersistentReplicator> replicators = new ConcurrentHashMap<>();\n \n     // Ever increasing counter of entries added\n     private static final AtomicLongFieldUpdater<NonPersistentTopic> ENTRIES_ADDED_COUNTER_UPDATER =\n@@ -152,17 +152,6 @@ public void reset() {\n \n     public NonPersistentTopic(String topic, BrokerService brokerService) {\n         super(topic, brokerService);\n-\n-        this.subscriptions =\n-                ConcurrentOpenHashMap.<String, NonPersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        this.replicators =\n-                ConcurrentOpenHashMap.<String, NonPersistentReplicator>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n         this.isFenced = false;\n         registerTopicPolicyListener();\n     }\n@@ -446,8 +435,8 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions, boolean c\n                     if (failIfHasSubscriptions) {\n                         if (!subscriptions.isEmpty()) {\n                             isFenced = false;\n-                            deleteFuture.completeExceptionally(\n-                                    new TopicBusyException(\"Topic has subscriptions:\" + subscriptions.keys()));\n+                            deleteFuture.completeExceptionally(new TopicBusyException(\"Topic has subscriptions:\"\n+                                    + subscriptions.keySet().stream().toList()));\n                             return;\n                         }\n                     } else {\n@@ -714,18 +703,18 @@ public int getNumberOfSameAddressConsumers(final String clientAddress) {\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, NonPersistentSubscription> getSubscriptions() {\n+    public Map<String, NonPersistentSubscription> getSubscriptions() {\n         return subscriptions;\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, NonPersistentReplicator> getReplicators() {\n+    public Map<String, NonPersistentReplicator> getReplicators() {\n         return replicators;\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, ? extends Replicator> getShadowReplicators() {\n-        return ConcurrentOpenHashMap.emptyMap();\n+    public Map<String, ? extends Replicator> getShadowReplicators() {\n+        return Map.of();\n     }\n \n     @Override\n@@ -1043,7 +1032,6 @@ private CompletableFuture<Void> checkAndUnsubscribeSubscriptions() {\n \n     private CompletableFuture<Void> disconnectReplicators() {\n         List<CompletableFuture<Void>> futures = new ArrayList<>();\n-        ConcurrentOpenHashMap<String, NonPersistentReplicator> replicators = getReplicators();\n         replicators.forEach((r, replicator) -> {\n             futures.add(replicator.terminate());\n         });\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\nindex d664d6812adaa..f8581cfc79985 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n@@ -44,6 +44,7 @@\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.RejectedExecutionException;\n@@ -187,7 +188,6 @@\n import org.apache.pulsar.common.topics.TopicCompactionStrategy;\n import org.apache.pulsar.common.util.Codec;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.compaction.CompactedTopicContext;\n import org.apache.pulsar.compaction.CompactedTopicImpl;\n import org.apache.pulsar.compaction.Compactor;\n@@ -207,10 +207,10 @@ public class PersistentTopic extends AbstractTopic implements Topic, AddEntryCal\n     protected final ManagedLedger ledger;\n \n     // Subscriptions to this topic\n-    private final ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions;\n+    private final Map<String, PersistentSubscription> subscriptions = new ConcurrentHashMap<>();\n \n-    private final ConcurrentOpenHashMap<String/*RemoteCluster*/, Replicator> replicators;\n-    private final ConcurrentOpenHashMap<String/*ShadowTopic*/, Replicator> shadowReplicators;\n+    private final Map<String/*RemoteCluster*/, Replicator> replicators = new ConcurrentHashMap<>();\n+    private final Map<String/*ShadowTopic*/, Replicator> shadowReplicators = new ConcurrentHashMap<>();\n     @Getter\n     private volatile List<String> shadowTopics;\n     private final TopicName shadowSourceTopic;\n@@ -392,18 +392,6 @@ public PersistentTopic(String topic, ManagedLedger ledger, BrokerService brokerS\n                 ? brokerService.getTopicOrderedExecutor().chooseThread(topic)\n                 : null;\n         this.ledger = ledger;\n-        this.subscriptions = ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n-        this.replicators = ConcurrentOpenHashMap.<String, Replicator>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n-        this.shadowReplicators = ConcurrentOpenHashMap.<String, Replicator>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n         this.backloggedCursorThresholdEntries =\n                 brokerService.pulsar().getConfiguration().getManagedLedgerCursorBackloggedThreshold();\n         this.messageDeduplication = new MessageDeduplication(brokerService.pulsar(), this, ledger);\n@@ -429,6 +417,28 @@ public PersistentTopic(String topic, ManagedLedger ledger, BrokerService brokerS\n         }\n     }\n \n+    @VisibleForTesting\n+    PersistentTopic(String topic, BrokerService brokerService, ManagedLedger ledger,\n+                    MessageDeduplication messageDeduplication) {\n+        super(topic, brokerService);\n+        // null check for backwards compatibility with tests which mock the broker service\n+        this.orderedExecutor = brokerService.getTopicOrderedExecutor() != null\n+                ? brokerService.getTopicOrderedExecutor().chooseThread(topic)\n+                : null;\n+        this.ledger = ledger;\n+        this.messageDeduplication = messageDeduplication;\n+        this.backloggedCursorThresholdEntries =\n+                brokerService.pulsar().getConfiguration().getManagedLedgerCursorBackloggedThreshold();\n+\n+        if (brokerService.pulsar().getConfiguration().isTransactionCoordinatorEnabled()) {\n+            this.transactionBuffer = brokerService.getPulsar()\n+                    .getTransactionBufferProvider().newTransactionBuffer(this);\n+        } else {\n+            this.transactionBuffer = new TransactionBufferDisable(this);\n+        }\n+        shadowSourceTopic = null;\n+    }\n+\n     @Override\n     public CompletableFuture<Void> initialize() {\n         List<CompletableFuture<Void>> futures = new ArrayList<>();\n@@ -476,41 +486,6 @@ public CompletableFuture<Void> initialize() {\n                 }));\n     }\n \n-    // for testing purposes\n-    @VisibleForTesting\n-    PersistentTopic(String topic, BrokerService brokerService, ManagedLedger ledger,\n-                    MessageDeduplication messageDeduplication) {\n-        super(topic, brokerService);\n-        // null check for backwards compatibility with tests which mock the broker service\n-        this.orderedExecutor = brokerService.getTopicOrderedExecutor() != null\n-                ? brokerService.getTopicOrderedExecutor().chooseThread(topic)\n-                : null;\n-        this.ledger = ledger;\n-        this.messageDeduplication = messageDeduplication;\n-        this.subscriptions = ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n-        this.replicators = ConcurrentOpenHashMap.<String, Replicator>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n-        this.shadowReplicators = ConcurrentOpenHashMap.<String, Replicator>newBuilder()\n-                .expectedItems(16)\n-                .concurrencyLevel(1)\n-                .build();\n-        this.backloggedCursorThresholdEntries =\n-                brokerService.pulsar().getConfiguration().getManagedLedgerCursorBackloggedThreshold();\n-\n-        if (brokerService.pulsar().getConfiguration().isTransactionCoordinatorEnabled()) {\n-            this.transactionBuffer = brokerService.getPulsar()\n-                    .getTransactionBufferProvider().newTransactionBuffer(this);\n-        } else {\n-            this.transactionBuffer = new TransactionBufferDisable(this);\n-        }\n-        shadowSourceTopic = null;\n-    }\n-\n     private void initializeDispatchRateLimiterIfNeeded() {\n         synchronized (dispatchRateLimiterLock) {\n             // dispatch rate limiter for topic\n@@ -1455,8 +1430,8 @@ private CompletableFuture<Void> delete(boolean failIfHasSubscriptions,\n             //     In this case, we shouldn't care if the usageCount is 0 or not, just proceed\n             if (!closeIfClientsConnected) {\n                 if (failIfHasSubscriptions && !subscriptions.isEmpty()) {\n-                    return FutureUtil.failedFuture(\n-                            new TopicBusyException(\"Topic has subscriptions: \" + subscriptions.keys()));\n+                    return FutureUtil.failedFuture(new TopicBusyException(\"Topic has subscriptions: \"\n+                            + subscriptions.keySet().stream().toList()));\n                 } else if (failIfHasBacklogs) {\n                     if (hasBacklogs(false)) {\n                         List<String> backlogSubs =\n@@ -2129,10 +2104,6 @@ protected CompletableFuture<Void> addReplicationCluster(String remoteCluster, Ma\n                             }\n                             return null;\n                         });\n-                        // clean up replicator if startup is failed\n-                        if (replicator == null) {\n-                            replicators.removeNullValue(remoteCluster);\n-                        }\n                     } finally {\n                         lock.readLock().unlock();\n                     }\n@@ -2210,11 +2181,6 @@ protected CompletableFuture<Void> addShadowReplicationCluster(String shadowTopic\n                         }\n                         return null;\n                     });\n-\n-                    // clean up replicator if startup is failed\n-                    if (replicator == null) {\n-                        shadowReplicators.removeNullValue(shadowTopic);\n-                    }\n                 });\n     }\n \n@@ -2274,7 +2240,7 @@ protected String getSchemaId() {\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, PersistentSubscription> getSubscriptions() {\n+    public Map<String, PersistentSubscription> getSubscriptions() {\n         return subscriptions;\n     }\n \n@@ -2284,12 +2250,12 @@ public PersistentSubscription getSubscription(String subscriptionName) {\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, Replicator> getReplicators() {\n+    public Map<String, Replicator> getReplicators() {\n         return replicators;\n     }\n \n     @Override\n-    public ConcurrentOpenHashMap<String, Replicator> getShadowReplicators() {\n+    public Map<String, Replicator> getShadowReplicators() {\n         return shadowReplicators;\n     }\n \n@@ -3091,7 +3057,6 @@ private CompletableFuture<Void> checkAndDisconnectProducers() {\n \n     private CompletableFuture<Void> checkAndDisconnectReplicators() {\n         List<CompletableFuture<Void>> futures = new ArrayList<>();\n-        ConcurrentOpenHashMap<String, Replicator> replicators = getReplicators();\n         replicators.forEach((r, replicator) -> {\n             if (replicator.getNumberOfEntriesInBacklog() <= 0) {\n                 futures.add(replicator.terminate());\n@@ -3106,12 +3071,9 @@ public boolean shouldProducerMigrate() {\n \n     @Override\n     public boolean isReplicationBacklogExist() {\n-        ConcurrentOpenHashMap<String, Replicator> replicators = getReplicators();\n-        if (replicators != null) {\n-            for (Replicator replicator : replicators.values()) {\n-                if (replicator.getNumberOfEntriesInBacklog() > 0) {\n-                    return true;\n-                }\n+        for (Replicator replicator : replicators.values()) {\n+            if (replicator.getNumberOfEntriesInBacklog() > 0) {\n+                return true;\n             }\n         }\n         return false;\n@@ -3759,9 +3721,9 @@ public boolean isOldestMessageExpired(ManagedCursor cursor, int messageTTLInSeco\n     public CompletableFuture<Void> clearBacklog() {\n         log.info(\"[{}] Clearing backlog on all cursors in the topic.\", topic);\n         List<CompletableFuture<Void>> futures = new ArrayList<>();\n-        List<String> cursors = getSubscriptions().keys();\n-        cursors.addAll(getReplicators().keys());\n-        cursors.addAll(getShadowReplicators().keys());\n+        List<String> cursors = new ArrayList<>(getSubscriptions().keySet());\n+        cursors.addAll(getReplicators().keySet());\n+        cursors.addAll(getShadowReplicators().keySet());\n         for (String cursor : cursors) {\n             futures.add(clearBacklog(cursor));\n         }\n@@ -4161,7 +4123,7 @@ private void unfenceReplicatorsToResume() {\n         checkShadowReplication();\n     }\n \n-    private void removeTerminatedReplicators(ConcurrentOpenHashMap<String, Replicator> replicators) {\n+    private void removeTerminatedReplicators(Map<String, Replicator> replicators) {\n         Map<String, Replicator> terminatedReplicators = new HashMap<>();\n         replicators.forEach((cluster, replicator) -> {\n             if (replicator.isTerminated()) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsController.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsController.java\nindex b873bc93cd1e4..f56cf9de66b75 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsController.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsController.java\n@@ -243,7 +243,8 @@ private void startNewSnapshot() {\n         pendingSnapshotsMetric.inc();\n         stats.recordSnapshotStarted();\n         ReplicatedSubscriptionsSnapshotBuilder builder = new ReplicatedSubscriptionsSnapshotBuilder(this,\n-                topic.getReplicators().keys(), topic.getBrokerService().pulsar().getConfiguration(), Clock.systemUTC());\n+                topic.getReplicators().keySet(), topic.getBrokerService().pulsar().getConfiguration(),\n+                Clock.systemUTC());\n         pendingSnapshots.put(builder.getSnapshotId(), builder);\n         builder.start();\n     }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilder.java\nindex 0dacade3eed1c..e08b549f8aec9 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilder.java\n@@ -20,7 +20,6 @@\n \n import io.prometheus.client.Summary;\n import java.time.Clock;\n-import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.TreeMap;\n@@ -43,7 +42,7 @@ public class ReplicatedSubscriptionsSnapshotBuilder {\n     private final ReplicatedSubscriptionsController controller;\n \n     private final Map<String, MarkersMessageIdData> responses = new TreeMap<>();\n-    private final List<String> remoteClusters;\n+    private final Set<String> remoteClusters;\n     private final Set<String> missingClusters;\n \n     private final boolean needTwoRounds;\n@@ -60,7 +59,7 @@ public class ReplicatedSubscriptionsSnapshotBuilder {\n             \"Time taken to create a consistent snapshot across clusters\").register();\n \n     public ReplicatedSubscriptionsSnapshotBuilder(ReplicatedSubscriptionsController controller,\n-                                                  List<String> remoteClusters, ServiceConfiguration conf, Clock clock) {\n+                                                  Set<String> remoteClusters, ServiceConfiguration conf, Clock clock) {\n         this.snapshotId = UUID.randomUUID().toString();\n         this.controller = controller;\n         this.remoteClusters = remoteClusters;\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java\nindex 5432b8a430d63..4a1dbface2c63 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiTest.java\n@@ -2315,8 +2315,8 @@ public void testUnsubscribeOnNamespace(Integer numBundles) throws Exception {\n \n         admin.namespaces().unsubscribeNamespace(\"prop-xyz/ns1-bundles\", \"my-sub\");\n \n-        assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/ns1-bundles/ds2\"),\n-                List.of(\"my-sub-1\", \"my-sub-2\"));\n+        assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/ns1-bundles/ds2\").stream().sorted()\n+                .toList(), List.of(\"my-sub-1\", \"my-sub-2\"));\n         assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/ns1-bundles/ds1\"),\n                 List.of(\"my-sub-1\"));\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\nindex 55b4c6e1c6f59..18fd3dd1c8bb3 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/PersistentTopicsTest.java\n@@ -251,7 +251,7 @@ public void testGetSubscriptions() {\n         response = mock(AsyncResponse.class);\n         persistentTopics.getSubscriptions(response, testTenant, testNamespace, testLocalTopicName + \"-partition-0\",\n                 true);\n-        verify(response, timeout(5000).times(1)).resume(List.of(\"test\"));\n+        verify(response, timeout(5000).times(1)).resume(Set.of(\"test\"));\n \n         // 6) Delete the subscription\n         response = mock(AsyncResponse.class);\n@@ -265,7 +265,7 @@ public void testGetSubscriptions() {\n         response = mock(AsyncResponse.class);\n         persistentTopics.getSubscriptions(response, testTenant, testNamespace, testLocalTopicName + \"-partition-0\",\n                 true);\n-        verify(response, timeout(5000).times(1)).resume(new ArrayList<>());\n+        verify(response, timeout(5000).times(1)).resume(Set.of());\n \n         // 8) Create a sub of partitioned-topic\n         response = mock(AsyncResponse.class);\n@@ -279,16 +279,16 @@ public void testGetSubscriptions() {\n         response = mock(AsyncResponse.class);\n         persistentTopics.getSubscriptions(response, testTenant, testNamespace, testLocalTopicName + \"-partition-1\",\n                 true);\n-        verify(response, timeout(5000).times(1)).resume(List.of(\"test\"));\n+        verify(response, timeout(5000).times(1)).resume(Set.of(\"test\"));\n         //\n         response = mock(AsyncResponse.class);\n         persistentTopics.getSubscriptions(response, testTenant, testNamespace, testLocalTopicName + \"-partition-0\",\n                 true);\n-        verify(response, timeout(5000).times(1)).resume(new ArrayList<>());\n+        verify(response, timeout(5000).times(1)).resume(Set.of());\n         //\n         response = mock(AsyncResponse.class);\n         persistentTopics.getSubscriptions(response, testTenant, testNamespace, testLocalTopicName, true);\n-        verify(response, timeout(5000).times(1)).resume(List.of(\"test\"));\n+        verify(response, timeout(5000).times(1)).resume(Set.of(\"test\"));\n \n         // 9) Delete the partitioned topic\n         response = mock(AsyncResponse.class);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\nindex 1351c41e4279e..dc9a7ec4429fc 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/TopicPoliciesTest.java\n@@ -88,10 +88,8 @@\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.policies.data.TopicPolicies;\n import org.apache.pulsar.common.policies.data.TopicStats;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.assertj.core.api.Assertions;\n import org.awaitility.Awaitility;\n-import org.awaitility.reflect.WhiteboxImpl;\n import org.mockito.Mockito;\n import org.testng.Assert;\n import org.testng.annotations.AfterMethod;\n@@ -3199,8 +3197,7 @@ public void testUpdateRetentionWithPartialFailure() throws Exception {\n         // Inject an error that makes dispatch rate update fail.\n         PersistentTopic persistentTopic =\n                 (PersistentTopic) pulsar.getBrokerService().getTopic(tpName, false).join().get();\n-        ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions =\n-                WhiteboxImpl.getInternalState(persistentTopic, \"subscriptions\");\n+        final var subscriptions = persistentTopic.getSubscriptions();\n         PersistentSubscription mockedSubscription = Mockito.mock(PersistentSubscription.class);\n         Mockito.when(mockedSubscription.getDispatcher()).thenThrow(new RuntimeException(\"Mocked error: getDispatcher\"));\n         subscriptions.put(\"mockedSubscription\", mockedSubscription);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java\nindex f2faa98636ba2..d92c3126c5404 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/v1/V1_AdminApiTest.java\n@@ -1380,8 +1380,8 @@ public void testUnsubscribeOnNamespace(Integer numBundles) throws Exception {\n \n         admin.namespaces().unsubscribeNamespace(\"prop-xyz/use/ns1-bundles\", \"my-sub\");\n \n-        assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/use/ns1-bundles/ds2\"),\n-                List.of(\"my-sub-1\", \"my-sub-2\"));\n+        assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/use/ns1-bundles/ds2\").stream()\n+                .sorted().toList(), List.of(\"my-sub-1\", \"my-sub-2\"));\n         assertEquals(admin.topics().getSubscriptions(\"persistent://prop-xyz/use/ns1-bundles/ds1\"),\n                 List.of(\"my-sub-1\"));\n \n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java\nindex 39be56e3f41cf..337717ed97b1b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractTopicTest.java\n@@ -24,10 +24,10 @@\n import static org.mockito.Mockito.when;\n import static org.mockito.Mockito.withSettings;\n import static org.testng.Assert.assertEquals;\n+import java.util.concurrent.ConcurrentHashMap;\n import org.apache.pulsar.broker.PulsarService;\n import org.apache.pulsar.broker.ServiceConfiguration;\n import org.apache.pulsar.broker.qos.AsyncTokenBucket;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n \n@@ -54,11 +54,7 @@ public void beforeMethod() {\n                 .useConstructor(\"topic\", brokerService)\n                 .defaultAnswer(CALLS_REAL_METHODS));\n \n-        ConcurrentOpenHashMap<String, Subscription> subscriptions =\n-                ConcurrentOpenHashMap.<String, Subscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n+        final var subscriptions = new ConcurrentHashMap<String, Subscription>();\n         subscriptions.put(\"subscription\", subscription);\n         when(topic.getSubscriptions()).thenAnswer(invocation -> subscriptions);\n     }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\nindex 8ec565f7d4566..e56a3495600f0 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ClusterMigrationTest.java\n@@ -49,7 +49,6 @@\n import org.apache.pulsar.common.policies.data.ClusterData;\n import org.apache.pulsar.common.policies.data.ClusterPolicies.ClusterUrl;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.testng.annotations.AfterMethod;\n@@ -344,7 +343,7 @@ public void testClusterMigration() throws Exception {\n         assertFalse(topic2.getSubscriptions().isEmpty());\n \n         topic1.checkClusterMigration().get();\n-        ConcurrentOpenHashMap<String, ? extends Replicator> replicators = topic1.getReplicators();\n+        final var replicators = topic1.getReplicators();\n         replicators.forEach((r, replicator) -> {\n             assertFalse(replicator.isConnected());\n         });\n@@ -798,20 +797,20 @@ public void testNamespaceMigration(SubscriptionType subType, boolean isClusterMi\n             blueTopicNs2_1.checkClusterMigration().get();\n         }\n \n-        ConcurrentOpenHashMap<String, ? extends Replicator> replicators = blueTopicNs1_1.getReplicators();\n+        final var replicators = blueTopicNs1_1.getReplicators();\n         replicators.forEach((r, replicator) -> {\n             assertFalse(replicator.isConnected());\n         });\n         assertTrue(blueTopicNs1_1.getSubscriptions().isEmpty());\n \n         if (isClusterMigrate) {\n-            ConcurrentOpenHashMap<String, ? extends Replicator> replicatorsNm = blueTopicNs2_1.getReplicators();\n+            final var replicatorsNm = blueTopicNs2_1.getReplicators();\n             replicatorsNm.forEach((r, replicator) -> {\n                 assertFalse(replicator.isConnected());\n             });\n             assertTrue(blueTopicNs2_1.getSubscriptions().isEmpty());\n         } else {\n-            ConcurrentOpenHashMap<String, ? extends Replicator> replicatorsNm = blueTopicNs2_1.getReplicators();\n+            final var replicatorsNm = blueTopicNs2_1.getReplicators();\n             replicatorsNm.forEach((r, replicator) -> {\n                 assertTrue(replicator.isConnected());\n             });\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java\nindex cbbb8808f3d1a..85e0887465db2 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicConcurrentTest.java\n@@ -53,7 +53,6 @@\n import org.apache.pulsar.common.naming.NamespaceBundle;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.policies.data.InactiveTopicDeleteMode;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n import org.testng.annotations.BeforeMethod;\n@@ -154,7 +153,7 @@ public void testConcurrentTopicAndSubscriptionDelete() throws Exception {\n             try {\n                 barrier.await();\n                 // do subscription delete\n-                ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions = topic.getSubscriptions();\n+                final var subscriptions = topic.getSubscriptions();\n                 PersistentSubscription ps = subscriptions.get(successSubName);\n                 // Thread.sleep(2,0);\n                 log.info(\"unsubscriber outcome is {}\", ps.doUnsubscribe(ps.getConsumers().get(0)).get());\n@@ -219,7 +218,7 @@ public void testConcurrentTopicGCAndSubscriptionDelete() throws Exception {\n             try {\n                 barrier.await();\n                 // do subscription delete\n-                ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions = topic.getSubscriptions();\n+                final var subscriptions = topic.getSubscriptions();\n                 PersistentSubscription ps = subscriptions.get(successSubName);\n                 // Thread.sleep(2,0);\n                 log.info(\"unsubscriber outcome is {}\", ps.doUnsubscribe(ps.getConsumers().get(0)).get());\n@@ -278,7 +277,7 @@ public void testConcurrentTopicDeleteAndUnsubscribe() throws Exception {\n                 barrier.await();\n                 // Thread.sleep(2,0);\n                 // assertTrue(topic.unsubscribe(successSubName).isDone());\n-                ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions = topic.getSubscriptions();\n+                final var subscriptions = topic.getSubscriptions();\n                 PersistentSubscription ps = subscriptions.get(successSubName);\n                 log.info(\"unsubscribe result : {}\", topic.unsubscribe(successSubName).get());\n                 log.info(\"closing consumer..\");\n@@ -339,7 +338,7 @@ public void testConcurrentTopicDeleteAndSubsUnsubscribe() throws Exception {\n                 log.info(\"&&&&&&&&& UNSUBSCRIBER TH\");\n                 // Thread.sleep(2,0);\n                 // assertTrue(topic.unsubscribe(successSubName).isDone());\n-                ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions = topic.getSubscriptions();\n+                final var subscriptions = topic.getSubscriptions();\n                 PersistentSubscription ps = subscriptions.get(successSubName);\n                 log.info(\"unsubscribe result : \" + ps.doUnsubscribe(ps.getConsumers().get(0)).get());\n             } catch (Exception e) {\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java\nindex b975041d04ee4..81c12df4f3918 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentTopicTest.java\n@@ -64,6 +64,7 @@\n import java.util.Optional;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.CyclicBarrier;\n import java.util.concurrent.ExecutionException;\n@@ -132,7 +133,6 @@\n import org.apache.pulsar.common.protocol.schema.SchemaVersion;\n import org.apache.pulsar.common.util.Codec;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.compaction.CompactedTopic;\n import org.apache.pulsar.compaction.CompactedTopicContext;\n import org.apache.pulsar.compaction.Compactor;\n@@ -777,11 +777,7 @@ private void testMaxConsumersShared() throws Exception {\n         addConsumerToSubscription.setAccessible(true);\n \n         // for count consumers on topic\n-        ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions =\n-                ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n+        final var subscriptions = new ConcurrentHashMap<String, PersistentSubscription>();\n         subscriptions.put(\"sub-1\", sub);\n         subscriptions.put(\"sub-2\", sub2);\n         Field field = topic.getClass().getDeclaredField(\"subscriptions\");\n@@ -873,11 +869,7 @@ private void testMaxConsumersFailover() throws Exception {\n         addConsumerToSubscription.setAccessible(true);\n \n         // for count consumers on topic\n-        ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions =\n-                ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n+        final var subscriptions = new ConcurrentHashMap<String, PersistentSubscription>();\n         subscriptions.put(\"sub-1\", sub);\n         subscriptions.put(\"sub-2\", sub2);\n         Field field = topic.getClass().getDeclaredField(\"subscriptions\");\n@@ -992,11 +984,7 @@ public void testMaxSameAddressConsumers() throws Exception {\n         addConsumerToSubscription.setAccessible(true);\n \n         // for count consumers on topic\n-        ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions =\n-                ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n+        final var subscriptions = new ConcurrentHashMap<String, PersistentSubscription>();\n         subscriptions.put(\"sub1\", sub1);\n         subscriptions.put(\"sub2\", sub2);\n         Field field = topic.getClass().getDeclaredField(\"subscriptions\");\n@@ -1299,7 +1287,7 @@ public void testConcurrentTopicAndSubscriptionDelete() throws Exception {\n             try {\n                 barrier.await();\n                 // do subscription delete\n-                ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions = topic.getSubscriptions();\n+                final var subscriptions = topic.getSubscriptions();\n                 PersistentSubscription ps = subscriptions.get(successSubName);\n                 // Thread.sleep(5,0);\n                 log.info(\"unsubscriber outcome is {}\", ps.doUnsubscribe(ps.getConsumers().get(0)).get());\n@@ -1681,7 +1669,7 @@ public void testAtomicReplicationRemoval() throws Exception {\n         PersistentTopic topic = new PersistentTopic(globalTopicName, ledgerMock, brokerService);\n         topic.initialize().join();\n         String remoteReplicatorName = topic.getReplicatorPrefix() + \".\" + remoteCluster;\n-        ConcurrentOpenHashMap<String, Replicator> replicatorMap = topic.getReplicators();\n+        final var replicatorMap = topic.getReplicators();\n \n         ManagedCursor cursor = mock(ManagedCursorImpl.class);\n         doReturn(remoteCluster).when(cursor).getName();\n@@ -2018,11 +2006,7 @@ public void addFailed(ManagedLedgerException exception, Object ctx) {\n     public void testCheckInactiveSubscriptions() throws Exception {\n         PersistentTopic topic = new PersistentTopic(successTopicName, ledgerMock, brokerService);\n \n-        ConcurrentOpenHashMap<String, PersistentSubscription> subscriptions =\n-                ConcurrentOpenHashMap.<String, PersistentSubscription>newBuilder()\n-                        .expectedItems(16)\n-                        .concurrencyLevel(1)\n-                        .build();\n+        final var subscriptions = new ConcurrentHashMap<String, PersistentSubscription>();\n         // This subscription is connected by consumer.\n         PersistentSubscription nonDeletableSubscription1 =\n                 spyWithClassAndConstructorArgsRecordingInvocations(PersistentSubscription.class, topic,\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java\nindex 4273e8bbaeb5b..5b896a22baa33 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatedSubscriptionTest.java\n@@ -68,7 +68,6 @@\n import org.apache.pulsar.common.policies.data.PersistentTopicInternalStats;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.policies.data.TopicStats;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -292,7 +291,7 @@ public void testReplicatedSubscribeAndSwitchToStandbyCluster() throws Exception\n             sentMessages.add(msg);\n         }\n         Awaitility.await().untilAsserted(() -> {\n-            ConcurrentOpenHashMap<String, ? extends Replicator> replicators = topic1.getReplicators();\n+            final var replicators = topic1.getReplicators();\n             assertTrue(replicators != null && replicators.size() == 1, \"Replicator should started\");\n             assertTrue(replicators.values().iterator().next().isConnected(), \"Replicator should be connected\");\n             assertTrue(topic1.getReplicatedSubscriptionController().get().getLastCompletedSnapshotId().isPresent(),\n@@ -1072,7 +1071,7 @@ private void testReplicatedSubscriptionWhenEnableReplication(Producer<byte[]> pr\n         Awaitility.await().untilAsserted(() -> {\n             List<String> keys = pulsar1.getBrokerService()\n                     .getTopic(topic, false).get().get()\n-                    .getReplicators().keys();\n+                    .getReplicators().keySet().stream().toList();\n             assertEquals(keys.size(), 1);\n             assertTrue(pulsar1.getBrokerService()\n                     .getTopic(topic, false).get().get()\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java\nindex 90df16360614d..bec6b558ea401 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorRateLimiterTest.java\n@@ -25,9 +25,11 @@\n import static org.testng.AssertJUnit.assertFalse;\n import com.google.common.collect.Sets;\n import java.lang.reflect.Method;\n+import java.util.Optional;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n import lombok.Cleanup;\n+import org.apache.pulsar.broker.service.persistent.DispatchRateLimiter;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.client.api.Consumer;\n import org.apache.pulsar.client.api.MessageRoutingMode;\n@@ -101,7 +103,7 @@ public void testReplicatorRateLimiterWithOnlyTopicLevel() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         // rate limiter disable by default\n-        assertFalse(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n+        assertFalse(getRateLimiter(topic).isPresent());\n \n         //set topic-level policy, which should take effect\n         DispatchRate topicRate = DispatchRate.builder()\n@@ -112,16 +114,16 @@ public void testReplicatorRateLimiterWithOnlyTopicLevel() throws Exception {\n         admin1.topics().setReplicatorDispatchRate(topicName, topicRate);\n         Awaitility.await().untilAsserted(() ->\n             assertEquals(admin1.topics().getReplicatorDispatchRate(topicName), topicRate));\n-        assertTrue(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 10);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 20L);\n+        assertTrue(getRateLimiter(topic).isPresent());\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 10);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 20L);\n \n         //remove topic-level policy\n         admin1.topics().removeReplicatorDispatchRate(topicName);\n         Awaitility.await().untilAsserted(() ->\n             assertNull(admin1.topics().getReplicatorDispatchRate(topicName)));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), -1);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(),\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), -1);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(),\n             -1L);\n     }\n \n@@ -145,7 +147,7 @@ public void testReplicatorRateLimiterWithOnlyNamespaceLevel() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         // rate limiter disable by default\n-        assertFalse(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n+        assertFalse(getRateLimiter(topic).isPresent());\n \n         //set namespace-level policy, which should take effect\n         DispatchRate topicRate = DispatchRate.builder()\n@@ -156,16 +158,16 @@ public void testReplicatorRateLimiterWithOnlyNamespaceLevel() throws Exception {\n         admin1.namespaces().setReplicatorDispatchRate(namespace, topicRate);\n         Awaitility.await().untilAsserted(() ->\n             assertEquals(admin1.namespaces().getReplicatorDispatchRate(namespace), topicRate));\n-        assertTrue(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 10);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 20L);\n+        assertTrue(getRateLimiter(topic).isPresent());\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 10);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 20L);\n \n         //remove topic-level policy\n         admin1.namespaces().removeReplicatorDispatchRate(namespace);\n         Awaitility.await().untilAsserted(() ->\n             assertNull(admin1.namespaces().getReplicatorDispatchRate(namespace)));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), -1);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(),\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), -1);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(),\n             -1L);\n     }\n \n@@ -189,7 +191,7 @@ public void testReplicatorRateLimiterWithOnlyBrokerLevel() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         // rate limiter disable by default\n-        assertFalse(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n+        assertFalse(getRateLimiter(topic).isPresent());\n \n         //set broker-level policy, which should take effect\n         admin1.brokers().updateDynamicConfiguration(\"dispatchThrottlingRatePerReplicatorInMsg\", \"10\");\n@@ -203,9 +205,9 @@ public void testReplicatorRateLimiterWithOnlyBrokerLevel() throws Exception {\n                 .getAllDynamicConfigurations().get(\"dispatchThrottlingRatePerReplicatorInByte\"), \"20\");\n         });\n \n-        assertTrue(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 10);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 20L);\n+        assertTrue(getRateLimiter(topic).isPresent());\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 10);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 20L);\n     }\n \n     @Test\n@@ -228,9 +230,9 @@ public void testReplicatorRatePriority() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         //use broker-level by default\n-        assertTrue(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 100);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 200L);\n+        assertTrue(getRateLimiter(topic).isPresent());\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 100);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 200L);\n \n         //set namespace-level policy, which should take effect\n         DispatchRate nsDispatchRate = DispatchRate.builder()\n@@ -241,8 +243,8 @@ public void testReplicatorRatePriority() throws Exception {\n         admin1.namespaces().setReplicatorDispatchRate(namespace, nsDispatchRate);\n         Awaitility.await()\n                 .untilAsserted(() -> assertEquals(admin1.namespaces().getReplicatorDispatchRate(namespace), nsDispatchRate));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 50);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 60L);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 50);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 60L);\n \n         //set topic-level policy, which should take effect\n         DispatchRate topicRate = DispatchRate.builder()\n@@ -253,8 +255,8 @@ public void testReplicatorRatePriority() throws Exception {\n         admin1.topics().setReplicatorDispatchRate(topicName, topicRate);\n         Awaitility.await().untilAsserted(() ->\n                 assertEquals(admin1.topics().getReplicatorDispatchRate(topicName), topicRate));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 10);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 20L);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 10);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 20L);\n \n         //Set the namespace-level policy, which should not take effect\n         DispatchRate nsDispatchRate2 = DispatchRate.builder()\n@@ -265,21 +267,21 @@ public void testReplicatorRatePriority() throws Exception {\n         admin1.namespaces().setReplicatorDispatchRate(namespace, nsDispatchRate2);\n         Awaitility.await()\n                 .untilAsserted(() -> assertEquals(admin1.namespaces().getReplicatorDispatchRate(namespace), nsDispatchRate2));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), 20L);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), 20L);\n \n         //remove topic-level policy, namespace-level should take effect\n         admin1.topics().removeReplicatorDispatchRate(topicName);\n         Awaitility.await().untilAsserted(() ->\n                 assertNull(admin1.topics().getReplicatorDispatchRate(topicName)));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 500);\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(),\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 500);\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(),\n                 600L);\n \n         //remove namespace-level policy, broker-level should take effect\n         admin1.namespaces().setReplicatorDispatchRate(namespace, null);\n         Awaitility.await().untilAsserted(() ->\n-                assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), 100));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(),\n+                assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), 100));\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(),\n                 200L);\n     }\n \n@@ -315,7 +317,7 @@ public void testReplicatorRateLimiterDynamicallyChange() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         // 1. default replicator throttling not configured\n-        Assert.assertFalse(topic.getReplicators().values().get(0).getRateLimiter().isPresent());\n+        Assert.assertFalse(getRateLimiter(topic).isPresent());\n \n         // 2. change namespace setting of replicator dispatchRateMsg, verify topic changed.\n         int messageRate = 100;\n@@ -329,7 +331,7 @@ public void testReplicatorRateLimiterDynamicallyChange() throws Exception {\n         boolean replicatorUpdated = false;\n         int retry = 5;\n         for (int i = 0; i < retry; i++) {\n-            if (topic.getReplicators().values().get(0).getRateLimiter().isPresent()) {\n+            if (getRateLimiter(topic).isPresent()) {\n                 replicatorUpdated = true;\n                 break;\n             } else {\n@@ -339,7 +341,7 @@ public void testReplicatorRateLimiterDynamicallyChange() throws Exception {\n             }\n         }\n         Assert.assertTrue(replicatorUpdated);\n-        Assert.assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), messageRate);\n+        Assert.assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), messageRate);\n \n         // 3. change namespace setting of replicator dispatchRateByte, verify topic changed.\n         messageRate = 500;\n@@ -351,7 +353,7 @@ public void testReplicatorRateLimiterDynamicallyChange() throws Exception {\n         admin1.namespaces().setReplicatorDispatchRate(namespace, dispatchRateByte);\n         replicatorUpdated = false;\n         for (int i = 0; i < retry; i++) {\n-            if (topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte() == messageRate) {\n+            if (getRateLimiter(topic).get().getDispatchRateOnByte() == messageRate) {\n                 replicatorUpdated = true;\n                 break;\n             } else {\n@@ -414,7 +416,7 @@ public void testReplicatorRateLimiterMessageNotReceivedAllMessages(DispatchRateT\n         boolean replicatorUpdated = false;\n         int retry = 5;\n         for (int i = 0; i < retry; i++) {\n-            if (topic.getReplicators().values().get(0).getRateLimiter().isPresent()) {\n+            if (getRateLimiter(topic).isPresent()) {\n                 replicatorUpdated = true;\n                 break;\n             } else {\n@@ -425,9 +427,9 @@ public void testReplicatorRateLimiterMessageNotReceivedAllMessages(DispatchRateT\n         }\n         Assert.assertTrue(replicatorUpdated);\n         if (DispatchRateType.messageRate.equals(dispatchRateType)) {\n-            Assert.assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), messageRate);\n+            Assert.assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), messageRate);\n         } else {\n-            Assert.assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), messageRate);\n+            Assert.assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), messageRate);\n         }\n \n         @Cleanup\n@@ -499,7 +501,7 @@ public void testReplicatorRateLimiterMessageReceivedAllMessages() throws Excepti\n         boolean replicatorUpdated = false;\n         int retry = 5;\n         for (int i = 0; i < retry; i++) {\n-            if (topic.getReplicators().values().get(0).getRateLimiter().isPresent()) {\n+            if (getRateLimiter(topic).isPresent()) {\n                 replicatorUpdated = true;\n                 break;\n             } else {\n@@ -509,7 +511,7 @@ public void testReplicatorRateLimiterMessageReceivedAllMessages() throws Excepti\n             }\n         }\n         Assert.assertTrue(replicatorUpdated);\n-        Assert.assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnMsg(), messageRate);\n+        Assert.assertEquals(getRateLimiter(topic).get().getDispatchRateOnMsg(), messageRate);\n \n         @Cleanup\n         PulsarClient client2 = PulsarClient.builder().serviceUrl(url2.toString()).statsInterval(0, TimeUnit.SECONDS)\n@@ -578,8 +580,8 @@ public void testReplicatorRateLimiterByBytes() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getOrCreateTopic(topicName).get();\n \n         Awaitility.await()\n-                .untilAsserted(() -> assertTrue(topic.getReplicators().values().get(0).getRateLimiter().isPresent()));\n-        assertEquals(topic.getReplicators().values().get(0).getRateLimiter().get().getDispatchRateOnByte(), byteRate);\n+                .untilAsserted(() -> assertTrue(getRateLimiter(topic).isPresent()));\n+        assertEquals(getRateLimiter(topic).get().getDispatchRateOnByte(), byteRate);\n \n         @Cleanup\n         PulsarClient client2 = PulsarClient.builder().serviceUrl(url2.toString())\n@@ -608,5 +610,9 @@ public void testReplicatorRateLimiterByBytes() throws Exception {\n                 });\n     }\n \n+    private static Optional<DispatchRateLimiter> getRateLimiter(PersistentTopic topic) {\n+        return getRateLimiter(topic);\n+    }\n+\n     private static final Logger log = LoggerFactory.getLogger(ReplicatorRateLimiterTest.class);\n }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\nindex 8e115e14b3770..aac7a85f477c5 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\n@@ -109,7 +109,6 @@\n import org.apache.pulsar.common.policies.data.SchemaCompatibilityStrategy;\n import org.apache.pulsar.common.policies.data.TopicStats;\n import org.apache.pulsar.common.protocol.Commands;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.opentelemetry.OpenTelemetryAttributes;\n import org.apache.pulsar.schema.Schemas;\n import org.awaitility.Awaitility;\n@@ -637,7 +636,7 @@ public void testReplicatePeekAndSkip() throws Exception {\n         producer1.produce(2);\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getTopicReference(dest.toString()).get();\n         PersistentReplicator replicator = (PersistentReplicator) topic.getReplicators()\n-                .get(topic.getReplicators().keys().get(0));\n+                .get(topic.getReplicators().keySet().stream().toList().get(0));\n         replicator.skipMessages(2);\n         CompletableFuture<Entry> result = replicator.peekNthMessage(1);\n         Entry entry = result.get(50, TimeUnit.MILLISECONDS);\n@@ -664,7 +663,7 @@ public void testReplicatorClearBacklog() throws Exception {\n         producer1.produce(2);\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getTopicReference(dest.toString()).get();\n         PersistentReplicator replicator = (PersistentReplicator) spy(\n-                topic.getReplicators().get(topic.getReplicators().keys().get(0)));\n+                topic.getReplicators().get(topic.getReplicators().keySet().stream().toList().get(0)));\n         replicator.readEntriesFailed(new ManagedLedgerException.InvalidCursorPositionException(\"failed\"), null);\n         replicator.clearBacklog().get();\n         Thread.sleep(100);\n@@ -691,7 +690,7 @@ public void testResetReplicatorSubscriptionPosition() throws Exception {\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getTopicReference(dest.toString()).get();\n \n         PersistentReplicator replicator = (PersistentReplicator) spy(\n-                topic.getReplicators().get(topic.getReplicators().keys().get(0)));\n+                topic.getReplicators().get(topic.getReplicators().keySet().stream().toList().get(0)));\n \n         MessageId id = topic.getLastMessageId().get();\n         admin1.topics().expireMessages(dest.getPartitionedTopicName(),\n@@ -795,7 +794,7 @@ public void testDeleteReplicatorFailure() throws Exception {\n         @Cleanup\n         MessageProducer producer1 = new MessageProducer(url1, dest);\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getTopicReference(topicName).get();\n-        final String replicatorClusterName = topic.getReplicators().keys().get(0);\n+        final String replicatorClusterName = topic.getReplicators().keySet().stream().toList().get(0);\n         ManagedLedgerImpl ledger = (ManagedLedgerImpl) topic.getManagedLedger();\n         CountDownLatch latch = new CountDownLatch(1);\n         // delete cursor already : so next time if topic.removeReplicator will get exception but then it should\n@@ -836,7 +835,7 @@ public void testReplicatorProducerClosing() throws Exception {\n         @Cleanup\n         MessageProducer producer1 = new MessageProducer(url1, dest);\n         PersistentTopic topic = (PersistentTopic) pulsar1.getBrokerService().getTopicReference(topicName).get();\n-        final String replicatorClusterName = topic.getReplicators().keys().get(0);\n+        final String replicatorClusterName = topic.getReplicators().keySet().stream().toList().get(0);\n         Replicator replicator = topic.getPersistentReplicator(replicatorClusterName);\n         pulsar2.close();\n         pulsar2 = null;\n@@ -1675,7 +1674,7 @@ public void testReplicatorWithFailedAck() throws Exception {\n         Awaitility.await().pollInterval(1, TimeUnit.SECONDS).timeout(30, TimeUnit.SECONDS)\n                 .ignoreExceptions()\n                 .untilAsserted(() -> {\n-                    ConcurrentOpenHashMap<String, Replicator> replicators = topic.getReplicators();\n+                    final var replicators = topic.getReplicators();\n                     PersistentReplicator replicator = (PersistentReplicator) replicators.get(\"r2\");\n                     assertEquals(org.apache.pulsar.broker.service.AbstractReplicator.State.Started,\n                             replicator.getState());\n@@ -1928,9 +1927,9 @@ public void testEnableReplicationWithNamespaceAllowedClustersPolices() throws Ex\n         // Verify the replication from cluster1 to cluster2 is ready, but the replication form the cluster2 to cluster1\n         // is not ready.\n         Awaitility.await().untilAsserted(() -> {\n-            ConcurrentOpenHashMap<String, Replicator> replicatorMap = persistentTopic1.getReplicators();\n+            final var replicatorMap = persistentTopic1.getReplicators();\n             assertEquals(replicatorMap.size(), 1);\n-            Replicator replicator = replicatorMap.get(replicatorMap.keys().get(0));\n+            Replicator replicator = replicatorMap.get(replicatorMap.keySet().stream().toList().get(0));\n             assertTrue(replicator.isConnected());\n         });\n \n@@ -1940,16 +1939,16 @@ public void testEnableReplicationWithNamespaceAllowedClustersPolices() throws Ex\n                 .get();\n \n         Awaitility.await().untilAsserted(() -> {\n-            ConcurrentOpenHashMap<String, Replicator> replicatorMap = persistentTopic2.getReplicators();\n+            final var replicatorMap = persistentTopic2.getReplicators();\n             assertEquals(replicatorMap.size(), 0);\n         });\n         // Enable replication at the topic level in the cluster2.\n         admin2.topics().setReplicationClusters(topicName.toString(), List.of(\"r1\", \"r2\"));\n         //  Verify the replication between cluster1 and cluster2  is ready.\n         Awaitility.await().untilAsserted(() -> {\n-            ConcurrentOpenHashMap<String, Replicator> replicatorMap = persistentTopic2.getReplicators();\n+            final var replicatorMap = persistentTopic2.getReplicators();\n             assertEquals(replicatorMap.size(), 1);\n-            Replicator replicator = replicatorMap.get(replicatorMap.keys().get(0));\n+            Replicator replicator = replicatorMap.get(replicatorMap.keySet().stream().toList().get(0));\n             assertTrue(replicator.isConnected());\n         });\n     }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java\nindex f89ca2bdebb91..ab1f0c0ece2e2 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTopicPoliciesTest.java\n@@ -29,7 +29,6 @@\n import java.util.List;\n import java.util.Set;\n import java.util.UUID;\n-import java.util.stream.Collectors;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.client.admin.PulsarAdmin;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n@@ -748,7 +747,7 @@ public void testRemoveReplicationClusters() throws Exception {\n         assertNotNull(topicRef);\n \n         Awaitility.await().untilAsserted(() -> {\n-            List<String> replicaClusters = topicRef.getReplicators().keys().stream().sorted().collect(Collectors.toList());\n+            List<String> replicaClusters = topicRef.getReplicators().keySet().stream().sorted().toList();\n             assertEquals(replicaClusters.size(), 1);\n             assertEquals(replicaClusters.toString(), \"[r2]\");\n         });\n@@ -756,7 +755,7 @@ public void testRemoveReplicationClusters() throws Exception {\n         // removing topic replica cluster policy, so namespace policy should take effect\n         admin1.topics().removeReplicationClusters(persistentTopicName);\n         Awaitility.await().untilAsserted(() -> {\n-            List<String> replicaClusters = topicRef.getReplicators().keys().stream().sorted().collect(Collectors.toList());\n+            List<String> replicaClusters = topicRef.getReplicators().keySet().stream().sorted().toList();\n             assertEquals(replicaClusters.size(), 2);\n             assertEquals(replicaClusters.toString(), \"[r2, r3]\");\n         });\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java\nindex 2d348f8259746..aa39e859a8c3d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/TransactionalReplicateSubscriptionTest.java\n@@ -32,7 +32,6 @@\n import org.apache.pulsar.common.naming.NamespaceName;\n import org.apache.pulsar.common.naming.SystemTopicNames;\n import org.apache.pulsar.common.partition.PartitionedTopicMetadata;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.metadata.api.MetadataStoreException;\n import org.awaitility.Awaitility;\n import org.testng.annotations.AfterClass;\n@@ -118,7 +117,7 @@ public void testReplicatedSubscribeAndSwitchToStandbyClusterWithTransaction() th\n         }\n         txn1.commit().get();\n         Awaitility.await().untilAsserted(() -> {\n-            ConcurrentOpenHashMap<String, ? extends Replicator> replicators = topic1.getReplicators();\n+            final var replicators = topic1.getReplicators();\n             assertTrue(replicators != null && replicators.size() == 1, \"Replicator should started\");\n             assertTrue(replicators.values().iterator().next().isConnected(), \"Replicator should be connected\");\n             assertTrue(topic1.getReplicatedSubscriptionController().get().getLastCompletedSnapshotId().isPresent(),\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java\nindex e2aec70fb114e..e0d6a432bdad2 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopicTest.java\n@@ -37,7 +37,6 @@\n import org.apache.pulsar.client.api.SubscriptionType;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.policies.data.TopicStats;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.mockito.Mockito;\n import org.testng.annotations.AfterMethod;\n@@ -212,7 +211,7 @@ public void testSubscriptionsOnNonPersistentTopic() throws Exception {\n                 .subscriptionMode(SubscriptionMode.Durable)\n                 .subscribe();\n \n-        ConcurrentOpenHashMap<String, NonPersistentSubscription> subscriptionMap = mockTopic.getSubscriptions();\n+        final var subscriptionMap = mockTopic.getSubscriptions();\n         assertEquals(subscriptionMap.size(), 4);\n \n         // Check exclusive subscription\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java\nindex 562c5eda58109..fa409832fc17b 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/ReplicatedSubscriptionsSnapshotBuilderTest.java\n@@ -28,9 +28,8 @@\n import io.netty.buffer.ByteBuf;\n import java.time.Clock;\n import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collections;\n import java.util.List;\n+import java.util.Set;\n import org.apache.bookkeeper.mledger.PositionFactory;\n import org.apache.pulsar.broker.ServiceConfiguration;\n import org.apache.pulsar.common.api.proto.ReplicatedSubscriptionsSnapshot;\n@@ -75,10 +74,8 @@ public void setup() {\n \n     @Test\n     public void testBuildSnapshotWith2Clusters() throws Exception {\n-        List<String> remoteClusters = Collections.singletonList(\"b\");\n-\n         ReplicatedSubscriptionsSnapshotBuilder builder = new ReplicatedSubscriptionsSnapshotBuilder(controller,\n-                remoteClusters,\n+                Set.of(\"b\"),\n                 conf, clock);\n \n         assertTrue(markers.isEmpty());\n@@ -115,10 +112,8 @@ public void testBuildSnapshotWith2Clusters() throws Exception {\n \n     @Test\n     public void testBuildSnapshotWith3Clusters() throws Exception {\n-        List<String> remoteClusters = Arrays.asList(\"b\", \"c\");\n-\n         ReplicatedSubscriptionsSnapshotBuilder builder = new ReplicatedSubscriptionsSnapshotBuilder(controller,\n-                remoteClusters,\n+                Set.of(\"b\", \"c\"),\n                 conf, clock);\n \n         assertTrue(markers.isEmpty());\n@@ -198,10 +193,8 @@ public void testBuildSnapshotWith3Clusters() throws Exception {\n \n     @Test\n     public void testBuildTimeout() {\n-        List<String> remoteClusters = Collections.singletonList(\"b\");\n-\n         ReplicatedSubscriptionsSnapshotBuilder builder = new ReplicatedSubscriptionsSnapshotBuilder(controller,\n-                remoteClusters,\n+                Set.of(\"b\"),\n                 conf, clock);\n \n         assertFalse(builder.isTimedOut());\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\nindex 45e3fb253bf11..e091eee178d8c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\n@@ -30,16 +30,14 @@\n import org.apache.pulsar.broker.ServiceConfiguration;\n import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.broker.service.Consumer;\n-import org.apache.pulsar.broker.service.Replicator;\n-import org.apache.pulsar.broker.service.Subscription;\n import org.apache.pulsar.broker.service.Topic;\n+import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.broker.service.persistent.PersistentTopicMetrics;\n import org.apache.pulsar.common.policies.data.BacklogQuota;\n import org.apache.pulsar.common.policies.data.stats.ConsumerStatsImpl;\n import org.apache.pulsar.common.policies.data.stats.SubscriptionStatsImpl;\n import org.apache.pulsar.common.policies.data.stats.TopicStatsImpl;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.metadata.impl.ZKMetadataStore;\n import org.mockito.Mockito;\n import org.testng.annotations.BeforeMethod;\n@@ -71,7 +69,7 @@ public void testGenerateSubscriptionsStats() {\n         // prepare multi-layer topic map\n         final var bundlesMap = new ConcurrentHashMap<String, Map<String, Topic>>();\n         final var topicsMap = new ConcurrentHashMap<String, Topic>();\n-        ConcurrentOpenHashMap subscriptionsMaps = ConcurrentOpenHashMap.newBuilder().build();\n+        final var subscriptionsMaps = new ConcurrentHashMap<String, PersistentSubscription>();\n         bundlesMap.put(\"my-bundle\", topicsMap);\n         multiLayerTopicsMap.put(namespace, bundlesMap);\n \n@@ -87,7 +85,7 @@ public void testGenerateSubscriptionsStats() {\n \n         // Prepare topic and subscription\n         PersistentTopic topic = Mockito.mock(PersistentTopic.class);\n-        Subscription subscription = Mockito.mock(Subscription.class);\n+        PersistentSubscription subscription = Mockito.mock(PersistentSubscription.class);\n         Consumer consumer = Mockito.mock(Consumer.class);\n         ConsumerStatsImpl consumerStats = new ConsumerStatsImpl();\n         when(consumer.getStats()).thenReturn(consumerStats);\n@@ -99,7 +97,7 @@ public void testGenerateSubscriptionsStats() {\n         when(topic.getStats(false, false, false)).thenReturn(topicStats);\n         when(topic.getBrokerService()).thenReturn(broker);\n         when(topic.getSubscriptions()).thenReturn(subscriptionsMaps);\n-        when(topic.getReplicators()).thenReturn(ConcurrentOpenHashMap.<String,Replicator>newBuilder().build());\n+        when(topic.getReplicators()).thenReturn(new ConcurrentHashMap<>());\n         when(topic.getManagedLedger()).thenReturn(ml);\n         when(topic.getBacklogQuota(Mockito.any())).thenReturn(Mockito.mock(BacklogQuota.class));\n         PersistentTopicMetrics persistentTopicMetrics = new PersistentTopicMetrics();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java\nindex bd0119823fd95..88286af98ae5f 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/DispatcherBlockConsumerTest.java\n@@ -29,7 +29,6 @@\n import com.google.common.collect.Multimap;\n import com.google.common.collect.Queues;\n import com.google.common.collect.Sets;\n-import java.lang.reflect.Field;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.HashSet;\n@@ -49,14 +48,11 @@\n import java.util.stream.Collectors;\n import lombok.Cleanup;\n import org.apache.pulsar.broker.namespace.NamespaceService;\n-import org.apache.pulsar.broker.service.BrokerService;\n-import org.apache.pulsar.broker.service.persistent.PersistentDispatcherMultipleConsumers;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.client.impl.ConsumerImpl;\n import org.apache.pulsar.client.impl.MessageIdImpl;\n import org.apache.pulsar.common.policies.data.SubscriptionStats;\n import org.apache.pulsar.common.policies.data.TopicStats;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashSet;\n import org.awaitility.Awaitility;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -703,11 +699,7 @@ public void testBlockBrokerDispatching() {\n             stopBroker();\n             startBroker();\n \n-            Field field = BrokerService.class.getDeclaredField(\"blockedDispatchers\");\n-            field.setAccessible(true);\n-            @SuppressWarnings(\"unchecked\")\n-            ConcurrentOpenHashSet<PersistentDispatcherMultipleConsumers> blockedDispatchers =\n-                    (ConcurrentOpenHashSet<PersistentDispatcherMultipleConsumers>) field.get(pulsar.getBrokerService());\n+            final var blockedDispatchers = pulsar.getBrokerService().getBlockedDispatchers();\n \n             final int receiverQueueSize = 10;\n             final int totalProducedMsgs = maxUnAckPerBroker * 3;\n@@ -783,7 +775,7 @@ public void testBlockBrokerDispatching() {\n             consumer2Sub1.close();\n             // (1.c) verify that dispatcher is part of blocked dispatcher\n             assertEquals(blockedDispatchers.size(), 1);\n-            String dispatcherName = blockedDispatchers.values().get(0).getName();\n+            String dispatcherName = blockedDispatchers.stream().findFirst().orElseThrow().getName();\n             String subName = dispatcherName.substring(dispatcherName.lastIndexOf(\"/\") + 2, dispatcherName.length());\n             assertEquals(subName, subscriberName1);\n             timestamps.add(System.currentTimeMillis());\n@@ -918,10 +910,7 @@ public void testBrokerDispatchBlockAndSubAckBackRequiredMsgs() {\n             stopBroker();\n             startBroker();\n \n-            Field field = BrokerService.class.getDeclaredField(\"blockedDispatchers\");\n-            field.setAccessible(true);\n-            ConcurrentOpenHashSet<PersistentDispatcherMultipleConsumers> blockedDispatchers =\n-                    (ConcurrentOpenHashSet<PersistentDispatcherMultipleConsumers>) field.get(pulsar.getBrokerService());\n+            final var blockedDispatchers = pulsar.getBrokerService().getBlockedDispatchers();\n \n             final int receiverQueueSize = 10;\n             final int totalProducedMsgs = maxUnAckPerBroker * 3;\n@@ -992,7 +981,7 @@ public void testBrokerDispatchBlockAndSubAckBackRequiredMsgs() {\n             consumer2Sub1.close();\n             // (1.c) verify that dispatcher is part of blocked dispatcher\n             assertEquals(blockedDispatchers.size(), 1);\n-            String dispatcherName = blockedDispatchers.values().get(0).getName();\n+            String dispatcherName = blockedDispatchers.stream().findFirst().orElseThrow().getName();\n             String subName = dispatcherName.substring(dispatcherName.lastIndexOf(\"/\") + 2, dispatcherName.length());\n             assertEquals(subName, subscriberName1);\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23320",
    "pr_id": 23320,
    "issue_id": 23215,
    "repo": "apache/pulsar",
    "problem_statement": "Replace the ConcurrentOpenHashMap as much as possible\n### PR list\r\n- [x] https://github.com/apache/pulsar/pull/23217\r\n- [x] https://github.com/apache/pulsar/pull/23320\r\n- [x] https://github.com/apache/pulsar/pull/23322\r\n- [x] https://github.com/apache/pulsar/pull/23329\r\n\r\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\nThere was a discussion at Sep. 2023 before to replace Customized Map with ConcurrentOpenHashMap. In this issue, I'd focus on the `ConcurrentOpenHashMap`.\r\n\r\nHere is the only advantage of this map.\r\n\r\n> Provides similar methods as a {@code ConcurrentMap<K,V>} but since it's an open hash map with linear probing,  no node allocations are required to store the values.\r\n\r\nLet me count the disadvantages.\r\n\r\n### 1. Bad performance\r\n\r\nThis map was aded in the initial commit (on 2016). However, this implementation was just based on the Java 7 implementation of the `ConcurrentHashMap`, which uses a segment based lock. Actually, this solution was discarded by the Java team since Java 8.\r\n\r\nhttps://github.com/apache/pulsar/pull/20647/#issuecomment-1607257960 did a benchmark and found the performance was much worse than the current `ConcurrentHashMap` provided by Java library. We can also search the PROs of the Java 8 design in network, or just ask for ChatGPT.\r\n\r\nBesides, the frequently used `keys()` and `values()` methods just copy the keys and values to a new list. While the `ConcurrentHashMap` just returns a thread-safe internal view that users can choose whether to make a copy.\r\n\r\nAnyway, to prove the performance is worse than `ConcurrentHashMap`, we need to have more tests and research. So it's the least important reason.\r\n\r\n### 2. Lack of the updates\r\n\r\nThis class was rarely updated. What I can remember is the shrink support two years ago. https://github.com/apache/pulsar/pull/14663\r\n\r\nFrom https://github.com/apache/bookkeeper/pull/3061, we can see the motivation is the frequently appeared Full GC caused by this implementation. However, adding a `shrink` method makes it harder to use. There are already many parameters to tune, see it's builder:\r\n\r\n```java\r\n    public static class Builder<K, V> {\r\n        int expectedItems = DefaultExpectedItems;\r\n        int concurrencyLevel = DefaultConcurrencyLevel;\r\n        float mapFillFactor = DefaultMapFillFactor;\r\n        float mapIdleFactor = DefaultMapIdleFactor;\r\n        float expandFactor = DefaultExpandFactor;\r\n        float shrinkFactor = DefaultShrinkFactor;\r\n        boolean autoShrink = DefaultAutoShrink;\r\n```\r\n\r\nMany `xxxFactor`s and the concurrency level. It's hard to determine a proper value by default. However, it makes new developers hard to modify it.\r\n\r\n### 3. Bad debug experience\r\n\r\nWhen I debugged the topics maintained in a `BrokerService`.\r\n\r\n<img width=\"1031\" alt=\"image\" src=\"https://github.com/user-attachments/assets/5dfb13d9-7897-429e-ab06-4888595a06c1\">\r\n\r\nAs you can see. There are 16 sections. And I have to iterate over all these sections and expand the `table` array to find the target topic.\r\n\r\nLet's compare it with the official `ConcurrentHashMap` (I replaced it locally)\r\n\r\n<img width=\"1211\" alt=\"image\" src=\"https://github.com/user-attachments/assets/49fbb5ba-7cb0-4225-922f-737af90ef5a7\">\r\n\r\nBesides, it's even harder to analyze in the heap dump.\r\n\r\n### 4. Not friendly to new developers\r\n\r\nMany places just use it as a concurrent hash map. **What's the reason for new developers to not use the official `ConcurrentHashMap`, which is developed and consistently improved by a professional team?** Just to reduce the node allocation? With the improving JVM GC?\r\n\r\nAs I've mentioned, this class might be introduced at the Java 7 era. Now the minimum required Java version of broker side is 17. We have ZGC. We have Shenandoah GC. We have many more JVM developers developing better GC. I'm suspecting if the advantage makes sense.\r\n\r\nI cannot think of a reason to choose this hard-to-maintain class rather than well-maintained official `ConcurrentHashMap`.\r\n\r\nFor example, when I maintained KoP, I encountered the deadlock of `ConcurrentLongHashMap` (maybe the similar implementation). https://github.com/streamnative/kop/pull/620 And it's hard to know if this case is fixed. So I have to switch to the official `ConcurrentHashMap`.\r\n\r\n### Solution\r\n\r\nReplace `ConcurrentOpenHashMap` with the official Java `ConcurrentHashMap`.\r\n\r\n### Alternatives\r\n\r\nN/A\r\n\r\n### Anything else?\r\n\r\nJava Concurrent HashMap Improvements over the years https://medium.com/@vikas.taank_40391/java-concurrent-hashmap-improvements-over-the-years-8d8b7be6ce37\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 709,
    "test_files_count": 22,
    "non_test_files_count": 7,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/v2/NonPersistentTopics.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/rest/TopicsBase.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PulsarStats.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregator.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/TransactionAggregator.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java"
    ],
    "base_commit": "105192d5baff8eb48814e89817a900a116624ac3",
    "head_commit": "0601dd315b30eeec32462b5fc3b20fe255ca4ba5",
    "repo_url": "https://github.com/apache/pulsar/pull/23320",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23320",
    "dockerfile": "",
    "pr_merged_at": "2024-09-21T07:02:24.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/v2/NonPersistentTopics.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/v2/NonPersistentTopics.java\nindex 9f58aa4ca9d44..edf4303e1adef 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/v2/NonPersistentTopics.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/v2/NonPersistentTopics.java\n@@ -62,7 +62,6 @@\n import org.apache.pulsar.common.policies.data.stats.NonPersistentPartitionedTopicStatsImpl;\n import org.apache.pulsar.common.policies.data.stats.NonPersistentTopicStatsImpl;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -478,18 +477,17 @@ public void getListFromBundle(\n             } else {\n                 validateNamespaceBundleOwnershipAsync(namespaceName, policies.bundles, bundleRange, true, true)\n                         .thenAccept(nsBundle -> {\n-                            ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>> bundleTopics =\n-                                    pulsar().getBrokerService()\n-                                            .getMultiLayerTopicsMap().get(namespaceName.toString());\n+                            final var bundleTopics = pulsar().getBrokerService().getMultiLayerTopicsMap()\n+                                    .get(namespaceName.toString());\n                             if (bundleTopics == null || bundleTopics.isEmpty()) {\n                                 asyncResponse.resume(Collections.emptyList());\n                                 return;\n                             }\n                             final List<String> topicList = new ArrayList<>();\n                             String bundleKey = namespaceName.toString() + \"/\" + nsBundle.getBundleRange();\n-                            ConcurrentOpenHashMap<String, Topic> topicMap = bundleTopics.get(bundleKey);\n+                            final var topicMap = bundleTopics.get(bundleKey);\n                             if (topicMap != null) {\n-                                topicList.addAll(topicMap.keys().stream()\n+                                topicList.addAll(topicMap.keySet().stream()\n                                         .filter(name -> !TopicName.get(name).isPersistent())\n                                         .collect(Collectors.toList()));\n                             }\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\nindex 92188f5e6eeee..0b1661fb9540a 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/namespace/NamespaceService.java\n@@ -1618,10 +1618,10 @@ public CompletableFuture<List<String>> getListOfNonPersistentTopics(NamespaceNam\n                         // Non-persistent topics don't have managed ledgers. So we have to retrieve them from local\n                         // cache.\n                         List<String> topics = new ArrayList<>();\n-                        synchronized (pulsar.getBrokerService().getMultiLayerTopicMap()) {\n-                            if (pulsar.getBrokerService().getMultiLayerTopicMap()\n+                        synchronized (pulsar.getBrokerService().getMultiLayerTopicsMap()) {\n+                            if (pulsar.getBrokerService().getMultiLayerTopicsMap()\n                                     .containsKey(namespaceName.toString())) {\n-                                pulsar.getBrokerService().getMultiLayerTopicMap().get(namespaceName.toString())\n+                                pulsar.getBrokerService().getMultiLayerTopicsMap().get(namespaceName.toString())\n                                         .forEach((__, bundle) -> bundle.forEach((topicName, topic) -> {\n                                             if (topic instanceof NonPersistentTopic\n                                                     && ((NonPersistentTopic) topic).isActive()) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/rest/TopicsBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/rest/TopicsBase.java\nindex 8f55df1107d0f..bf6e7350186c2 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/rest/TopicsBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/rest/TopicsBase.java\n@@ -38,7 +38,9 @@\n import java.util.Collections;\n import java.util.List;\n import java.util.Optional;\n+import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n import javax.ws.rs.container.AsyncResponse;\n@@ -95,7 +97,6 @@\n import org.apache.pulsar.common.schema.SchemaType;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.ObjectMapperFactory;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashSet;\n import org.apache.pulsar.websocket.data.ProducerAck;\n import org.apache.pulsar.websocket.data.ProducerAcks;\n import org.apache.pulsar.websocket.data.ProducerMessage;\n@@ -122,8 +123,9 @@ protected void publishMessages(AsyncResponse asyncResponse, ProducerMessages req\n                         .thenAccept(schemaMeta -> {\n                             // Both schema version and schema data are necessary.\n                             if (schemaMeta.getLeft() != null && schemaMeta.getRight() != null) {\n-                                internalPublishMessages(topicName, request, pulsar().getBrokerService()\n-                                                .getOwningTopics().get(topic).values(), asyncResponse,\n+                                final var partitionIndexes = pulsar().getBrokerService().getOwningTopics()\n+                                        .getOrDefault(topic, Set.of()).stream().toList();\n+                                internalPublishMessages(topicName, request, partitionIndexes, asyncResponse,\n                                         AutoConsumeSchema.getSchema(schemaMeta.getLeft().toSchemaInfo()),\n                                         schemaMeta.getRight());\n                             } else {\n@@ -446,7 +448,7 @@ private CompletableFuture<Void> lookUpBrokerForTopic(TopicName partitionedTopicN\n                 }\n                 pulsar().getBrokerService().getOwningTopics().computeIfAbsent(partitionedTopicName\n                                 .getPartitionedTopicName(),\n-                        (key) -> ConcurrentOpenHashSet.<Integer>newBuilder().build())\n+                        __ -> ConcurrentHashMap.newKeySet())\n                         .add(partitionedTopicName.getPartitionIndex());\n                 completeLookup(Pair.of(Collections.emptyList(), false), redirectAddresses, future);\n             } else {\n@@ -517,7 +519,7 @@ private CompletableFuture<SchemaVersion> addSchema(SchemaData schemaData) {\n         // Only need to add to first partition the broker owns since the schema id in schema registry are\n         // same for all partitions which is the partitionedTopicName\n         List<Integer> partitions = pulsar().getBrokerService().getOwningTopics()\n-                .get(topicName.getPartitionedTopicName()).values();\n+                .get(topicName.getPartitionedTopicName()).stream().toList();\n         CompletableFuture<SchemaVersion> result = new CompletableFuture<>();\n         for (int index = 0; index < partitions.size(); index++) {\n             CompletableFuture<SchemaVersion> future = new CompletableFuture<>();\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex c7a210bc543cf..6b0be07c8f7a8 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -63,6 +63,7 @@\n import java.util.Set;\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentLinkedQueue;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.RejectedExecutionException;\n@@ -177,8 +178,6 @@\n import org.apache.pulsar.common.util.FieldParser;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.GracefulExecutorServicesShutdown;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashSet;\n import org.apache.pulsar.common.util.netty.ChannelFutures;\n import org.apache.pulsar.common.util.netty.EventLoopUtil;\n import org.apache.pulsar.common.util.netty.NettyFutureUtil;\n@@ -217,27 +216,26 @@ public class BrokerService implements Closeable {\n     private final PulsarService pulsar;\n     private final ManagedLedgerFactory managedLedgerFactory;\n \n-    private final ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics;\n+    private final Map<String, CompletableFuture<Optional<Topic>>> topics = new ConcurrentHashMap<>();\n \n-    private final ConcurrentOpenHashMap<String, PulsarClient> replicationClients;\n-    private final ConcurrentOpenHashMap<String, PulsarAdmin> clusterAdmins;\n+    private final Map<String, PulsarClient> replicationClients = new ConcurrentHashMap<>();\n+    private final Map<String, PulsarAdmin> clusterAdmins = new ConcurrentHashMap<>();\n \n     // Multi-layer topics map:\n     // Namespace --> Bundle --> topicName --> topic\n-    private final ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>\n-            multiLayerTopicsMap;\n+    private final Map<String, Map<String, Map<String, Topic>>> multiLayerTopicsMap = new ConcurrentHashMap<>();\n     // Keep track of topics and partitions served by this broker for fast lookup.\n     @Getter\n-    private final ConcurrentOpenHashMap<String, ConcurrentOpenHashSet<Integer>> owningTopics;\n+    private final Map<String, Set<Integer>> owningTopics = new ConcurrentHashMap<>();\n     private long numberOfNamespaceBundles = 0;\n \n     private final EventLoopGroup acceptorGroup;\n     private final EventLoopGroup workerGroup;\n     private final OrderedExecutor topicOrderedExecutor;\n     // offline topic backlog cache\n-    private final ConcurrentOpenHashMap<TopicName, PersistentOfflineTopicStats> offlineTopicStatCache;\n-    private final ConcurrentOpenHashMap<String, ConfigField> dynamicConfigurationMap;\n-    private final ConcurrentOpenHashMap<String, Consumer<?>> configRegisteredListeners;\n+    private final Map<TopicName, PersistentOfflineTopicStats> offlineTopicStatCache = new ConcurrentHashMap<>();\n+    private final Map<String, ConfigField> dynamicConfigurationMap;\n+    private final Map<String, Consumer<?>> configRegisteredListeners = new ConcurrentHashMap<>();\n \n     private final ConcurrentLinkedQueue<TopicLoadingContext> pendingTopicLoadingQueue;\n \n@@ -297,7 +295,7 @@ public class BrokerService implements Closeable {\n     private final int maxUnackedMessages;\n     public final int maxUnackedMsgsPerDispatcher;\n     private final AtomicBoolean blockedDispatcherOnHighUnackedMsgs = new AtomicBoolean(false);\n-    private final ConcurrentOpenHashSet<PersistentDispatcherMultipleConsumers> blockedDispatchers;\n+    private final Set<PersistentDispatcherMultipleConsumers> blockedDispatchers = ConcurrentHashMap.newKeySet();\n     private final ReadWriteLock lock = new ReentrantReadWriteLock();\n     @VisibleForTesting\n     private final DelayedDeliveryTrackerFactory delayedDeliveryTrackerFactory;\n@@ -335,28 +333,9 @@ public BrokerService(PulsarService pulsar, EventLoopGroup eventLoopGroup) throws\n         this.preciseTopicPublishRateLimitingEnable =\n                 pulsar.getConfiguration().isPreciseTopicPublishRateLimiterEnable();\n         this.managedLedgerFactory = pulsar.getManagedLedgerFactory();\n-        this.topics =\n-                ConcurrentOpenHashMap.<String, CompletableFuture<Optional<Topic>>>newBuilder()\n-                .build();\n-        this.replicationClients =\n-                ConcurrentOpenHashMap.<String, PulsarClient>newBuilder().build();\n-        this.clusterAdmins =\n-                ConcurrentOpenHashMap.<String, PulsarAdmin>newBuilder().build();\n         this.keepAliveIntervalSeconds = pulsar.getConfiguration().getKeepAliveIntervalSeconds();\n-        this.configRegisteredListeners =\n-                ConcurrentOpenHashMap.<String, Consumer<?>>newBuilder().build();\n         this.pendingTopicLoadingQueue = Queues.newConcurrentLinkedQueue();\n-\n-        this.multiLayerTopicsMap = ConcurrentOpenHashMap.<String,\n-                ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>newBuilder()\n-                .build();\n-        this.owningTopics = ConcurrentOpenHashMap.<String,\n-                ConcurrentOpenHashSet<Integer>>newBuilder()\n-                .build();\n         this.pulsarStats = new PulsarStats(pulsar);\n-        this.offlineTopicStatCache =\n-                ConcurrentOpenHashMap.<TopicName,\n-                        PersistentOfflineTopicStats>newBuilder().build();\n \n         this.topicOrderedExecutor = OrderedExecutor.newBuilder()\n                 .numThreads(pulsar.getConfiguration().getTopicOrderedExecutorThreadNum())\n@@ -403,8 +382,6 @@ public BrokerService(PulsarService pulsar, EventLoopGroup eventLoopGroup) throws\n                 .build();\n         this.authenticationService = new AuthenticationService(pulsar.getConfiguration(),\n                 pulsar.getOpenTelemetry().getOpenTelemetry());\n-        this.blockedDispatchers =\n-                ConcurrentOpenHashSet.<PersistentDispatcherMultipleConsumers>newBuilder().build();\n         this.topicFactory = createPersistentTopicFactory();\n         // update dynamic configuration and register-listener\n         updateConfigurationAndRegisterListeners();\n@@ -500,7 +477,7 @@ private int getPendingTopicLoadRequests() {\n \n     public void addTopicEventListener(TopicEventsListener... listeners) {\n         topicEventsDispatcher.addTopicEventListener(listeners);\n-        getTopics().keys().forEach(topic ->\n+        topics.keySet().forEach(topic ->\n                 TopicEventsDispatcher.notify(listeners, topic, TopicEvent.LOAD, EventStage.SUCCESS, null));\n     }\n \n@@ -572,13 +549,8 @@ private ServerBootstrap defaultServerBootstrap() {\n     }\n \n     public Map<String, TopicStatsImpl> getTopicStats(NamespaceBundle bundle) {\n-        ConcurrentOpenHashMap<String, Topic> topicMap = getMultiLayerTopicMap()\n-                .computeIfAbsent(bundle.getNamespaceObject().toString(), k -> {\n-                    return ConcurrentOpenHashMap\n-                            .<String, ConcurrentOpenHashMap<String, Topic>>newBuilder().build();\n-                }).computeIfAbsent(bundle.toString(), k -> {\n-                    return ConcurrentOpenHashMap.<String, Topic>newBuilder().build();\n-                });\n+        final var topicMap = multiLayerTopicsMap.computeIfAbsent(bundle.getNamespaceObject().toString(),\n+                __ -> new ConcurrentHashMap<>()).computeIfAbsent(bundle.toString(), __ -> new ConcurrentHashMap<>());\n \n         Map<String, TopicStatsImpl> topicStatsMap = new HashMap<>();\n         topicMap.forEach((name, topic) -> {\n@@ -2047,14 +2019,10 @@ private void addTopicToStatsMaps(TopicName topicName, Topic topic) {\n                     if (namespaceBundle != null) {\n                         synchronized (multiLayerTopicsMap) {\n                             String serviceUnit = namespaceBundle.toString();\n-                            multiLayerTopicsMap //\n-                                    .computeIfAbsent(topicName.getNamespace(),\n-                                            k -> ConcurrentOpenHashMap.<String,\n-                                                    ConcurrentOpenHashMap<String, Topic>>newBuilder()\n-                                                    .build()) //\n-                                    .computeIfAbsent(serviceUnit,\n-                                            k -> ConcurrentOpenHashMap.<String, Topic>newBuilder().build()) //\n-                                    .put(topicName.toString(), topic);\n+                            multiLayerTopicsMap.computeIfAbsent(topicName.getNamespace(),\n+                                    __ -> new ConcurrentHashMap<>()\n+                            ).computeIfAbsent(serviceUnit, __ -> new ConcurrentHashMap<>()\n+                            ).put(topicName.toString(), topic);\n                         }\n                     }\n                     invalidateOfflineTopicStatCache(topicName);\n@@ -2353,7 +2321,7 @@ private CompletableFuture<Integer> unloadServiceUnit(NamespaceBundle serviceUnit\n     }\n \n     public void cleanUnloadedTopicFromCache(NamespaceBundle serviceUnit) {\n-        for (String topic : topics.keys()) {\n+        for (String topic : topics.keySet()) {\n             TopicName topicName = TopicName.get(topic);\n             if (serviceUnit.includes(topicName) && getTopicReference(topic).isPresent()) {\n                 log.info(\"[{}][{}] Clean unloaded topic from cache.\", serviceUnit.toString(), topic);\n@@ -2418,10 +2386,9 @@ private void removeTopicFromCache(String topic, NamespaceBundle namespaceBundle,\n         topicEventsDispatcher.notify(topic, TopicEvent.UNLOAD, EventStage.BEFORE);\n \n         synchronized (multiLayerTopicsMap) {\n-            ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>> namespaceMap = multiLayerTopicsMap\n-                    .get(namespaceName);\n+            final var namespaceMap = multiLayerTopicsMap.get(namespaceName);\n             if (namespaceMap != null) {\n-                ConcurrentOpenHashMap<String, Topic> bundleMap = namespaceMap.get(bundleName);\n+                final var bundleMap = namespaceMap.get(bundleName);\n                 if (bundleMap != null) {\n                     bundleMap.remove(topic);\n                     if (bundleMap.isEmpty()) {\n@@ -2462,10 +2429,6 @@ public long getNumberOfNamespaceBundles() {\n         return this.numberOfNamespaceBundles;\n     }\n \n-    public ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> getTopics() {\n-        return topics;\n-    }\n-\n \n     private void handleMetadataChanges(Notification n) {\n         if (n.getType() == NotificationType.Modified && NamespaceResources.pathIsFromNamespace(n.getPath())) {\n@@ -2660,10 +2623,6 @@ public EventLoopGroup executor() {\n         return workerGroup;\n     }\n \n-    public ConcurrentOpenHashMap<String, PulsarClient> getReplicationClients() {\n-        return replicationClients;\n-    }\n-\n     public boolean isAuthenticationEnabled() {\n         return pulsar.getConfiguration().isAuthenticationEnabled();\n     }\n@@ -2693,17 +2652,17 @@ public AuthenticationService getAuthenticationService() {\n     }\n \n     public List<Topic> getAllTopicsFromNamespaceBundle(String namespace, String bundle) {\n-        ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>> map1 = multiLayerTopicsMap.get(namespace);\n+        final var map1 = multiLayerTopicsMap.get(namespace);\n         if (map1 == null) {\n             return Collections.emptyList();\n         }\n \n-        ConcurrentOpenHashMap<String, Topic> map2 = map1.get(bundle);\n+        final var map2 = map1.get(bundle);\n         if (map2 == null) {\n             return Collections.emptyList();\n         }\n \n-        return map2.values();\n+        return map2.values().stream().toList();\n     }\n \n     /**\n@@ -3080,60 +3039,17 @@ private void createDynamicConfigPathIfNotExist() {\n         }\n     }\n \n-    /**\n-     * Updates pulsar.ServiceConfiguration's dynamic field with value persistent into zk-dynamic path. It also validates\n-     * dynamic-value before updating it and throws {@code IllegalArgumentException} if validation fails\n-     */\n-    private void updateDynamicServiceConfiguration() {\n-        Optional<Map<String, String>> configCache = Optional.empty();\n-\n-        try {\n-            configCache  =\n-                    pulsar().getPulsarResources().getDynamicConfigResources().getDynamicConfiguration();\n-\n-            // create dynamic-config if not exist.\n-            if (!configCache.isPresent()) {\n-                pulsar().getPulsarResources().getDynamicConfigResources()\n-                        .setDynamicConfigurationWithCreate(n -> new HashMap<>());\n-            }\n-        } catch (Exception e) {\n-            log.warn(\"Failed to read dynamic broker configuration\", e);\n-        }\n-\n-        configCache.ifPresent(stringStringMap -> stringStringMap.forEach((key, value) -> {\n-            // validate field\n-            if (dynamicConfigurationMap.containsKey(key) && dynamicConfigurationMap.get(key).validator != null) {\n-                if (!dynamicConfigurationMap.get(key).validator.test(value)) {\n-                    log.error(\"Failed to validate dynamic config {} with value {}\", key, value);\n-                    throw new IllegalArgumentException(\n-                            String.format(\"Failed to validate dynamic-config %s/%s\", key, value));\n-                }\n-            }\n-            // update field value\n-            try {\n-                Field field = ServiceConfiguration.class.getDeclaredField(key);\n-                if (field != null && field.isAnnotationPresent(FieldContext.class)) {\n-                    field.setAccessible(true);\n-                    field.set(pulsar().getConfiguration(), FieldParser.value(value, field));\n-                    log.info(\"Successfully updated {}/{}\", key, value);\n-                }\n-            } catch (Exception e) {\n-                log.warn(\"Failed to update service configuration {}/{}, {}\", key, value, e.getMessage());\n-            }\n-        }));\n-    }\n-\n     public DelayedDeliveryTrackerFactory getDelayedDeliveryTrackerFactory() {\n         return delayedDeliveryTrackerFactory;\n     }\n \n     public List<String> getDynamicConfiguration() {\n-        return dynamicConfigurationMap.keys();\n+        return dynamicConfigurationMap.keySet().stream().toList();\n     }\n \n     public Map<String, String> getRuntimeConfiguration() {\n         Map<String, String> configMap = new HashMap<>();\n-        ConcurrentOpenHashMap<String, Object> runtimeConfigurationMap = getRuntimeConfigurationMap();\n+        ConcurrentHashMap<String, Object> runtimeConfigurationMap = getRuntimeConfigurationMap();\n         runtimeConfigurationMap.forEach((key, value) -> {\n             configMap.put(key, String.valueOf(value));\n         });\n@@ -3151,9 +3067,8 @@ public boolean validateDynamicConfiguration(String key, String value) {\n         return true;\n     }\n \n-    private ConcurrentOpenHashMap<String, ConfigField> prepareDynamicConfigurationMap() {\n-        ConcurrentOpenHashMap<String, ConfigField> dynamicConfigurationMap =\n-                ConcurrentOpenHashMap.<String, ConfigField>newBuilder().build();\n+    private Map<String, ConfigField> prepareDynamicConfigurationMap() {\n+        final var dynamicConfigurationMap = new ConcurrentHashMap<String, ConfigField>();\n         try {\n             for (Field field : ServiceConfiguration.class.getDeclaredFields()) {\n                 if (field != null && field.isAnnotationPresent(FieldContext.class)) {\n@@ -3172,9 +3087,8 @@ private ConcurrentOpenHashMap<String, ConfigField> prepareDynamicConfigurationMa\n         return dynamicConfigurationMap;\n     }\n \n-    private ConcurrentOpenHashMap<String, Object> getRuntimeConfigurationMap() {\n-        ConcurrentOpenHashMap<String, Object> runtimeConfigurationMap =\n-                ConcurrentOpenHashMap.<String, Object>newBuilder().build();\n+    private ConcurrentHashMap<String, Object> getRuntimeConfigurationMap() {\n+        final var runtimeConfigurationMap = new ConcurrentHashMap<String, Object>();\n         for (Field field : ServiceConfiguration.class.getDeclaredFields()) {\n             if (field != null && field.isAnnotationPresent(FieldContext.class)) {\n                 field.setAccessible(true);\n@@ -3337,11 +3251,6 @@ public OrderedExecutor getTopicOrderedExecutor() {\n         return topicOrderedExecutor;\n     }\n \n-    public ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>\n-    getMultiLayerTopicMap() {\n-        return multiLayerTopicsMap;\n-    }\n-\n     /**\n      * If per-broker unacked message reached to limit then it blocks dispatcher if its unacked message limit has been\n      * reached to {@link #maxUnackedMsgsPerDispatcher}.\n@@ -3393,7 +3302,7 @@ public void checkUnAckMessageDispatching() {\n         } else if (blockedDispatcherOnHighUnackedMsgs.get() && unAckedMessages < maxUnackedMessages / 2) {\n             // unblock broker-dispatching if received enough acked messages back\n             if (blockedDispatcherOnHighUnackedMsgs.compareAndSet(true, false)) {\n-                unblockDispatchersOnUnAckMessages(blockedDispatchers.values());\n+                unblockDispatchersOnUnAckMessages(blockedDispatchers.stream().toList());\n             }\n         }\n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PulsarStats.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PulsarStats.java\nindex 7ffc7818d4c2d..b96e00a8909d6 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PulsarStats.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/PulsarStats.java\n@@ -38,7 +38,6 @@\n import org.apache.pulsar.broker.stats.NamespaceStats;\n import org.apache.pulsar.common.naming.NamespaceBundle;\n import org.apache.pulsar.common.stats.Metrics;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.policies.data.loadbalancer.NamespaceBundleStats;\n import org.apache.pulsar.utils.StatsOutputStream;\n import org.slf4j.Logger;\n@@ -101,9 +100,7 @@ public ClusterReplicationMetrics getClusterReplicationMetrics() {\n         return clusterReplicationMetrics;\n     }\n \n-    public synchronized void updateStats(\n-            ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>\n-                    topicsMap) {\n+    public synchronized void updateStats(Map<String, Map<String, Map<String, Topic>>> topicsMap) {\n \n         StatsOutputStream topicStatsStream = new StatsOutputStream(tempTopicStatsBuf);\n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregator.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregator.java\nindex 25c875778c05c..110a8aa82f112 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregator.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregator.java\n@@ -83,7 +83,7 @@ public static void generate(PulsarService pulsar, boolean includeTopicMetrics, b\n         Optional<CompactorMXBean> compactorMXBean = getCompactorMXBean(pulsar);\n         LongAdder topicsCount = new LongAdder();\n         Map<String, Long> localNamespaceTopicCount = new HashMap<>();\n-        pulsar.getBrokerService().getMultiLayerTopicMap().forEach((namespace, bundlesMap) -> {\n+        pulsar.getBrokerService().getMultiLayerTopicsMap().forEach((namespace, bundlesMap) -> {\n             namespaceStats.reset();\n             topicsCount.reset();\n \n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/TransactionAggregator.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/TransactionAggregator.java\nindex 3da061f6ffef2..df2638b3bb810 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/TransactionAggregator.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/stats/prometheus/TransactionAggregator.java\n@@ -56,7 +56,7 @@ public static void generate(PulsarService pulsar, PrometheusMetricStreams stream\n \n         if (includeTopicMetrics) {\n \n-            pulsar.getBrokerService().getMultiLayerTopicMap().forEach((namespace, bundlesMap) ->\n+            pulsar.getBrokerService().getMultiLayerTopicsMap().forEach((namespace, bundlesMap) ->\n                     bundlesMap.forEach((bundle, topicsMap) -> topicsMap.forEach((name, topic) -> {\n                         if (topic instanceof PersistentTopic) {\n                             topic.getSubscriptions().values().forEach(subscription -> {\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java\nindex df9862691d6d5..900babbecf4ad 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApi2Test.java\n@@ -114,9 +114,7 @@\n import org.apache.pulsar.common.policies.data.*;\n import org.apache.pulsar.common.policies.data.impl.BacklogQuotaImpl;\n import org.apache.pulsar.common.protocol.schema.SchemaData;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n-import org.awaitility.reflect.WhiteboxImpl;\n import org.mockito.Mockito;\n import org.mockito.invocation.InvocationOnMock;\n import org.mockito.stubbing.Answer;\n@@ -2913,8 +2911,7 @@ public void testMaxProducersPerTopicUnlimited() throws Exception {\n     }\n \n     private AtomicInteger injectSchemaCheckCounterForTopic(String topicName) {\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                WhiteboxImpl.getInternalState(pulsar.getBrokerService(), \"topics\");\n+        final var topics = pulsar.getBrokerService().getTopics();\n         AbstractTopic topic = (AbstractTopic) topics.get(topicName).join().get();\n         AbstractTopic spyTopic = Mockito.spy(topic);\n         AtomicInteger counter = new AtomicInteger();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java\nindex bb6ef9d363652..9861ab5723732 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/delayed/DelayedDeliveryTrackerFactoryTest.java\n@@ -24,12 +24,10 @@\n import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.broker.service.Dispatcher;\n import org.apache.pulsar.broker.service.Subscription;\n-import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.broker.service.persistent.PersistentDispatcherMultipleConsumers;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n import org.apache.pulsar.client.api.*;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.mockito.Mockito;\n import org.testng.Assert;\n@@ -166,11 +164,7 @@ public void testPublishDelayMessagesAndCreateBucketDelayDeliveryTrackerFailed()\n         Mockito.doReturn(brokerService).when(topic).getBrokerService();\n \n         // Set Mocked topic to BrokerService\n-        Field topics = BrokerService.class.getDeclaredField(\"topics\");\n-        topics.setAccessible(true);\n-        @SuppressWarnings(\"unchecked\")\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topicMap =\n-                (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) topics.get(brokerService);\n+        final var topicMap = brokerService.getTopics();\n         topicMap.put(topicName, CompletableFuture.completedFuture(Optional.of(topic)));\n \n         // Create consumer\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java\nindex 6b2669275dfdb..951247bd68861 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/namespace/NamespaceServiceTest.java\n@@ -87,7 +87,6 @@\n import org.apache.pulsar.common.policies.data.TenantInfo;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.util.ObjectMapperFactory;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.metadata.api.GetResult;\n import org.apache.pulsar.metadata.api.MetadataCache;\n import org.apache.pulsar.metadata.api.Notification;\n@@ -300,8 +299,7 @@ public void testUnloadNamespaceBundleFailure() throws Exception {\n         final String topicName = \"persistent://my-property/use/my-ns/my-topic1\";\n         pulsarClient.newConsumer().topic(topicName).subscriptionName(\"my-subscriber-name\").subscribe();\n \n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics = pulsar.getBrokerService()\n-                .getTopics();\n+        final var topics = pulsar.getBrokerService().getTopics();\n         Topic spyTopic = spy(topics.get(topicName).get().get());\n         topics.clear();\n         CompletableFuture<Optional<Topic>> topicFuture = CompletableFuture.completedFuture(Optional.of(spyTopic));\n@@ -331,7 +329,7 @@ public void testUnloadNamespaceBundleWithStuckTopic() throws Exception {\n         final String topicName = \"persistent://my-property/use/my-ns/my-topic1\";\n         Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(\"my-subscriber-name\")\n                 .subscribe();\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics = pulsar.getBrokerService().getTopics();\n+        final var topics = pulsar.getBrokerService().getTopics();\n         Topic spyTopic = spy(topics.get(topicName).get().get());\n         topics.clear();\n         CompletableFuture<Optional<Topic>> topicFuture = CompletableFuture.completedFuture(Optional.of(spyTopic));\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java\nindex 7415a40ad5553..374296e68671d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/AbstractReplicatorTest.java\n@@ -28,6 +28,7 @@\n import io.netty.util.internal.DefaultPriorityQueue;\n import java.util.Optional;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n@@ -45,7 +46,6 @@\n import org.apache.pulsar.client.impl.PulsarClientImpl;\n import org.apache.pulsar.client.impl.conf.ProducerConfigurationData;\n import org.apache.pulsar.common.policies.data.stats.ReplicatorStatsImpl;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.awaitility.reflect.WhiteboxImpl;\n import org.testng.Assert;\n@@ -74,7 +74,7 @@ public void testRetryStartProducerStoppedByTopicRemove() throws Exception {\n         when(remoteClient.getCnxPool()).thenReturn(connectionPool);\n         final ProducerConfigurationData producerConf = new ProducerConfigurationData();\n         final ProducerBuilderImpl producerBuilder = mock(ProducerBuilderImpl.class);\n-        final ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics = new ConcurrentOpenHashMap<>();\n+        final var topics = new ConcurrentHashMap<String, CompletableFuture<Optional<Topic>>>();\n         when(broker.executor()).thenReturn(eventLoopGroup);\n         when(broker.getTopics()).thenReturn(topics);\n         when(remoteClient.newProducer(any(Schema.class))).thenReturn(producerBuilder);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java\nindex ea5365bcf4b2c..71303fcd775af 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceAutoTopicCreationTest.java\n@@ -25,11 +25,11 @@\n \n \n import java.util.List;\n-import java.util.Optional;\n+import java.util.Map;\n import java.util.Set;\n import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n import lombok.Cleanup;\n import org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerImpl;\n import org.apache.pulsar.broker.loadbalance.extensions.channel.ServiceUnitStateChannelImpl;\n@@ -45,7 +45,6 @@\n import org.apache.pulsar.common.policies.data.AutoTopicCreationOverride;\n import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n import org.apache.pulsar.common.policies.data.TopicType;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n@@ -552,10 +551,9 @@ public void testExtensibleLoadManagerImplInternalTopicAutoCreations()\n         admin.topics().createNonPartitionedTopic(ExtensibleLoadManagerImpl.TOP_BUNDLES_LOAD_DATA_STORE_TOPIC);\n \n         // clear the topics to test the auto creation of non-persistent topics.\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                pulsar.getBrokerService().getTopics();\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> oldTopics = new ConcurrentOpenHashMap<>();\n-        topics.forEach((key, val) -> oldTopics.put(key, val));\n+        final var topics = pulsar.getBrokerService().getTopics();\n+        final var oldTopics = topics.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                Map.Entry::getValue));\n         topics.clear();\n \n         // The created persistent topic correctly can be found by\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\nindex 2f27d5917f025..c5ab577dadccd 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n@@ -1630,7 +1630,7 @@ public void testGetTopic() throws Exception {\n         producer1.close();\n         PersistentTopic persistentTopic = (PersistentTopic) pulsar.getBrokerService().getTopic(topicName.toString(), false).get().get();\n         persistentTopic.close().join();\n-        List<String> topics = new ArrayList<>(pulsar.getBrokerService().getTopics().keys());\n+        List<String> topics = new ArrayList<>(pulsar.getBrokerService().getTopics().keySet());\n         topics.removeIf(item -> item.contains(SystemTopicNames.NAMESPACE_EVENTS_LOCAL_NAME));\n         Assert.assertEquals(topics.size(), 0);\n         @Cleanup\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\nindex d684b4af7c251..a8f8d7ecbbd47 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n@@ -92,7 +92,6 @@\n import org.apache.pulsar.common.policies.data.TopicStats;\n import org.apache.pulsar.common.policies.data.impl.AutoTopicCreationOverrideImpl;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.awaitility.reflect.WhiteboxImpl;\n import org.glassfish.jersey.client.JerseyClient;\n@@ -293,8 +292,7 @@ private Runnable injectMockReplicatorProducerBuilder(\n         });\n \n         // Inject spy client.\n-        ConcurrentOpenHashMap<String, PulsarClient>\n-                replicationClients = WhiteboxImpl.getInternalState(brokerService, \"replicationClients\");\n+        final var replicationClients = brokerService.getReplicationClients();\n         PulsarClientImpl internalClient = (PulsarClientImpl) replicationClients.get(cluster2);\n         PulsarClient spyClient = spy(internalClient);\n         assertTrue(replicationClients.remove(cluster2, internalClient));\n@@ -1141,9 +1139,9 @@ public void testDifferentTopicCreationRule(ReplicationMode replicationMode) thro\n             return t.startsWith(tp);\n         };\n         Awaitility.await().untilAsserted(() -> {\n-            List<String> topics1 = pulsar1.getBrokerService().getTopics().keys()\n+            List<String> topics1 = pulsar1.getBrokerService().getTopics().keySet()\n                     .stream().filter(topicNameFilter).collect(Collectors.toList());\n-            List<String> topics2 = pulsar2.getBrokerService().getTopics().keys()\n+            List<String> topics2 = pulsar2.getBrokerService().getTopics().keySet()\n                     .stream().filter(topicNameFilter).collect(Collectors.toList());\n             Collections.sort(topics1);\n             Collections.sort(topics2);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java\nindex a5d14ca0487dc..c214378fd94a3 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsTest.java\n@@ -23,10 +23,8 @@\n import static org.testng.Assert.assertTrue;\n import java.util.List;\n import java.util.Optional;\n-import org.apache.pulsar.client.admin.PulsarAdmin;\n import org.apache.pulsar.client.admin.internal.PulsarAdminImpl;\n import org.apache.pulsar.client.impl.conf.ClientConfigurationData;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n@@ -55,7 +53,7 @@ public void testReplicationAdmin() throws Exception {\n             ns.getClusterPulsarAdmin(cluster3, Optional.of(admin1.clusters().getCluster(cluster3)));\n \n             // verify the admin\n-            ConcurrentOpenHashMap<String, PulsarAdmin> clusterAdmins = ns.getClusterAdmins();\n+            final var clusterAdmins = ns.getClusterAdmins();\n             assertFalse(clusterAdmins.isEmpty());\n             clusterAdmins.forEach((cluster, admin) -> {\n                 ClientConfigurationData clientConfigData = ((PulsarAdminImpl) admin).getClientConfigData();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java\nindex 3d3eb3faa727f..451bdd10eb106 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorAdminTlsWithKeyStoreTest.java\n@@ -23,10 +23,8 @@\n import static org.testng.Assert.assertTrue;\n import java.util.List;\n import java.util.Optional;\n-import org.apache.pulsar.client.admin.PulsarAdmin;\n import org.apache.pulsar.client.admin.internal.PulsarAdminImpl;\n import org.apache.pulsar.client.impl.conf.ClientConfigurationData;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n@@ -56,7 +54,7 @@ public void testReplicationAdmin() throws Exception {\n             ns.getClusterPulsarAdmin(cluster3, Optional.of(admin1.clusters().getCluster(cluster3)));\n \n             // verify the admin\n-            ConcurrentOpenHashMap<String, PulsarAdmin> clusterAdmins = ns.getClusterAdmins();\n+            final var clusterAdmins = ns.getClusterAdmins();\n             assertFalse(clusterAdmins.isEmpty());\n             clusterAdmins.forEach((cluster, admin) -> {\n                 ClientConfigurationData clientConfigData = ((PulsarAdminImpl) admin).getClientConfigData();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java\nindex 514e0207fbfb1..a1f147cbb6273 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorGlobalNSTest.java\n@@ -34,7 +34,6 @@\n import org.apache.pulsar.client.impl.ConsumerImpl;\n import org.apache.pulsar.client.impl.ProducerImpl;\n import org.apache.pulsar.common.naming.TopicName;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n@@ -169,9 +168,9 @@ public Void call() throws Exception {\n \n         Thread.sleep(1000L);\n         // Make sure that the internal replicators map contains remote cluster info\n-        ConcurrentOpenHashMap<String, PulsarClient> replicationClients1 = ns1.getReplicationClients();\n-        ConcurrentOpenHashMap<String, PulsarClient> replicationClients2 = ns2.getReplicationClients();\n-        ConcurrentOpenHashMap<String, PulsarClient> replicationClients3 = ns3.getReplicationClients();\n+        final var replicationClients1 = ns1.getReplicationClients();\n+        final var replicationClients2 = ns2.getReplicationClients();\n+        final var replicationClients3 = ns3.getReplicationClients();\n \n         Assert.assertNotNull(replicationClients1.get(\"r2\"));\n         Assert.assertNotNull(replicationClients1.get(\"r3\"));\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\nindex 1c47abab775b3..8e115e14b3770 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorTest.java\n@@ -234,11 +234,7 @@ public void testConcurrentReplicator() throws Exception {\n         final Method startRepl = PersistentTopic.class.getDeclaredMethod(\"startReplicator\", String.class);\n         startRepl.setAccessible(true);\n \n-        Field replClientField = BrokerService.class.getDeclaredField(\"replicationClients\");\n-        replClientField.setAccessible(true);\n-        ConcurrentOpenHashMap<String, PulsarClient> replicationClients =\n-                (ConcurrentOpenHashMap<String, PulsarClient>) replClientField\n-                .get(pulsar1.getBrokerService());\n+        final var replicationClients = pulsar1.getBrokerService().getReplicationClients();\n         replicationClients.put(\"r3\", pulsarClient);\n \n         admin1.namespaces().setNamespaceReplicationClusters(namespace, Sets.newHashSet(\"r1\", \"r2\", \"r3\"));\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\nindex ddc5eeab1d20e..f1940a2899978 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\n@@ -27,7 +27,6 @@\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n \n-import java.lang.reflect.Field;\n import java.util.Optional;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n@@ -45,7 +44,6 @@\n import org.apache.pulsar.client.api.ProducerConsumerBase;\n import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.common.naming.TopicName;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.awaitility.reflect.WhiteboxImpl;\n import org.testng.Assert;\n@@ -591,12 +589,7 @@ public void testFinishTakeSnapshotWhenTopicLoading() throws Exception {\n             return false;\n         });\n \n-        Field field2 = BrokerService.class.getDeclaredField(\"topics\");\n-        field2.setAccessible(true);\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>)\n-                        field2.get(pulsar.getBrokerService());\n-\n+        final var topics = pulsar.getBrokerService().getTopics();\n         try {\n             pulsar.getBrokerService().getTopic(topic, false).join().get();\n             Assert.fail();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\nindex 4df2d36a95303..a92f5a4acc208 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/PrometheusMetricsTest.java\n@@ -424,16 +424,16 @@ public void testPerTopicStats() throws Exception {\n         // There should be 2 metrics with different tags for each topic\n         List<Metric> cm = (List<Metric>) metrics.get(\"pulsar_storage_write_latency_le_1\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_producers_count\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n-        assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_topic_load_times_count\");\n@@ -446,33 +446,33 @@ public void testPerTopicStats() throws Exception {\n \n         cm = (List<Metric>) metrics.get(\"pulsar_in_bytes_total\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_in_messages_total\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_out_bytes_total\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n         assertEquals(cm.get(0).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n         assertEquals(cm.get(1).tags.get(\"subscription\"), \"test\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_out_messages_total\");\n         assertEquals(cm.size(), 2);\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n         assertEquals(cm.get(0).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n         assertEquals(cm.get(1).tags.get(\"subscription\"), \"test\");\n \n@@ -1086,26 +1086,26 @@ public void testPerProducerStats() throws Exception {\n         List<Metric> cm = (List<Metric>) metrics.get(\"pulsar_producer_msg_rate_in\");\n         assertEquals(cm.size(), 2);\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n-        assertEquals(cm.get(0).tags.get(\"producer_name\"), \"producer2\");\n-        assertEquals(cm.get(0).tags.get(\"producer_id\"), \"1\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(0).tags.get(\"producer_name\"), \"producer1\");\n+        assertEquals(cm.get(0).tags.get(\"producer_id\"), \"0\");\n \n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n-        assertEquals(cm.get(1).tags.get(\"producer_name\"), \"producer1\");\n-        assertEquals(cm.get(1).tags.get(\"producer_id\"), \"0\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(1).tags.get(\"producer_name\"), \"producer2\");\n+        assertEquals(cm.get(1).tags.get(\"producer_id\"), \"1\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_producer_msg_throughput_in\");\n         assertEquals(cm.size(), 2);\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n-        assertEquals(cm.get(0).tags.get(\"producer_name\"), \"producer2\");\n-        assertEquals(cm.get(0).tags.get(\"producer_id\"), \"1\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(0).tags.get(\"producer_name\"), \"producer1\");\n+        assertEquals(cm.get(0).tags.get(\"producer_id\"), \"0\");\n \n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n-        assertEquals(cm.get(1).tags.get(\"producer_name\"), \"producer1\");\n-        assertEquals(cm.get(1).tags.get(\"producer_id\"), \"0\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(1).tags.get(\"producer_name\"), \"producer2\");\n+        assertEquals(cm.get(1).tags.get(\"producer_id\"), \"1\");\n \n         p1.close();\n         p2.close();\n@@ -1155,42 +1155,42 @@ public void testPerConsumerStats() throws Exception {\n         List<Metric> cm = (List<Metric>) metrics.get(\"pulsar_out_bytes_total\");\n         assertEquals(cm.size(), 4);\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"subscription\"), \"test\");\n \n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(1).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(1).tags.get(\"consumer_id\"), \"1\");\n+        assertEquals(cm.get(1).tags.get(\"consumer_id\"), \"0\");\n \n         assertEquals(cm.get(2).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(2).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(2).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(2).tags.get(\"subscription\"), \"test\");\n \n         assertEquals(cm.get(3).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(3).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(3).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(3).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(3).tags.get(\"consumer_id\"), \"0\");\n+        assertEquals(cm.get(3).tags.get(\"consumer_id\"), \"1\");\n \n         cm = (List<Metric>) metrics.get(\"pulsar_out_messages_total\");\n         assertEquals(cm.size(), 4);\n         assertEquals(cm.get(0).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(0).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(0).tags.get(\"subscription\"), \"test\");\n \n         assertEquals(cm.get(1).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n+        assertEquals(cm.get(1).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n         assertEquals(cm.get(1).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(1).tags.get(\"consumer_id\"), \"1\");\n+        assertEquals(cm.get(1).tags.get(\"consumer_id\"), \"0\");\n \n         assertEquals(cm.get(2).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(2).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(2).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(2).tags.get(\"subscription\"), \"test\");\n \n         assertEquals(cm.get(3).tags.get(\"namespace\"), \"my-property/use/my-ns\");\n-        assertEquals(cm.get(3).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic1\");\n+        assertEquals(cm.get(3).tags.get(\"topic\"), \"persistent://my-property/use/my-ns/my-topic2\");\n         assertEquals(cm.get(3).tags.get(\"subscription\"), \"test\");\n-        assertEquals(cm.get(3).tags.get(\"consumer_id\"), \"0\");\n+        assertEquals(cm.get(3).tags.get(\"consumer_id\"), \"1\");\n \n         p1.close();\n         p2.close();\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\nindex cf923df0411dd..45e3fb253bf11 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/stats/prometheus/NamespaceStatsAggregatorTest.java\n@@ -21,6 +21,8 @@\n import static org.mockito.Mockito.doReturn;\n import static org.mockito.Mockito.when;\n import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n import org.apache.bookkeeper.mledger.ManagedLedger;\n import org.apache.bookkeeper.mledger.impl.ManagedLedgerMBeanImpl;\n import org.apache.bookkeeper.mledger.util.StatsBuckets;\n@@ -47,17 +49,14 @@\n public class NamespaceStatsAggregatorTest {\n     protected PulsarService pulsar;\n     private BrokerService broker;\n-    private ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>\n-            multiLayerTopicsMap;\n+    private Map<String, Map<String, Map<String, Topic>>> multiLayerTopicsMap;\n \n     @BeforeMethod(alwaysRun = true)\n     public void setup() throws Exception {\n-        multiLayerTopicsMap = ConcurrentOpenHashMap.<String,\n-                        ConcurrentOpenHashMap<String, ConcurrentOpenHashMap<String, Topic>>>newBuilder()\n-                .build();\n+        multiLayerTopicsMap = new ConcurrentHashMap<>();\n         pulsar = Mockito.mock(PulsarService.class);\n         broker = Mockito.mock(BrokerService.class);\n-        doReturn(multiLayerTopicsMap).when(broker).getMultiLayerTopicMap();\n+        doReturn(multiLayerTopicsMap).when(broker).getMultiLayerTopicsMap();\n         Mockito.when(pulsar.getLocalMetadataStore()).thenReturn(Mockito.mock(ZKMetadataStore.class));\n         ServiceConfiguration mockConfig = Mockito.mock(ServiceConfiguration.class);\n         doReturn(mockConfig).when(pulsar).getConfiguration();\n@@ -70,8 +69,8 @@ public void testGenerateSubscriptionsStats() {\n         final String namespace = \"tenant/cluster/ns\";\n \n         // prepare multi-layer topic map\n-        ConcurrentOpenHashMap bundlesMap = ConcurrentOpenHashMap.newBuilder().build();\n-        ConcurrentOpenHashMap topicsMap = ConcurrentOpenHashMap.newBuilder().build();\n+        final var bundlesMap = new ConcurrentHashMap<String, Map<String, Topic>>();\n+        final var topicsMap = new ConcurrentHashMap<String, Topic>();\n         ConcurrentOpenHashMap subscriptionsMaps = ConcurrentOpenHashMap.newBuilder().build();\n         bundlesMap.put(\"my-bundle\", topicsMap);\n         multiLayerTopicsMap.put(namespace, bundlesMap);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java\nindex 3924281c094b1..f21e11b980209 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TopicTransactionBufferRecoverTest.java\n@@ -93,7 +93,6 @@\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.protocol.Commands;\n import org.apache.pulsar.common.util.FutureUtil;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n import org.testng.annotations.AfterMethod;\n@@ -201,20 +200,14 @@ private void recoverTest(String testTopic) throws Exception {\n \n         Awaitility.await().until(() -> {\n             for (int i = 0; i < getPulsarServiceList().size(); i++) {\n-                Field field = BrokerService.class.getDeclaredField(\"topics\");\n-                field.setAccessible(true);\n-                ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                        (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                                .get(getPulsarServiceList().get(i).getBrokerService());\n+                final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n                 CompletableFuture<Optional<Topic>> completableFuture = topics.get(\"persistent://\" + testTopic);\n                 if (completableFuture != null) {\n                     Optional<Topic> topic = completableFuture.get();\n                     if (topic.isPresent()) {\n                         PersistentTopic persistentTopic = (PersistentTopic) topic.get();\n-                        field = PersistentTopic.class.getDeclaredField(\"transactionBuffer\");\n-                        field.setAccessible(true);\n                         TopicTransactionBuffer topicTransactionBuffer =\n-                                (TopicTransactionBuffer) field.get(persistentTopic);\n+                                (TopicTransactionBuffer) persistentTopic.getTransactionBuffer();\n                         if (topicTransactionBuffer.checkIfReady()) {\n                             return true;\n                         } else {\n@@ -455,17 +448,13 @@ private void testTopicTransactionBufferDeleteAbort(Boolean enableSnapshotSegment\n         assertTrue(((MessageIdImpl) messageId2).getLedgerId() != ((MessageIdImpl) messageId1).getLedgerId());\n         boolean exist = false;\n         for (int i = 0; i < getPulsarServiceList().size(); i++) {\n-            Field field = BrokerService.class.getDeclaredField(\"topics\");\n-            field.setAccessible(true);\n-            ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                    (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                            .get(getPulsarServiceList().get(i).getBrokerService());\n+            final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n             CompletableFuture<Optional<Topic>> completableFuture = topics.get(\"persistent://\" + ABORT_DELETE);\n             if (completableFuture != null) {\n                 Optional<Topic> topic = completableFuture.get();\n                 if (topic.isPresent()) {\n                     PersistentTopic persistentTopic = (PersistentTopic) topic.get();\n-                    field = ManagedLedgerImpl.class.getDeclaredField(\"ledgers\");\n+                    var field = ManagedLedgerImpl.class.getDeclaredField(\"ledgers\");\n                     field.setAccessible(true);\n                     NavigableMap<Long, MLDataFormats.ManagedLedgerInfo.LedgerInfo> ledgers\n                             = (NavigableMap<Long, MLDataFormats.ManagedLedgerInfo.LedgerInfo>) field.get(persistentTopic.getManagedLedger());\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java\nindex 39f36f4d38c65..14b1d563c11ec 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionProduceTest.java\n@@ -390,7 +390,7 @@ private int getPendingAckCount(String topic, String subscriptionName) throws Exc\n \n         int pendingAckCount = 0;\n         for (PulsarService pulsarService : getPulsarServiceList()) {\n-            for (String key : pulsarService.getBrokerService().getTopics().keys()) {\n+            for (String key : pulsarService.getBrokerService().getTopics().keySet()) {\n                 if (key.contains(topic)) {\n                     Field field = clazz.getDeclaredField(\"pendingAckHandle\");\n                     field.setAccessible(true);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java\nindex cc09fa212198d..5480b1a21d5a0 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/TransactionTest.java\n@@ -145,7 +145,6 @@\n import org.apache.pulsar.common.policies.data.RetentionPolicies;\n import org.apache.pulsar.common.policies.data.stats.TopicStatsImpl;\n import org.apache.pulsar.common.schema.SchemaInfo;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.compaction.CompactionServiceFactory;\n import org.apache.pulsar.compaction.PulsarCompactionServiceFactory;\n import org.apache.pulsar.opentelemetry.OpenTelemetryAttributes;\n@@ -385,8 +384,7 @@ public void brokerNotInitTxnManagedLedgerTopic() throws Exception {\n             return true;\n         });\n \n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                getPulsarServiceList().get(0).getBrokerService().getTopics();\n+        final var topics = getPulsarServiceList().get(0).getBrokerService().getTopics();\n \n         Assert.assertNull(topics.get(TopicName.get(TopicDomain.persistent.value(),\n                 NamespaceName.SYSTEM_NAMESPACE, TRANSACTION_LOG_PREFIX).toString() + 0));\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java\nindex 2e6d9c61bde79..818b854ffe941 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TransactionLowWaterMarkTest.java\n@@ -33,7 +33,6 @@\n import lombok.extern.slf4j.Slf4j;\n import org.apache.bookkeeper.mledger.Position;\n import org.apache.commons.collections4.map.LinkedMap;\n-import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n@@ -54,7 +53,6 @@\n import org.apache.pulsar.common.naming.SystemTopicNames;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.partition.PartitionedTopicMetadata;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.transaction.coordinator.TransactionCoordinatorID;\n import org.apache.pulsar.transaction.coordinator.TransactionMetadataStore;\n import org.apache.pulsar.transaction.coordinator.TransactionMetadataStoreState;\n@@ -215,18 +213,14 @@ public void testPendingAckLowWaterMark() throws Exception {\n         LinkedMap<TxnID, HashMap<Position, Position>> individualAckOfTransaction = null;\n \n         for (int i = 0; i < getPulsarServiceList().size(); i++) {\n-            Field field = BrokerService.class.getDeclaredField(\"topics\");\n-            field.setAccessible(true);\n-            ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                    (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                            .get(getPulsarServiceList().get(i).getBrokerService());\n+            final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n             CompletableFuture<Optional<Topic>> completableFuture = topics.get(TOPIC);\n             if (completableFuture != null) {\n                 Optional<Topic> topic = completableFuture.get();\n                 if (topic.isPresent()) {\n                     PersistentSubscription persistentSubscription = (PersistentSubscription) topic.get()\n                             .getSubscription(subName);\n-                    field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n+                    var field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n                     field.setAccessible(true);\n                     PendingAckHandleImpl pendingAckHandle = (PendingAckHandleImpl) field.get(persistentSubscription);\n                     field = PendingAckHandleImpl.class.getDeclaredField(\"individualAckOfTransaction\");\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java\nindex fd4e984b6c1fc..58cf59aa6b3b9 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/pendingack/PendingAckInMemoryDeleteTest.java\n@@ -21,7 +21,6 @@\n \n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertTrue;\n-import java.lang.reflect.Field;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.Optional;\n@@ -35,7 +34,6 @@\n import org.apache.bookkeeper.mledger.impl.ManagedCursorImpl;\n import org.apache.commons.collections4.map.LinkedMap;\n import org.apache.commons.lang3.tuple.MutablePair;\n-import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.transaction.TransactionTestBase;\n@@ -48,7 +46,6 @@\n import org.apache.pulsar.client.api.transaction.Transaction;\n import org.apache.pulsar.client.api.transaction.TxnID;\n import org.apache.pulsar.common.util.collections.BitSetRecyclable;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.testng.Assert;\n import org.testng.annotations.AfterMethod;\n@@ -120,18 +117,14 @@ public void txnAckTestNoBatchAndSharedSubMemoryDeleteTest() throws Exception {\n \n             int count = 0;\n             for (int i = 0; i < getPulsarServiceList().size(); i++) {\n-                Field field = BrokerService.class.getDeclaredField(\"topics\");\n-                field.setAccessible(true);\n-                ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                        (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                                .get(getPulsarServiceList().get(i).getBrokerService());\n+                final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n                 CompletableFuture<Optional<Topic>> completableFuture = topics.get(\"persistent://\" + normalTopic);\n                 if (completableFuture != null) {\n                     Optional<Topic> topic = completableFuture.get();\n                     if (topic.isPresent()) {\n                         PersistentSubscription persistentSubscription = (PersistentSubscription) topic.get()\n                                 .getSubscription(subscriptionName);\n-                        field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n+                        var field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n                         field.setAccessible(true);\n                         PendingAckHandleImpl pendingAckHandle = (PendingAckHandleImpl) field.get(persistentSubscription);\n                         field = PendingAckHandleImpl.class.getDeclaredField(\"individualAckOfTransaction\");\n@@ -214,18 +207,14 @@ public void txnAckTestBatchAndSharedSubMemoryDeleteTest() throws Exception {\n             commitTxn.commit().get();\n             int count = 0;\n             for (int i = 0; i < getPulsarServiceList().size(); i++) {\n-                Field field = BrokerService.class.getDeclaredField(\"topics\");\n-                field.setAccessible(true);\n-                ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                        (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                                .get(getPulsarServiceList().get(i).getBrokerService());\n+                final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n                 CompletableFuture<Optional<Topic>> completableFuture = topics.get(\"persistent://\" + normalTopic);\n                 if (completableFuture != null) {\n                     Optional<Topic> topic = completableFuture.get();\n                     if (topic.isPresent()) {\n                         PersistentSubscription testPersistentSubscription =\n                                 (PersistentSubscription) topic.get().getSubscription(subscriptionName);\n-                        field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n+                        var field = PersistentSubscription.class.getDeclaredField(\"pendingAckHandle\");\n                         field.setAccessible(true);\n                         pendingAckHandle = (PendingAckHandleImpl) field.get(testPersistentSubscription);\n                         field = PendingAckHandleImpl.class.getDeclaredField(\"individualAckOfTransaction\");\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java\nindex 424081b904c81..e04dde65fa872 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/TopicReaderTest.java\n@@ -996,7 +996,7 @@ public void testMultiReaderMessageAvailableAfterRestart() throws Exception {\n         }\n \n         // cause broker to drop topic. Will be loaded next time we access it\n-        pulsar.getBrokerService().getTopics().keys().forEach(topicName -> {\n+        pulsar.getBrokerService().getTopics().keySet().forEach(topicName -> {\n             try {\n                 pulsar.getBrokerService().getTopicReference(topicName).get().close(false).get();\n             } catch (Exception e) {\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java\nindex 06c6069ebae71..1e8754a2d675c 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/BrokerClientIntegrationTest.java\n@@ -48,7 +48,6 @@\n import java.util.HashSet;\n import java.util.List;\n import java.util.NavigableMap;\n-import java.util.Optional;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ConcurrentSkipListMap;\n@@ -101,7 +100,6 @@\n import org.apache.pulsar.common.protocol.PulsarHandler;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.collections.ConcurrentLongHashMap;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n import org.mockito.Mockito;\n import org.mockito.invocation.InvocationOnMock;\n@@ -697,8 +695,7 @@ public void testCleanProducer() throws Exception {\n     @Test(expectedExceptions = PulsarClientException.TimeoutException.class)\n     public void testOperationTimeout() throws PulsarClientException {\n         final String topicName = \"persistent://my-property/my-ns/my-topic1\";\n-        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics = pulsar.getBrokerService()\n-                .getTopics();\n+        final var topics = pulsar.getBrokerService().getTopics();\n         // non-complete topic future so, create topic should timeout\n         topics.put(topicName, new CompletableFuture<>());\n         try (PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(lookupUrl.toString())\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java\nindex 812f8fd571cac..f490fa70539ea 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/TransactionEndToEndTest.java\n@@ -73,7 +73,6 @@\n import org.apache.pulsar.common.api.proto.CommandAck;\n import org.apache.pulsar.common.naming.TopicName;\n import org.apache.pulsar.common.policies.data.PersistentTopicInternalStats;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.apache.pulsar.transaction.coordinator.TransactionCoordinatorID;\n import org.apache.pulsar.transaction.coordinator.TransactionMetadataStore;\n import org.apache.pulsar.transaction.coordinator.TransactionSubscription;\n@@ -415,11 +414,7 @@ public void produceAbortTest() throws Exception {\n                 boolean exist = false;\n                 for (int i = 0; i < getPulsarServiceList().size(); i++) {\n \n-                    Field field = BrokerService.class.getDeclaredField(\"topics\");\n-                    field.setAccessible(true);\n-                    ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                            (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                                    .get(getPulsarServiceList().get(i).getBrokerService());\n+                    final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n                     CompletableFuture<Optional<Topic>> topicFuture = topics.get(topic);\n \n                     if (topicFuture != null) {\n@@ -722,9 +717,7 @@ public void txnMessageAckTest() throws Exception {\n \n             Field field = BrokerService.class.getDeclaredField(\"topics\");\n             field.setAccessible(true);\n-            ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                    (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                            .get(getPulsarServiceList().get(i).getBrokerService());\n+            final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n             CompletableFuture<Optional<Topic>> topicFuture = topics.get(topic);\n \n             if (topicFuture != null) {\n@@ -1193,9 +1186,7 @@ public void txnTransactionRedeliverNullDispatcher(CommandAck.AckType ackType) th\n \n             Field field = BrokerService.class.getDeclaredField(\"topics\");\n             field.setAccessible(true);\n-            ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n-                    (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>) field\n-                            .get(getPulsarServiceList().get(i).getBrokerService());\n+            final var topics = getPulsarServiceList().get(i).getBrokerService().getTopics();\n             CompletableFuture<Optional<Topic>> topicFuture = topics.get(topic);\n \n             if (topicFuture != null) {\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23274",
    "pr_id": 23274,
    "issue_id": 23273,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Broker Fails to Restart Due to Incomplete NAR File Extraction in `/tmp` Directory\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nMaster branch\n\n### Minimal reproduce step\n\n1. Configure the Pulsar broker with a filter NAR file, using the following parameters:\r\n    * `entryFilterNames=<your-filter-name>`\r\n    * `entryFiltersDirectory=<path-to-filter-directory>`\r\n2. Attempt to start the broker. Ensure the NAR file is available in the filters directory.\r\n3. While the broker is attempting to unpack the NAR file, stop the broker mid-process.\r\n4. Restart the broker.\r\n5. Observe that the broker fails to restart due to a `NoSuchFileException` related to the `/tmp` directory.\n\n### What did you expect to see?\n\nThe Pulsar broker should restart normally without any manual intervention or deletion of files in the `/tmp` directory.\n\n### What did you see instead?\n\nThe broker fails to start, throwing a `NoSuchFileException` for missing files in the `/tmp` directory, specifically related to the filter NAR file. Manually deleting the `/tmp` directory allows the broker to start normally, but the issue reappears on subsequent restarts.\r\n\r\n```\r\njava.nio.file.NoSuchFileException: /tmp/pulsar-nar/pulsar-jms-5.0.4-nar.nar-unpacked/_Cvs_KLip3kCfKeErKASDO/META-INF/services/entry_filter.yml\r\n\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:92) ~[?:?]\r\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106) ~[?:?]\r\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) ~[?:?]\r\n\tat sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:218) ~[?:?]\r\n\tat java.nio.file.Files.newByteChannel(Files.java:380) ~[?:?]\r\n\tat java.nio.file.Files.newByteChannel(Files.java:432) ~[?:?]\r\n\tat java.nio.file.Files.readAllBytes(Files.java:3288) ~[?:?]\r\n\tat org.apache.pulsar.common.nar.NarClassLoader.getServiceDefinition(NarClassLoader.java:204) ~[org.apache.pulsar-pulsar-common-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.service.plugin.EntryFilterProvider.getEntryFilterDefinition(EntryFilterProvider.java:125) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.service.plugin.EntryFilterProvider.getEntryFilterDefinition(EntryFilterProvider.java:114) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.service.plugin.EntryFilterProvider.searchForEntryFilters(EntryFilterProvider.java:84) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.service.plugin.EntryFilterProvider.createEntryFilters(EntryFilterProvider.java:49) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.service.BrokerService.<init>(BrokerService.java:328) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.PulsarService.newBrokerService(PulsarService.java:1843) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.broker.PulsarService.start(PulsarService.java:756) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.PulsarBrokerStarter$BrokerStarter.start(PulsarBrokerStarter.java:274) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n\tat org.apache.pulsar.PulsarBrokerStarter.main(PulsarBrokerStarter.java:354) ~[org.apache.pulsar-pulsar-broker-2.11.1.jar:2.11.1]\r\n```\n\n### Anything else?\n\n* This issue only occurs in bare metal installations, as the /tmp directory is retained across broker restarts.\r\n* Possible root cause: The broker might have been restarted while the NAR file was being extracted, leaving the extraction incomplete. Upon restart, the broker assumes the incomplete files are valid, leading to the error.\r\n* Suggested fix: Implement a mechanism that writes a \".success\" file after successful NAR extraction and ensures this file is present before using the directory.\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 620,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-common/src/main/java/org/apache/pulsar/common/nar/NarUnpacker.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java"
    ],
    "base_commit": "a875debe9144e69764bde8f04ada36a5302519e5",
    "head_commit": "78687627997c89ca110ea41c7ed72505faddeb61",
    "repo_url": "https://github.com/apache/pulsar/pull/23274",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23274",
    "dockerfile": "",
    "pr_merged_at": "2024-09-19T08:57:37.000Z",
    "patch": "diff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/nar/NarUnpacker.java b/pulsar-common/src/main/java/org/apache/pulsar/common/nar/NarUnpacker.java\nindex e1806836d2833..ef802674b421a 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/nar/NarUnpacker.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/nar/NarUnpacker.java\n@@ -32,7 +32,9 @@\n import java.io.RandomAccessFile;\n import java.nio.channels.FileChannel;\n import java.nio.channels.FileLock;\n+import java.nio.file.Files;\n import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n import java.security.MessageDigest;\n import java.security.NoSuchAlgorithmException;\n import java.util.Base64;\n@@ -86,19 +88,32 @@ static File doUnpackNar(final File nar, final File baseWorkingDirectory, Runnabl\n             try (FileChannel channel = new RandomAccessFile(lockFile, \"rw\").getChannel();\n                  FileLock lock = channel.lock()) {\n                 File narWorkingDirectory = new File(parentDirectory, md5Sum);\n-                if (narWorkingDirectory.mkdir()) {\n+                if (!narWorkingDirectory.exists()) {\n+                    File narExtractionTempDirectory = new File(parentDirectory, md5Sum + \".tmp\");\n+                    if (narExtractionTempDirectory.exists()) {\n+                        FileUtils.deleteFile(narExtractionTempDirectory, true);\n+                    }\n+                    if (!narExtractionTempDirectory.mkdir()) {\n+                        throw new IOException(\"Cannot create \" + narExtractionTempDirectory);\n+                    }\n                     try {\n-                        log.info(\"Extracting {} to {}\", nar, narWorkingDirectory);\n+                        log.info(\"Extracting {} to {}\", nar, narExtractionTempDirectory);\n                         if (extractCallback != null) {\n                             extractCallback.run();\n                         }\n-                        unpack(nar, narWorkingDirectory);\n+                        unpack(nar, narExtractionTempDirectory);\n                     } catch (IOException e) {\n                         log.error(\"There was a problem extracting the nar file. Deleting {} to clean up state.\",\n-                                narWorkingDirectory, e);\n-                        FileUtils.deleteFile(narWorkingDirectory, true);\n+                                narExtractionTempDirectory, e);\n+                        try {\n+                            FileUtils.deleteFile(narExtractionTempDirectory, true);\n+                        } catch (IOException e2) {\n+                            log.error(\"Failed to delete temporary directory {}\", narExtractionTempDirectory, e2);\n+                        }\n                         throw e;\n                     }\n+                    Files.move(narExtractionTempDirectory.toPath(), narWorkingDirectory.toPath(),\n+                            StandardCopyOption.ATOMIC_MOVE);\n                 }\n                 return narWorkingDirectory;\n             }\n@@ -166,7 +181,7 @@ private static void makeFile(final InputStream inputStream, final File file) thr\n      * @throws IOException\n      *             if cannot read file\n      */\n-    private static byte[] calculateMd5sum(final File file) throws IOException {\n+    protected static byte[] calculateMd5sum(final File file) throws IOException {\n         try (final FileInputStream inputStream = new FileInputStream(file)) {\n             // codeql[java/weak-cryptographic-algorithm] - md5 is sufficient for this use case\n             final MessageDigest md5 = MessageDigest.getInstance(\"md5\");\n@@ -184,4 +199,4 @@ private static byte[] calculateMd5sum(final File file) throws IOException {\n             throw new IllegalArgumentException(nsae);\n         }\n     }\n-}\n+}\n\\ No newline at end of file\n",
    "test_patch": "diff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java\nindex a1f915c8b7828..1c3a2c276537b 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/nar/NarUnpackerTest.java\n@@ -118,6 +118,17 @@ public static void main(String[] args) {\n         }\n     }\n \n+    @Test\n+    void shouldReExtractWhenUnpackedDirectoryIsMissing() throws IOException {\n+        AtomicInteger extractCounter = new AtomicInteger();\n+\n+        File narWorkingDirectory = NarUnpacker.doUnpackNar(sampleZipFile, extractDirectory, extractCounter::incrementAndGet);\n+        FileUtils.deleteFile(narWorkingDirectory, true);\n+        NarUnpacker.doUnpackNar(sampleZipFile, extractDirectory, extractCounter::incrementAndGet);\n+\n+        assertEquals(extractCounter.get(), 2);\n+    }\n+\n     @Test\n     void shouldExtractFilesOnceInDifferentProcess() throws InterruptedException {\n         int processes = 5;\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23243",
    "pr_id": 23243,
    "issue_id": 19508,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: MessageChunkingSharedTest.testMultiConsumers\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\nError:  Tests run: 14, Failures: 1, Errors: 0, Skipped: 12, Time elapsed: 14.557 s <<< FAILURE! - in org.apache.pulsar.client.impl.MessageChunkingSharedTest\r\n[551](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:552)\r\n  Error:  testMultiConsumers(org.apache.pulsar.client.impl.MessageChunkingSharedTest)  Time elapsed: 3.308 s  <<< FAILURE!\r\n[552](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:553)\r\n  org.awaitility.core.ConditionTimeoutException: Condition with org.apache.pulsar.client.impl.MessageChunkingSharedTest was not fulfilled within 3 seconds.\r\n[553](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:554)\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n[554](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:555)\r\n  \tat org.awaitility.core.CallableCondition.await(CallableCondition.java:78)\r\n[555](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:556)\r\n  \tat org.awaitility.core.CallableCondition.await(CallableCondition.java:26)\r\n[556](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:557)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n[557](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:558)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:954)\r\n[558](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:559)\r\n  \tat org.apache.pulsar.client.impl.MessageChunkingSharedTest.testMultiConsumers(MessageChunkingSharedTest.java:136)\r\n[559](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:560)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n[560](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:561)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n[561](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:562)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n[562](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:563)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n[563](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:564)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n[564](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:565)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n[565](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:566)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n[566](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:567)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n[567](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:568)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n[568](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:569)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n[569](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:570)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n[570](https://github.com/apache/pulsar/actions/runs/4169319611/jobs/7217300566#step:11:571)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:833)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 579,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java"
    ],
    "base_commit": "8da3bf8322c536c495541c80926cdf9389612515",
    "head_commit": "16cd913f0f4c80240aaf5c3cc563591fc48cd5bb",
    "repo_url": "https://github.com/apache/pulsar/pull/23243",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23243",
    "dockerfile": "",
    "pr_merged_at": "2024-09-02T17:12:14.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java\nindex 93d5bf30ec6b1..22f7a5d6a43e4 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/UnloadSubscriptionTest.java\n@@ -60,6 +60,7 @@ protected void doInitConf() throws Exception {\n         super.doInitConf();\n         conf.setSystemTopicEnabled(false);\n         conf.setTransactionCoordinatorEnabled(false);\n+        conf.setAcknowledgmentAtBatchIndexLevelEnabled(true);\n     }\n \n     @AfterClass(alwaysRun = true)\n@@ -242,6 +243,7 @@ private Consumer<String> createConsumer(String topicName, String subName, Subscr\n                 .subscriptionName(subName)\n                 .subscriptionType(subType)\n                 .isAckReceiptEnabled(true)\n+                .enableBatchIndexAcknowledgment(true)\n                 .subscribe();\n         return consumer;\n     }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23234",
    "pr_id": 23234,
    "issue_id": 23233,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Pulsar CLI is not able to peek encrypted and compressed message\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\n> 1.x\n\n### Minimal reproduce step\n\n1. Publish encrypted and compressed message\r\n2. Try to peek the same message to find various metadata of the published message such as publish-time, encryption-keys\r\n\r\n```\r\n./bin/pulsar-admin topics peek-message persistent://tenant1/ns1/t1  -s test\r\n:\r\n--- An unexpected error occurred in the server ---\r\n\r\nMessage: offset outside destination buffer: offset=10\r\n\r\nStacktrace:\r\n\r\nio.airlift.compress.MalformedInputException: offset outside destination buffer: offset=10\r\n\tat io.airlift.compress.lz4.Lz4RawDecompressor.decompress(Lz4RawDecompressor.java:112)\r\n\tat io.airlift.compress.lz4.Lz4Decompressor.decompress(Lz4Decompressor.java:93)\r\n\tat org.apache.pulsar.common.compression.CompressionCodecLZ4.decode(CompressionCodecLZ4.java:98)\r\n\tat org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.generateResponseWithEntry(PersistentTopicsBase.java:2927)\r\n\tat org.apache.pulsar.broker.admin.impl.PersistentTopicsBase.internalPeekNthMessage(PersistentTopicsBase.java:2740)\r\n\tat org.apache.pulsar.broker.admin.v1.PersistentTopics.peekNthMessage(PersistentTopics.java:707)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\r\n```\n\n### What did you expect to see?\n\nIt should return the message with metadata for message debugging\n\n### What did you see instead?\n\nReceiving 5xx parsing error\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 286,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java"
    ],
    "base_commit": "d98e51f7a54463d68d4521189d24566888888514",
    "head_commit": "d16cd4d2b9fd071cf21f3b341c52f8308576847e",
    "repo_url": "https://github.com/apache/pulsar/pull/23234",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23234",
    "dockerfile": "",
    "pr_merged_at": "2024-08-30T05:25:58.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\nindex 40e74f83e986d..b2d455f645daf 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/PersistentTopicsBase.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.broker.admin.impl;\n \n+import static org.apache.pulsar.common.api.proto.CompressionType.NONE;\n import static org.apache.pulsar.common.naming.SystemTopicNames.isSystemTopic;\n import static org.apache.pulsar.common.naming.SystemTopicNames.isTransactionCoordinatorAssign;\n import static org.apache.pulsar.common.naming.SystemTopicNames.isTransactionInternalName;\n@@ -2999,6 +3000,7 @@ private Response generateResponseWithEntry(Entry entry, PersistentTopic persiste\n         checkNotNull(entry);\n         Position pos = entry.getPosition();\n         ByteBuf metadataAndPayload = entry.getDataBuffer();\n+        boolean isEncrypted = false;\n \n         long totalSize = metadataAndPayload.readableBytes();\n         BrokerEntryMetadata brokerEntryMetadata = Commands.peekBrokerEntryMetadataIfExist(metadataAndPayload);\n@@ -3070,6 +3072,7 @@ private Response generateResponseWithEntry(Entry entry, PersistentTopic persiste\n         for (EncryptionKeys encryptionKeys : metadata.getEncryptionKeysList()) {\n             responseBuilder.header(\"X-Pulsar-Base64-encryption-keys\",\n                     Base64.getEncoder().encodeToString(encryptionKeys.toByteArray()));\n+            isEncrypted = true;\n         }\n         if (metadata.hasEncryptionParam()) {\n             responseBuilder.header(\"X-Pulsar-Base64-encryption-param\",\n@@ -3123,7 +3126,8 @@ private Response generateResponseWithEntry(Entry entry, PersistentTopic persiste\n         responseBuilder.header(\"X-Pulsar-txn-uncommitted\", isTxnUncommitted);\n \n         // Decode if needed\n-        CompressionCodec codec = CompressionCodecProvider.getCompressionCodec(metadata.getCompression());\n+        CompressionCodec codec = CompressionCodecProvider\n+                .getCompressionCodec(isEncrypted ? NONE : metadata.getCompression());\n         ByteBuf uncompressedPayload = codec.decode(metadataAndPayload, metadata.getUncompressedSize());\n \n         // Copy into a heap buffer for output stream compatibility\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\nindex a9d97b7febdb7..61dd33be64aa2 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n@@ -2712,12 +2712,17 @@ public EncryptionKeyInfo getPrivateKey(String keyName, Map<String, String> keyMe\n \n         Producer<byte[]> cryptoProducer = pulsarClient.newProducer()\n                 .topic(topicName).addEncryptionKey(\"client-ecdsa.pem\")\n+                .compressionType(CompressionType.LZ4)\n                 .cryptoKeyReader(new EncKeyReader()).create();\n         for (int i = 0; i < totalMsg; i++) {\n             String message = \"my-message-\" + i;\n             cryptoProducer.send(message.getBytes());\n         }\n \n+        // admin api should be able to fetch compressed and encrypted message\n+        List<Message<byte[]>> msgs = admin.topics().peekMessages(topicName, \"my-subscriber-name\", 1);\n+        assertNotNull(msgs);\n+\n         Message<byte[]> msg;\n \n         msg = normalConsumer.receive(RECEIVE_TIMEOUT_MEDIUM_MILLIS, TimeUnit.MILLISECONDS);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23219",
    "pr_id": 23219,
    "issue_id": 23212,
    "repo": "apache/pulsar",
    "problem_statement": "[feat] Replace the default NONE_KEY in Key_Shared implementation with producer name and producer sequence number\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\nThe Key_Shared implementation expects that the incoming message contain either a key/keyBytes or orderingKey. \r\nIf the key isn't set, the implementation will use the bytes of the NONE_KEY string as the key. This could be a surprise to users since the implications of not setting the key is not documented. \r\n\r\nAnother related detail is that there doesn't seem to be documentation (other than TypedMessageBuilder javadoc) for orderingKey and key/keyBytes and how orderingKey is preferred over the key/keyBytes for key_shared subscriptions. There's no documentation for the purpose of 2 separate keys.\r\n\r\nBroker side code:\r\nhttps://github.com/apache/pulsar/blob/6236116754472c61b2166da6d4797fc63c83f364/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java#L1969-L1987\r\nhttps://github.com/apache/pulsar/blob/82237d3684fe506bcb6426b3b23f413422e6e4fb/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java#L52-L61\r\n\r\nClient code:\r\nhttps://github.com/apache/pulsar/blob/10f4e0248f0f985b1dc7ad38970c906b7fe629be/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java#L1186-L1196\r\n\r\nThe problem that this causes is that all messages without a key will handled by a single consumer. If any of these messages is  in redelivery, it will cause all message delivery to be blocked.\n\n### Solution\n\nReplace the default NONE_KEY with a key that is derived from the producer name and producer sequence number.\n\n### Alternatives\n\nDocument the current behavior and requirement in https://pulsar.apache.org/docs/next/concepts-messaging/#key_shared.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 288,
    "test_files_count": 4,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java",
      "pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java",
      "pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java"
    ],
    "base_commit": "09a16c26974408de270bcaaf6162b0e2a9a6d203",
    "head_commit": "82bb37d33c78470d87f539c46a434eadea0b9d47",
    "repo_url": "https://github.com/apache/pulsar/pull/23219",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23219",
    "dockerfile": "",
    "pr_merged_at": "2024-10-01T11:32:02.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java\nindex 70643d5de2a3f..efa89a8ff16f6 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/EntryAndMetadata.java\n@@ -55,6 +55,9 @@ public byte[] getStickyKey() {\n                 return metadata.getOrderingKey();\n             } else if (metadata.hasPartitionKey()) {\n                 return metadata.getPartitionKey().getBytes(StandardCharsets.UTF_8);\n+            } else if (metadata.hasProducerName() && metadata.hasSequenceId()) {\n+                String fallbackKey = metadata.getProducerName() + \"-\" + metadata.getSequenceId();\n+                return fallbackKey.getBytes(StandardCharsets.UTF_8);\n             }\n         }\n         return \"NONE_KEY\".getBytes(StandardCharsets.UTF_8);\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\nindex 9748a42f0cb2b..b8e222a5b976c 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBase.java\n@@ -1186,11 +1186,13 @@ protected void callMessageListener(Message<T> msg) {\n     static final byte[] NONE_KEY = \"NONE_KEY\".getBytes(StandardCharsets.UTF_8);\n     protected byte[] peekMessageKey(Message<?> msg) {\n         byte[] key = NONE_KEY;\n-        if (msg.hasKey()) {\n-            key = msg.getKeyBytes();\n-        }\n         if (msg.hasOrderingKey()) {\n             key = msg.getOrderingKey();\n+        } else if (msg.hasKey()) {\n+            key = msg.getKeyBytes();\n+        } else if (msg.getProducerName() != null) {\n+            String fallbackKey = msg.getProducerName() + \"-\" + msg.getSequenceId();\n+            key = fallbackKey.getBytes(StandardCharsets.UTF_8);\n         }\n         return key;\n     }\n\ndiff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java b/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\nindex 224e093baf112..000d2f258fa4f 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java\n@@ -1979,6 +1979,9 @@ public static byte[] peekStickyKey(ByteBuf metadataAndPayload, String topic, Str\n                     return Base64.getDecoder().decode(metadata.getPartitionKey());\n                 }\n                 return metadata.getPartitionKey().getBytes(StandardCharsets.UTF_8);\n+            } else if (metadata.hasProducerName() && metadata.hasSequenceId()) {\n+                String fallbackKey = metadata.getProducerName() + \"-\" + metadata.getSequenceId();\n+                return fallbackKey.getBytes(StandardCharsets.UTF_8);\n             }\n         } catch (Throwable t) {\n             log.error(\"[{}] [{}] Failed to peek sticky key from the message metadata\", topic, subscription, t);\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\nindex e8fd537831673..059866bf8d035 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/KeySharedSubscriptionTest.java\n@@ -40,6 +40,7 @@\n import java.util.LinkedHashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Optional;\n import java.util.Random;\n import java.util.Set;\n@@ -327,11 +328,11 @@ public void testConsumerCrashSendAndReceiveWithHashRangeAutoSplitStickyKeyConsum\n     }\n \n     @Test(dataProvider = \"data\")\n-    public void testNonKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelector(\n+    public void testNoKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelector(\n         String topicType,\n         boolean enableBatch\n     ) throws PulsarClientException {\n-        String topic = topicType + \"://public/default/key_shared_none_key-\" + UUID.randomUUID();\n+        String topic = topicType + \"://public/default/key_shared_no_key-\" + UUID.randomUUID();\n \n         @Cleanup\n         Consumer<Integer> consumer1 = createConsumer(topic);\n@@ -351,13 +352,13 @@ public void testNonKeySendAndReceiveWithHashRangeAutoSplitStickyKeyConsumerSelec\n                     .send();\n         }\n \n-        receive(Lists.newArrayList(consumer1, consumer2, consumer3));\n+        receiveAndCheckDistribution(Lists.newArrayList(consumer1, consumer2, consumer3), 100);\n     }\n \n     @Test(dataProvider = \"batch\")\n-    public void testNonKeySendAndReceiveWithHashRangeExclusiveStickyKeyConsumerSelector(boolean enableBatch)\n+    public void testNoKeySendAndReceiveWithHashRangeExclusiveStickyKeyConsumerSelector(boolean enableBatch)\n             throws PulsarClientException {\n-        String topic = \"persistent://public/default/key_shared_none_key_exclusive-\" + UUID.randomUUID();\n+        String topic = \"persistent://public/default/key_shared_no_key_exclusive-\" + UUID.randomUUID();\n \n         @Cleanup\n         Consumer<Integer> consumer1 = createConsumer(topic, KeySharedPolicy.stickyHashRange()\n@@ -374,21 +375,32 @@ public void testNonKeySendAndReceiveWithHashRangeExclusiveStickyKeyConsumerSelec\n         @Cleanup\n         Producer<Integer> producer = createProducer(topic, enableBatch);\n \n+        int consumer1ExpectMessages = 0;\n+        int consumer2ExpectMessages = 0;\n+        int consumer3ExpectMessages = 0;\n+\n         for (int i = 0; i < 100; i++) {\n             producer.newMessage()\n                     .value(i)\n                     .send();\n+\n+            String fallbackKey = producer.getProducerName() + \"-\" + producer.getLastSequenceId();\n+            int slot = Murmur3_32Hash.getInstance().makeHash(fallbackKey.getBytes())\n+                    % KeySharedPolicy.DEFAULT_HASH_RANGE_SIZE;\n+            if (slot <= 20000) {\n+                consumer1ExpectMessages++;\n+            } else if (slot <= 40000) {\n+                consumer2ExpectMessages++;\n+            } else {\n+                consumer3ExpectMessages++;\n+            }\n         }\n-        int slot = Murmur3_32Hash.getInstance().makeHash(\"NONE_KEY\".getBytes())\n-                % KeySharedPolicy.DEFAULT_HASH_RANGE_SIZE;\n+\n         List<KeyValue<Consumer<Integer>, Integer>> checkList = new ArrayList<>();\n-        if (slot <= 20000) {\n-            checkList.add(new KeyValue<>(consumer1, 100));\n-        } else if (slot <= 40000) {\n-            checkList.add(new KeyValue<>(consumer2, 100));\n-        } else {\n-            checkList.add(new KeyValue<>(consumer3, 100));\n-        }\n+        checkList.add(new KeyValue<>(consumer1, consumer1ExpectMessages));\n+        checkList.add(new KeyValue<>(consumer2, consumer2ExpectMessages));\n+        checkList.add(new KeyValue<>(consumer3, consumer3ExpectMessages));\n+\n         receiveAndCheck(checkList);\n     }\n \n@@ -1725,19 +1737,17 @@ private void receiveAndCheckDistribution(List<Consumer<?>> consumers, int expect\n     private void receiveAndCheck(List<KeyValue<Consumer<Integer>, Integer>> checkList) throws PulsarClientException {\n         Map<Consumer, Set<String>> consumerKeys = new HashMap<>();\n         for (KeyValue<Consumer<Integer>, Integer> check : checkList) {\n-            if (check.getValue() % 2 != 0) {\n-                throw new IllegalArgumentException();\n-            }\n+            Consumer<Integer> consumer = check.getKey();\n             int received = 0;\n             Map<String, Message<Integer>> lastMessageForKey = new HashMap<>();\n             for (Integer i = 0; i < check.getValue(); i++) {\n-                Message<Integer> message = check.getKey().receive();\n+                Message<Integer> message = consumer.receive();\n                 if (i % 2 == 0) {\n-                    check.getKey().acknowledge(message);\n+                    consumer.acknowledge(message);\n                 }\n                 String key = message.hasOrderingKey() ? new String(message.getOrderingKey()) : message.getKey();\n                 log.info(\"[{}] Receive message key: {} value: {} messageId: {}\",\n-                    check.getKey().getConsumerName(), key, message.getValue(), message.getMessageId());\n+                        consumer.getConsumerName(), key, message.getValue(), message.getMessageId());\n                 // check messages is order by key\n                 if (lastMessageForKey.get(key) == null) {\n                     Assert.assertNotNull(message);\n@@ -1746,8 +1756,8 @@ private void receiveAndCheck(List<KeyValue<Consumer<Integer>, Integer>> checkLis\n                         .compareTo(lastMessageForKey.get(key).getValue()) > 0);\n                 }\n                 lastMessageForKey.put(key, message);\n-                consumerKeys.putIfAbsent(check.getKey(), new HashSet<>());\n-                consumerKeys.get(check.getKey()).add(key);\n+                consumerKeys.putIfAbsent(consumer, new HashSet<>());\n+                consumerKeys.get(consumer).add(key);\n                 received++;\n             }\n             Assert.assertEquals(check.getValue().intValue(), received);\n@@ -1756,12 +1766,12 @@ private void receiveAndCheck(List<KeyValue<Consumer<Integer>, Integer>> checkLis\n             // messages not acked, test redelivery\n             lastMessageForKey = new HashMap<>();\n             for (int i = 0; i < redeliveryCount; i++) {\n-                Message<Integer> message = check.getKey().receive();\n+                Message<Integer> message = consumer.receive();\n                 received++;\n-                check.getKey().acknowledge(message);\n+                consumer.acknowledge(message);\n                 String key = message.hasOrderingKey() ? new String(message.getOrderingKey()) : message.getKey();\n                 log.info(\"[{}] Receive redeliver message key: {} value: {} messageId: {}\",\n-                        check.getKey().getConsumerName(), key, message.getValue(), message.getMessageId());\n+                        consumer.getConsumerName(), key, message.getValue(), message.getMessageId());\n                 // check redelivery messages is order by key\n                 if (lastMessageForKey.get(key) == null) {\n                     Assert.assertNotNull(message);\n@@ -1773,16 +1783,16 @@ private void receiveAndCheck(List<KeyValue<Consumer<Integer>, Integer>> checkLis\n             }\n             Message noMessages = null;\n             try {\n-                noMessages = check.getKey().receive(100, TimeUnit.MILLISECONDS);\n+                noMessages = consumer.receive(100, TimeUnit.MILLISECONDS);\n             } catch (PulsarClientException ignore) {\n             }\n             Assert.assertNull(noMessages, \"redeliver too many messages.\");\n             Assert.assertEquals((check.getValue() + redeliveryCount), received);\n         }\n         Set<String> allKeys = new HashSet<>();\n-        consumerKeys.forEach((k, v) -> v.forEach(key -> {\n+        consumerKeys.forEach((k, v) -> v.stream().filter(Objects::nonNull).forEach(key -> {\n             assertTrue(allKeys.add(key),\n-                \"Key \"+ key +  \"is distributed to multiple consumers.\" );\n+                \"Key \" + key + \" is distributed to multiple consumers.\" );\n         }));\n     }\n \n\ndiff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java\nindex 42f1a58100283..a1f79b7ae7faf 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/compression/CommandsTest.java\n@@ -98,9 +98,11 @@ private int computeChecksum(MessageMetadata msgMetadata, ByteBuf compressedPaylo\n     public void testPeekStickyKey() {\n         String message = \"msg-1\";\n         String partitionedKey = \"key1\";\n+        String producerName = \"testProducer\";\n+        int sequenceId = 1;\n         MessageMetadata messageMetadata2 = new MessageMetadata()\n-                .setSequenceId(1)\n-                .setProducerName(\"testProducer\")\n+                .setSequenceId(sequenceId)\n+                .setProducerName(producerName)\n                 .setPartitionKey(partitionedKey)\n                 .setPartitionKeyB64Encoded(false)\n                 .setPublishTime(System.currentTimeMillis());\n@@ -113,16 +115,28 @@ public void testPeekStickyKey() {\n         // test 64 encoded\n         String partitionedKey2 = Base64.getEncoder().encodeToString(\"key2\".getBytes(UTF_8));\n         MessageMetadata messageMetadata = new MessageMetadata()\n-                .setSequenceId(1)\n-                .setProducerName(\"testProducer\")\n+                .setSequenceId(sequenceId)\n+                .setProducerName(producerName)\n                 .setPartitionKey(partitionedKey2)\n                 .setPartitionKeyB64Encoded(true)\n                 .setPublishTime(System.currentTimeMillis());\n         ByteBuf byteBuf2 = serializeMetadataAndPayload(Commands.ChecksumType.Crc32c, messageMetadata,\n                 Unpooled.copiedBuffer(message.getBytes(UTF_8)));\n         byte[] bytes2 = Commands.peekStickyKey(byteBuf2, \"topic-2\", \"sub-2\");\n-        String key2 = Base64.getEncoder().encodeToString(bytes2);;\n+        String key2 = Base64.getEncoder().encodeToString(bytes2);\n         Assert.assertEquals(partitionedKey2, key2);\n         ReferenceCountUtil.safeRelease(byteBuf2);\n+        // test fallback key if no key given in message metadata\n+        String fallbackPartitionedKey = producerName + \"-\" + sequenceId;\n+        MessageMetadata messageMetadataWithoutKey = new MessageMetadata()\n+                .setSequenceId(sequenceId)\n+                .setProducerName(producerName)\n+                .setPublishTime(System.currentTimeMillis());\n+        ByteBuf byteBuf3 = serializeMetadataAndPayload(Commands.ChecksumType.Crc32c, messageMetadataWithoutKey,\n+                Unpooled.copiedBuffer(message.getBytes(UTF_8)));\n+        byte[] bytes3 = Commands.peekStickyKey(byteBuf3, \"topic-3\", \"sub-3\");\n+        String key3 = new String(bytes3);\n+        Assert.assertEquals(fallbackPartitionedKey, key3);\n+        ReferenceCountUtil.safeRelease(byteBuf3);\n     }\n }\n\ndiff --git a/pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java b/pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java\nindex d0b25c6971697..519bed6cdb5ae 100644\n--- a/pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java\n+++ b/pulsar-testclient/src/test/java/org/apache/pulsar/testclient/PerformanceProducerTest.java\n@@ -98,26 +98,20 @@ public void testMsgKey() throws Exception {\n \n         thread.start();\n \n-        int count1 = 0;\n-        int count2 = 0;\n-        for (int i = 0; i < 10; i++) {\n-            Message<byte[]> message = consumer1.receive(1, TimeUnit.SECONDS);\n-            if (message == null) {\n-                break;\n-            }\n-            count1++;\n-            consumer1.acknowledge(message);\n-        }\n-        for (int i = 0; i < 10; i++) {\n-            Message<byte[]> message = consumer2.receive(1, TimeUnit.SECONDS);\n-            if (message == null) {\n-                break;\n-            }\n-            count2++;\n-            consumer2.acknowledge(message);\n-        }\n-        //in key_share mode, only one consumer can get msg\n-        Assert.assertTrue(count1 == 0 || count2 == 0);\n+        // in key_shared mode if no message key is set, both consumers should receive messages\n+        Awaitility.await()\n+                .untilAsserted(() -> {\n+                    Message<byte[]> message = consumer1.receive(1, TimeUnit.SECONDS);\n+                    assertNotNull(message);\n+                    consumer1.acknowledge(message);\n+                });\n+\n+        Awaitility.await()\n+                .untilAsserted(() -> {\n+                    Message<byte[]> message = consumer2.receive(1, TimeUnit.SECONDS);\n+                    assertNotNull(message);\n+                    consumer2.acknowledge(message);\n+                });\n \n         consumer1.close();\n         consumer2.close();\n@@ -149,19 +143,15 @@ public void testMsgKey() throws Exception {\n         Awaitility.await()\n                 .untilAsserted(() -> {\n                     Message<byte[]> message = newConsumer1.receive(1, TimeUnit.SECONDS);\n-                    if (message != null) {\n-                        newConsumer1.acknowledge(message);\n-                    }\n                     assertNotNull(message);\n+                    newConsumer1.acknowledge(message);\n                 });\n \n         Awaitility.await()\n                 .untilAsserted(() -> {\n                     Message<byte[]> message = newConsumer2.receive(1, TimeUnit.SECONDS);\n-                    if (message != null) {\n-                        newConsumer2.acknowledge(message);\n-                    }\n                     assertNotNull(message);\n+                    newConsumer2.acknowledge(message);\n                 });\n \n         thread2.interrupt();\n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java\nindex 0e7106ef65ea1..ddedacc531a7c 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/messaging/MessagingBase.java\n@@ -36,6 +36,7 @@\n import java.util.Iterator;\n import java.util.List;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n import java.util.concurrent.TimeUnit;\n \n@@ -150,11 +151,11 @@ protected String getPartitionedTopic(String topicPrefix, boolean isPersistent, i\n                 }\n             }\n         }\n-        // Make sure key will not be distributed to multiple consumers\n+        // Make sure key will not be distributed to multiple consumers (except null key)\n         Set<String> allKeys = Sets.newHashSet();\n-        consumerKeys.forEach((k, v) -> v.forEach(key -> {\n+        consumerKeys.forEach((k, v) -> v.stream().filter(Objects::nonNull).forEach(key -> {\n             assertTrue(allKeys.add(key),\n-                    \"Key \"+ key +  \"is distributed to multiple consumers\" );\n+                    \"Key \" + key + \" is distributed to multiple consumers\" );\n         }));\n         assertEquals(messagesReceived.size(), messagesToReceive);\n     }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23138",
    "pr_id": 23138,
    "issue_id": 23125,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] The Elected Leader Broker Thinks It's a Follower\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\npulsar-2.11\n\n### Minimal reproduce step\n\nIt is hard to simulate this case, but essentially it seems like this could happen when the zk cluster is unstable or slow.\r\n\n\n### What did you expect to see?\n\nEventually, when the zk cluster regains stability, all brokers should see the same leader, and the leader should play its role such as load shedding.\r\n\r\n\r\n\n\n### What did you see instead?\n\nThe elected leader broker continued to play the follower role Indefinitely, and hence no load shedding logic occurred.\r\n\r\n\r\nLog that the elected broker thinks it's a follower.\r\n\r\n[metadata-store-10-1] INFO  org.apache.pulsar.broker.PulsarService - This broker is a follower. Current leader is Optional[LeaderBroker(serviceUrl=http://xxx-broker-8.yyyy:8080/)]\txxx-broker-8\n\n### Anything else?\n\nPotentially this is the root cause of this issue, https://github.com/apache/pulsar/issues/16145\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 217,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/LeaderElectionImpl.java",
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java",
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java",
      "pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java"
    ],
    "base_commit": "8707fbe8351fb6ac4337fbd88d86eb32aff55b04",
    "head_commit": "f797af37f4a275edd265e9e6ff94411ebffe6c31",
    "repo_url": "https://github.com/apache/pulsar/pull/23138",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23138",
    "dockerfile": "",
    "pr_merged_at": "2024-08-08T08:19:38.000Z",
    "patch": "diff --git a/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/LeaderElectionImpl.java b/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/LeaderElectionImpl.java\nindex aa606084173e5..ab35eb7040c10 100644\n--- a/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/LeaderElectionImpl.java\n+++ b/pulsar-metadata/src/main/java/org/apache/pulsar/metadata/coordination/impl/LeaderElectionImpl.java\n@@ -134,8 +134,11 @@ private synchronized CompletableFuture<LeaderElectionState> handleExistingLeader\n             // If the value is the same as our proposed value, it means this instance was the leader at some\n             // point before. The existing value can either be for this same session or for a previous one.\n             if (res.getStat().isCreatedBySelf()) {\n+                log.info(\"Keeping the existing value {} for {} as it's from the same session stat={}\", existingValue,\n+                        path, res.getStat());\n                 // The value is still valid because it was created in the same session\n                 changeState(LeaderElectionState.Leading);\n+                return CompletableFuture.completedFuture(LeaderElectionState.Leading);\n             } else {\n                 log.info(\"Conditionally deleting existing equals value {} for {} because it's not created in the \"\n                         + \"current session. stat={}\", existingValue, path, res.getStat());\n@@ -271,7 +274,13 @@ public synchronized CompletableFuture<Void> asyncClose() {\n             return CompletableFuture.completedFuture(null);\n         }\n \n-        return store.delete(path, version);\n+        return store.delete(path, version)\n+                .thenAccept(__ -> {\n+                            synchronized (LeaderElectionImpl.this) {\n+                                leaderElectionState = LeaderElectionState.NoLeader;\n+                            }\n+                        }\n+                );\n     }\n \n     @Override\n@@ -292,8 +301,8 @@ public Optional<T> getLeaderValueIfPresent() {\n     private void handleSessionNotification(SessionEvent event) {\n         // Ensure we're only processing one session event at a time.\n         sequencer.sequential(() -> FutureUtil.composeAsync(() -> {\n-            if (event == SessionEvent.SessionReestablished) {\n-                log.info(\"Revalidating leadership for {}\", path);\n+            if (event == SessionEvent.Reconnected || event == SessionEvent.SessionReestablished) {\n+                log.info(\"Revalidating leadership for {}, event:{}\", path, event);\n                 return elect().thenAccept(leaderState -> {\n                     log.info(\"Resynced leadership for {} - State: {}\", path, leaderState);\n                 }).exceptionally(ex -> {\n",
    "test_patch": "diff --git a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java\nindex 6b4f74a30b563..4b48f3c20b02b 100644\n--- a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java\n+++ b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/LeaderElectionTest.java\n@@ -69,6 +69,8 @@ public void basicTest(String provider, Supplier<String> urlSupplier) throws Exce\n \n         leaderElection.close();\n \n+        assertEquals(leaderElection.getState(), LeaderElectionState.NoLeader);\n+\n         assertEquals(cache.get(\"/my/leader-election\").join(), Optional.empty());\n     }\n \n\ndiff --git a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java\nindex 36cb0f132ba58..02d65fd21ed5c 100644\n--- a/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java\n+++ b/pulsar-metadata/src/test/java/org/apache/pulsar/metadata/ZKSessionTest.java\n@@ -27,6 +27,7 @@\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.TimeUnit;\n import lombok.Cleanup;\n+import org.apache.commons.lang3.reflect.FieldUtils;\n import org.apache.pulsar.metadata.api.MetadataStoreConfig;\n import org.apache.pulsar.metadata.api.coordination.CoordinationService;\n import org.apache.pulsar.metadata.api.coordination.LeaderElection;\n@@ -180,4 +181,58 @@ public void testReacquireLeadershipAfterSessionLost() throws Exception {\n                 .untilAsserted(()-> assertEquals(le1.getState(),LeaderElectionState.Leading));\n         assertTrue(store.get(path).join().isPresent());\n     }\n+\n+\n+    @Test\n+    public void testElectAfterReconnected() throws Exception {\n+        //  ---  init\n+        @Cleanup\n+        MetadataStoreExtended store = MetadataStoreExtended.create(zks.getConnectionString(),\n+                MetadataStoreConfig.builder()\n+                        .sessionTimeoutMillis(2_000)\n+                        .build());\n+\n+\n+        BlockingQueue<SessionEvent> sessionEvents = new LinkedBlockingQueue<>();\n+        store.registerSessionListener(sessionEvents::add);\n+        BlockingQueue<LeaderElectionState> leaderElectionEvents = new LinkedBlockingQueue<>();\n+        String path = newKey();\n+\n+        @Cleanup\n+        CoordinationService coordinationService = new CoordinationServiceImpl(store);\n+        @Cleanup\n+        LeaderElection<String> le1 = coordinationService.getLeaderElection(String.class, path,\n+                leaderElectionEvents::add);\n+\n+        // --- test manual elect\n+        String proposed = \"value-1\";\n+        le1.elect(proposed).join();\n+        assertEquals(le1.getState(), LeaderElectionState.Leading);\n+        LeaderElectionState les = leaderElectionEvents.poll(5, TimeUnit.SECONDS);\n+        assertEquals(les, LeaderElectionState.Leading);\n+\n+\n+        // simulate no leader state\n+        FieldUtils.writeDeclaredField(le1, \"leaderElectionState\", LeaderElectionState.NoLeader, true);\n+\n+        // reconnect\n+        zks.stop();\n+\n+        SessionEvent e = sessionEvents.poll(5, TimeUnit.SECONDS);\n+        assertEquals(e, SessionEvent.ConnectionLost);\n+\n+        zks.start();\n+\n+\n+        // --- test  le1 can be leader\n+        e = sessionEvents.poll(10, TimeUnit.SECONDS);\n+        assertEquals(e, SessionEvent.Reconnected);\n+        Awaitility.await().atMost(Duration.ofSeconds(15))\n+                .untilAsserted(()-> {\n+                    assertEquals(le1.getState(),LeaderElectionState.Leading);\n+                }); // reacquire leadership\n+\n+\n+        assertTrue(store.get(path).join().isPresent());\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23128",
    "pr_id": 23128,
    "issue_id": 23127,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Pulsar Admin client will timeout requests with the read timeout value and retry in the background up to 5 times\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nSince Pulsar version 2.6.0 (#6547 changes)\n\n### Minimal reproduce step\n\nBy default, the read timeout is 60000 ms. If a request takes longer than the read timeout, the client will keep on retrying the request in the background up to 5 times by default. \r\n\n\n### What did you expect to see?\n\nThe read timeout shouldn't be used as the request timeout. The client shouldn't do retries in the background when the timeout occurs.\n\n### What did you see instead?\n\nThe read timeout is used as the request timeout. A read timeout is supposed to handle the case where the client doesn't receive any data and the connection is idle for more than the read timeout value.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 209,
    "test_files_count": 2,
    "non_test_files_count": 23,
    "pr_changed_files": [
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BaseResource.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BookiesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokerStatsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokersImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ClustersImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ComponentResource.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NamespacesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NonPersistentTopicsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ProxyStatsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceGroupsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceQuotasImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SchemasImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TenantsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TopicsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TransactionsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/WorkerImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java",
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java",
      "pulsar-client-admin/src/test/resources/log4j2.xml",
      "pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdBase.java"
    ],
    "pr_changed_test_files": [
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java",
      "pulsar-client-admin/src/test/resources/log4j2.xml"
    ],
    "base_commit": "4a44f45783772780000878cdddbdc2aefd08bcfe",
    "head_commit": "f2ae67bb3dd6daf70ac50651b748fb95dffb1b7a",
    "repo_url": "https://github.com/apache/pulsar/pull/23128",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23128",
    "dockerfile": "",
    "pr_merged_at": "2024-08-07T05:22:25.000Z",
    "patch": "diff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BaseResource.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BaseResource.java\nindex 22550666cb698..ea39053c2ceeb 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BaseResource.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BaseResource.java\n@@ -62,11 +62,11 @@ public abstract class BaseResource {\n     private static final Logger log = LoggerFactory.getLogger(BaseResource.class);\n \n     protected final Authentication auth;\n-    protected final long readTimeoutMs;\n+    protected final long requestTimeoutMs;\n \n-    protected BaseResource(Authentication auth, long readTimeoutMs) {\n+    protected BaseResource(Authentication auth, long requestTimeoutMs) {\n         this.auth = auth;\n-        this.readTimeoutMs = readTimeoutMs;\n+        this.requestTimeoutMs = requestTimeoutMs;\n     }\n \n     public Builder request(final WebTarget target) throws PulsarAdminException {\n@@ -339,7 +339,7 @@ public static String getReasonFromServer(WebApplicationException e) {\n \n     protected <T> T sync(Supplier<CompletableFuture<T>> executor) throws PulsarAdminException {\n         try {\n-            return executor.get().get(this.readTimeoutMs, TimeUnit.MILLISECONDS);\n+            return executor.get().get(this.requestTimeoutMs, TimeUnit.MILLISECONDS);\n         } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n           throw new PulsarAdminException(e);\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BookiesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BookiesImpl.java\nindex 2286fb8c8a381..0bf92e0267791 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BookiesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BookiesImpl.java\n@@ -32,8 +32,8 @@\n public class BookiesImpl extends BaseResource implements Bookies {\n     private final WebTarget adminBookies;\n \n-    public BookiesImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public BookiesImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminBookies = web.path(\"/admin/v2/bookies\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokerStatsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokerStatsImpl.java\nindex e409d6f4492de..6ddabe9837ef9 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokerStatsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokerStatsImpl.java\n@@ -38,8 +38,8 @@ public class BrokerStatsImpl extends BaseResource implements BrokerStats {\n     private final WebTarget adminBrokerStats;\n     private final WebTarget adminV2BrokerStats;\n \n-    public BrokerStatsImpl(WebTarget target, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public BrokerStatsImpl(WebTarget target, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminBrokerStats = target.path(\"/admin/broker-stats\");\n         adminV2BrokerStats = target.path(\"/admin/v2/broker-stats\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokersImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokersImpl.java\nindex 7b4ebb1778d8e..b82c3fd0f414b 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokersImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/BrokersImpl.java\n@@ -37,8 +37,8 @@\n public class BrokersImpl extends BaseResource implements Brokers {\n     private final WebTarget adminBrokers;\n \n-    public BrokersImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public BrokersImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminBrokers = web.path(\"admin/v2/brokers\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ClustersImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ClustersImpl.java\nindex 231d4506d6173..24048ea3c0a41 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ClustersImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ClustersImpl.java\n@@ -47,8 +47,8 @@ public class ClustersImpl extends BaseResource implements Clusters {\n \n     private final WebTarget adminClusters;\n \n-    public ClustersImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public ClustersImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminClusters = web.path(\"/admin/v2/clusters\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ComponentResource.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ComponentResource.java\nindex 8beecff38975a..0301f0fc2ee2b 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ComponentResource.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ComponentResource.java\n@@ -37,8 +37,8 @@\n  */\n public class ComponentResource extends BaseResource {\n \n-    protected ComponentResource(Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    protected ComponentResource(Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n     }\n \n     public RequestBuilder addAuthHeaders(WebTarget target, RequestBuilder requestBuilder) throws PulsarAdminException {\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\nindex bb4cb0c1ef8ef..97c42e5c1a95a 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\n@@ -72,8 +72,8 @@ public class FunctionsImpl extends ComponentResource implements Functions {\n     private final WebTarget functions;\n     private final AsyncHttpClient asyncHttpClient;\n \n-    public FunctionsImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public FunctionsImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.functions = web.path(\"/admin/v3/functions\");\n         this.asyncHttpClient = asyncHttpClient;\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NamespacesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NamespacesImpl.java\nindex c7492a26ab324..7d41c7203d2c7 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NamespacesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NamespacesImpl.java\n@@ -64,8 +64,8 @@ public class NamespacesImpl extends BaseResource implements Namespaces {\n     private final WebTarget adminNamespaces;\n     private final WebTarget adminV2Namespaces;\n \n-    public NamespacesImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public NamespacesImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminNamespaces = web.path(\"/admin/namespaces\");\n         adminV2Namespaces = web.path(\"/admin/v2/namespaces\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NonPersistentTopicsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NonPersistentTopicsImpl.java\nindex 76727cd1e0fc4..e98d44fdc4a69 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NonPersistentTopicsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/NonPersistentTopicsImpl.java\n@@ -38,8 +38,8 @@ public class NonPersistentTopicsImpl extends BaseResource implements NonPersiste\n     private final WebTarget adminNonPersistentTopics;\n     private final WebTarget adminV2NonPersistentTopics;\n \n-    public NonPersistentTopicsImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public NonPersistentTopicsImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminNonPersistentTopics = web.path(\"/admin\");\n         adminV2NonPersistentTopics = web.path(\"/admin/v2\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\nindex 694c2160b0f80..d69bef448c12e 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\n@@ -57,8 +57,8 @@ public class PackagesImpl extends ComponentResource implements Packages {\n     private final WebTarget packages;\n     private final AsyncHttpClient httpClient;\n \n-    public PackagesImpl(WebTarget webTarget, Authentication auth, AsyncHttpClient client, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public PackagesImpl(WebTarget webTarget, Authentication auth, AsyncHttpClient client, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.httpClient = client;\n         this.packages = webTarget.path(\"/admin/v3/packages\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ProxyStatsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ProxyStatsImpl.java\nindex e98d9bf57b31e..7ed07a1a6ad54 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ProxyStatsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ProxyStatsImpl.java\n@@ -32,8 +32,8 @@ public class ProxyStatsImpl extends BaseResource implements ProxyStats {\n \n     private final WebTarget adminProxyStats;\n \n-    public ProxyStatsImpl(WebTarget target, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public ProxyStatsImpl(WebTarget target, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminProxyStats = target.path(\"/proxy-stats\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\nindex 39347850cf69c..e00caa6dbbca1 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\n@@ -159,29 +159,29 @@ public PulsarAdminImpl(String serviceUrl, ClientConfigurationData clientConfigDa\n                 Math.toIntExact(clientConfigData.getRequestTimeoutMs()),\n                 clientConfigData.getAutoCertRefreshSeconds());\n \n-        long readTimeoutMs = clientConfigData.getReadTimeoutMs();\n-        this.clusters = new ClustersImpl(root, auth, readTimeoutMs);\n-        this.brokers = new BrokersImpl(root, auth, readTimeoutMs);\n-        this.brokerStats = new BrokerStatsImpl(root, auth, readTimeoutMs);\n-        this.proxyStats = new ProxyStatsImpl(root, auth, readTimeoutMs);\n-        this.tenants = new TenantsImpl(root, auth, readTimeoutMs);\n-        this.resourcegroups = new ResourceGroupsImpl(root, auth, readTimeoutMs);\n-        this.properties = new TenantsImpl(root, auth, readTimeoutMs);\n-        this.namespaces = new NamespacesImpl(root, auth, readTimeoutMs);\n-        this.topics = new TopicsImpl(root, auth, readTimeoutMs);\n-        this.localTopicPolicies = new TopicPoliciesImpl(root, auth, readTimeoutMs, false);\n-        this.globalTopicPolicies = new TopicPoliciesImpl(root, auth, readTimeoutMs, true);\n-        this.nonPersistentTopics = new NonPersistentTopicsImpl(root, auth, readTimeoutMs);\n-        this.resourceQuotas = new ResourceQuotasImpl(root, auth, readTimeoutMs);\n-        this.lookups = new LookupImpl(root, auth, useTls, readTimeoutMs, topics);\n-        this.functions = new FunctionsImpl(root, auth, asyncHttpConnector.getHttpClient(), readTimeoutMs);\n-        this.sources = new SourcesImpl(root, auth, asyncHttpConnector.getHttpClient(), readTimeoutMs);\n-        this.sinks = new SinksImpl(root, auth, asyncHttpConnector.getHttpClient(), readTimeoutMs);\n-        this.worker = new WorkerImpl(root, auth, readTimeoutMs);\n-        this.schemas = new SchemasImpl(root, auth, readTimeoutMs);\n-        this.bookies = new BookiesImpl(root, auth, readTimeoutMs);\n-        this.packages = new PackagesImpl(root, auth, asyncHttpConnector.getHttpClient(), readTimeoutMs);\n-        this.transactions = new TransactionsImpl(root, auth, readTimeoutMs);\n+        long requestTimeoutMs = clientConfigData.getRequestTimeoutMs();\n+        this.clusters = new ClustersImpl(root, auth, requestTimeoutMs);\n+        this.brokers = new BrokersImpl(root, auth, requestTimeoutMs);\n+        this.brokerStats = new BrokerStatsImpl(root, auth, requestTimeoutMs);\n+        this.proxyStats = new ProxyStatsImpl(root, auth, requestTimeoutMs);\n+        this.tenants = new TenantsImpl(root, auth, requestTimeoutMs);\n+        this.resourcegroups = new ResourceGroupsImpl(root, auth, requestTimeoutMs);\n+        this.properties = new TenantsImpl(root, auth, requestTimeoutMs);\n+        this.namespaces = new NamespacesImpl(root, auth, requestTimeoutMs);\n+        this.topics = new TopicsImpl(root, auth, requestTimeoutMs);\n+        this.localTopicPolicies = new TopicPoliciesImpl(root, auth, requestTimeoutMs, false);\n+        this.globalTopicPolicies = new TopicPoliciesImpl(root, auth, requestTimeoutMs, true);\n+        this.nonPersistentTopics = new NonPersistentTopicsImpl(root, auth, requestTimeoutMs);\n+        this.resourceQuotas = new ResourceQuotasImpl(root, auth, requestTimeoutMs);\n+        this.lookups = new LookupImpl(root, auth, useTls, requestTimeoutMs, topics);\n+        this.functions = new FunctionsImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.sources = new SourcesImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.sinks = new SinksImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.worker = new WorkerImpl(root, auth, requestTimeoutMs);\n+        this.schemas = new SchemasImpl(root, auth, requestTimeoutMs);\n+        this.bookies = new BookiesImpl(root, auth, requestTimeoutMs);\n+        this.packages = new PackagesImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.transactions = new TransactionsImpl(root, auth, requestTimeoutMs);\n \n         if (originalCtxLoader != null) {\n             Thread.currentThread().setContextClassLoader(originalCtxLoader);\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceGroupsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceGroupsImpl.java\nindex a8cef60232fc0..4e7230eebd980 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceGroupsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceGroupsImpl.java\n@@ -32,8 +32,8 @@\n public class ResourceGroupsImpl extends BaseResource implements ResourceGroups {\n     private final WebTarget adminResourceGroups;\n \n-    public ResourceGroupsImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public ResourceGroupsImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminResourceGroups = web.path(\"/admin/v2/resourcegroups\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceQuotasImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceQuotasImpl.java\nindex 1e80c9eda94a5..68884d99448dd 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceQuotasImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/ResourceQuotasImpl.java\n@@ -33,8 +33,8 @@ public class ResourceQuotasImpl extends BaseResource implements ResourceQuotas {\n     private final WebTarget adminQuotas;\n     private final WebTarget adminV2Quotas;\n \n-    public ResourceQuotasImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public ResourceQuotasImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminQuotas = web.path(\"/admin/resource-quotas\");\n         adminV2Quotas = web.path(\"/admin/v2/resource-quotas\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SchemasImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SchemasImpl.java\nindex 593eb67fc0dc3..28b435ab5676b 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SchemasImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SchemasImpl.java\n@@ -46,8 +46,8 @@ public class SchemasImpl extends BaseResource implements Schemas {\n     private final WebTarget adminV2;\n     private final WebTarget adminV1;\n \n-    public SchemasImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public SchemasImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.adminV1 = web.path(\"/admin/schemas\");\n         this.adminV2 = web.path(\"/admin/v2/schemas\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\nindex c14f75ab36750..a30f51264cc2e 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\n@@ -53,8 +53,8 @@ public class SinksImpl extends ComponentResource implements Sinks, Sink {\n     private final WebTarget sink;\n     private final AsyncHttpClient asyncHttpClient;\n \n-    public SinksImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public SinksImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.sink = web.path(\"/admin/v3/sink\");\n         this.asyncHttpClient = asyncHttpClient;\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\nindex 6e5b84c7f0412..8821ed61ce5b8 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\n@@ -52,8 +52,8 @@ public class SourcesImpl extends ComponentResource implements Sources, Source {\n     private final WebTarget source;\n     private final AsyncHttpClient asyncHttpClient;\n \n-    public SourcesImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public SourcesImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.source = web.path(\"/admin/v3/source\");\n         this.asyncHttpClient = asyncHttpClient;\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TenantsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TenantsImpl.java\nindex 9b70e39ec4986..c12f3754b4a92 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TenantsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TenantsImpl.java\n@@ -34,8 +34,8 @@\n public class TenantsImpl extends BaseResource implements Tenants, Properties {\n     private final WebTarget adminTenants;\n \n-    public TenantsImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public TenantsImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminTenants = web.path(\"/admin/v2/tenants\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TopicsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TopicsImpl.java\nindex b7a8b87664075..9c4a6eef753de 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TopicsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TopicsImpl.java\n@@ -137,8 +137,8 @@ public class TopicsImpl extends BaseResource implements Topics {\n \n     public static final String PROPERTY_SHADOW_SOURCE_KEY = \"PULSAR.SHADOW_SOURCE\";\n \n-    public TopicsImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public TopicsImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminTopics = web.path(\"/admin\");\n         adminV2Topics = web.path(\"/admin/v2\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TransactionsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TransactionsImpl.java\nindex 460478787eb10..a0b9dd234d920 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TransactionsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/TransactionsImpl.java\n@@ -46,8 +46,8 @@\n public class TransactionsImpl extends BaseResource implements Transactions {\n     private final WebTarget adminV3Transactions;\n \n-    public TransactionsImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public TransactionsImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         adminV3Transactions = web.path(\"/admin/v3/transactions\");\n     }\n \n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/WorkerImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/WorkerImpl.java\nindex 60b1226d5817e..12a691edb08a2 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/WorkerImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/WorkerImpl.java\n@@ -40,8 +40,8 @@ public class WorkerImpl extends BaseResource implements Worker {\n     private final WebTarget workerStats;\n     private final WebTarget worker;\n \n-    public WorkerImpl(WebTarget web, Authentication auth, long readTimeoutMs) {\n-        super(auth, readTimeoutMs);\n+    public WorkerImpl(WebTarget web, Authentication auth, long requestTimeoutMs) {\n+        super(auth, requestTimeoutMs);\n         this.worker = web.path(\"/admin/v2/worker\");\n         this.workerStats = web.path(\"/admin/v2/worker-stats\");\n     }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\nindex 9ad0ce5029c47..a0569c391ad50 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\n@@ -35,7 +35,6 @@\n import java.util.concurrent.Future;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeoutException;\n-import java.util.function.Function;\n import java.util.function.Supplier;\n import javax.net.ssl.SSLContext;\n import javax.ws.rs.client.Client;\n@@ -59,6 +58,7 @@\n import org.asynchttpclient.BoundRequestBuilder;\n import org.asynchttpclient.DefaultAsyncHttpClient;\n import org.asynchttpclient.DefaultAsyncHttpClientConfig;\n+import org.asynchttpclient.ListenableFuture;\n import org.asynchttpclient.Request;\n import org.asynchttpclient.Response;\n import org.asynchttpclient.channel.DefaultKeepAliveStrategy;\n@@ -74,11 +74,11 @@\n  */\n @Slf4j\n public class AsyncHttpConnector implements Connector {\n-    private static final TimeoutException READ_TIMEOUT_EXCEPTION =\n-            FutureUtil.createTimeoutException(\"Read timeout\", AsyncHttpConnector.class, \"retryOrTimeout(...)\");\n+    private static final TimeoutException REQUEST_TIMEOUT_EXCEPTION =\n+            FutureUtil.createTimeoutException(\"Request timeout\", AsyncHttpConnector.class, \"retryOrTimeout(...)\");\n     @Getter\n     private final AsyncHttpClient httpClient;\n-    private final Duration readTimeout;\n+    private final Duration requestTimeout;\n     private final int maxRetries;\n     private final PulsarServiceNameResolver serviceNameResolver;\n     private final ScheduledExecutorService delayer = Executors.newScheduledThreadPool(1,\n@@ -185,7 +185,7 @@ public boolean keepAlive(InetSocketAddress remoteAddress, Request ahcRequest,\n             confBuilder.setDisableHttpsEndpointIdentificationAlgorithm(!conf.isTlsHostnameVerificationEnable());\n         }\n         httpClient = new DefaultAsyncHttpClient(confBuilder.build());\n-        this.readTimeout = Duration.ofMillis(readTimeoutMs);\n+        this.requestTimeout = requestTimeoutMs > 0 ? Duration.ofMillis(requestTimeoutMs) : null;\n         this.maxRetries = httpClient.getConfig().getMaxRequestRetry();\n     }\n \n@@ -264,9 +264,10 @@ public String getReasonPhrase() {\n     private CompletableFuture<Response> retryOrTimeOut(ClientRequest request) {\n         final CompletableFuture<Response> resultFuture = new CompletableFuture<>();\n         retryOperation(resultFuture, () -> oneShot(serviceNameResolver.resolveHost(), request), maxRetries);\n-        CompletableFuture<Response> timeoutAfter = FutureUtil.createFutureWithTimeout(readTimeout, delayer,\n-                () -> READ_TIMEOUT_EXCEPTION);\n-        return resultFuture.applyToEither(timeoutAfter, Function.identity());\n+        if (requestTimeout != null) {\n+            FutureUtil.addTimeoutHandling(resultFuture, requestTimeout, delayer, () -> REQUEST_TIMEOUT_EXCEPTION);\n+        }\n+        return resultFuture;\n     }\n \n     private <T> void retryOperation(\n@@ -285,11 +286,18 @@ private <T> void retryOperation(\n                                         new RetryException(\"Operation future was cancelled.\", throwable));\n                             } else {\n                                 if (retries > 0) {\n+                                    if (log.isDebugEnabled()) {\n+                                        log.debug(\"Retrying operation. Remaining retries: {}\", retries);\n+                                    }\n                                     retryOperation(\n                                             resultFuture,\n                                             operation,\n                                             retries - 1);\n                                 } else {\n+                                    if (log.isDebugEnabled()) {\n+                                        log.debug(\"Number of retries has been exhausted. Failing the operation.\",\n+                                                throwable);\n+                                    }\n                                     resultFuture.completeExceptionally(\n                                         new RetryException(\"Could not complete the operation. Number of retries \"\n                                             + \"has been exhausted. Failed reason: \" + throwable.getMessage(),\n@@ -315,7 +323,7 @@ public RetryException(String message, Throwable cause) {\n         }\n     }\n \n-    private CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequest request) {\n+    protected CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequest request) {\n         ClientRequest currentRequest = new ClientRequest(request);\n         URI newUri = replaceWithNew(host, currentRequest.getUri());\n         currentRequest.setUri(newUri);\n@@ -347,7 +355,16 @@ private CompletableFuture<Response> oneShot(InetSocketAddress host, ClientReques\n             builder.setHeader(HttpHeaders.ACCEPT_ENCODING, \"gzip\");\n         }\n \n-        return builder.execute().toCompletableFuture();\n+        ListenableFuture<Response> responseFuture = builder.execute();\n+        CompletableFuture<Response> completableFuture = responseFuture.toCompletableFuture();\n+        completableFuture.whenComplete((response, throwable) -> {\n+            if (throwable != null && (throwable instanceof CancellationException\n+                    || throwable instanceof TimeoutException)) {\n+                // abort the request if the future is cancelled or timed out\n+                responseFuture.abort(throwable);\n+            }\n+        });\n+        return completableFuture;\n     }\n \n     @Override\n\ndiff --git a/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdBase.java b/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdBase.java\nindex 07e8a8b5df63b..8ff7f1c31ce2a 100644\n--- a/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdBase.java\n+++ b/pulsar-client-tools/src/main/java/org/apache/pulsar/admin/cli/CmdBase.java\n@@ -37,10 +37,10 @@ public abstract class CmdBase {\n     private final Supplier<PulsarAdmin> adminSupplier;\n \n     /**\n-     * Default read timeout in milliseconds.\n-     * Used if not found from configuration data in {@link #getReadTimeoutMs()}\n+     * Default request timeout in milliseconds.\n+     * Used if not found from configuration data in {@link #getRequestTimeoutMs()}\n      */\n-    private static final long DEFAULT_READ_TIMEOUT_MILLIS = 60000;\n+    private static final long DEFAULT_REQUEST_TIMEOUT_MILLIS = 60000;\n \n     public CmdBase(String cmdName, Supplier<PulsarAdmin> adminSupplier) {\n         this.adminSupplier = adminSupplier;\n@@ -56,17 +56,17 @@ protected PulsarAdmin getAdmin() {\n         return adminSupplier.get();\n     }\n \n-    protected long getReadTimeoutMs() {\n+    protected long getRequestTimeoutMs() {\n         PulsarAdmin pulsarAdmin = getAdmin();\n         if (pulsarAdmin instanceof PulsarAdminImpl) {\n-            return ((PulsarAdminImpl) pulsarAdmin).getClientConfigData().getReadTimeoutMs();\n+            return ((PulsarAdminImpl) pulsarAdmin).getClientConfigData().getRequestTimeoutMs();\n         }\n-        return DEFAULT_READ_TIMEOUT_MILLIS;\n+        return DEFAULT_REQUEST_TIMEOUT_MILLIS;\n     }\n \n     protected <T> T sync(Supplier<CompletableFuture<T>> executor) throws PulsarAdminException {\n         try {\n-            return executor.get().get(getReadTimeoutMs(), TimeUnit.MILLISECONDS);\n+            return executor.get().get(getRequestTimeoutMs(), TimeUnit.MILLISECONDS);\n         } catch (InterruptedException e) {\n             Thread.currentThread().interrupt();\n             throw new PulsarAdminException(e);\n",
    "test_patch": "diff --git a/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java\nnew file mode 100644\nindex 0000000000000..dd3fb40ae9ab0\n--- /dev/null\n+++ b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java\n@@ -0,0 +1,140 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.client.admin.internal.http;\n+\n+import static com.github.tomakehurst.wiremock.client.WireMock.aResponse;\n+import static com.github.tomakehurst.wiremock.client.WireMock.get;\n+import static com.github.tomakehurst.wiremock.client.WireMock.urlEqualTo;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+import com.github.tomakehurst.wiremock.WireMockServer;\n+import com.github.tomakehurst.wiremock.core.WireMockConfiguration;\n+import com.github.tomakehurst.wiremock.stubbing.Scenario;\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.URI;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import lombok.Cleanup;\n+import org.apache.pulsar.client.impl.conf.ClientConfigurationData;\n+import org.asynchttpclient.Response;\n+import org.glassfish.jersey.client.ClientConfig;\n+import org.glassfish.jersey.client.ClientRequest;\n+import org.glassfish.jersey.client.ClientResponse;\n+import org.glassfish.jersey.client.JerseyClient;\n+import org.glassfish.jersey.client.JerseyClientBuilder;\n+import org.glassfish.jersey.client.spi.AsyncConnectorCallback;\n+import org.glassfish.jersey.internal.MapPropertiesDelegate;\n+import org.glassfish.jersey.internal.PropertiesDelegate;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+public class AsyncHttpConnectorTest {\n+    WireMockServer server;\n+\n+    @BeforeClass(alwaysRun = true)\n+    void beforeClass() throws IOException {\n+        server = new WireMockServer(WireMockConfiguration.wireMockConfig()\n+                .port(0));\n+        server.start();\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    void afterClass() {\n+        if (server != null) {\n+            server.stop();\n+        }\n+    }\n+\n+    static class TestClientRequest extends ClientRequest {\n+        public TestClientRequest(URI uri, ClientConfig clientConfig, PropertiesDelegate propertiesDelegate) {\n+            super(uri, clientConfig, propertiesDelegate);\n+        }\n+    }\n+\n+    @Test\n+    public void testShouldStopRetriesWhenTimeoutOccurs() throws IOException, ExecutionException, InterruptedException {\n+        server.stubFor(get(urlEqualTo(\"/admin/v2/clusters\"))\n+                .inScenario(\"once\")\n+                .whenScenarioStateIs(Scenario.STARTED)\n+                .willSetStateTo(\"next\")\n+                .willReturn(aResponse()\n+                        .withHeader(\"Content-Type\", \"application/json\")\n+                        .withBody(\"[\\\"test-cluster\\\"]\")));\n+\n+        server.stubFor(get(urlEqualTo(\"/admin/v2/clusters\"))\n+                        .inScenario(\"once\")\n+                        .whenScenarioStateIs(\"next\")\n+                        .willSetStateTo(\"retried\")\n+                .willReturn(aResponse().withStatus(500)));\n+\n+        ClientConfigurationData conf = new ClientConfigurationData();\n+        conf.setServiceUrl(\"http://localhost:\" + server.port());\n+\n+        int requestTimeout = 500;\n+\n+        @Cleanup(\"shutdownNow\")\n+        ScheduledExecutorService scheduledExecutor = Executors.newSingleThreadScheduledExecutor();\n+        Executor delayedExecutor = runnable -> {\n+            scheduledExecutor.schedule(runnable, requestTimeout, TimeUnit.MILLISECONDS);\n+        };\n+        @Cleanup\n+        AsyncHttpConnector connector = new AsyncHttpConnector(5000, requestTimeout,\n+                requestTimeout, 0, conf, false) {\n+            @Override\n+            protected CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequest request) {\n+                // delay the response to simulate a timeout\n+                return super.oneShot(host, request)\n+                        .thenApplyAsync(response -> {\n+                            return response;\n+                        }, delayedExecutor);\n+            }\n+        };\n+\n+        JerseyClient jerseyClient = JerseyClientBuilder.createClient();\n+        ClientConfig clientConfig = jerseyClient.getConfiguration();\n+        PropertiesDelegate propertiesDelegate = new MapPropertiesDelegate();\n+        URI requestUri = URI.create(\"http://localhost:\" + server.port() + \"/admin/v2/clusters\");\n+        ClientRequest request = new TestClientRequest(requestUri, clientConfig, propertiesDelegate);\n+        request.setMethod(\"GET\");\n+        CompletableFuture<ClientResponse> future = new CompletableFuture<>();\n+        connector.apply(request, new AsyncConnectorCallback() {\n+            @Override\n+            public void response(ClientResponse response) {\n+                future.complete(response);\n+            }\n+\n+            @Override\n+            public void failure(Throwable failure) {\n+                future.completeExceptionally(failure);\n+            }\n+        });\n+        Thread.sleep(2 * requestTimeout);\n+        String scenarioState =\n+                server.getAllScenarios().getScenarios().stream().filter(scenario -> \"once\".equals(scenario.getName()))\n+                        .findFirst().get().getState();\n+        assertEquals(scenarioState, \"next\");\n+        assertTrue(future.isCompletedExceptionally());\n+    }\n+}\n\\ No newline at end of file\n\ndiff --git a/pulsar-client-admin/src/test/resources/log4j2.xml b/pulsar-client-admin/src/test/resources/log4j2.xml\nnew file mode 100644\nindex 0000000000000..9b57b450ffa43\n--- /dev/null\n+++ b/pulsar-client-admin/src/test/resources/log4j2.xml\n@@ -0,0 +1,41 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\"\n+               xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+               xsi:schemaLocation=\"http://logging.apache.org/log4j/2.0/config https://logging.apache.org/log4j/2.0/log4j-core.xsd\">\n+  <Appenders>\n+    <!-- setting follow=\"true\" is required for using ConsoleCaptor to validate log messages -->\n+    <Console name=\"CONSOLE\" target=\"SYSTEM_OUT\" follow=\"true\">\n+      <PatternLayout pattern=\"%d{ISO8601} - %-5p - [%t:%c{1}] - %m%n\"/>\n+    </Console>\n+  </Appenders>\n+  <Loggers>\n+<!--    <Logger name=\"org.apache.pulsar.broker.service.persistent.PersistentTopic\" level=\"DEBUG\" additivity=\"false\">-->\n+<!--       <AppenderRef ref=\"CONSOLE\" />-->\n+<!--    </Logger>-->\n+\n+    <Root level=\"INFO\">\n+      <AppenderRef ref=\"CONSOLE\"/>\n+    </Root>\n+    <Logger name=\"org.apache.pulsar.client.admin\" level=\"DEBUG\" />\n+  </Loggers>\n+</Configuration>\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23100",
    "pr_id": 23100,
    "issue_id": 23092,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Breaking contract b/w 2.9 / 2.10 and 3.0 for ns-isolation-policy\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nPulsar: 3.0.5\r\nAdmin Client: 3.0.5\n\n### Minimal reproduce step\n\n- 2 clusters (cluster-1, cluster-2)\r\n- Tenant present in all clusters. (tenant1)\r\n- Namespace (tenant1/ns1) present in only one cluster (cluster-1)\r\n- When updating the ns-isolation-policy for cluster-2 with policy data as `tenant1/.*`, `setNamespaceIsolationPolicy()` fails. This serves usecases where other namespaces under this tenant should be a part of certain broker group. This used to work in 2.9.x and 2.10.x.\n\n### What did you expect to see?\n\n200 returned and setNamespaceIsolationPolicy() setting up the ns-isolation-policy correctly. This should not try to unload namespaces which are not present in current cluster.\n\n### What did you see instead?\n\nPR that introduced this change: https://github.com/apache/pulsar/pull/15527\r\n\r\n[Here](https://github.com/apache/pulsar/blob/fdeeba597d1689f858a0eec072441872ad33c0ed/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java#L737), set policy call tries to unload all matching namespaces (all bundles). There should be a check that namespace should be present in the current cluster.\n\n### Anything else?\n\nApart from the above issue, this way of unloading all the namespace bundles is very impactful (That will definitely lead to some amount of downtime). If some namespaces are already present in the correct broker group (as per ns isolation policy), then those namespace bundles should not be unloaded. For a broker group with many small namespaces, this will lead to timeouts and or even 5xx (when there are too many bundles unloaded). One of such scenario:\r\n\r\n```\r\njava.util.concurrent.CompletionException: org.apache.pulsar.client.admin.PulsarAdminException$ServerSideErrorException: \r\n --- An unexpected error occurred in the server ---\r\n\r\nMessage: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\r\n\r\nStacktrace:\r\n\r\njava.lang.IllegalStateException: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$11(NamespaceService.java:463)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptNow(CompletableFuture.java:757)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:735)\r\n\tat java.base/java.util.concurrent.CompletableFuture.thenAccept(CompletableFuture.java:2182)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$15(NamespaceService.java:448)\r\n\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.put(ConcurrentOpenHashMap.java:418)\r\n\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.computeIfAbsent(ConcurrentOpenHashMap.java:243)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.findBrokerServiceUrl(NamespaceService.java:444)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$internalGetWebServiceUrl$9(NamespaceService.java:314)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)\r\n\tat java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.internalGetWebServiceUrl(NamespaceService.java:296)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.getWebServiceUrlAsync(NamespaceService.java:277)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.isBundleOwnedByAnyBroker(PulsarWebResource.java:623)\r\n\tat org.apache.pulsar.broker.admin.impl.NamespacesBase.lambda$internalUnloadNamespaceBundleAsync$125(NamespacesBase.java:1052)\r\n\tat java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1150)\r\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$11(ZKMetadataStore.java:362)\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n\r\n\tat java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture$BiRelay.tryFire(CompletableFuture.java:1498) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147) ~[?:?]\r\n\tat org.apache.pulsar.client.admin.internal.BaseResource$1.completed(BaseResource.java:130) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat org.apache.pulsar.client.admin.internal.BaseResource$1.completed(BaseResource.java:126) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat org.glassfish.jersey.client.JerseyInvocation$1.completed(JerseyInvocation.java:861) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.ClientRuntime.processResponse(ClientRuntime.java:229) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.ClientRuntime.access$200(ClientRuntime.java:62) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.ClientRuntime$2.lambda$response$0(ClientRuntime.java:173) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:244) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:288) ~[org.glassfish.jersey.core-jersey-common-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.ClientRuntime$2.response(ClientRuntime.java:173) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.apache.pulsar.client.admin.internal.http.AsyncHttpConnector.lambda$apply$1(AsyncHttpConnector.java:254) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147) ~[?:?]\r\n\tat org.apache.pulsar.client.admin.internal.http.AsyncHttpConnector.lambda$retryOperation$4(AsyncHttpConnector.java:296) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510) ~[?:?]\r\n\tat java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147) ~[?:?]\r\n\tat org.asynchttpclient.netty.NettyResponseFuture.loadContent(NettyResponseFuture.java:222) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat org.asynchttpclient.netty.NettyResponseFuture.done(NettyResponseFuture.java:257) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat org.asynchttpclient.netty.handler.AsyncHttpClientHandler.finishUpdate(AsyncHttpClientHandler.java:241) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat org.asynchttpclient.netty.handler.HttpHandler.handleChunk(HttpHandler.java:114) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat org.asynchttpclient.netty.handler.HttpHandler.handleRead(HttpHandler.java:143) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat org.asynchttpclient.netty.handler.AsyncHttpClientHandler.channelRead(AsyncHttpClientHandler.java:78) ~[org.asynchttpclient-async-http-client-2.12.1.jar:?]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) ~[io.netty-netty-codec-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346) ~[io.netty-netty-codec-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318) ~[io.netty-netty-codec-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1407) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:918) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[io.netty-netty-transport-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:994) ~[io.netty-netty-common-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.netty-netty-common-4.1.111.Final.jar:4.1.111.Final]\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.netty-netty-common-4.1.111.Final.jar:4.1.111.Final]\r\n\tat java.lang.Thread.run(Thread.java:840) ~[?:?]\r\nCaused by: org.apache.pulsar.client.admin.PulsarAdminException$ServerSideErrorException: \r\n --- An unexpected error occurred in the server ---\r\n\r\nMessage: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\r\n\r\nStacktrace:\r\n\r\njava.lang.IllegalStateException: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$11(NamespaceService.java:463)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptNow(CompletableFuture.java:757)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:735)\r\n\tat java.base/java.util.concurrent.CompletableFuture.thenAccept(CompletableFuture.java:2182)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$15(NamespaceService.java:448)\r\n\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.put(ConcurrentOpenHashMap.java:418)\r\n\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.computeIfAbsent(ConcurrentOpenHashMap.java:243)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.findBrokerServiceUrl(NamespaceService.java:444)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$internalGetWebServiceUrl$9(NamespaceService.java:314)\r\n\tat java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)\r\n\tat java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.internalGetWebServiceUrl(NamespaceService.java:296)\r\n\tat org.apache.pulsar.broker.namespace.NamespaceService.getWebServiceUrlAsync(NamespaceService.java:277)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.isBundleOwnedByAnyBroker(PulsarWebResource.java:623)\r\n\tat org.apache.pulsar.broker.admin.impl.NamespacesBase.lambda$internalUnloadNamespaceBundleAsync$125(NamespacesBase.java:1052)\r\n\tat java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1150)\r\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\r\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\r\n\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$11(ZKMetadataStore.java:362)\r\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\r\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n\r\n\tat org.apache.pulsar.client.admin.internal.BaseResource.getApiException(BaseResource.java:272) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat org.apache.pulsar.client.admin.internal.BaseResource$1.failed(BaseResource.java:136) ~[org.apache.pulsar-pulsar-client-admin-original-3.0.6-SNAPSHOT.jar:3.0.6-SNAPSHOT]\r\n\tat org.glassfish.jersey.client.JerseyInvocation$1.failed(JerseyInvocation.java:882) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.JerseyInvocation$1.completed(JerseyInvocation.java:863) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\t... 53 more\r\nCaused by: javax.ws.rs.InternalServerErrorException: HTTP 500 {\"reason\":\"\\n --- An unexpected error occurred in the server ---\\n\\nMessage: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\\n\\nStacktrace:\\n\\njava.lang.IllegalStateException: Namespace bundle tenant1/ns1/0x1af286bc_0x21af286b is being unloaded\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$11(NamespaceService.java:463)\\n\\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptNow(CompletableFuture.java:757)\\n\\tat java.base/java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:735)\\n\\tat java.base/java.util.concurrent.CompletableFuture.thenAccept(CompletableFuture.java:2182)\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$findBrokerServiceUrl$15(NamespaceService.java:448)\\n\\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap$Section.put(ConcurrentOpenHashMap.java:418)\\n\\tat org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap.computeIfAbsent(ConcurrentOpenHashMap.java:243)\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.findBrokerServiceUrl(NamespaceService.java:444)\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.lambda$internalGetWebServiceUrl$9(NamespaceService.java:314)\\n\\tat java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)\\n\\tat java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.internalGetWebServiceUrl(NamespaceService.java:296)\\n\\tat org.apache.pulsar.broker.namespace.NamespaceService.getWebServiceUrlAsync(NamespaceService.java:277)\\n\\tat org.apache.pulsar.broker.web.PulsarWebResource.isBundleOwnedByAnyBroker(PulsarWebResource.java:623)\\n\\tat org.apache.pulsar.broker.admin.impl.NamespacesBase.lambda$internalUnloadNamespaceBundleAsync$125(NamespacesBase.java:1052)\\n\\tat java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1150)\\n\\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\\n\\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\\n\\tat org.apache.pulsar.metadata.impl.ZKMetadataStore.lambda$existsFromStore$11(ZKMetadataStore.java:362)\\n\\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\\n\\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\\n\\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\n\\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\"}\r\n\tat org.glassfish.jersey.client.JerseyInvocation.convertToException(JerseyInvocation.java:960) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.JerseyInvocation.access$700(JerseyInvocation.java:82) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\tat org.glassfish.jersey.client.JerseyInvocation$1.completed(JerseyInvocation.java:863) ~[org.glassfish.jersey.core-jersey-client-2.34.jar:?]\r\n\t... 53 more\r\n09:48:33.593 [AsyncHttpClient-48-2] INFO  org.eclipse.jetty.server.RequestLog - 10.65.158.154 - - [26/Jul/2024:09:48:31 +0000] \"PUT /admin/v2/namespaces/tenant1/ns1/unload HTTP/1.1\" 500 2957 \"-\" \"Pulsar-Java-v3.0.6-SNAPSHOT\" 1807\r\n09:48:33.593 [pulsar-web-39-4] INFO  org.eclipse.jetty.server.ConnectionLimit - Connection Limit(2048) cleared for [ServerConnector@6fa02932{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}]\r\n09:48:33.593 [pulsar-web-39-2-acceptor-0@5222da2b-ServerConnector@6fa02932{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}] INFO  org.eclipse.jetty.server.ConnectionLimit - Connection Limit(2048) reached for [ServerConnector@6fa02932{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}]\r\n```\n\n### Are you willing to submit a PR?\n\n- [x] I'm willing to submit a PR!",
    "issue_word_count": 2834,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiNamespaceIsolationMultiBrokersTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiNamespaceIsolationMultiBrokersTest.java"
    ],
    "base_commit": "6bbaec1f6b1cc09de42f14dccca1afd932c547d5",
    "head_commit": "13bf97a9242120186494292f21c0774bd57fd340",
    "repo_url": "https://github.com/apache/pulsar/pull/23100",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23100",
    "dockerfile": "",
    "pr_merged_at": "2024-07-31T06:09:41.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java\nindex 6eb324a63f341..4fe8a01e679da 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/admin/impl/ClustersBase.java\n@@ -33,8 +33,8 @@\n import java.util.Objects;\n import java.util.Optional;\n import java.util.concurrent.CompletableFuture;\n+import java.util.regex.Pattern;\n import java.util.stream.Collectors;\n-import java.util.stream.Stream;\n import javax.ws.rs.DELETE;\n import javax.ws.rs.GET;\n import javax.ws.rs.POST;\n@@ -723,8 +723,8 @@ public void setNamespaceIsolationPolicy(\n                 ).thenCompose(nsIsolationPolicies -> {\n                     nsIsolationPolicies.setPolicy(policyName, policyData);\n                     return namespaceIsolationPolicies()\n-                                    .setIsolationDataAsync(cluster, old -> nsIsolationPolicies.getPolicies());\n-                }).thenCompose(__ -> filterAndUnloadMatchedNamespaceAsync(policyData))\n+                            .setIsolationDataAsync(cluster, old -> nsIsolationPolicies.getPolicies());\n+                }).thenCompose(__ -> filterAndUnloadMatchedNamespaceAsync(cluster, policyData))\n                 .thenAccept(__ -> {\n                     log.info(\"[{}] Successful to update clusters/{}/namespaceIsolationPolicies/{}.\",\n                             clientAppId(), cluster, policyName);\n@@ -758,42 +758,53 @@ public void setNamespaceIsolationPolicy(\n     /**\n      * Get matched namespaces; call unload for each namespaces.\n      */\n-    private CompletableFuture<Void> filterAndUnloadMatchedNamespaceAsync(NamespaceIsolationDataImpl policyData) {\n+    private CompletableFuture<Void> filterAndUnloadMatchedNamespaceAsync(String cluster,\n+                                                                         NamespaceIsolationDataImpl policyData) {\n         PulsarAdmin adminClient;\n         try {\n             adminClient = pulsar().getAdminClient();\n         } catch (PulsarServerException e) {\n             return FutureUtil.failedFuture(e);\n         }\n-        return adminClient.tenants().getTenantsAsync()\n-                .thenCompose(tenants -> {\n-                    Stream<CompletableFuture<List<String>>> completableFutureStream = tenants.stream()\n-                            .map(tenant -> adminClient.namespaces().getNamespacesAsync(tenant));\n-                    return FutureUtil.waitForAll(completableFutureStream)\n-                            .thenApply(namespaces -> {\n-                                // if namespace match any policy regex, add it to ns list to be unload.\n-                                return namespaces.stream()\n-                                        .filter(namespaceName ->\n-                                                policyData.getNamespaces().stream().anyMatch(namespaceName::matches))\n-                                        .collect(Collectors.toList());\n-                            });\n-                }).thenCompose(shouldUnloadNamespaces -> {\n-                    if (CollectionUtils.isEmpty(shouldUnloadNamespaces)) {\n-                        return CompletableFuture.completedFuture(null);\n-                    }\n-                    List<CompletableFuture<Void>> futures = shouldUnloadNamespaces.stream()\n-                            .map(namespaceName -> adminClient.namespaces().unloadAsync(namespaceName))\n-                            .collect(Collectors.toList());\n-                    return FutureUtil.waitForAll(futures)\n-                            .thenAccept(__ -> {\n-                                try {\n-                                    // write load info to load manager to make the load happens fast\n-                                    pulsar().getLoadManager().get().writeLoadReportOnZookeeper(true);\n-                                } catch (Exception e) {\n-                                    log.warn(\"[{}] Failed to writeLoadReportOnZookeeper.\", clientAppId(), e);\n-                                }\n-                            });\n-                });\n+        // compile regex patterns once\n+        List<Pattern> namespacePatterns = policyData.getNamespaces().stream().map(Pattern::compile).toList();\n+        return adminClient.tenants().getTenantsAsync().thenCompose(tenants -> {\n+            List<CompletableFuture<List<String>>> filteredNamespacesForEachTenant = tenants.stream()\n+                    .map(tenant -> adminClient.namespaces().getNamespacesAsync(tenant).thenCompose(namespaces -> {\n+                        List<CompletableFuture<String>> namespaceNamesInCluster = namespaces.stream()\n+                                .filter(namespaceName -> namespacePatterns.stream()\n+                                        .anyMatch(pattern -> pattern.matcher(namespaceName).matches()))\n+                                .map(namespaceName -> adminClient.namespaces().getPoliciesAsync(namespaceName)\n+                                        .thenApply(policies -> policies.replication_clusters.contains(cluster)\n+                                                ? namespaceName : null))\n+                                .collect(Collectors.toList());\n+                        return FutureUtil.waitForAll(namespaceNamesInCluster).thenApply(\n+                                __ -> namespaceNamesInCluster.stream()\n+                                        .map(CompletableFuture::join)\n+                                        .filter(Objects::nonNull)\n+                                        .collect(Collectors.toList()));\n+                    })).toList();\n+            return FutureUtil.waitForAll(filteredNamespacesForEachTenant)\n+                    .thenApply(__ -> filteredNamespacesForEachTenant.stream()\n+                            .map(CompletableFuture::join)\n+                            .flatMap(List::stream)\n+                            .collect(Collectors.toList()));\n+        }).thenCompose(shouldUnloadNamespaces -> {\n+            if (CollectionUtils.isEmpty(shouldUnloadNamespaces)) {\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            List<CompletableFuture<Void>> futures = shouldUnloadNamespaces.stream()\n+                    .map(namespaceName -> adminClient.namespaces().unloadAsync(namespaceName))\n+                    .collect(Collectors.toList());\n+            return FutureUtil.waitForAll(futures).thenAccept(__ -> {\n+                try {\n+                    // write load info to load manager to make the load happens fast\n+                    pulsar().getLoadManager().get().writeLoadReportOnZookeeper(true);\n+                } catch (Exception e) {\n+                    log.warn(\"[{}] Failed to writeLoadReportOnZookeeper.\", clientAppId(), e);\n+                }\n+            });\n+        });\n     }\n \n     @DELETE\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiNamespaceIsolationMultiBrokersTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiNamespaceIsolationMultiBrokersTest.java\nnew file mode 100644\nindex 0000000000000..da7d95d677af8\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/admin/AdminApiNamespaceIsolationMultiBrokersTest.java\n@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.admin;\n+\n+import static org.testng.Assert.assertEquals;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.pulsar.broker.MultiBrokerBaseTest;\n+import org.apache.pulsar.client.admin.PulsarAdmin;\n+import org.apache.pulsar.common.policies.data.AutoFailoverPolicyData;\n+import org.apache.pulsar.common.policies.data.AutoFailoverPolicyType;\n+import org.apache.pulsar.common.policies.data.ClusterData;\n+import org.apache.pulsar.common.policies.data.NamespaceIsolationData;\n+import org.apache.pulsar.common.policies.data.TenantInfoImpl;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+/**\n+ * Test multi-broker admin api.\n+ */\n+@Slf4j\n+@Test(groups = \"broker-admin\")\n+public class AdminApiNamespaceIsolationMultiBrokersTest extends MultiBrokerBaseTest {\n+\n+    PulsarAdmin localAdmin;\n+    PulsarAdmin remoteAdmin;\n+\n+    @Override\n+    protected void doInitConf() throws Exception {\n+        super.doInitConf();\n+        this.conf.setManagedLedgerMaxEntriesPerLedger(10);\n+    }\n+\n+    @Override\n+    protected void onCleanup() {\n+        super.onCleanup();\n+    }\n+\n+    @BeforeClass\n+    public void setupClusters() throws Exception {\n+        localAdmin = getAllAdmins().get(1);\n+        remoteAdmin = getAllAdmins().get(2);\n+        String localBrokerWebService = additionalPulsarTestContexts.get(0).getPulsarService().getWebServiceAddress();\n+        String remoteBrokerWebService = additionalPulsarTestContexts.get(1).getPulsarService().getWebServiceAddress();\n+        localAdmin.clusters()\n+                .createCluster(\"cluster-1\", ClusterData.builder().serviceUrl(localBrokerWebService).build());\n+        remoteAdmin.clusters()\n+                .createCluster(\"cluster-2\", ClusterData.builder().serviceUrl(remoteBrokerWebService).build());\n+        TenantInfoImpl tenantInfo = new TenantInfoImpl(Set.of(\"\"), Set.of(\"test\", \"cluster-1\", \"cluster-2\"));\n+        localAdmin.tenants().createTenant(\"prop-ig\", tenantInfo);\n+        localAdmin.namespaces().createNamespace(\"prop-ig/ns1\", Set.of(\"test\", \"cluster-1\"));\n+    }\n+\n+    public void testNamespaceIsolationPolicyForReplNS() throws Exception {\n+\n+        // Verify that namespace is not present in cluster-2.\n+        Set<String> replicationClusters = localAdmin.namespaces().getPolicies(\"prop-ig/ns1\").replication_clusters;\n+        Assert.assertFalse(replicationClusters.contains(\"cluster-2\"));\n+\n+        // setup ns-isolation-policy in both the clusters.\n+        String policyName1 = \"policy-1\";\n+        Map<String, String> parameters1 = new HashMap<>();\n+        parameters1.put(\"min_limit\", \"1\");\n+        parameters1.put(\"usage_threshold\", \"100\");\n+        List<String> nsRegexList = new ArrayList<>(Arrays.asList(\"prop-ig/.*\"));\n+\n+        NamespaceIsolationData nsPolicyData1 = NamespaceIsolationData.builder()\n+                // \"prop-ig/ns1\" is present in test cluster, policy set on test2 should work\n+                .namespaces(nsRegexList)\n+                .primary(Collections.singletonList(\".*\"))\n+                .secondary(Collections.singletonList(\"\"))\n+                .autoFailoverPolicy(AutoFailoverPolicyData.builder()\n+                        .policyType(AutoFailoverPolicyType.min_available)\n+                        .parameters(parameters1)\n+                        .build())\n+                .build();\n+\n+        localAdmin.clusters().createNamespaceIsolationPolicy(\"test\", policyName1, nsPolicyData1);\n+        // verify policy is present in local cluster\n+        Map<String, ? extends NamespaceIsolationData> policiesMap =\n+                localAdmin.clusters().getNamespaceIsolationPolicies(\"test\");\n+        assertEquals(policiesMap.get(policyName1), nsPolicyData1);\n+\n+        remoteAdmin.clusters().createNamespaceIsolationPolicy(\"cluster-2\", policyName1, nsPolicyData1);\n+        // verify policy is present in remote cluster\n+        policiesMap = remoteAdmin.clusters().getNamespaceIsolationPolicies(\"cluster-2\");\n+        assertEquals(policiesMap.get(policyName1), nsPolicyData1);\n+\n+    }\n+\n+}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23005",
    "pr_id": 23005,
    "issue_id": 6108,
    "repo": "apache/pulsar",
    "problem_statement": "[doc] 404 error in pulsar io-use\n**Describe the bug**\r\n404 error in pulsar io-use.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to 'http://pulsar.apache.org/docs/en/io-use'\r\n2. Click on 'Use'\r\n3. Scroll down to 'reload'\r\n4.Click `here` link\r\n4. See error\r\n\r\n**Expected behavior**\r\nRight page is displayed.\r\n\r\n**Screenshots**\r\n![](https://user-images.githubusercontent.com/29513837/72782364-84c02a00-3c5e-11ea-991e-45b5b8543839.png)\r\n.\r\n\r\n**Desktop (please complete the following information):**\r\n - OS: [e.g. iOS]\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "issue_word_count": 91,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-opentelemetry/src/main/java/org/apache/pulsar/opentelemetry/OpenTelemetryService.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java"
    ],
    "pr_changed_test_files": [
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java"
    ],
    "base_commit": "8b7754f11f113af9d341a460795d0c7b8095f594",
    "head_commit": "aebc1324fa9db8c6308ae07b406ea3bcd7dcc604",
    "repo_url": "https://github.com/apache/pulsar/pull/23005",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23005",
    "dockerfile": "",
    "pr_merged_at": "2024-07-05T07:55:06.000Z",
    "patch": "diff --git a/pulsar-opentelemetry/src/main/java/org/apache/pulsar/opentelemetry/OpenTelemetryService.java b/pulsar-opentelemetry/src/main/java/org/apache/pulsar/opentelemetry/OpenTelemetryService.java\nindex b32d353eb5ae7..e6c6d95273e0e 100644\n--- a/pulsar-opentelemetry/src/main/java/org/apache/pulsar/opentelemetry/OpenTelemetryService.java\n+++ b/pulsar-opentelemetry/src/main/java/org/apache/pulsar/opentelemetry/OpenTelemetryService.java\n@@ -21,6 +21,7 @@\n import static com.google.common.base.Preconditions.checkArgument;\n import com.google.common.annotations.VisibleForTesting;\n import io.opentelemetry.api.OpenTelemetry;\n+import io.opentelemetry.exporter.prometheus.PrometheusHttpServer;\n import io.opentelemetry.instrumentation.runtimemetrics.java17.RuntimeMetrics;\n import io.opentelemetry.sdk.OpenTelemetrySdk;\n import io.opentelemetry.sdk.autoconfigure.AutoConfiguredOpenTelemetrySdk;\n@@ -97,6 +98,20 @@ public OpenTelemetryService(String clusterName,\n                     return resource.merge(resourceBuilder.build());\n                 });\n \n+        sdkBuilder.addMetricReaderCustomizer((metricReader, configProperties) -> {\n+            if (metricReader instanceof PrometheusHttpServer prometheusHttpServer) {\n+                // At this point, the server is already started. We need to close it and create a new one with the\n+                // correct resource attributes filter.\n+                prometheusHttpServer.close();\n+\n+                // Allow all resource attributes to be exposed.\n+                return prometheusHttpServer.toBuilder()\n+                        .setAllowedResourceAttributesFilter(s -> true)\n+                        .build();\n+            }\n+            return metricReader;\n+        });\n+\n         if (builderCustomizer != null) {\n             builderCustomizer.accept(sdkBuilder);\n         }\n",
    "test_patch": "diff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java\nindex 38afc1f127d18..31e600f3aa812 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/metrics/OpenTelemetrySanityTest.java\n@@ -18,6 +18,8 @@\n  */\n package org.apache.pulsar.tests.integration.metrics;\n \n+import static org.assertj.core.api.AssertionsForClassTypes.assertThat;\n+import static org.awaitility.Awaitility.waitAtMost;\n import java.util.Arrays;\n import java.util.HashMap;\n import java.util.List;\n@@ -37,7 +39,6 @@\n import org.apache.pulsar.tests.integration.topologies.PulsarCluster;\n import org.apache.pulsar.tests.integration.topologies.PulsarClusterSpec;\n import org.apache.pulsar.tests.integration.topologies.PulsarTestBase;\n-import org.awaitility.Awaitility;\n import org.testng.annotations.Test;\n \n public class OpenTelemetrySanityTest {\n@@ -71,17 +72,17 @@ public void testOpenTelemetryMetricsOtlpExport() throws Exception {\n         // TODO: Validate cluster name and service version are present once\n         // https://github.com/open-telemetry/opentelemetry-java/issues/6108 is solved.\n         var metricName = \"queueSize_ratio\"; // Sent automatically by the OpenTelemetry SDK.\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n             var metrics = getMetricsFromPrometheus(\n                     openTelemetryCollectorContainer, OpenTelemetryCollectorContainer.PROMETHEUS_EXPORTER_PORT);\n             return !metrics.findByNameAndLabels(metricName, \"job\", PulsarBrokerOpenTelemetry.SERVICE_NAME).isEmpty();\n         });\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n             var metrics = getMetricsFromPrometheus(\n                     openTelemetryCollectorContainer, OpenTelemetryCollectorContainer.PROMETHEUS_EXPORTER_PORT);\n             return !metrics.findByNameAndLabels(metricName, \"job\", PulsarProxyOpenTelemetry.SERVICE_NAME).isEmpty();\n         });\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n             var metrics = getMetricsFromPrometheus(\n                     openTelemetryCollectorContainer, OpenTelemetryCollectorContainer.PROMETHEUS_EXPORTER_PORT);\n             return !metrics.findByNameAndLabels(metricName, \"job\", PulsarWorkerOpenTelemetry.SERVICE_NAME).isEmpty();\n@@ -120,30 +121,34 @@ public void testOpenTelemetryMetricsPrometheusExport() throws Exception {\n         pulsarCluster.start();\n         pulsarCluster.setupFunctionWorkers(PulsarTestBase.randomName(), FunctionRuntimeType.PROCESS, 1);\n \n-        var metricName = \"target_info\"; // Sent automatically by the OpenTelemetry SDK.\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n-            var metrics = getMetricsFromPrometheus(pulsarCluster.getBroker(0), prometheusExporterPort);\n-            return !metrics.findByNameAndLabels(metricName,\n+        var targetInfoMetricName = \"target_info\"; // Sent automatically by the OpenTelemetry SDK.\n+        var cpuCountMetricName = \"jvm_cpu_count\"; // Configured by the OpenTelemetryService.\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).untilAsserted(() -> {\n+            var expectedMetrics = new String[] {targetInfoMetricName, cpuCountMetricName, \"pulsar_broker_topic_producer_count\"};\n+            var actualMetrics = getMetricsFromPrometheus(pulsarCluster.getBroker(0), prometheusExporterPort);\n+            assertThat(expectedMetrics).allMatch(expectedMetric -> !actualMetrics.findByNameAndLabels(expectedMetric,\n                     Pair.of(\"pulsar_cluster\", clusterName),\n                     Pair.of(\"service_name\", PulsarBrokerOpenTelemetry.SERVICE_NAME),\n                     Pair.of(\"service_version\", PulsarVersion.getVersion()),\n-                    Pair.of(\"host_name\", pulsarCluster.getBroker(0).getHostname())).isEmpty();\n+                    Pair.of(\"host_name\", pulsarCluster.getBroker(0).getHostname())).isEmpty());\n         });\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n-            var metrics = getMetricsFromPrometheus(pulsarCluster.getProxy(), prometheusExporterPort);\n-            return !metrics.findByNameAndLabels(metricName,\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).untilAsserted(() -> {\n+            var expectedMetrics = new String[] {targetInfoMetricName, cpuCountMetricName};\n+            var actualMetrics = getMetricsFromPrometheus(pulsarCluster.getProxy(), prometheusExporterPort);\n+            assertThat(expectedMetrics).allMatch(expectedMetric -> !actualMetrics.findByNameAndLabels(expectedMetric,\n                     Pair.of(\"pulsar_cluster\", clusterName),\n                     Pair.of(\"service_name\", PulsarProxyOpenTelemetry.SERVICE_NAME),\n                     Pair.of(\"service_version\", PulsarVersion.getVersion()),\n-                    Pair.of(\"host_name\", pulsarCluster.getProxy().getHostname())).isEmpty();\n+                    Pair.of(\"host_name\", pulsarCluster.getProxy().getHostname())).isEmpty());\n         });\n-        Awaitility.waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).until(() -> {\n-            var metrics = getMetricsFromPrometheus(pulsarCluster.getAnyWorker(), prometheusExporterPort);\n-            return !metrics.findByNameAndLabels(metricName,\n+        waitAtMost(90, TimeUnit.SECONDS).ignoreExceptions().pollInterval(1, TimeUnit.SECONDS).untilAsserted(() -> {\n+            var expectedMetrics = new String[] {targetInfoMetricName, cpuCountMetricName};\n+            var actualMetrics = getMetricsFromPrometheus(pulsarCluster.getAnyWorker(), prometheusExporterPort);\n+            assertThat(expectedMetrics).allMatch(expectedMetric -> !actualMetrics.findByNameAndLabels(expectedMetric,\n                     Pair.of(\"pulsar_cluster\", clusterName),\n                     Pair.of(\"service_name\", PulsarWorkerOpenTelemetry.SERVICE_NAME),\n                     Pair.of(\"service_version\", PulsarVersion.getVersion()),\n-                    Pair.of(\"host_name\", pulsarCluster.getAnyWorker().getHostname())).isEmpty();\n+                    Pair.of(\"host_name\", pulsarCluster.getAnyWorker().getHostname())).isEmpty());\n         });\n     }\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-23004",
    "pr_id": 23004,
    "issue_id": 23003,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug][broker] MessageDeduplication replay timeout would cause topic loading stuck and become unavailable\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nmaster \r\n\r\n### Minimal reproduce step\r\n\r\nenter this dead loop, and topic loading keep failed.\r\n1. topic load\r\n2. MessageDeduplication replay need much time\r\n3. topic load timeout\r\n4. topic close and reload\r\n\r\n### What did you expect to see?\r\n\r\ntopic become available\r\n\r\n### What did you see instead?\r\n\r\nThe issue's root is as following:\r\n\r\nhttps://github.com/apache/pulsar/pull/21540 , this pr modify that topic would be closed if 60s timeout.\r\n\r\nhttps://github.com/apache/pulsar/pull/22479, this pr add a logic that takeSnapshot after MessageDeduplication replay, so that topic loading won't timeout. \r\n\r\nhttps://github.com/apache/pulsar/pull/22860, this pr refactor the topic loading process. Now topic loading should not be concurrent. If topic loading would timeout, the loading process is sequentially \"create -> timeout -> close -> create\".\r\n\r\nHowever, topic loading is still stuck. The reason is if topic loading timeout, the topic would close. However, topic close and takeSnapshot is executed concurrently, so takeSnapshot may throw exception since topic has been closed. This would result in each time we retry loading topic, we need to replaying the same entries in MessageDeduplication, and we are always 60s timeout.\r\n\r\n\r\nThe error log is :\r\n```\r\n17:49:30.300 [broker-topic-workers-OrderedExecutor-6-0] INFO org.apache.pulsar.broker.service.persistent.MessageDeduplication - [persistent://test/test/test-partition-0] Replaying 2383098 entries for deduplication\r\n17:53:05.845 [BookKeeperClientWorker-OrderedExecutor-17-0] INFO org.apache.pulsar.broker.service.persistent.MessageDeduplication - [persistent://test/test/test-partition-0] Enabled deduplication\r\n17:53:05.886 [bookkeeper-ml-scheduler-OrderedScheduler-5-0] WARN org.apache.bookkeeper.mledger.impl.ManagedCursorImpl - [test/test/persistent/test-partition-0] Failed to update cursor metadata for pulsar.dedup due to version conflict org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/test/test/persistent/test-partition-0/pulsar.dedup\r\n17:53:05.908 [BookKeeperClientWorker-OrderedExecutor-6-0] WARN org.apache.pulsar.broker.service.persistent.MessageDeduplication - [persistent://test/test/test-partition-0] Failed to store new deduplication snapshot at 1033467:11005. ex: org.apache.bookkeeper.mledger.ManagedLedgerException$BadVersionException: org.apache.pulsar.metadata.api.MetadataStoreException$BadVersionException: org.apache.zookeeper.KeeperException$BadVersionException: KeeperErrorCode = BadVersion for /managed-ledgers/test/test/persistent/test-partition-0/pulsar.dedup\r\n\r\n\r\n17:53:05.974 [bookkeeper-ml-scheduler-OrderedScheduler-5-0] INFO org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl - [test/test/persistent/test-partition-0] Recovery for cursor pulsar.dedup completed. pos=1028289:2816218 -- todo=0\r\n17:53:05.975 [broker-topic-workers-OrderedExecutor-3-0] INFO org.apache.pulsar.broker.service.persistent.MessageDeduplication - [persistent://test/test/test-partition-0] Replaying 2383098 entries for deduplication\r\n17:56:06.764 [BookKeeperClientWorker-OrderedExecutor-19-0] WARN org.apache.pulsar.broker.service.persistent.MessageDeduplication - [persistent://test/test/test-partition-0] Failed to store new deduplication snapshot at 1033467:11005. ex: org.apache.bookkeeper.mledger.ManagedLedgerException$MetaStoreException: org.apache.bookkeeper.mledger.ManagedLedgerException$CursorAlreadyClosedException: pulsar.dedup cursor already closed\r\n``` \r\n\r\n\r\n\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 564,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java"
    ],
    "base_commit": "8b7754f11f113af9d341a460795d0c7b8095f594",
    "head_commit": "155e0c35e5fa64250b31807cbf63eed815682f80",
    "repo_url": "https://github.com/apache/pulsar/pull/23004",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/23004",
    "dockerfile": "",
    "pr_merged_at": "2024-07-05T22:26:29.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\nindex 9d970479400ba..a4879f2e9520a 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/MessageDeduplication.java\n@@ -159,11 +159,12 @@ private CompletableFuture<Void> recoverSequenceIdsMap() {\n         log.info(\"[{}] Replaying {} entries for deduplication\", topic.getName(), managedCursor.getNumberOfEntries());\n         CompletableFuture<Position> future = new CompletableFuture<>();\n         replayCursor(future);\n-        return future.thenAccept(lastPosition -> {\n+        return future.thenCompose(lastPosition -> {\n             if (lastPosition != null && snapshotCounter >= snapshotInterval) {\n                 snapshotCounter = 0;\n-                takeSnapshot(lastPosition);\n+                return takeSnapshot(lastPosition);\n             }\n+            return CompletableFuture.completedFuture(null);\n         });\n     }\n \n@@ -438,13 +439,15 @@ public void resetHighestSequenceIdPushed() {\n         }\n     }\n \n-    private void takeSnapshot(Position position) {\n+    private CompletableFuture<Void> takeSnapshot(Position position) {\n+        CompletableFuture<Void> future = new CompletableFuture<>();\n         if (log.isDebugEnabled()) {\n             log.debug(\"[{}] Taking snapshot of sequence ids map\", topic.getName());\n         }\n \n         if (!snapshotTaking.compareAndSet(false, true)) {\n-            return;\n+            future.complete(null);\n+            return future;\n         }\n \n         Map<String, Long> snapshot = new TreeMap<>();\n@@ -462,14 +465,17 @@ public void markDeleteComplete(Object ctx) {\n                 }\n                 lastSnapshotTimestamp = System.currentTimeMillis();\n                 snapshotTaking.set(false);\n+                future.complete(null);\n             }\n \n             @Override\n             public void markDeleteFailed(ManagedLedgerException exception, Object ctx) {\n                 log.warn(\"[{}] Failed to store new deduplication snapshot at {}\", topic.getName(), position);\n                 snapshotTaking.set(false);\n+                future.completeExceptionally(exception);\n             }\n         }, null);\n+        return future;\n     }\n \n     /**\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\nindex 2feaacd5b8209..ddc5eeab1d20e 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/TopicDuplicationTest.java\n@@ -18,6 +18,7 @@\n  */\n package org.apache.pulsar.broker.service.persistent;\n \n+import static org.apache.pulsar.broker.service.persistent.PersistentTopic.DEDUPLICATION_CURSOR_NAME;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertNotEquals;\n@@ -25,6 +26,8 @@\n import static org.testng.Assert.assertNull;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n+\n+import java.lang.reflect.Field;\n import java.util.Optional;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n@@ -33,12 +36,18 @@\n import lombok.Cleanup;\n import org.apache.bookkeeper.mledger.ManagedCursor;\n import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.impl.ManagedCursorImpl;\n+import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n+import org.apache.pulsar.broker.service.BrokerService;\n import org.apache.pulsar.broker.service.Topic;\n import org.apache.pulsar.client.api.Producer;\n import org.apache.pulsar.client.api.ProducerConsumerBase;\n import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.common.naming.TopicName;\n+import org.apache.pulsar.common.util.collections.ConcurrentOpenHashMap;\n import org.awaitility.Awaitility;\n+import org.awaitility.reflect.WhiteboxImpl;\n import org.testng.Assert;\n import org.testng.annotations.AfterMethod;\n import org.testng.annotations.BeforeMethod;\n@@ -529,6 +538,101 @@ public void testDisableNamespacePolicyTakeSnapshotShouldNotThrowException() thro\n         persistentTopic.checkDeduplicationSnapshot();\n     }\n \n+    @Test\n+    public void testFinishTakeSnapshotWhenTopicLoading() throws Exception {\n+        cleanup();\n+        setup();\n+\n+        // Create a topic and wait deduplication is started.\n+        int brokerDeduplicationEntriesInterval = 1000;\n+        pulsar.getConfiguration().setBrokerDeduplicationEnabled(true);\n+        pulsar.getConfiguration().setBrokerDeduplicationEntriesInterval(brokerDeduplicationEntriesInterval);\n+        final String topic = BrokerTestUtil.newUniqueName(\"persistent://public/default/tp\");\n+        admin.topics().createNonPartitionedTopic(topic);\n+        final PersistentTopic persistentTopic1 =\n+                (PersistentTopic) pulsar.getBrokerService().getTopic(topic, false).join().get();\n+        final ManagedLedgerImpl ml1 = (ManagedLedgerImpl) persistentTopic1.getManagedLedger();\n+        Awaitility.await().untilAsserted(() -> {\n+            ManagedCursorImpl cursor1 =\n+                    (ManagedCursorImpl) ml1.getCursors().get(PersistentTopic.DEDUPLICATION_CURSOR_NAME);\n+            assertNotNull(cursor1);\n+        });\n+        final MessageDeduplication deduplication1 = persistentTopic1.getMessageDeduplication();\n+\n+\n+        // Send 999 messages, it is less than \"brokerDeduplicationEntriesInterval\".\n+        // So it would not trigger takeSnapshot\n+        final Producer<String> producer = pulsarClient.newProducer(Schema.STRING)\n+                .topic(topic).enableBatching(false).create();\n+        for (int i = 0; i < brokerDeduplicationEntriesInterval - 1; i++) {\n+            producer.send(i + \"\");\n+        }\n+        producer.close();\n+        int snapshotCounter1 = WhiteboxImpl.getInternalState(deduplication1, \"snapshotCounter\");\n+        assertEquals(snapshotCounter1, brokerDeduplicationEntriesInterval - 1);\n+\n+\n+        // Unload and load topic, simulate topic load is timeout.\n+        // SetBrokerDeduplicationEntriesInterval to 10, therefore recoverSequenceIdsMap#takeSnapshot\n+        // would trigger and should update the snapshot position.\n+        // However, if topic close and takeSnapshot are concurrent,\n+        // it would result in takeSnapshot throw exception\n+        admin.topics().unload(topic);\n+        pulsar.getConfiguration().setBrokerDeduplicationEntriesInterval(10);\n+\n+        // Mock message deduplication recovery speed topicLoadTimeoutSeconds\n+        pulsar.getConfiguration().setTopicLoadTimeoutSeconds(1);\n+        String mlPath = BrokerService.MANAGED_LEDGER_PATH_ZNODE + \"/\" +\n+                TopicName.get(topic).getPersistenceNamingEncoding() + \"/\" + DEDUPLICATION_CURSOR_NAME;\n+        mockZooKeeper.delay(2 * 1000, (op, path) -> {\n+            if (mlPath.equals(path)) {\n+                return true;\n+            }\n+            return false;\n+        });\n+\n+        Field field2 = BrokerService.class.getDeclaredField(\"topics\");\n+        field2.setAccessible(true);\n+        ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>> topics =\n+                (ConcurrentOpenHashMap<String, CompletableFuture<Optional<Topic>>>)\n+                        field2.get(pulsar.getBrokerService());\n+\n+        try {\n+            pulsar.getBrokerService().getTopic(topic, false).join().get();\n+            Assert.fail();\n+        } catch (Exception e) {\n+            // topic loading should timeout.\n+        }\n+        Awaitility.await().untilAsserted(() -> {\n+            // topic loading timeout then close topic and remove from topicsMap\n+            Assert.assertFalse(topics.containsKey(topic));\n+        });\n+\n+\n+        // Load topic again, setBrokerDeduplicationEntriesInterval to 10000,\n+        // make recoverSequenceIdsMap#takeSnapshot not trigger takeSnapshot.\n+        // But actually it should not replay again in recoverSequenceIdsMap,\n+        // since previous topic loading should finish the replay process.\n+        pulsar.getConfiguration().setBrokerDeduplicationEntriesInterval(10000);\n+        pulsar.getConfiguration().setTopicLoadTimeoutSeconds(60);\n+        PersistentTopic persistentTopic2 =\n+                (PersistentTopic) pulsar.getBrokerService().getTopic(topic, false).join().get();\n+        ManagedLedgerImpl ml2 = (ManagedLedgerImpl) persistentTopic2.getManagedLedger();\n+        MessageDeduplication deduplication2 = persistentTopic2.getMessageDeduplication();\n+\n+        Awaitility.await().untilAsserted(() -> {\n+            int snapshotCounter3 = WhiteboxImpl.getInternalState(deduplication2, \"snapshotCounter\");\n+            Assert.assertEquals(snapshotCounter3, 0);\n+            Assert.assertEquals(ml2.getLedgersInfo().size(), 1);\n+        });\n+\n+\n+        // cleanup.\n+        admin.topics().delete(topic);\n+        cleanup();\n+        setup();\n+    }\n+\n     private void waitCacheInit(String topicName) throws Exception {\n         pulsarClient.newConsumer().topic(topicName).subscriptionName(\"my-sub\").subscribe().close();\n         TopicName topic = TopicName.get(topicName);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22998",
    "pr_id": 22998,
    "issue_id": 22995,
    "repo": "apache/pulsar",
    "problem_statement": "[master branch] failed-test: OpenTelemetrySanityTest.testOpenTelemetryMetricsOtlpExport\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Example failure\r\n\r\n- Test Master Branch: https://github.com/shibd/pulsar/actions/runs/9771102112/job/26973748574?pr=48\r\n  - Test PR: https://github.com/shibd/pulsar/pull/48\r\n- and: https://github.com/apache/pulsar/actions/runs/9760781448/job/26979018887?pr=22991\r\n\r\n### Exception stacktrace\r\n\r\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n2024-07-03T07:18:46.5933934Z [ERROR] Tests run: 3, Failures: 1, Errors: 0, Skipped: 2, Time elapsed: 510.27 s <<< FAILURE! - in TestSuite\r\n2024-07-03T07:18:46.5938249Z [ERROR] org.apache.pulsar.tests.integration.metrics.OpenTelemetrySanityTest.testOpenTelemetryMetricsOtlpExport  Time elapsed: 251.315 s  <<< FAILURE!\r\n2024-07-03T07:18:46.5941382Z org.awaitility.core.ConditionTimeoutException: Condition with org.apache.pulsar.tests.integration.metrics.OpenTelemetrySanityTest was not fulfilled within 1 minutes  30 seconds.\r\n2024-07-03T07:18:46.5943820Z \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n2024-07-03T07:18:46.5945262Z \tat org.awaitility.core.CallableCondition.await(CallableCondition.java:78)\r\n2024-07-03T07:18:46.5946790Z \tat org.awaitility.core.CallableCondition.await(CallableCondition.java:26)\r\n2024-07-03T07:18:46.5948214Z \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n2024-07-03T07:18:46.5949947Z \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:954)\r\n2024-07-03T07:18:46.5952425Z \tat org.apache.pulsar.tests.integration.metrics.OpenTelemetrySanityTest.testOpenTelemetryMetricsOtlpExport(OpenTelemetrySanityTest.java:74)\r\n2024-07-03T07:18:46.5954710Z \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n2024-07-03T07:18:46.5956107Z \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n2024-07-03T07:18:46.5957755Z \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n2024-07-03T07:18:46.5959183Z \tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n2024-07-03T07:18:46.5960450Z \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n2024-07-03T07:18:46.5962091Z \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n2024-07-03T07:18:46.5963587Z \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n2024-07-03T07:18:46.5965007Z \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n2024-07-03T07:18:46.5966244Z \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n2024-07-03T07:18:46.5967497Z \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n2024-07-03T07:18:46.5968792Z \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n2024-07-03T07:18:46.5969467Z \tat java.base/java.lang.Thread.run(Thread.java:840)\r\n2024-07-03T07:18:46.5969758Z \r\n```\r\n\r\nmaybe root cause log is:\r\n```\r\n2024-07-03T07:17:44.9011520Z 2024-07-03T07:17:44,006+0000 [pulsar-web-38-7] INFO  org.eclipse.jetty.server.RequestLog - 172.19.0.10 - - [03/Jul/2024:07:17:44 +0000] \"GET /admin/v2/persistent/public/functions/coordinate/stats?getPreciseBacklog=false&subscriptionBacklogSize=false&getEarliestTim\r\n2024-07-03T07:17:44.9014528Z 2024-07-03T07:17:44,805 - INFO  - [docker-java-stream--2146097482:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-0:tail -f /var/log/pulsar/broker.log): STDOUT: eInBacklog=false&excludePublishers=false&excludeConsumers=false HTTP/1.1\" 307 0 \"-\" \"Pulsar-Java-v3.4.0-SNAPSHOT\" 3\r\n2024-07-03T07:17:44.9016341Z Jul 03, 2024 7:17:44 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:17:44.9017526Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:17:47.8023898Z 2024-07-03T07:17:47,790 - INFO  - [docker-java-stream--1775748643:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-proxy:tail -f /var/log/pulsar/proxy.log): STDOUT: Jul 03, 2024 7:17:46 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:17:47.8026180Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:17:49.2035035Z 2024-07-03T07:17:49,176 - INFO  - [docker-java-stream-137418396:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-1:tail -f /var/log/pulsar/broker.log): STDOUT: Jul 03, 2024 7:17:48 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:17:49.2037493Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:17:57.8109310Z 2024-07-03T07:17:57,806 - INFO  - [docker-java-stream--2146097482:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-0:tail -f /var/log/pulsar/broker.log): STDOUT: Jul 03, 2024 7:17:57 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:17:57.8111871Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:17:59.8127874Z 2024-07-03T07:17:59,791 - INFO  - [docker-java-stream--1775748643:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-proxy:tail -f /var/log/pulsar/proxy.log): STDOUT: Jul 03, 2024 7:17:58 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:17:59.8132360Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:18:02.2147343Z 2024-07-03T07:18:02,177 - INFO  - [docker-java-stream-137418396:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-1:tail -f /var/log/pulsar/broker.log): STDOUT: Jul 03, 2024 7:18:01 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:18:02.2150153Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:18:10.8219967Z 2024-07-03T07:18:10,807 - INFO  - [docker-java-stream--2146097482:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-0:tail -f /var/log/pulsar/broker.log): STDOUT: Jul 03, 2024 7:18:10 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:18:10.8222400Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:18:12.8236678Z 2024-07-03T07:18:12,792 - INFO  - [docker-java-stream--1775748643:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-proxy:tail -f /var/log/pulsar/proxy.log): STDOUT: Jul 03, 2024 7:18:11 AM io.opentelemetry.sdk.internal.ThrottlingLogger doLog\r\n2024-07-03T07:18:12.8239105Z WARNING: Failed to export metrics. Server responded with gRPC status code 2. Error message: Failed to connect to otel-collector/172.19.0.9:4317\r\n2024-07-03T07:18:14.2250651Z 2024-07-03T07:18:14,178 - INFO  - [docker-java-stream-137418396:DockerUtils$4@383] - DOCKER.exec(testOpenTelemetryMetrics-068292b9-9c6a-4802-8ad5-a3878a7c6c74-pulsar-broker-1:tail -f /var/log/pulsar/broker.log): STDOUT: 2024-07-03T07:18:13,985+0000 [pulsar-web-38-8] INFO  org.eclipse.jetty.server.RequestLog - 172.19.0.10 - - [03/Jul/2024:07:18:13 +0000] \"GET /admin/v2/persistent/public/functions/coordinate/\r\n```\r\n\r\n\r\nfull log:\r\n[failed.txt.zip](https://github.com/user-attachments/files/16081381/failed.txt.zip)\r\n\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1286,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "tests/integration/src/test/resources/containers/otel-collector-config.yaml"
    ],
    "pr_changed_test_files": [
      "tests/integration/src/test/resources/containers/otel-collector-config.yaml"
    ],
    "base_commit": "dbbb6b66c99afd12762dec198482dbf766bff3bb",
    "head_commit": "b9c575712835879d824598565166953d8f8be977",
    "repo_url": "https://github.com/apache/pulsar/pull/22998",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22998",
    "dockerfile": "",
    "pr_merged_at": "2024-07-03T18:00:48.000Z",
    "patch": "",
    "test_patch": "diff --git a/tests/integration/src/test/resources/containers/otel-collector-config.yaml b/tests/integration/src/test/resources/containers/otel-collector-config.yaml\nindex bd332f0428307..2ba532f3c6cba 100644\n--- a/tests/integration/src/test/resources/containers/otel-collector-config.yaml\n+++ b/tests/integration/src/test/resources/containers/otel-collector-config.yaml\n@@ -21,6 +21,7 @@ receivers:\n   otlp:\n     protocols:\n       grpc:\n+        endpoint: 0.0.0.0:4317\n \n exporters:\n   prometheus:\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22993",
    "pr_id": 22993,
    "issue_id": 22992,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] PulsarStandalone started with error if `--stream-storage-port` is not 4181\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\n- master\r\n- 3.3.0\r\n\r\n### Minimal reproduce step\r\n\r\nRun `PULSAR_STANDALONE_USE_ZOOKEEPER=1 bin/pulsar standalone --stream-storage-port 4182`\r\n\r\n\r\n### What did you expect to see?\r\n\r\nPulsarStandalone started without error.\r\n\r\n### What did you see instead?\r\n\r\nFollowing error appears in console repeatedly.\r\n```\r\n2024-07-02T22:36:31,943+0800 [client-scheduler-OrderedScheduler-1-0] ERROR org.apache.bookkeeper.clients.impl.internal.LocationClientImpl - Not able to locate storage container\r\nio.grpc.StatusRuntimeException: UNAVAILABLE: io exception\r\n\tat io.grpc.Status.asRuntimeException(Status.java:539) ~[io.grpc-grpc-api-1.56.0.jar:1.56.0]\r\n\tat io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:548) ~[io.grpc-grpc-stub-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133) ~[io.grpc-grpc-core-1.56.0.jar:1.56.0]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]\r\n\tat java.base/java.lang.Thread.run(Thread.java:840) [?:?]\r\nCaused by: io.grpc.netty.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: localhost/127.0.0.1:4181\r\nCaused by: java.net.ConnectException: Connection refused\r\n\tat java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[?:?]\r\n\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[?:?]\r\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946) ~[?:?]\r\n\tat io.grpc.netty.shaded.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\tat io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[io.grpc-grpc-netty-shaded-1.56.0.jar:1.56.0]\r\n\t... 1 more\r\n```\r\n\r\nMain thread keeps waiting\r\n```\r\n\"main\" #1 prio=5 os_prio=31 cpu=1278.18ms elapsed=520.07s tid=0x000000012a016400 nid=0x2203 waiting on condition  [0x000000016c072000]\r\n   java.lang.Thread.State: TIMED_WAITING (parking)\r\n        at jdk.internal.misc.Unsafe.park(java.base@17.0.11/Native Method)\r\n        - parking to wait for  <0x000020000bf03bd0> (a java.util.concurrent.CompletableFuture$Signaller)\r\n        at java.util.concurrent.locks.LockSupport.parkNanos(java.base@17.0.11/LockSupport.java:252)\r\n        at java.util.concurrent.CompletableFuture$Signaller.block(java.base@17.0.11/CompletableFuture.java:1866)\r\n        at java.util.concurrent.ForkJoinPool.unmanagedBlock(java.base@17.0.11/ForkJoinPool.java:3465)\r\n        at java.util.concurrent.ForkJoinPool.managedBlock(java.base@17.0.11/ForkJoinPool.java:3436)\r\n        at java.util.concurrent.CompletableFuture.timedGet(java.base@17.0.11/CompletableFuture.java:1939)\r\n        at java.util.concurrent.CompletableFuture.get(java.base@17.0.11/CompletableFuture.java:2095)\r\n        at org.apache.bookkeeper.common.concurrent.FutureUtils.result(FutureUtils.java:80)\r\n        at org.apache.bookkeeper.common.concurrent.FutureUtils.result(FutureUtils.java:61)\r\n        at org.apache.pulsar.zookeeper.LocalBookkeeperEnsemble.runStreamStorage(LocalBookkeeperEnsemble.java:372)\r\n        at org.apache.pulsar.zookeeper.LocalBookkeeperEnsemble.startStandalone(LocalBookkeeperEnsemble.java:437)\r\n        at org.apache.pulsar.PulsarStandalone.startBookieWithZookeeper(PulsarStandalone.java:474)\r\n        at org.apache.pulsar.PulsarStandalone.start(PulsarStandalone.java:302)\r\n        at org.apache.pulsar.PulsarStandaloneStarter.main(PulsarStandaloneStarter.java:149)\r\n```\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 857,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsemble.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java"
    ],
    "base_commit": "ed39c4db671c29057e51b9142a0d4cdb71e3eb88",
    "head_commit": "909a5885353b887939b300aec92458e811d2b247",
    "repo_url": "https://github.com/apache/pulsar/pull/22993",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22993",
    "dockerfile": "",
    "pr_merged_at": "2024-07-08T06:47:25.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsemble.java b/pulsar-broker/src/main/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsemble.java\nindex cf1a30951ebdf..de3077959a444 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsemble.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsemble.java\n@@ -360,7 +360,7 @@ public void runStreamStorage(CompositeConfiguration conf) throws Exception {\n         // create a default namespace\n         try (StorageAdminClient admin = StorageClientBuilder.newBuilder()\n              .withSettings(StorageClientSettings.newBuilder()\n-                 .serviceUri(\"bk://localhost:4181\")\n+                 .serviceUri(\"bk://localhost:\" + streamStoragePort)\n                  .backoffPolicy(Backoff.Jitter.of(\n                      Type.EXPONENTIAL,\n                      1000,\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java\nindex a4bc69a7266cc..bfbdf675bd81d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/zookeeper/LocalBookkeeperEnsembleTest.java\n@@ -21,6 +21,8 @@\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertTrue;\n+\n+import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.testng.annotations.AfterMethod;\n import org.testng.annotations.BeforeMethod;\n import org.testng.annotations.Test;\n@@ -54,4 +56,18 @@ public void testStartStop() throws Exception {\n         assertFalse(ensemble.getZkClient().getState().isConnected());\n         assertFalse(ensemble.getBookies()[0].isRunning());\n     }\n+\n+    @Test(timeOut = 10_000)\n+    public void testStartWithSpecifiedStreamStoragePort() throws Exception {\n+        LocalBookkeeperEnsemble ensemble = null;\n+        try {\n+            ensemble =\n+                    new LocalBookkeeperEnsemble(1, 0, 0, 4182, null, null, true, null);\n+            ensemble.startStandalone(new ServerConfiguration(), true);\n+        } finally {\n+            if (ensemble != null) {\n+                ensemble.stop();\n+            }\n+        }\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22988",
    "pr_id": 22988,
    "issue_id": 22051,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Downgrade issue \n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Version\r\n\r\nI'm trying to downgrade from 3.0.2 to 2.10.4\r\n\r\n### Minimal reproduce step\r\n\r\nI'm using Kubernetes and I've deployed Pulsar with Helm. Pulsar works fine with 3.0.2 but I want to try the procedure to downgrade to 2.10.4 (in case of emergency). \r\n\r\n### What did you expect to see?\r\n\r\nI expect that Pulsar downgrade works\r\n\r\n### What did you see instead?\r\n\r\nBookkeepers cannot start and from the logs I see:\r\njava.io.IOException: Error open RocksDB database\r\nCaused by: org.rocksdb.RocksDBException: **unknown checksum type 4** in /pulsar/data/bookkeeper/ledgers/current/ledgers/000006.sst offset 929 size 32\r\n\r\n\r\n### Anything else?\r\n\r\nZookeeper and brokers seem to run correctly\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 152,
    "test_files_count": 6,
    "non_test_files_count": 2,
    "pr_changed_files": [
      ".github/workflows/pulsar-ci.yaml",
      "build/run_integration_group.sh",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/upgrade/PulsarUpgradeDowngradeTest.java",
      "tests/integration/src/test/resources/pulsar-upgrade.xml"
    ],
    "pr_changed_test_files": [
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java",
      "tests/integration/src/test/java/org/apache/pulsar/tests/integration/upgrade/PulsarUpgradeDowngradeTest.java",
      "tests/integration/src/test/resources/pulsar-upgrade.xml"
    ],
    "base_commit": "4e535cb3f4a3482b0d5dc5a3a0a63c87490704e3",
    "head_commit": "30b5271b47dd17068fe6e36f0fd48ece8d745420",
    "repo_url": "https://github.com/apache/pulsar/pull/22988",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22988",
    "dockerfile": "",
    "pr_merged_at": "2024-10-08T22:22:41.000Z",
    "patch": "diff --git a/.github/workflows/pulsar-ci.yaml b/.github/workflows/pulsar-ci.yaml\nindex 8decde1c999ca..8ad6548e1e257 100644\n--- a/.github/workflows/pulsar-ci.yaml\n+++ b/.github/workflows/pulsar-ci.yaml\n@@ -603,6 +603,9 @@ jobs:\n           - name: Metrics\n             group: METRICS\n \n+          - name: Upgrade\n+            group: UPGRADE\n+\n     steps:\n       - name: checkout\n         uses: actions/checkout@v4\n\ndiff --git a/build/run_integration_group.sh b/build/run_integration_group.sh\nindex 2d82fce08878d..63b92d4e0a798 100755\n--- a/build/run_integration_group.sh\n+++ b/build/run_integration_group.sh\n@@ -177,6 +177,10 @@ test_group_standalone() {\n   mvn_run_integration_test \"$@\" -DintegrationTestSuiteFile=pulsar-standalone.xml -DintegrationTests\n }\n \n+test_group_upgrade() {\n+ mvn_run_integration_test \"$@\" -DintegrationTestSuiteFile=pulsar-upgrade.xml -DintegrationTests\n+}\n+\n test_group_transaction() {\n   mvn_run_integration_test \"$@\" -DintegrationTestSuiteFile=pulsar-transaction.xml -DintegrationTests\n }\n",
    "test_patch": "diff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java\nindex 77cdc1bfd28a9..3cdb048aea55f 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/containers/PulsarContainer.java\n@@ -51,8 +51,13 @@ public abstract class PulsarContainer<SelfT extends PulsarContainer<SelfT>> exte\n     public static final int BROKER_HTTP_PORT = 8080;\n     public static final int BROKER_HTTPS_PORT = 8081;\n \n+    public static final String ALPINE_IMAGE_NAME = \"alpine:3.20\";\n     public static final String DEFAULT_IMAGE_NAME = System.getenv().getOrDefault(\"PULSAR_TEST_IMAGE_NAME\",\n             \"apachepulsar/pulsar-test-latest-version:latest\");\n+    public static final String UPGRADE_TEST_IMAGE_NAME = System.getenv().getOrDefault(\"PULSAR_UPGRADE_TEST_IMAGE_NAME\",\n+            DEFAULT_IMAGE_NAME);\n+    public static final String LAST_RELEASE_IMAGE_NAME = System.getenv().getOrDefault(\"PULSAR_LAST_RELEASE_IMAGE_NAME\",\n+            \"apachepulsar/pulsar:3.0.7\");\n     public static final String DEFAULT_HTTP_PATH = \"/metrics\";\n     public static final String PULSAR_2_5_IMAGE_NAME = \"apachepulsar/pulsar:2.5.0\";\n     public static final String PULSAR_2_4_IMAGE_NAME = \"apachepulsar/pulsar:2.4.0\";\n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java\nindex 90f08a9639471..35fb453c4bb8e 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarCluster.java\n@@ -72,22 +72,28 @@ public class PulsarCluster {\n      * @return the built pulsar cluster\n      */\n     public static PulsarCluster forSpec(PulsarClusterSpec spec) {\n+        return forSpec(spec, Network.newNetwork());\n+    }\n+\n+    public static PulsarCluster forSpec(PulsarClusterSpec spec, Network network) {\n+        checkArgument(network != null, \"Network should not be null\");\n         CSContainer csContainer = null;\n         if (!spec.enableOxia) {\n             csContainer = new CSContainer(spec.clusterName)\n-                    .withNetwork(Network.newNetwork())\n+                    .withNetwork(network)\n                     .withNetworkAliases(CSContainer.NAME);\n         }\n-        return new PulsarCluster(spec, csContainer, false);\n+        return new PulsarCluster(spec, network, csContainer, false);\n     }\n \n     public static PulsarCluster forSpec(PulsarClusterSpec spec, CSContainer csContainer) {\n-        return new PulsarCluster(spec, csContainer, true);\n+        return new PulsarCluster(spec, csContainer.getNetwork(), csContainer, true);\n     }\n \n     @Getter\n     private final PulsarClusterSpec spec;\n \n+    public boolean closeNetworkOnExit = true;\n     @Getter\n     private final String clusterName;\n     private final Network network;\n@@ -108,19 +114,18 @@ public static PulsarCluster forSpec(PulsarClusterSpec spec, CSContainer csContai\n     private final String metadataStoreUrl;\n     private final String configurationMetadataStoreUrl;\n \n-    private PulsarCluster(PulsarClusterSpec spec, CSContainer csContainer, boolean sharedCsContainer) {\n-\n+    private PulsarCluster(PulsarClusterSpec spec, Network network, CSContainer csContainer, boolean sharedCsContainer) {\n         this.spec = spec;\n         this.sharedCsContainer = sharedCsContainer;\n         this.clusterName = spec.clusterName();\n-        if (csContainer != null ) {\n+        if (network != null) {\n+            this.network = network;\n+        } else if (csContainer != null) {\n             this.network = csContainer.getNetwork();\n         } else {\n             this.network = Network.newNetwork();\n         }\n \n-\n-\n         if (spec.enableOxia) {\n             this.zkContainer = null;\n             this.oxiaContainer = new OxiaContainer(clusterName);\n@@ -203,7 +208,9 @@ private PulsarCluster(PulsarClusterSpec spec, CSContainer csContainer, boolean s\n                             .withEnv(\"PULSAR_PREFIX_diskUsageWarnThreshold\", \"0.95\")\n                             .withEnv(\"diskUsageThreshold\", \"0.99\")\n                             .withEnv(\"PULSAR_PREFIX_diskUsageLwmThreshold\", \"0.97\")\n-                            .withEnv(\"nettyMaxFrameSizeBytes\", String.valueOf(spec.maxMessageSize));\n+                            .withEnv(\"nettyMaxFrameSizeBytes\", String.valueOf(spec.maxMessageSize))\n+                            .withEnv(\"ledgerDirectories\", \"data/bookkeeper/\" + name + \"/ledgers\")\n+                            .withEnv(\"journalDirectory\", \"data/bookkeeper/\" + name + \"/journal\");\n                     if (spec.bookkeeperEnvs != null) {\n                         bookieContainer.withEnv(spec.bookkeeperEnvs);\n                     }\n@@ -262,10 +269,27 @@ private PulsarCluster(PulsarClusterSpec spec, CSContainer csContainer, boolean s\n                         }\n                 ));\n \n+        if (spec.dataContainer != null) {\n+            if (!sharedCsContainer && csContainer != null) {\n+                csContainer.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE);\n+            }\n+            if (zkContainer != null) {\n+                zkContainer.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE);\n+            }\n+            proxyContainer.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE);\n+\n+            bookieContainers.values().forEach(c -> c.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE));\n+            brokerContainers.values().forEach(c -> c.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE));\n+            workerContainers.values().forEach(c -> c.withVolumesFrom(spec.dataContainer, BindMode.READ_WRITE));\n+        }\n+\n         spec.classPathVolumeMounts.forEach((key, value) -> {\n             if (zkContainer != null) {\n                 zkContainer.withClasspathResourceMapping(key, value, BindMode.READ_WRITE);\n             }\n+            if (!sharedCsContainer && csContainer != null) {\n+                csContainer.withClasspathResourceMapping(key, value, BindMode.READ_WRITE);\n+            }\n             proxyContainer.withClasspathResourceMapping(key, value, BindMode.READ_WRITE);\n \n             bookieContainers.values().forEach(c -> c.withClasspathResourceMapping(key, value, BindMode.READ_WRITE));\n@@ -323,6 +347,10 @@ public Map<String, GenericContainer<?>> getExternalServices() {\n     }\n \n     public void start() throws Exception {\n+        start(true);\n+    }\n+\n+    public void start(boolean doInit) throws Exception {\n \n         if (!spec.enableOxia) {\n             // start the local zookeeper\n@@ -338,7 +366,7 @@ public void start() throws Exception {\n             oxiaContainer.start();\n         }\n \n-        {\n+        if (doInit) {\n             // Run cluster metadata initialization\n             @Cleanup\n             PulsarInitMetadataContainer init = new PulsarInitMetadataContainer(\n@@ -453,10 +481,12 @@ public synchronized void stop() {\n             oxiaContainer.stop();\n         }\n \n-        try {\n-            network.close();\n-        } catch (Exception e) {\n-            log.info(\"Failed to shutdown network for pulsar cluster {}\", clusterName, e);\n+        if (closeNetworkOnExit) {\n+            try {\n+                network.close();\n+            } catch (Exception e) {\n+                log.info(\"Failed to shutdown network for pulsar cluster {}\", clusterName, e);\n+            }\n         }\n     }\n \n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java\nindex 8a991be49fad0..ca45c9b7c9b82 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterSpec.java\n@@ -124,6 +124,12 @@ public class PulsarClusterSpec {\n     @Builder.Default\n     Map<String, String> classPathVolumeMounts = new TreeMap<>();\n \n+    /**\n+     * Data container\n+     */\n+    @Builder.Default\n+    GenericContainer<?> dataContainer = null;\n+\n     /**\n      * Pulsar Test Image Name\n      *\n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java\nindex 93e2221ab2493..8b99f21373560 100644\n--- a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/topologies/PulsarClusterTestBase.java\n@@ -142,6 +142,10 @@ protected void beforeStartCluster() throws Exception {\n     }\n \n     protected void setupCluster(PulsarClusterSpec spec) throws Exception {\n+        setupCluster(spec, true);\n+    }\n+\n+    protected void setupCluster(PulsarClusterSpec spec, boolean doInit) throws Exception {\n         incrementSetupNumber();\n         log.info(\"Setting up cluster {} with {} bookies, {} brokers\",\n                 spec.clusterName(), spec.numBookies(), spec.numBrokers());\n@@ -150,7 +154,7 @@ protected void setupCluster(PulsarClusterSpec spec) throws Exception {\n \n         beforeStartCluster();\n \n-        pulsarCluster.start();\n+        pulsarCluster.start(doInit);\n \n         pulsarAdmin = PulsarAdmin.builder().serviceHttpUrl(pulsarCluster.getHttpServiceUrl()).build();\n \n\ndiff --git a/tests/integration/src/test/java/org/apache/pulsar/tests/integration/upgrade/PulsarUpgradeDowngradeTest.java b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/upgrade/PulsarUpgradeDowngradeTest.java\nnew file mode 100644\nindex 0000000000000..ddabd67b2294b\n--- /dev/null\n+++ b/tests/integration/src/test/java/org/apache/pulsar/tests/integration/upgrade/PulsarUpgradeDowngradeTest.java\n@@ -0,0 +1,175 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.tests.integration.upgrade;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.pulsar.client.api.Consumer;\n+import org.apache.pulsar.client.api.Message;\n+import org.apache.pulsar.client.api.MessageId;\n+import org.apache.pulsar.client.api.Producer;\n+import org.apache.pulsar.client.api.PulsarClient;\n+import org.apache.pulsar.client.api.Schema;\n+import org.apache.pulsar.client.api.SubscriptionInitialPosition;\n+import org.apache.pulsar.tests.integration.containers.PulsarContainer;\n+import org.apache.pulsar.tests.integration.topologies.PulsarCluster;\n+import org.apache.pulsar.tests.integration.topologies.PulsarClusterSpec;\n+import org.apache.pulsar.tests.integration.topologies.PulsarClusterTestBase;\n+import org.testcontainers.containers.GenericContainer;\n+import org.testcontainers.containers.Network;\n+import org.testng.annotations.Test;\n+import java.util.stream.Stream;\n+import static java.util.stream.Collectors.joining;\n+import static org.testng.Assert.assertEquals;\n+\n+/**\n+ * Test upgrading/downgrading Pulsar cluster from major releases.\n+ */\n+@Slf4j\n+public class PulsarUpgradeDowngradeTest extends PulsarClusterTestBase {\n+\n+    @Test(timeOut=600_000)\n+    public void upgradeTest() throws Exception {\n+        testUpgradeDowngrade(PulsarContainer.LAST_RELEASE_IMAGE_NAME, PulsarContainer.UPGRADE_TEST_IMAGE_NAME);\n+    }\n+\n+    private void testUpgradeDowngrade(String imageOld, String imageNew) throws Exception {\n+        final String clusterName = Stream.of(this.getClass().getSimpleName(), randomName(5))\n+                .filter(s -> !s.isEmpty())\n+                .collect(joining(\"-\"));\n+        String topicName = generateTopicName(\"testupdown\", true);\n+\n+        @Cleanup\n+        Network network = Network.newNetwork();\n+        @Cleanup\n+        GenericContainer<?> alpine = new GenericContainer<>(PulsarContainer.ALPINE_IMAGE_NAME)\n+                .withExposedPorts(80)\n+                .withNetwork(network)\n+                .withNetworkAliases(\"shared-storage\")\n+                .withEnv(\"MAGIC_NUMBER\", \"42\")\n+                .withCreateContainerCmdModifier(createContainerCmd -> createContainerCmd\n+                    .getHostConfig()\n+                    .withBinds(Bind.parse(\"/pulsar/data:/pulsar/data\")))\n+                .withCommand(\"/bin/sh\", \"-c\",\n+                        \"mkdir -p /pulsar/data && \"\n+                                + \"chmod -R ug+rwx /pulsar/data && \"\n+                                + \"chown -R 10000:0 /pulsar/data && \"\n+                                + \"rm -rf /pulsar/data/* && \"\n+                                + \"while true; do echo \\\"$MAGIC_NUMBER\\\" | nc -l -p 80; done\");\n+        alpine.start();\n+\n+        PulsarClusterSpec specOld = PulsarClusterSpec.builder()\n+                .numBookies(2)\n+                .numBrokers(1)\n+                .clusterName(clusterName)\n+                .dataContainer(alpine)\n+                .pulsarTestImage(imageOld)\n+                .build();\n+\n+        PulsarClusterSpec specNew = PulsarClusterSpec.builder()\n+                .numBookies(2)\n+                .numBrokers(1)\n+                .clusterName(clusterName)\n+                .dataContainer(alpine)\n+                .pulsarTestImage(imageNew)\n+                .build();\n+\n+        log.info(\"Setting up OLD cluster {} with {} bookies, {} brokers using {}\",\n+                specOld.clusterName(), specOld.numBookies(), specOld.numBrokers(), imageOld);\n+\n+        pulsarCluster = PulsarCluster.forSpec(specNew, network);\n+        pulsarCluster.closeNetworkOnExit = false;\n+        pulsarCluster.start(true);\n+\n+        try {\n+            log.info(\"setting retention\");\n+            pulsarCluster.runAdminCommandOnAnyBroker(\"namespaces\",\n+                \"set-retention\", \"--size\", \"100M\", \"--time\", \"100m\", \"public/default\");\n+\n+            publishAndConsume(topicName, pulsarCluster.getPlainTextServiceUrl(), 10, 10);\n+        } finally {\n+            pulsarCluster.stop();\n+        }\n+\n+        log.info(\"Upgrading to NEW cluster {} with {} bookies, {} brokers using {}\",\n+                specNew.clusterName(), specNew.numBookies(), specNew.numBrokers(), imageNew);\n+\n+        pulsarCluster = PulsarCluster.forSpec(specNew, network);\n+        pulsarCluster.closeNetworkOnExit = false;\n+        pulsarCluster.start(false);\n+\n+        try {\n+            publishAndConsume(topicName, pulsarCluster.getPlainTextServiceUrl(), 10, 20);\n+        } finally {\n+            pulsarCluster.stop();\n+        }\n+\n+        log.info(\"Downgrading to OLD cluster {} with {} bookies, {} brokers using {}\",\n+                specOld.clusterName(), specOld.numBookies(), specOld.numBrokers(), imageOld);\n+\n+        pulsarCluster = PulsarCluster.forSpec(specOld, network);\n+        pulsarCluster.closeNetworkOnExit = false;\n+        pulsarCluster.start(false);\n+\n+        try {\n+            publishAndConsume(topicName, pulsarCluster.getPlainTextServiceUrl(), 10, 30);\n+        } finally {\n+            pulsarCluster.stop();\n+            alpine.stop();\n+            network.close();\n+        }\n+    }\n+\n+    private void publishAndConsume(String topicName, String serviceUrl, int numProduce, int numConsume) throws Exception {\n+        log.info(\"publishAndConsume: topic name: {}\", topicName);\n+\n+        @Cleanup\n+        PulsarClient client = PulsarClient.builder()\n+                .serviceUrl(serviceUrl)\n+                .build();\n+\n+        @Cleanup\n+        Producer<String> producer = client.newProducer(Schema.STRING)\n+                .topic(topicName)\n+                .create();\n+\n+        log.info(\"Publishing {} messages\", numProduce);\n+        for (int i = numConsume - numProduce; i < numConsume; i++) {\n+            log.info(\"Publishing message: {}\", \"smoke-message-\" + i);\n+            producer.send(\"smoke-message-\" + i);\n+        }\n+\n+        @Cleanup\n+        Consumer<String> consumer = client.newConsumer(Schema.STRING)\n+                .topic(topicName)\n+                .subscriptionName(\"my-sub\")\n+                .subscriptionInitialPosition(SubscriptionInitialPosition.Earliest)\n+                .subscribe();\n+        consumer.seek(MessageId.earliest);\n+\n+        log.info(\"Consuming {} messages\", numConsume);\n+        for (int i = 0; i < numConsume; i++) {\n+            log.info(\"Waiting for message: {}\", i);\n+            Message<String> m = consumer.receive();\n+            log.info(\"Received message: {}\", m.getValue());\n+            assertEquals(\"smoke-message-\" + i, m.getValue());\n+        }\n+    }\n+}\n\ndiff --git a/tests/integration/src/test/resources/pulsar-upgrade.xml b/tests/integration/src/test/resources/pulsar-upgrade.xml\nindex a52db54753372..dc966b160ba17 100644\n--- a/tests/integration/src/test/resources/pulsar-upgrade.xml\n+++ b/tests/integration/src/test/resources/pulsar-upgrade.xml\n@@ -22,7 +22,7 @@\n <suite name=\"Pulsar Upgrade Integration Tests\" verbose=\"2\" annotations=\"JDK\">\n     <test name=\"pulsar-upgrade-test-suite\" preserve-order=\"true\" >\n         <classes>\n-            <class name=\"org.apache.pulsar.tests.integration.upgrade.PulsarZKDowngradeTest\" />\n+            <class name=\"org.apache.pulsar.tests.integration.upgrade.PulsarUpgradeDowngradeTest\" />\n         </classes>\n     </test>\n </suite>\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22966",
    "pr_id": 22966,
    "issue_id": 18388,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] ArrayIndexOutOfBoundsException caused by optimistic locking in ConcurrentLongLongPairHashMap implementation\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Version\r\n\r\nlatest.\r\n\r\n### Minimal reproduce step\r\n\r\n ConcurrentLongLongPairHashMap  use optimistic locking to read data in Section, but if there is another thread that is removing data from the same Section, and trigger the shrink process, then the index calculated  basing on dirty capacity exceed the array size,  an ArrayIndexOut0fBoundsException will be throw, which is not handled now. Eventually the connection with client will be closed.\r\n<img width=\"473\" alt=\"_6c48e27c-dc0c-4cc5-8ff6-77563d379e6e\" src=\"https://user-images.githubusercontent.com/52550727/200548263-fb885993-0799-499f-953a-c4f1f55ecacf.png\">\r\n\r\n\r\n### What did you expect to see?\r\n,\r\n\r\n### What did you see instead?\r\n\r\n```\r\nWARN org.apache.pulsar.broker.service.Servernx-[] Got exception, cause: java.lang.ArrayIndexOut0fBoundsException: Index 6821 out of bounds for length 4\r\n096, stackTrace: java.lang.ArrayIndexOutOfBoundsException: Index 6821 out of bounds for length 4096\r\natorg.apache.pulsar.common.util.collections.ConcurrentLongLongPairHashMap$Section.get(ConcurrentLongLongPairHashMap.java:331)\r\natorg.apache.pulsar.common.util.collections.ConcurrentLongLongPairHashMap.get(ConcurrentLongLongPairHashMap.java:204)\r\nat org.apache.pulsar.common.util.collections.ConcurrentLongLongPairHashMap.containsKey(ConcurrentLongLongPairHashMap.java:208)\r\nat org.apache.pulsar.broker.service.Consumer.getAckOwnerConsumer(Consumer.java:596)\r\nat org.apache.pulsar.broker.service.Consumer.individualAckNormal(Consumer.java:408)\r\nat org.apache.pulsar.broker.service.Consumer.messageAcked(Consumer.java:395)\r\nat org.apache.pulsar .broker .service.ServerCnx.handleAck(Server(nx.java:1456)\r\nat org.apache.pulsar.common.protocol.PulsarDecoder.channelRead(PulsarDecoder.java:145)\r\n```\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 269,
    "test_files_count": 2,
    "non_test_files_count": 4,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerConfig.java",
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java",
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/RangeSetWrapper.java",
      "pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSet.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSetTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java",
      "pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSetTest.java"
    ],
    "base_commit": "fe726db49c32eb539b6eb0b83c8735e48f742a35",
    "head_commit": "66b228c56361f4429bf7dc0ca492296bd3a1d557",
    "repo_url": "https://github.com/apache/pulsar/pull/22966",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22966",
    "dockerfile": "",
    "pr_merged_at": "2024-07-03T13:09:31.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerConfig.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerConfig.java\nindex fb2c6de3c7423..03439f93ccad8 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerConfig.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerConfig.java\n@@ -33,7 +33,7 @@\n import org.apache.bookkeeper.mledger.impl.NullLedgerOffloader;\n import org.apache.bookkeeper.mledger.intercept.ManagedLedgerInterceptor;\n import org.apache.commons.collections4.MapUtils;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenLongPairRangeSet;\n+import org.apache.pulsar.common.util.collections.OpenLongPairRangeSet;\n \n /**\n  * Configuration class for a ManagedLedger.\n@@ -282,7 +282,7 @@ public ManagedLedgerConfig setPassword(String password) {\n     }\n \n     /**\n-     * should use {@link ConcurrentOpenLongPairRangeSet} to store unacked ranges.\n+     * should use {@link OpenLongPairRangeSet} to store unacked ranges.\n      * @return\n      */\n     public boolean isUnackedRangesOpenCacheSetEnabled() {\n\ndiff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\nindex bf46aa2fdffa9..98ba722ba1c9b 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n@@ -336,7 +336,12 @@ public Map<String, Long> getProperties() {\n \n     @Override\n     public boolean isCursorDataFullyPersistable() {\n-        return individualDeletedMessages.size() <= getConfig().getMaxUnackedRangesToPersist();\n+        lock.readLock().lock();\n+        try {\n+            return individualDeletedMessages.size() <= getConfig().getMaxUnackedRangesToPersist();\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     @Override\n@@ -1099,7 +1104,12 @@ public long getNumberOfEntriesSinceFirstNotAckedMessage() {\n \n     @Override\n     public int getTotalNonContiguousDeletedMessagesRange() {\n-        return individualDeletedMessages.size();\n+        lock.readLock().lock();\n+        try {\n+            return individualDeletedMessages.size();\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     @Override\n@@ -2383,8 +2393,9 @@ public void asyncDelete(Iterable<Position> positions, AsyncCallbacks.DeleteCallb\n             callback.deleteFailed(getManagedLedgerException(e), ctx);\n             return;\n         } finally {\n+            boolean empty = individualDeletedMessages.isEmpty();\n             lock.writeLock().unlock();\n-            if (individualDeletedMessages.isEmpty()) {\n+            if (empty) {\n                 callback.deleteComplete(ctx);\n             }\n         }\n@@ -2661,10 +2672,15 @@ public void operationFailed(MetaStoreException e) {\n     }\n \n     private boolean shouldPersistUnackRangesToLedger() {\n-        return cursorLedger != null\n-                && !isCursorLedgerReadOnly\n-                && getConfig().getMaxUnackedRangesToPersist() > 0\n-                && individualDeletedMessages.size() > getConfig().getMaxUnackedRangesToPersistInMetadataStore();\n+        lock.readLock().lock();\n+        try {\n+            return cursorLedger != null\n+                    && !isCursorLedgerReadOnly\n+                    && getConfig().getMaxUnackedRangesToPersist() > 0\n+                    && individualDeletedMessages.size() > getConfig().getMaxUnackedRangesToPersistInMetadataStore();\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     private void persistPositionMetaStore(long cursorsLedgerId, Position position, Map<String, Long> properties,\n@@ -3023,7 +3039,7 @@ private static List<StringProperty> buildStringPropertiesMap(Map<String, String>\n     }\n \n     private List<MLDataFormats.MessageRange> buildIndividualDeletedMessageRanges() {\n-        lock.readLock().lock();\n+        lock.writeLock().lock();\n         try {\n             if (individualDeletedMessages.isEmpty()) {\n                 this.individualDeletedMessagesSerializedSize = 0;\n@@ -3065,7 +3081,7 @@ private List<MLDataFormats.MessageRange> buildIndividualDeletedMessageRanges() {\n             individualDeletedMessages.resetDirtyKeys();\n             return rangeList;\n         } finally {\n-            lock.readLock().unlock();\n+            lock.writeLock().unlock();\n         }\n     }\n \n@@ -3451,8 +3467,13 @@ public LongPairRangeSet<Position> getIndividuallyDeletedMessagesSet() {\n     }\n \n     public boolean isMessageDeleted(Position position) {\n-        return position.compareTo(markDeletePosition) <= 0\n-                || individualDeletedMessages.contains(position.getLedgerId(), position.getEntryId());\n+        lock.readLock().lock();\n+        try {\n+            return position.compareTo(markDeletePosition) <= 0\n+                    || individualDeletedMessages.contains(position.getLedgerId(), position.getEntryId());\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     //this method will return a copy of the position's ack set\n@@ -3477,13 +3498,19 @@ public long[] getBatchPositionAckSet(Position position) {\n      * @return next available position\n      */\n     public Position getNextAvailablePosition(Position position) {\n-        Range<Position> range = individualDeletedMessages.rangeContaining(position.getLedgerId(),\n-                position.getEntryId());\n-        if (range != null) {\n-            Position nextPosition = range.upperEndpoint().getNext();\n-            return (nextPosition != null && nextPosition.compareTo(position) > 0) ? nextPosition : position.getNext();\n+        lock.readLock().lock();\n+        try {\n+            Range<Position> range = individualDeletedMessages.rangeContaining(position.getLedgerId(),\n+                    position.getEntryId());\n+            if (range != null) {\n+                Position nextPosition = range.upperEndpoint().getNext();\n+                return (nextPosition != null && nextPosition.compareTo(position) > 0)\n+                        ? nextPosition : position.getNext();\n+            }\n+            return position.getNext();\n+        } finally {\n+            lock.readLock().unlock();\n         }\n-        return position.getNext();\n     }\n \n     public Position getNextLedgerPosition(long currentLedgerId) {\n@@ -3534,7 +3561,12 @@ public ManagedLedger getManagedLedger() {\n \n     @Override\n     public Range<Position> getLastIndividualDeletedRange() {\n-        return individualDeletedMessages.lastRange();\n+        lock.readLock().lock();\n+        try {\n+            return individualDeletedMessages.lastRange();\n+        } finally {\n+            lock.readLock().unlock();\n+        }\n     }\n \n     @Override\n@@ -3664,15 +3696,20 @@ public ManagedLedgerConfig getConfig() {\n     public ManagedCursor duplicateNonDurableCursor(String nonDurableCursorName) throws ManagedLedgerException {\n         NonDurableCursorImpl newNonDurableCursor =\n                 (NonDurableCursorImpl) ledger.newNonDurableCursor(getMarkDeletedPosition(), nonDurableCursorName);\n-        if (individualDeletedMessages != null) {\n-            this.individualDeletedMessages.forEach(range -> {\n-                newNonDurableCursor.individualDeletedMessages.addOpenClosed(\n-                        range.lowerEndpoint().getLedgerId(),\n-                        range.lowerEndpoint().getEntryId(),\n-                        range.upperEndpoint().getLedgerId(),\n-                        range.upperEndpoint().getEntryId());\n-                return true;\n-            });\n+        lock.readLock().lock();\n+        try {\n+            if (individualDeletedMessages != null) {\n+                this.individualDeletedMessages.forEach(range -> {\n+                    newNonDurableCursor.individualDeletedMessages.addOpenClosed(\n+                            range.lowerEndpoint().getLedgerId(),\n+                            range.lowerEndpoint().getEntryId(),\n+                            range.upperEndpoint().getLedgerId(),\n+                            range.upperEndpoint().getEntryId());\n+                    return true;\n+                });\n+            }\n+        } finally {\n+            lock.readLock().unlock();\n         }\n         if (batchDeletedIndexes != null) {\n             for (Map.Entry<Position, BitSetRecyclable> entry : this.batchDeletedIndexes.entrySet()) {\n\ndiff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/RangeSetWrapper.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/RangeSetWrapper.java\nindex f235ffc63ace5..299fd3dc74cb4 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/RangeSetWrapper.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/RangeSetWrapper.java\n@@ -25,8 +25,8 @@\n import java.util.Collection;\n import java.util.List;\n import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n-import org.apache.pulsar.common.util.collections.ConcurrentOpenLongPairRangeSet;\n import org.apache.pulsar.common.util.collections.LongPairRangeSet;\n+import org.apache.pulsar.common.util.collections.OpenLongPairRangeSet;\n \n /**\n  * Wraps other Range classes, and adds LRU, marking dirty data and other features on this basis.\n@@ -55,7 +55,7 @@ public RangeSetWrapper(LongPairConsumer<T> rangeConverter,\n         this.config = managedCursor.getManagedLedger().getConfig();\n         this.rangeConverter = rangeConverter;\n         this.rangeSet = config.isUnackedRangesOpenCacheSetEnabled()\n-                ? new ConcurrentOpenLongPairRangeSet<>(4096, rangeConverter)\n+                ? new OpenLongPairRangeSet<>(4096, rangeConverter)\n                 : new LongPairRangeSet.DefaultRangeSet<>(rangeConverter, rangeBoundConsumer);\n         this.enableMultiEntry = config.isPersistentUnackedRangesWithMultipleEntriesEnabled();\n     }\n@@ -148,16 +148,16 @@ public int cardinality(long lowerKey, long lowerValue, long upperKey, long upper\n \n     @VisibleForTesting\n     void add(Range<LongPair> range) {\n-        if (!(rangeSet instanceof ConcurrentOpenLongPairRangeSet)) {\n+        if (!(rangeSet instanceof OpenLongPairRangeSet)) {\n             throw new UnsupportedOperationException(\"Only ConcurrentOpenLongPairRangeSet support this method\");\n         }\n-        ((ConcurrentOpenLongPairRangeSet<T>) rangeSet).add(range);\n+        ((OpenLongPairRangeSet<T>) rangeSet).add(range);\n     }\n \n     @VisibleForTesting\n     void remove(Range<T> range) {\n-        if (rangeSet instanceof ConcurrentOpenLongPairRangeSet) {\n-            ((ConcurrentOpenLongPairRangeSet<T>) rangeSet).remove((Range<LongPair>) range);\n+        if (rangeSet instanceof OpenLongPairRangeSet) {\n+            ((OpenLongPairRangeSet<T>) rangeSet).remove((Range<LongPair>) range);\n         } else {\n             ((DefaultRangeSet<T>) rangeSet).remove(range);\n         }\n\ndiff --git a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSet.java b/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSet.java\nsimilarity index 97%\nrename from pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSet.java\nrename to pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSet.java\nindex 72215d7296cc3..c053c106be206 100644\n--- a/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSet.java\n+++ b/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSet.java\n@@ -28,6 +28,7 @@\n import java.util.NavigableMap;\n import java.util.concurrent.ConcurrentSkipListMap;\n import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.annotation.concurrent.NotThreadSafe;\n import org.apache.commons.lang.mutable.MutableInt;\n \n /**\n@@ -41,7 +42,8 @@\n  * So, this rangeSet is not suitable for large number of unique keys.\n  * </pre>\n  */\n-public class ConcurrentOpenLongPairRangeSet<T extends Comparable<T>> implements LongPairRangeSet<T> {\n+@NotThreadSafe\n+public class OpenLongPairRangeSet<T extends Comparable<T>> implements LongPairRangeSet<T> {\n \n     protected final NavigableMap<Long, BitSet> rangeBitSetMap = new ConcurrentSkipListMap<>();\n     private boolean threadSafe = true;\n@@ -54,15 +56,15 @@ public class ConcurrentOpenLongPairRangeSet<T extends Comparable<T>> implements\n     private volatile boolean updatedAfterCachedForSize = true;\n     private volatile boolean updatedAfterCachedForToString = true;\n \n-    public ConcurrentOpenLongPairRangeSet(LongPairConsumer<T> consumer) {\n+    public OpenLongPairRangeSet(LongPairConsumer<T> consumer) {\n         this(1024, true, consumer);\n     }\n \n-    public ConcurrentOpenLongPairRangeSet(int size, LongPairConsumer<T> consumer) {\n+    public OpenLongPairRangeSet(int size, LongPairConsumer<T> consumer) {\n         this(size, true, consumer);\n     }\n \n-    public ConcurrentOpenLongPairRangeSet(int size, boolean threadSafe, LongPairConsumer<T> consumer) {\n+    public OpenLongPairRangeSet(int size, boolean threadSafe, LongPairConsumer<T> consumer) {\n         this.threadSafe = threadSafe;\n         this.bitSetSize = size;\n         this.consumer = consumer;\n",
    "test_patch": "diff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java\nindex f6103061a420c..730f4b4ceca22 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/DefaultRangeSetTest.java\n@@ -34,8 +34,8 @@ public class DefaultRangeSetTest {\n     public void testBehavior() {\n         LongPairRangeSet.DefaultRangeSet<LongPairRangeSet.LongPair> set =\n                 new LongPairRangeSet.DefaultRangeSet<>(consumer, reverseConsumer);\n-        ConcurrentOpenLongPairRangeSet<LongPairRangeSet.LongPair> rangeSet =\n-                new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPairRangeSet.LongPair> rangeSet =\n+                new OpenLongPairRangeSet<>(consumer);\n \n         assertNull(set.firstRange());\n         assertNull(set.lastRange());\n\ndiff --git a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSetTest.java b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSetTest.java\nsimilarity index 92%\nrename from pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSetTest.java\nrename to pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSetTest.java\nindex 40bb337935742..4dd0f5551f1f9 100644\n--- a/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/ConcurrentOpenLongPairRangeSetTest.java\n+++ b/pulsar-common/src/test/java/org/apache/pulsar/common/util/collections/OpenLongPairRangeSetTest.java\n@@ -37,14 +37,14 @@\n import com.google.common.collect.Range;\n import com.google.common.collect.TreeRangeSet;\n \n-public class ConcurrentOpenLongPairRangeSetTest {\n+public class OpenLongPairRangeSetTest {\n \n     static final LongPairConsumer<LongPair> consumer = LongPair::new;\n     static final RangeBoundConsumer<LongPair> reverseConsumer = pair -> pair;\n \n     @Test\n     public void testIsEmpty() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         assertTrue(set.isEmpty());\n         // lowerValueOpen and upperValue are both -1 so that an empty set will be added\n         set.addOpenClosed(0, -1, 0, -1);\n@@ -55,7 +55,7 @@ public void testIsEmpty() {\n \n     @Test\n     public void testAddForSameKey() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         // add 0 to 5\n         set.add(Range.closed(new LongPair(0, 0), new LongPair(0, 5)));\n         // add 8,9,10\n@@ -76,7 +76,7 @@ public void testAddForSameKey() {\n \n     @Test\n     public void testAddForDifferentKey() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         // [98,100],[(1,5),(1,5)],[(1,10,1,15)],[(1,20),(1,20)],[(2,0),(2,10)]\n         set.addOpenClosed(0, 98, 0, 99);\n         set.addOpenClosed(0, 100, 1, 5);\n@@ -93,7 +93,7 @@ public void testAddForDifferentKey() {\n \n     @Test\n     public void testAddCompareCompareWithGuava() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         com.google.common.collect.RangeSet<LongPair> gSet = TreeRangeSet.create();\n \n         // add 10K values for key 0\n@@ -132,14 +132,14 @@ public void testAddCompareCompareWithGuava() {\n \n     @Test\n     public void testNPE() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         assertNull(set.span());\n     }\n \n     @Test\n     public void testDeleteCompareWithGuava() {\n \n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         com.google.common.collect.RangeSet<LongPair> gSet = TreeRangeSet.create();\n \n         // add 10K values for key 0\n@@ -193,7 +193,7 @@ public void testDeleteCompareWithGuava() {\n \n     @Test\n     public void testRemoveRangeInSameKey() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.addOpenClosed(0, 1, 0, 50);\n         set.addOpenClosed(0, 97, 0, 99);\n         set.addOpenClosed(0, 99, 1, 5);\n@@ -217,7 +217,7 @@ public void testRemoveRangeInSameKey() {\n \n     @Test\n     public void testSpanWithGuava() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         com.google.common.collect.RangeSet<LongPair> gSet = TreeRangeSet.create();\n         set.add(Range.openClosed(new LongPair(0, 97), new LongPair(0, 99)));\n         gSet.add(Range.openClosed(new LongPair(0, 97), new LongPair(0, 99)));\n@@ -242,7 +242,7 @@ public void testSpanWithGuava() {\n \n     @Test\n     public void testFirstRange() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         assertNull(set.firstRange());\n         Range<LongPair> range = Range.openClosed(new LongPair(0, 97), new LongPair(0, 99));\n         set.add(range);\n@@ -260,7 +260,7 @@ public void testFirstRange() {\n \n     @Test\n     public void testLastRange() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         assertNull(set.lastRange());\n         Range<LongPair> range = Range.openClosed(new LongPair(0, 97), new LongPair(0, 99));\n         set.add(range);\n@@ -282,7 +282,7 @@ public void testLastRange() {\n \n     @Test\n     public void testToString() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         Range<LongPair> range = Range.openClosed(new LongPair(0, 97), new LongPair(0, 99));\n         set.add(range);\n         assertEquals(set.toString(), \"[(0:97..0:99]]\");\n@@ -296,7 +296,7 @@ public void testToString() {\n \n     @Test\n     public void testDeleteForDifferentKey() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.addOpenClosed(0, 97, 0, 99);\n         set.addOpenClosed(0, 99, 1, 5);\n         set.addOpenClosed(1, 9, 1, 15);\n@@ -327,7 +327,7 @@ public void testDeleteForDifferentKey() {\n \n     @Test\n     public void testDeleteWithAtMost() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.add(Range.closed(new LongPair(0, 98), new LongPair(0, 99)));\n         set.add(Range.closed(new LongPair(0, 100), new LongPair(1, 5)));\n         set.add(Range.closed(new LongPair(1, 10), new LongPair(1, 15)));\n@@ -353,7 +353,7 @@ public void testDeleteWithAtMost() {\n \n     @Test\n     public void testDeleteWithLeastMost() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.add(Range.closed(new LongPair(0, 98), new LongPair(0, 99)));\n         set.add(Range.closed(new LongPair(0, 100), new LongPair(1, 5)));\n         set.add(Range.closed(new LongPair(1, 10), new LongPair(1, 15)));\n@@ -382,7 +382,7 @@ public void testDeleteWithLeastMost() {\n \n     @Test\n     public void testRangeContaining() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.add(Range.closed(new LongPair(0, 98), new LongPair(0, 99)));\n         set.add(Range.closed(new LongPair(0, 100), new LongPair(1, 5)));\n         com.google.common.collect.RangeSet<LongPair> gSet = TreeRangeSet.create();\n@@ -423,7 +423,7 @@ public void testRangeContaining() {\n      */\n     @Test\n     public void testCacheFlagConflict() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         set.add(Range.openClosed(new LongPair(0, 1), new LongPair(0, 2)));\n         set.add(Range.openClosed(new LongPair(0, 3), new LongPair(0, 4)));\n         assertEquals(set.toString(), \"[(0:1..0:2],(0:3..0:4]]\");\n@@ -466,7 +466,7 @@ private List<Range<LongPair>> getConnectedRange(Set<Range<LongPair>> gRanges) {\n \n     @Test\n     public void testCardinality() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set = new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set = new OpenLongPairRangeSet<>(consumer);\n         int v = set.cardinality(0, 0, Integer.MAX_VALUE, Integer.MAX_VALUE);\n         assertEquals(v, 0 );\n         set.addOpenClosed(1, 0, 1, 20);\n@@ -486,8 +486,8 @@ public void testCardinality() {\n \n     @Test\n     public void testForEachResultTheSameAsForEachWithRangeBoundMapper() {\n-        ConcurrentOpenLongPairRangeSet<LongPair> set =\n-                new ConcurrentOpenLongPairRangeSet<>(consumer);\n+        OpenLongPairRangeSet<LongPair> set =\n+                new OpenLongPairRangeSet<>(consumer);\n \n         LongPairRangeSet.DefaultRangeSet<LongPair> defaultRangeSet =\n                 new LongPairRangeSet.DefaultRangeSet<>(consumer, reverseConsumer);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22864",
    "pr_id": 22864,
    "issue_id": 22871,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ExtensibleLoadManagerImplTest.testGetMetrics (fails consistently)\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/9412677464/job/25928002659?pr=22867#step:9:2239\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n Error:  Tests run: 45, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 130.133 s <<< FAILURE! - in org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerImplTest\r\n  Error:  org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerImplTest.testGetMetrics  Time elapsed: 0.008 s  <<< FAILURE!\r\n  java.lang.AssertionError: Sets differ: expected [dimensions=[{broker=localhost, metric=loadBalancing}], metrics=[{brk_lb_bandwidth_in_usage=3.0, brk_lb_bandwidth_out_usage=4.0, brk_lb_cpu_usage=1.0, brk_lb_directMemory_usage=2.0, brk_lb_memory_usage=400.0}], dimensions=[{broker=localhost, event=Unload, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=5}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Cancel}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=7}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Unknown, result=Failure}], metrics=[{brk_lb_bundles_split_breakdown_total=6}], dimensions=[{broker=localhost, event=Assigning, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=8}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Deleted}], metrics=[{brk_sunit_state_chn_owner_lookup_total=14}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Unknown, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=9}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoBundles, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=4}], dimensions=[{broker=localhost, event=Init, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=1}], dimensions=[{broker=localhost, event=Splitting, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=12}], dimensions=[{broker=localhost, event=Assign, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=1}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Sessions, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=2}], dimensions=[{broker=localhost, event=Split, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Releasing}], metrics=[{brk_sunit_state_chn_owner_lookup_total=10}], dimensions=[{broker=localhost, feature=max_ema, metric=bundleUnloading, stat=avg}], metrics=[{brk_lb_resource_usage_stats=1.5}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Splitting}], metrics=[{brk_sunit_state_chn_owner_lookup_total=12}], dimensions=[{broker=localhost, event=Assign, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=2}], dimensions=[{broker=localhost, event=Free, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=3}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Overloaded, result=Success}], metrics=[{brk_lb_unload_broker_breakdown_total=1}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=OutDatedData, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=6}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoBrokers, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=8}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Assigning}], metrics=[{brk_sunit_state_chn_owner_lookup_total=8}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=MsgRate, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=3}], dimensions=[{broker=localhost, event=Assigning, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=7}], dimensions=[{broker=localhost, event=Free, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=4}], dimensions=[{broker=localhost, feature=max, metric=loadBalancing}], metrics=[{brk_lb_resource_usage=0.04}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=CoolDown, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=5}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Init}], metrics=[{brk_sunit_state_chn_owner_lookup_total=2}], dimensions=[{broker=localhost, event=Deleted, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=14}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Deleted}], metrics=[{brk_sunit_state_chn_owner_lookup_total=13}], dimensions=[{broker=localhost, event=Owned, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=5}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Free}], metrics=[{brk_sunit_state_chn_owner_lookup_total=4}], dimensions=[{broker=localhost, metric=bundleUnloading}], metrics=[{brk_lb_unload_broker_total=2, brk_lb_unload_bundle_total=3}], dimensions=[{broker=localhost, event=Unload, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=6}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Topics, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=1}], dimensions=[{broker=localhost, feature=max_ema, metric=loadBalancing}], metrics=[{brk_lb_resource_usage=4.0}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoLoadData, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=7}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Schedule}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=5}], dimensions=[{broker=localhost, event=Split, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=4}], dimensions=[{broker=localhost, metric=assign, result=Success}], metrics=[{brk_lb_assign_broker_breakdown_total=1}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Assigning}], metrics=[{brk_sunit_state_chn_owner_lookup_total=7}], dimensions=[{broker=localhost, event=Splitting, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=11}], dimensions=[{broker=localhost, metric=bundleUnloading}], metrics=[{brk_lb_ignored_ack_total=3, brk_lb_ignored_send_total=2}], dimensions=[{broker=localhost, metric=sunitStateChn}], metrics=[{brk_sunit_state_chn_orphan_su_cleanup_ops_total=3, brk_sunit_state_chn_owned_su_total=10, brk_sunit_state_chn_su_tombstone_cleanup_ops_total=2}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Underloaded, result=Success}], metrics=[{brk_lb_unload_broker_breakdown_total=2}], dimensions=[{broker=localhost, event=Init, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=2}], dimensions=[{broker=localhost, event=Releasing, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=9}], dimensions=[{broker=localhost, event=Override, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=7}], dimensions=[{broker=localhost, metric=assign, result=Skip}], metrics=[{brk_lb_assign_broker_breakdown_total=3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Init}], metrics=[{brk_sunit_state_chn_owner_lookup_total=1}], dimensions=[{broker=localhost, feature=max_ema, metric=bundleUnloading, stat=std}], metrics=[{brk_lb_resource_usage_stats=0.3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Success}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=1}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_cleanup_ops_total=4}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Owned}], metrics=[{brk_sunit_state_chn_owner_lookup_total=6}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Bandwidth, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=4}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Owned}], metrics=[{brk_sunit_state_chn_owner_lookup_total=5}], dimensions=[{broker=localhost, event=Releasing, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=10}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Skip}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=6}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Free}], metrics=[{brk_sunit_state_chn_owner_lookup_total=3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Splitting}], metrics=[{brk_sunit_state_chn_owner_lookup_total=11}], dimensions=[{broker=localhost, metric=bundlesSplit}], metrics=[{brk_lb_bundles_split_total=35}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Unknown, result=Failure}], metrics=[{brk_lb_unload_broker_breakdown_total=10}], dimensions=[{broker=localhost, event=Owned, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=6}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Admin, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=5}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=HitCount, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=3}], dimensions=[{broker=localhost, event=Override, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=8}], dimensions=[{broker=localhost, event=Deleted, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=13}], dimensions=[{broker=localhost, metric=assign, result=Failure}], metrics=[{brk_lb_assign_broker_breakdown_total=2}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Releasing}], metrics=[{brk_sunit_state_chn_owner_lookup_total=9}]] but got [dimensions=[{broker=localhost, metric=bundleUnloading, reason=Underloaded, result=Success}], metrics=[{brk_lb_unload_broker_breakdown_total=2}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=CoolDown, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=5}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Overloaded, result=Success}], metrics=[{brk_lb_unload_broker_breakdown_total=1}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoBundles, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=4}], dimensions=[{broker=localhost, metric=bundleUnloading}], metrics=[{brk_lb_unload_broker_total=2, brk_lb_unload_bundle_total=3}], dimensions=[{broker=localhost, feature=max_ema, metric=bundleUnloading, stat=avg}], metrics=[{brk_lb_resource_usage_stats=1.5}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Assigning}], metrics=[{brk_sunit_state_chn_owner_lookup_total=7}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Sessions, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=2}], dimensions=[{broker=localhost, event=Init, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=1}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Unknown, result=Failure}], metrics=[{brk_lb_unload_broker_breakdown_total=10}], dimensions=[{broker=localhost, metric=assign, result=Skip}], metrics=[{brk_lb_assign_broker_breakdown_total=3}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=MsgRate, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Owned}], metrics=[{brk_sunit_state_chn_owner_lookup_total=6}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Free}], metrics=[{brk_sunit_state_chn_owner_lookup_total=4}], dimensions=[{broker=localhost, event=Override, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=8}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Owned}], metrics=[{brk_sunit_state_chn_owner_lookup_total=5}], dimensions=[{broker=localhost, event=Assign, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=2}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoLoadData, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=7}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Unknown, result=Failure}], metrics=[{brk_lb_bundles_split_breakdown_total=6}], dimensions=[{broker=localhost, event=Assign, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=1}], dimensions=[{broker=localhost, metric=bundleUnloading}], metrics=[{brk_lb_ignored_ack_total=3, brk_lb_ignored_send_total=2}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Releasing}], metrics=[{brk_sunit_state_chn_owner_lookup_total=10}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=NoBrokers, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=8}], dimensions=[{broker=localhost, event=Assigning, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=8}], dimensions=[{broker=localhost, event=Splitting, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=12}], dimensions=[{broker=localhost, feature=max_ema, metric=bundleUnloading, stat=std}], metrics=[{brk_lb_resource_usage_stats=0.3}], dimensions=[{broker=localhost, event=Unload, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=6}], dimensions=[{broker=localhost, event=Owned, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=6}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Cancel}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=7}], dimensions=[{broker=localhost, metric=sunitStateChn}], metrics=[{brk_sunit_state_chn_orphan_su_cleanup_ops_total=3, brk_sunit_state_chn_owned_su_total=10, brk_sunit_state_chn_su_tombstone_cleanup_ops_total=2}], dimensions=[{broker=localhost, event=Free, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=4}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Releasing}], metrics=[{brk_sunit_state_chn_owner_lookup_total=9}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Splitting}], metrics=[{brk_sunit_state_chn_owner_lookup_total=11}], dimensions=[{broker=localhost, metric=assign, result=Success}], metrics=[{brk_lb_assign_broker_breakdown_total=1}], dimensions=[{broker=localhost, event=Releasing, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=10}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Success}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=1}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Schedule}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=5}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Bandwidth, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=4}], dimensions=[{broker=localhost, event=Override, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=7}], dimensions=[{broker=localhost, metric=loadBalancing}], metrics=[{brk_lb_bandwidth_in_usage=3.0, brk_lb_bandwidth_out_usage=4.0, brk_lb_cpu_usage=1.0, brk_lb_directMemory_usage=2.0, brk_lb_memory_usage=400.0}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Init}], metrics=[{brk_sunit_state_chn_owner_lookup_total=1}], dimensions=[{broker=localhost, event=Split, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=3}], dimensions=[{broker=localhost, event=Init, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=2}], dimensions=[{broker=localhost, event=Splitting, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=11}], dimensions=[{broker=localhost, event=Owned, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=5}], dimensions=[{broker=localhost, event=Releasing, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=9}], dimensions=[{broker=localhost, event=Split, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=4}], dimensions=[{broker=localhost, event=Deleted, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=13}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Admin, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=5}], dimensions=[{broker=localhost, feature=max_ema, metric=loadBalancing}], metrics=[{brk_lb_resource_usage=0.04}], dimensions=[{broker=localhost, feature=max, metric=loadBalancing}], metrics=[{brk_lb_resource_usage=0.04}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=OutDatedData, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=6}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Splitting}], metrics=[{brk_sunit_state_chn_owner_lookup_total=12}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Skip}], metrics=[{brk_sunit_state_chn_inactive_broker_cleanup_ops_total=6}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=Unknown, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=9}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Init}], metrics=[{brk_sunit_state_chn_owner_lookup_total=2}], dimensions=[{broker=localhost, event=Assigning, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=7}], dimensions=[{broker=localhost, event=Free, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=3}], dimensions=[{broker=localhost, metric=bundleUnloading, reason=HitCount, result=Skip}], metrics=[{brk_lb_unload_broker_breakdown_total=3}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Deleted}], metrics=[{brk_sunit_state_chn_owner_lookup_total=13}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Assigning}], metrics=[{brk_sunit_state_chn_owner_lookup_total=8}], dimensions=[{broker=localhost, event=Deleted, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_subscribe_ops_total=14}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure}], metrics=[{brk_sunit_state_chn_cleanup_ops_total=4}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Failure, state=Deleted}], metrics=[{brk_sunit_state_chn_owner_lookup_total=14}], dimensions=[{broker=localhost, metric=assign, result=Failure}], metrics=[{brk_lb_assign_broker_breakdown_total=2}], dimensions=[{broker=localhost, event=Unload, metric=sunitStateChn, result=Total}], metrics=[{brk_sunit_state_chn_event_publish_ops_total=5}], dimensions=[{broker=localhost, metric=bundlesSplit}], metrics=[{brk_lb_bundles_split_total=35}], dimensions=[{broker=localhost, metric=sunitStateChn, result=Total, state=Free}], metrics=[{brk_sunit_state_chn_owner_lookup_total=3}], dimensions=[{broker=localhost, metric=bundlesSplit, reason=Topics, result=Success}], metrics=[{brk_lb_bundles_split_breakdown_total=1}]]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:2036)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:1963)\r\n  \tat org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerImplTest.testGetMetrics(ExtensibleLoadManagerImplTest.java:1484)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1904,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java"
    ],
    "base_commit": "fb80007a47deaadb82d0b1b1e4fcd6ca04c05c9c",
    "head_commit": "0e13c30df13780cd9a6e0a6ef134d6cf2175e243",
    "repo_url": "https://github.com/apache/pulsar/pull/22864",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22864",
    "dockerfile": "",
    "pr_merged_at": "2024-06-07T12:27:27.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java\nindex 07855fda4d758..43c50a8ac54f4 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerImplTest.java\n@@ -1292,6 +1292,8 @@ public void testRoleChange() throws Exception {\n     @Test\n     public void testGetMetrics() throws Exception {\n         {\n+            ServiceConfiguration conf = getDefaultConf();\n+            conf.setLoadBalancerMemoryResourceWeight(1);\n             var brokerLoadDataReporter = mock(BrokerLoadDataReporter.class);\n             FieldUtils.writeDeclaredField(primaryLoadManager, \"brokerLoadDataReporter\", brokerLoadDataReporter, true);\n             BrokerLoadData loadData = new BrokerLoadData();\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22815",
    "pr_id": 22815,
    "issue_id": 22811,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] [cli] Pulsar Tokens Create is mishandling time units (specifically, treating seconds as milliseconds)\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nThe versions affected 3.2.0 3.2.1 3.2.2 and 3.2.3\r\n\r\n### Minimal reproduce step\r\n\r\nCreate a JWT token using an affected version.\r\nbin/pulsar tokens create --secret-key /pulsar/secret.key --subject test-user --expiry-time 3600s\r\nUse a [JWT decoder](https://jwt.io/) and you will see that the expiry time is wrong.\r\n\r\n\r\n\r\n### What did you expect to see?\r\n\r\nA JWT token with the desired --expiry-time\r\n\r\n### What did you see instead?\r\n\r\nAs a workaround, you can multiply the --expiry-time by 1000 if you specify s in at the end of --expiry-time. To convert it to mili sec.\r\n\r\nThe mentioned bug affects all time units, not just seconds.\r\n\r\n### Anything else?\r\n\r\nIt appears that the bug was introduced in this pull request: [GitHub link](https://github.com/apache/pulsar/pull/21412/files). I'll work on fixing it and submit a pull request. Additionally, I'll look into adding test coverage.\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 238,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtils.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java"
    ],
    "base_commit": "a6cee2b4f331a57429dfdbbfbec9777955855edb",
    "head_commit": "be41731ac59efa2e21c1cb76e180fe52f0d6eb07",
    "repo_url": "https://github.com/apache/pulsar/pull/22815",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22815",
    "dockerfile": "",
    "pr_merged_at": "2024-06-03T16:33:44.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtils.java b/pulsar-broker/src/main/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtils.java\nindex 78268a6295c28..82f0178c9ca82 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtils.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtils.java\n@@ -40,7 +40,7 @@\n import javax.crypto.SecretKey;\n import lombok.Cleanup;\n import org.apache.pulsar.broker.authentication.utils.AuthTokenUtils;\n-import org.apache.pulsar.cli.converters.picocli.TimeUnitToSecondsConverter;\n+import org.apache.pulsar.cli.converters.picocli.TimeUnitToMillisConverter;\n import org.apache.pulsar.docs.tools.CmdGenerateDocs;\n import picocli.CommandLine;\n import picocli.CommandLine.Command;\n@@ -128,7 +128,7 @@ public static class CommandCreateToken implements Callable<Integer> {\n                 \"--expiry-time\"},\n                 description = \"Relative expiry time for the token (eg: 1h, 3d, 10y).\"\n                         + \" (m=minutes) Default: no expiration\",\n-                converter = TimeUnitToSecondsConverter.class)\n+                converter = TimeUnitToMillisConverter.class)\n         private Long expiryTime = null;\n \n         @Option(names = {\"-sk\",\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java\nindex 65c5d9981bfd2..eec568c64e313 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/utils/auth/tokens/TokensCliUtilsTest.java\n@@ -20,6 +20,8 @@\n \n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertTrue;\n+\n+import io.jsonwebtoken.Claims;\n import io.jsonwebtoken.JwsHeader;\n import io.jsonwebtoken.Jwt;\n import io.jsonwebtoken.Jwts;\n@@ -27,7 +29,12 @@\n import java.io.ByteArrayOutputStream;\n import java.io.PrintStream;\n import java.lang.reflect.Field;\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n import java.util.Arrays;\n+import java.util.Date;\n+\n+import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n import picocli.CommandLine.Option;\n \n@@ -36,6 +43,18 @@\n  */\n public class TokensCliUtilsTest {\n \n+    @DataProvider(name = \"desiredExpireTime\")\n+    public Object[][] desiredExpireTime() {\n+        return new Object[][] {\n+                {\"600\", 600}, //10m\n+                {\"5m\", 300},\n+                {\"1h\", 3600},\n+                {\"1d\", 86400},\n+                {\"1w\", 604800},\n+                {\"1y\", 31536000}\n+        };\n+    }\n+\n     @Test\n     public void testCreateToken() {\n         PrintStream oldStream = System.out;\n@@ -75,6 +94,44 @@ public void testCreateToken() {\n         }\n     }\n \n+    @Test(dataProvider = \"desiredExpireTime\")\n+    public void commandCreateToken_WhenCreatingATokenWithExpiryTime_ShouldHaveTheDesiredExpireTime(String expireTime, int expireAsSec) throws Exception {\n+        PrintStream oldStream = System.out;\n+        try {\n+            //Arrange\n+            ByteArrayOutputStream baoStream = new ByteArrayOutputStream();\n+            System.setOut(new PrintStream(baoStream));\n+\n+            String[] command = {\"create\", \"--secret-key\",\n+                    \"data:;base64,u+FxaxYWpsTfxeEmMh8fQeS3g2jfXw4+sGIv+PTY+BY=\",\n+                    \"--subject\", \"test\",\n+                    \"--expiry-time\", expireTime,\n+            };\n+\n+            new TokensCliUtils().execute(command);\n+            String token = baoStream.toString();\n+\n+            Instant start = (new Date().toInstant().plus(expireAsSec - 5, ChronoUnit.SECONDS));\n+            Instant stop = (new Date().toInstant().plus(expireAsSec + 5, ChronoUnit.SECONDS));\n+\n+            //Act\n+            Claims jwt = Jwts.parserBuilder()\n+                    .setSigningKey(Decoders.BASE64.decode(\"u+FxaxYWpsTfxeEmMh8fQeS3g2jfXw4+sGIv+PTY+BY=\"))\n+                    .build()\n+                    .parseClaimsJws(token)\n+                    .getBody();\n+\n+            //Assert\n+            //Checks if the token expires within +-5 sec.\n+            assertTrue(( ! jwt.getExpiration().toInstant().isBefore( start ) ) && ( jwt.getExpiration().toInstant().isBefore( stop ) ));\n+\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        } finally {\n+            System.setOut(oldStream);\n+        }\n+    }\n+\n     /**\n      * Test tokens generate docs.\n      *\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22792",
    "pr_id": 22792,
    "issue_id": 22129,
    "repo": "apache/pulsar",
    "problem_statement": "Optimise seeking by timestamp\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Motivation\n\nRight now it seems that seeking a reader or a consumer to a specific timestamp is an unoptimised process that can take many seconds / over a minute for larger topics (single GB data size, tens of messages per second). From a slack comment @lhotari it appears that seeking via a timestamp is not optimised, and I'm here to propose optimising it as a valuable feature.\n\n### Solution\n\nSeeking currently works by message ID or by timestamp. I _assume_ (though I could be wrong) that seeking by messageID *is* optimised. Without going into the implementation details properly and just spitballing ideas, something like binary searching on the time, or creating a treemap from timestamp to message ID (at any level of sparsity) might allow seeking to become far faster\n\n### Alternatives\n\n_No response_\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 173,
    "test_files_count": 2,
    "non_test_files_count": 5,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedCursor.java",
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java",
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java",
      "pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java"
    ],
    "base_commit": "6d59b1a292eea1469c606a346b4a8e32afc33254",
    "head_commit": "38a8fa653ce6c61e57f47ff9594ca88b859b6a19",
    "repo_url": "https://github.com/apache/pulsar/pull/22792",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22792",
    "dockerfile": "",
    "pr_merged_at": "2025-01-09T13:05:40.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedCursor.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedCursor.java\nindex 042e03998696c..4e5e12365480c 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedCursor.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedCursor.java\n@@ -660,6 +660,31 @@ void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate<Entry>\n     void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate<Entry> condition,\n             FindEntryCallback callback, Object ctx, boolean isFindFromLedger);\n \n+\n+    /**\n+     * Find the newest entry that matches the given predicate.\n+     *\n+     * @param constraint\n+     *            search only active entries or all entries\n+     * @param condition\n+     *            predicate that reads an entry an applies a condition\n+     * @param callback\n+     *            callback object returning the resultant position\n+     * @param startPosition\n+     *           start position to search from.\n+     * @param endPosition\n+     *          end position to search to.\n+     * @param ctx\n+     *            opaque context\n+     * @param isFindFromLedger\n+     *            find the newest entry from ledger\n+     */\n+    default void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate<Entry> condition,\n+                                 Position startPosition, Position endPosition, FindEntryCallback callback,\n+                                 Object ctx, boolean isFindFromLedger) {\n+        asyncFindNewestMatching(constraint, condition, callback, ctx, isFindFromLedger);\n+    }\n+\n     /**\n      * reset the cursor to specified position to enable replay of messages.\n      *\n\ndiff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\nindex 934bfba4b0d81..50f5f36b2d53d 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedCursorImpl.java\n@@ -1272,27 +1272,55 @@ public void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate\n     @Override\n     public void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate<Entry> condition,\n             FindEntryCallback callback, Object ctx, boolean isFindFromLedger) {\n-        OpFindNewest op;\n-        Position startPosition = null;\n-        long max = 0;\n+        asyncFindNewestMatching(constraint, condition, null, null, callback, ctx,\n+                isFindFromLedger);\n+    }\n+\n+\n+    @Override\n+    public void asyncFindNewestMatching(FindPositionConstraint constraint, Predicate<Entry> condition,\n+                                        Position start, Position end, FindEntryCallback callback,\n+                                        Object ctx, boolean isFindFromLedger) {\n+        Position startPosition;\n         switch (constraint) {\n-        case SearchAllAvailableEntries:\n-            startPosition = getFirstPosition();\n-            max = ledger.getNumberOfEntries() - 1;\n-            break;\n-        case SearchActiveEntries:\n-            startPosition = ledger.getNextValidPosition(markDeletePosition);\n-            max = getNumberOfEntriesInStorage();\n-            break;\n-        default:\n-            callback.findEntryFailed(new ManagedLedgerException(\"Unknown position constraint\"), Optional.empty(), ctx);\n-            return;\n+            case SearchAllAvailableEntries ->\n+                    startPosition = start == null ?  getFirstPosition() : start;\n+            case SearchActiveEntries -> {\n+                if (start == null) {\n+                    startPosition = ledger.getNextValidPosition(markDeletePosition);\n+                } else {\n+                    startPosition = start;\n+                    startPosition = startPosition.compareTo(markDeletePosition) <= 0\n+                            ? ledger.getNextValidPosition(startPosition) : startPosition;\n+                }\n+            }\n+            default -> {\n+                callback.findEntryFailed(\n+                        new ManagedLedgerException(\"Unknown position constraint\"), Optional.empty(), ctx);\n+                return;\n+            }\n         }\n+        // startPosition can't be null, should never go here.\n         if (startPosition == null) {\n             callback.findEntryFailed(new ManagedLedgerException(\"Couldn't find start position\"),\n                     Optional.empty(), ctx);\n             return;\n         }\n+        // Calculate the end position\n+        Position endPosition = end == null ? ledger.lastConfirmedEntry : end;\n+        endPosition = endPosition.compareTo(ledger.lastConfirmedEntry) > 0 ? ledger.lastConfirmedEntry : endPosition;\n+        // Calculate the number of entries between the startPosition and endPosition\n+        long max = 0;\n+        if (startPosition.compareTo(endPosition) <= 0) {\n+            max = ledger.getNumberOfEntries(Range.closed(startPosition, endPosition));\n+        }\n+\n+        if (max <= 0) {\n+            callback.findEntryComplete(null, ctx);\n+            return;\n+        }\n+\n+        OpFindNewest op;\n         if (isFindFromLedger) {\n             op = new OpFindNewest(this.ledger, startPosition, condition, max, callback, ctx);\n         } else {\n\ndiff --git a/pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java b/pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java\nindex 0b6f0e9418cf9..d27661d0ee65e 100644\n--- a/pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java\n+++ b/pulsar-broker-common/src/main/java/org/apache/pulsar/broker/ServiceConfiguration.java\n@@ -2238,6 +2238,24 @@ The max allowed delay for delayed delivery (in milliseconds). If the broker rece\n         doc = \"Max time before triggering a rollover on a cursor ledger\"\n     )\n     private int managedLedgerCursorRolloverTimeInSeconds = 14400;\n+\n+    @FieldContext(\n+            category = CATEGORY_STORAGE_ML,\n+            dynamic = true,\n+            doc = \"When resetting a subscription by timestamp, the broker will use the\"\n+                    + \" ledger closing timestamp metadata to determine the range of ledgers\"\n+                    + \" to search for the message where the subscription position is reset to. \"\n+                    + \" Since by default, the search condition is based on the message publish time provided by the \"\n+                    + \" client at the publish time, there will be some clock skew between the ledger closing timestamp \"\n+                    + \" metadata and the publish time.\"\n+                    + \" This configuration is used to set the max clock skew between the ledger closing\"\n+                    + \" timestamp and the message publish time for finding the range of ledgers to open for searching.\"\n+                    + \" The default value is 60000 milliseconds (60 seconds). When set to -1, the broker will not\"\n+                    + \" use the ledger closing timestamp metadata to determine the range of ledgers to search for the\"\n+                    + \" message.\"\n+    )\n+    private int managedLedgerCursorResetLedgerCloseTimestampMaxClockSkewMillis = 60000;\n+\n     @FieldContext(\n         category = CATEGORY_STORAGE_ML,\n         doc = \"Max number of `acknowledgment holes` that are going to be persistently stored.\\n\\n\"\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\nindex 08273155e4cfa..5a4631cf205f1 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentMessageFinder.java\n@@ -25,6 +25,9 @@\n import org.apache.bookkeeper.mledger.ManagedCursor;\n import org.apache.bookkeeper.mledger.ManagedLedgerException;\n import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.PositionFactory;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+import org.apache.commons.lang3.tuple.Pair;\n import org.apache.pulsar.client.impl.MessageImpl;\n import org.apache.pulsar.common.protocol.Commands;\n import org.apache.pulsar.common.util.Codec;\n@@ -37,6 +40,7 @@\n public class PersistentMessageFinder implements AsyncCallbacks.FindEntryCallback {\n     private final ManagedCursor cursor;\n     private final String subName;\n+    private final int ledgerCloseTimestampMaxClockSkewMillis;\n     private final String topicName;\n     private long timestamp = 0;\n \n@@ -48,19 +52,23 @@ public class PersistentMessageFinder implements AsyncCallbacks.FindEntryCallback\n             AtomicIntegerFieldUpdater\n                     .newUpdater(PersistentMessageFinder.class, \"messageFindInProgress\");\n \n-    public PersistentMessageFinder(String topicName, ManagedCursor cursor) {\n+    public PersistentMessageFinder(String topicName, ManagedCursor cursor, int ledgerCloseTimestampMaxClockSkewMillis) {\n         this.topicName = topicName;\n         this.cursor = cursor;\n         this.subName = Codec.decode(cursor.getName());\n+        this.ledgerCloseTimestampMaxClockSkewMillis = ledgerCloseTimestampMaxClockSkewMillis;\n     }\n \n     public void findMessages(final long timestamp, AsyncCallbacks.FindEntryCallback callback) {\n-        this.timestamp = timestamp;\n         if (messageFindInProgressUpdater.compareAndSet(this, FALSE, TRUE)) {\n+            this.timestamp = timestamp;\n             if (log.isDebugEnabled()) {\n                 log.debug(\"[{}] Starting message position find at timestamp {}\", subName, timestamp);\n             }\n-\n+            Pair<Position, Position> range =\n+                    getFindPositionRange(cursor.getManagedLedger().getLedgersInfo().values(),\n+                            cursor.getManagedLedger().getLastConfirmedEntry(), timestamp,\n+                            ledgerCloseTimestampMaxClockSkewMillis);\n             cursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, entry -> {\n                 try {\n                     long entryTimestamp = Commands.getEntryTimestamp(entry.getDataBuffer());\n@@ -71,7 +79,7 @@ public void findMessages(final long timestamp, AsyncCallbacks.FindEntryCallback\n                     entry.release();\n                 }\n                 return false;\n-            }, this, callback, true);\n+            }, range.getLeft(), range.getRight(), this, callback, true);\n         } else {\n             if (log.isDebugEnabled()) {\n                 log.debug(\"[{}][{}] Ignore message position find scheduled task, last find is still running\", topicName,\n@@ -83,6 +91,59 @@ public void findMessages(final long timestamp, AsyncCallbacks.FindEntryCallback\n         }\n     }\n \n+    public static Pair<Position, Position> getFindPositionRange(Iterable<LedgerInfo> ledgerInfos,\n+                                                                Position lastConfirmedEntry, long targetTimestamp,\n+                                                                int ledgerCloseTimestampMaxClockSkewMillis) {\n+        if (ledgerCloseTimestampMaxClockSkewMillis < 0) {\n+            // this feature is disabled when the value is negative\n+            return Pair.of(null, null);\n+        }\n+\n+        long targetTimestampMin = targetTimestamp - ledgerCloseTimestampMaxClockSkewMillis;\n+        long targetTimestampMax = targetTimestamp + ledgerCloseTimestampMaxClockSkewMillis;\n+\n+        Position start = null;\n+        Position end = null;\n+\n+        LedgerInfo secondToLastLedgerInfo = null;\n+        LedgerInfo lastLedgerInfo = null;\n+        for (LedgerInfo info : ledgerInfos) {\n+            if (!info.hasTimestamp()) {\n+                // unexpected case, don't set start and end\n+                return Pair.of(null, null);\n+            }\n+            secondToLastLedgerInfo = lastLedgerInfo;\n+            lastLedgerInfo = info;\n+            long closeTimestamp = info.getTimestamp();\n+            // For an open ledger, closeTimestamp is 0\n+            if (closeTimestamp == 0) {\n+                end = null;\n+                break;\n+            }\n+            if (closeTimestamp <= targetTimestampMin) {\n+                start = PositionFactory.create(info.getLedgerId(), 0);\n+            } else if (closeTimestamp > targetTimestampMax) {\n+                // If the close timestamp is greater than the timestamp\n+                end = PositionFactory.create(info.getLedgerId(), info.getEntries() - 1);\n+                break;\n+            }\n+        }\n+        // If the second-to-last ledger's close timestamp is less than the target timestamp, then start from the\n+        // first entry of the last ledger when there are confirmed entries in the ledger\n+        if (lastLedgerInfo != null && secondToLastLedgerInfo != null\n+                && secondToLastLedgerInfo.getTimestamp() > 0\n+                && secondToLastLedgerInfo.getTimestamp() < targetTimestampMin) {\n+            Position firstPositionInLedger = PositionFactory.create(lastLedgerInfo.getLedgerId(), 0);\n+            if (lastConfirmedEntry != null\n+                    && lastConfirmedEntry.compareTo(firstPositionInLedger) >= 0) {\n+                start = firstPositionInLedger;\n+            } else {\n+                start = lastConfirmedEntry;\n+            }\n+        }\n+        return Pair.of(start, end);\n+    }\n+\n     private static final Logger log = LoggerFactory.getLogger(PersistentMessageFinder.class);\n \n     @Override\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\nindex b5a1a9db5deb1..a96a7e75506eb 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentSubscription.java\n@@ -134,6 +134,7 @@ public class PersistentSubscription extends AbstractSubscription {\n     private volatile CompletableFuture<Void> fenceFuture;\n     private volatile CompletableFuture<Void> inProgressResetCursorFuture;\n     private volatile Boolean replicatedControlled;\n+    private final ServiceConfiguration config;\n \n     static Map<String, Long> getBaseCursorProperties(Boolean isReplicated) {\n         return isReplicated != null && isReplicated ? REPLICATED_SUBSCRIPTION_CURSOR_PROPERTIES :\n@@ -156,6 +157,7 @@ public PersistentSubscription(PersistentTopic topic, String subscriptionName, Ma\n     public PersistentSubscription(PersistentTopic topic, String subscriptionName, ManagedCursor cursor,\n                                   Boolean replicated, Map<String, String> subscriptionProperties) {\n         this.topic = topic;\n+        this.config = topic.getBrokerService().getPulsar().getConfig();\n         this.cursor = cursor;\n         this.topicName = topic.getName();\n         this.subName = subscriptionName;\n@@ -166,7 +168,7 @@ public PersistentSubscription(PersistentTopic topic, String subscriptionName, Ma\n         }\n         this.subscriptionProperties = MapUtils.isEmpty(subscriptionProperties)\n                 ? Collections.emptyMap() : Collections.unmodifiableMap(subscriptionProperties);\n-        if (topic.getBrokerService().getPulsar().getConfig().isTransactionCoordinatorEnabled()\n+        if (config.isTransactionCoordinatorEnabled()\n                 && !isEventSystemTopic(TopicName.get(topicName))\n                 && !ExtensibleLoadManagerImpl.isInternalTopic(topicName)) {\n             this.pendingAckHandle = new PendingAckHandleImpl(this);\n@@ -203,7 +205,6 @@ public boolean isReplicated() {\n \n     public boolean setReplicated(boolean replicated) {\n         replicatedControlled = replicated;\n-        ServiceConfiguration config = topic.getBrokerService().getPulsar().getConfig();\n \n         if (!replicated || !config.isEnableReplicatedSubscriptions()) {\n             this.replicatedSubscriptionSnapshotCache = null;\n@@ -261,7 +262,6 @@ private CompletableFuture<Void> addConsumerInternal(Consumer consumer) {\n                         case Shared:\n                             if (dispatcher == null || dispatcher.getType() != SubType.Shared) {\n                                 previousDispatcher = dispatcher;\n-                                ServiceConfiguration config = topic.getBrokerService().getPulsar().getConfig();\n                                 if (config.isSubscriptionSharedUseClassicPersistentImplementation()) {\n                                     dispatcher = new PersistentDispatcherMultipleConsumersClassic(topic, cursor, this);\n                                 } else {\n@@ -290,7 +290,6 @@ private CompletableFuture<Void> addConsumerInternal(Consumer consumer) {\n                                     || !((StickyKeyDispatcher) dispatcher)\n                                     .hasSameKeySharedPolicy(ksm)) {\n                                 previousDispatcher = dispatcher;\n-                                ServiceConfiguration config = topic.getBrokerService().getPulsar().getConfig();\n                                 if (config.isSubscriptionKeySharedUseClassicPersistentImplementation()) {\n                                     dispatcher =\n                                             new PersistentStickyKeyDispatcherMultipleConsumersClassic(topic, cursor,\n@@ -426,7 +425,7 @@ public void acknowledgeMessage(List<Position> positions, AckType ackType, Map<St\n                 log.debug(\"[{}][{}] Individual acks on {}\", topicName, subName, positions);\n             }\n             cursor.asyncDelete(positions, deleteCallback, previousMarkDeletePosition);\n-            if (topic.getBrokerService().getPulsar().getConfig().isTransactionCoordinatorEnabled()) {\n+            if (config.isTransactionCoordinatorEnabled()) {\n                 positions.forEach(position -> {\n                     if ((cursor.isMessageDeleted(position))) {\n                         pendingAckHandle.clearIndividualPosition(position);\n@@ -602,10 +601,9 @@ public CompletableFuture<AnalyzeBacklogResult> analyzeBacklog(Optional<Position>\n         final EntryFilterSupport entryFilterSupport = dispatcher != null\n                 ? (EntryFilterSupport) dispatcher : new EntryFilterSupport(this);\n         // we put some hard limits on the scan, in order to prevent denial of services\n-        ServiceConfiguration configuration = topic.getBrokerService().getPulsar().getConfiguration();\n-        long maxEntries = configuration.getSubscriptionBacklogScanMaxEntries();\n-        long timeOutMs = configuration.getSubscriptionBacklogScanMaxTimeMs();\n-        int batchSize = configuration.getDispatcherMaxReadBatchSize();\n+        long maxEntries = config.getSubscriptionBacklogScanMaxEntries();\n+        long timeOutMs = config.getSubscriptionBacklogScanMaxTimeMs();\n+        int batchSize = config.getDispatcherMaxReadBatchSize();\n         AtomicReference<Position> firstPosition = new AtomicReference<>();\n         AtomicReference<Position> lastPosition = new AtomicReference<>();\n         final Predicate<Entry> condition = entry -> {\n@@ -780,7 +778,8 @@ public void skipEntriesFailed(ManagedLedgerException exception, Object ctx) {\n     @Override\n     public CompletableFuture<Void> resetCursor(long timestamp) {\n         CompletableFuture<Void> future = new CompletableFuture<>();\n-        PersistentMessageFinder persistentMessageFinder = new PersistentMessageFinder(topicName, cursor);\n+        PersistentMessageFinder persistentMessageFinder = new PersistentMessageFinder(topicName, cursor,\n+                config.getManagedLedgerCursorResetLedgerCloseTimestampMaxClockSkewMillis());\n \n         if (log.isDebugEnabled()) {\n             log.debug(\"[{}][{}] Resetting subscription to timestamp {}\", topicName, subName, timestamp);\n",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\nindex 69b74fcf8f5c1..d3ea98131ad8f 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ManagedCursorTest.java\n@@ -4873,6 +4873,297 @@ public void operationFailed(ManagedLedgerException exception) {\n         assertEquals(cursor.getReadPosition(), markDeletedPosition.getNext());\n     }\n \n+    @Test\n+    public void testFindNewestMatching_SearchAllAvailableEntries_ByStartAndEnd() throws Exception {\n+        ManagedLedgerConfig managedLedgerConfig = new ManagedLedgerConfig();\n+        managedLedgerConfig.setMaxEntriesPerLedger(2);\n+        managedLedgerConfig.setMinimumRolloverTime(0, TimeUnit.MILLISECONDS);\n+        @Cleanup\n+        ManagedLedgerImpl ledger = (ManagedLedgerImpl) factory.open(\"testFindNewestMatching_SearchAllAvailableEntries_ByStartAndEnd\", managedLedgerConfig);\n+        @Cleanup\n+        ManagedCursor managedCursor = ledger.openCursor(\"test\");\n+\n+        Position position = ledger.addEntry(\"test\".getBytes(Encoding));\n+        Position position1 = ledger.addEntry(\"test1\".getBytes(Encoding));\n+        Position position2 = ledger.addEntry(\"test2\".getBytes(Encoding));\n+        Position position3 = ledger.addEntry(\"test3\".getBytes(Encoding));\n+\n+        Predicate<Entry> condition = entry -> {\n+            try {\n+                Position p = entry.getPosition();\n+                return p.compareTo(position1) <= 0;\n+            } finally {\n+                entry.release();\n+            }\n+        };\n+\n+        // find the newest entry with start and end position\n+        AtomicBoolean failed = new AtomicBoolean(false);\n+        CountDownLatch latch = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, condition, position, position2, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef.set(position);\n+                latch.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed.set(true);\n+                latch.countDown();\n+            }\n+        }, null, true);\n+\n+        latch.await();\n+        assertFalse(failed.get());\n+        assertNotNull(positionRef.get());\n+        assertEquals(positionRef.get(), position1);\n+\n+        // find the newest entry with start\n+        AtomicBoolean failed1 = new AtomicBoolean(false);\n+        CountDownLatch latch1 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef1 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, condition, position, null, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef1.set(position);\n+                latch1.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed1.set(true);\n+                latch1.countDown();\n+            }\n+        }, null, true);\n+        latch1.await();\n+        assertFalse(failed1.get());\n+        assertNotNull(positionRef1.get());\n+        assertEquals(positionRef1.get(), position1);\n+\n+        // find the newest entry with end\n+        AtomicBoolean failed2 = new AtomicBoolean(false);\n+        CountDownLatch latch2 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef2 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, condition, null, position2, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef2.set(position);\n+                latch2.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed2.set(true);\n+                latch2.countDown();\n+            }\n+        }, null, true);\n+        latch2.await();\n+        assertFalse(failed2.get());\n+        assertNotNull(positionRef2.get());\n+        assertEquals(positionRef2.get(), position1);\n+\n+        // find the newest entry without start and end position\n+        AtomicBoolean failed3 = new AtomicBoolean(false);\n+        CountDownLatch latch3 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef3 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, condition, null, null, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef3.set(position);\n+                latch3.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed3.set(true);\n+                latch3.countDown();\n+            }\n+        }, null, true);\n+        latch3.await();\n+        assertFalse(failed3.get());\n+        assertNotNull(positionRef3.get());\n+        assertEquals(positionRef3.get(), position1);\n+\n+        // find position3\n+        AtomicBoolean failed4 = new AtomicBoolean(false);\n+        CountDownLatch latch4 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef4 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchAllAvailableEntries, entry -> {\n+            try {\n+                Position p = entry.getPosition();\n+                return p.compareTo(position3) <= 0;\n+            } finally {\n+                entry.release();\n+            }\n+        }, position3, position3, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef4.set(position);\n+                latch4.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed4.set(true);\n+                latch4.countDown();\n+            }\n+        }, null, true);\n+        latch4.await();\n+        assertFalse(failed4.get());\n+        assertNotNull(positionRef4.get());\n+        assertEquals(positionRef4.get(), position3);\n+    }\n+\n+\n+    @Test\n+    public void testFindNewestMatching_SearchActiveEntries_ByStartAndEnd() throws Exception {\n+        ManagedLedgerConfig managedLedgerConfig = new ManagedLedgerConfig();\n+        managedLedgerConfig.setMaxEntriesPerLedger(2);\n+        managedLedgerConfig.setMinimumRolloverTime(0, TimeUnit.MILLISECONDS);\n+        @Cleanup\n+        ManagedLedgerImpl ledger = (ManagedLedgerImpl) factory.open(\"testFindNewestMatching_SearchActiveEntries_ByStartAndEnd\", managedLedgerConfig);\n+        @Cleanup\n+        ManagedCursorImpl managedCursor = (ManagedCursorImpl) ledger.openCursor(\"test\");\n+\n+        Position position = ledger.addEntry(\"test\".getBytes(Encoding));\n+        Position position1 = ledger.addEntry(\"test1\".getBytes(Encoding));\n+        Position position2 = ledger.addEntry(\"test2\".getBytes(Encoding));\n+        Position position3 = ledger.addEntry(\"test3\".getBytes(Encoding));\n+        Position position4 = ledger.addEntry(\"test4\".getBytes(Encoding));\n+        managedCursor.markDelete(position1);\n+        assertEquals(managedCursor.getNumberOfEntries(), 3);\n+\n+        Predicate<Entry> condition = entry -> {\n+            try {\n+                Position p = entry.getPosition();\n+                return p.compareTo(position3) <= 0;\n+            } finally {\n+                entry.release();\n+            }\n+        };\n+\n+        // find the newest entry with start and end position\n+        AtomicBoolean failed = new AtomicBoolean(false);\n+        CountDownLatch latch = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchActiveEntries, condition, position2, position4, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef.set(position);\n+                latch.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed.set(true);\n+                latch.countDown();\n+            }\n+        }, null, true);\n+        latch.await();\n+        assertFalse(failed.get());\n+        assertNotNull(positionRef.get());\n+        assertEquals(positionRef.get(), position3);\n+\n+        // find the newest entry with start\n+        AtomicBoolean failed1 = new AtomicBoolean(false);\n+        CountDownLatch latch1 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef1 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchActiveEntries, condition, position2, null, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef1.set(position);\n+                latch1.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed1.set(true);\n+                latch1.countDown();\n+            }\n+        }, null, true);\n+\n+        latch1.await();\n+        assertFalse(failed1.get());\n+        assertNotNull(positionRef1.get());\n+        assertEquals(positionRef1.get(), position3);\n+\n+        // find the newest entry with end\n+        AtomicBoolean failed2 = new AtomicBoolean(false);\n+        CountDownLatch latch2 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef2 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchActiveEntries, condition, null, position4, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef2.set(position);\n+                latch2.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed2.set(true);\n+                latch2.countDown();\n+            }\n+        }, null, true);\n+\n+        latch2.await();\n+        assertFalse(failed2.get());\n+        assertNotNull(positionRef2.get());\n+        assertEquals(positionRef2.get(), position3);\n+\n+        // find the newest entry without start and end position\n+        AtomicBoolean failed3 = new AtomicBoolean(false);\n+        CountDownLatch latch3 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef3 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchActiveEntries, condition, null, null, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef3.set(position);\n+                latch3.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed3.set(true);\n+                latch3.countDown();\n+            }\n+        }, null, true);\n+        latch3.await();\n+        assertFalse(failed3.get());\n+        assertNotNull(positionRef3.get());\n+        assertEquals(positionRef3.get(), position3);\n+\n+        // find position4\n+        AtomicBoolean failed4 = new AtomicBoolean(false);\n+        CountDownLatch latch4 = new CountDownLatch(1);\n+        AtomicReference<Position> positionRef4 = new AtomicReference<>();\n+        managedCursor.asyncFindNewestMatching(ManagedCursor.FindPositionConstraint.SearchActiveEntries, entry -> {\n+            try {\n+                Position p = entry.getPosition();\n+                return p.compareTo(position4) <= 0;\n+            } finally {\n+                entry.release();\n+            }\n+        }, position4, position4, new AsyncCallbacks.FindEntryCallback() {\n+            @Override\n+            public void findEntryComplete(Position position, Object ctx) {\n+                positionRef4.set(position);\n+                latch4.countDown();\n+            }\n+\n+            @Override\n+            public void findEntryFailed(ManagedLedgerException exception, Optional<Position> failedReadPosition, Object ctx) {\n+                failed4.set(true);\n+                latch4.countDown();\n+            }\n+        }, null, true);\n+        latch4.await();\n+        assertFalse(failed4.get());\n+        assertNotNull(positionRef4.get());\n+        assertEquals(positionRef4.get(), position4);\n+    }\n+\n     @Test\n     void testForceCursorRecovery() throws Exception {\n         TestPulsarMockBookKeeper bk = new TestPulsarMockBookKeeper(executor);\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\nindex 176a799292ac3..6f2f1f3a1a2c0 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/PersistentMessageFinderTest.java\n@@ -59,6 +59,7 @@\n import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n import org.apache.bookkeeper.test.MockedBookKeeperTestCase;\n import org.apache.commons.lang3.reflect.FieldUtils;\n+import org.apache.commons.lang3.tuple.Pair;\n import org.apache.pulsar.broker.service.persistent.PersistentMessageExpiryMonitor;\n import org.apache.pulsar.broker.service.persistent.PersistentMessageFinder;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n@@ -138,7 +139,7 @@ void reset() {\n     }\n \n     CompletableFuture<Void> findMessage(final Result result, final ManagedCursor c1, final long timestamp) {\n-        PersistentMessageFinder messageFinder = new PersistentMessageFinder(\"topicname\", c1);\n+        PersistentMessageFinder messageFinder = new PersistentMessageFinder(\"topicname\", c1, 0);\n \n         final CompletableFuture<Void> future = new CompletableFuture<>();\n         messageFinder.findMessages(timestamp, new AsyncCallbacks.FindEntryCallback() {\n@@ -217,7 +218,7 @@ void testPersistentMessageFinder() throws Exception {\n         assertNotEquals(result.position, null);\n         assertEquals(result.position, lastPosition);\n \n-        PersistentMessageFinder messageFinder = new PersistentMessageFinder(\"topicname\", c1);\n+        PersistentMessageFinder messageFinder = new PersistentMessageFinder(\"topicname\", c1, 0);\n         final AtomicBoolean ex = new AtomicBoolean(false);\n         messageFinder.findEntryFailed(new ManagedLedgerException(\"failed\"), Optional.empty(),\n                 new AsyncCallbacks.FindEntryCallback() {\n@@ -589,4 +590,241 @@ public void test() {\n         resetCursorData.setExcluded(true);\n         System.out.println(Entity.entity(resetCursorData, MediaType.APPLICATION_JSON));\n     }\n+\n+    @Test\n+    public void testGetFindPositionRange_EmptyLedgerInfos() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        Position lastConfirmedEntry = null;\n+        long targetTimestamp = 2000;\n+        Pair<Position, Position> range =\n+                PersistentMessageFinder.getFindPositionRange(ledgerInfos, lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNull(range.getLeft());\n+        assertNull(range.getRight());\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_AllTimestampsLessThanTarget() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(1500).build());\n+        Position lastConfirmedEntry = PositionFactory.create(2, 9);\n+\n+        long targetTimestamp = 2000;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_LastTimestampIsZero() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(1500).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(3, 5);\n+\n+        long targetTimestamp = 2000;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(3, 0));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_LastTimestampIsZeroWithNoEntries() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(1500).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(2, 9);\n+\n+        long targetTimestamp = 2000;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_AllTimestampsGreaterThanTarget() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(3000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(4000).build());\n+        Position lastConfirmedEntry = PositionFactory.create(2, 9);\n+\n+        long targetTimestamp = 2000;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getRight(), PositionFactory.create(1, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_MixedTimestamps() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(3000).build());\n+        Position lastConfirmedEntry = PositionFactory.create(3, 9);\n+\n+        long targetTimestamp = 2500;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(3, 0));\n+        assertEquals(range.getRight(), PositionFactory.create(3, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_TimestampAtBoundary() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(3000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(4).setEntries(10).setTimestamp(4000).build());\n+        Position lastConfirmedEntry = PositionFactory.create(4, 9);\n+\n+        long targetTimestamp = 3000;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(3, 0));\n+        // there might be entries in the next ledger with the same timestamp as the target timestamp, even though\n+        // the close timestamp of ledger 3 is equals to the target timestamp\n+        assertEquals(range.getRight(), PositionFactory.create(4, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_ClockSkew() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(2010).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(4).setEntries(10).setTimestamp(4000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(5).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(5, 5);\n+\n+        long targetTimestamp = 2009;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 10);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(1, 0));\n+        assertEquals(range.getRight(), PositionFactory.create(4, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_ClockSkewCase2() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(3000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(4).setEntries(10).setTimestamp(4000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(5).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(5, 5);\n+\n+        long targetTimestamp = 2995;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 10);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n+        assertEquals(range.getRight(), PositionFactory.create(4, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_ClockSkewCase3() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(3000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(4).setEntries(10).setTimestamp(4000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(5).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(5, 5);\n+\n+        long targetTimestamp = 3005;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 10);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNotNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(2, 0));\n+        assertEquals(range.getRight(), PositionFactory.create(4, 9));\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_FeatureDisabledWithNegativeClockSkew() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(2).setEntries(10).setTimestamp(2000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(3).setEntries(10).setTimestamp(2010).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(4).setEntries(10).setTimestamp(4000).build());\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(5).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(5, 5);\n+\n+        long targetTimestamp = 2009;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, -1);\n+\n+        assertNotNull(range);\n+        assertNull(range.getLeft());\n+        assertNull(range.getRight());\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_SingleLedger() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setTimestamp(0).build());\n+        Position lastConfirmedEntry = PositionFactory.create(1, 5);\n+\n+        long targetTimestamp = 2500;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNull(range.getLeft());\n+        assertNull(range.getRight());\n+    }\n+\n+    @Test\n+    public void testGetFindPositionRange_SingleClosedLedger() {\n+        List<LedgerInfo> ledgerInfos = new ArrayList<>();\n+        ledgerInfos.add(LedgerInfo.newBuilder().setLedgerId(1).setEntries(10).setTimestamp(1000).build());\n+        Position lastConfirmedEntry = PositionFactory.create(1, 9);\n+\n+        long targetTimestamp = 2500;\n+        Pair<Position, Position> range = PersistentMessageFinder.getFindPositionRange(ledgerInfos,\n+                lastConfirmedEntry, targetTimestamp, 0);\n+\n+        assertNotNull(range);\n+        assertNotNull(range.getLeft());\n+        assertNull(range.getRight());\n+        assertEquals(range.getLeft(), PositionFactory.create(1, 0));\n+    }\n }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22751",
    "pr_id": 22751,
    "issue_id": 22748,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] An error log occurs when running healthcheck after upgrading to 3.0.5\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nOS: linux\r\nJava version: 17\r\nPulsar version: 3.0.5\n\n### Minimal reproduce step\n\n1. do healthcheck\r\n2. error log occurs\n\n### What did you expect to see?\n\nno error log\n\n### What did you see instead?\n\nError log occurs at the last line.\r\n\r\n```\r\n2024-05-20T20:41:14,220+0800 [pulsar-web-42-7] INFO  org.apache.pulsar.broker.admin.impl.BrokersBase - [broker-admin] Running healthCheck with topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck\r\n2024-05-20T20:41:14,221+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ProducerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] [null] Creating producer on cnx [id: 0x3e9b8088, L:/10.130.0.150:54620 - R:10.130.0.150/10.130.0.150:6650]\r\n2024-05-20T20:41:14,224+0800 [broker-topic-workers-OrderedExecutor-15-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.130.0.150:54620] Created new producer: Producer{topic=SystemTopic{topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck}, client=[id: 0xa4af907c, L:/10.130.0.150:6650 - R:/10.130.0.150:54620] [SR:10.130.0.150, state:Connected], producerName=pulsarxx-3211-59, producerId=59}\r\n2024-05-20T20:41:14,224+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ProducerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] [pulsarxx-3211-59] Created producer on cnx [id: 0x3e9b8088, L:/10.130.0.150:54620 - R:10.130.0.150/10.130.0.150:6650]\r\n2024-05-20T20:41:14,226+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck][healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Subscribing to topic on cnx [id: 0x3e9b8088, L:/10.130.0.150:54620 - R:10.130.0.150/10.130.0.150:6650], consumerId 59\r\n2024-05-20T20:41:14,226+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.ServerCnx - [[id: 0xa4af907c, L:/10.130.0.150:6650 - R:/10.130.0.150:54620] [SR:10.130.0.150, state:Connected]] Subscribing on topic persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck / healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423. consumerId: 59\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck][healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Creating non-durable subscription at msg id 9223372036854775807:9223372036854775807:-1:-1 - {}\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.bookkeeper.mledger.impl.NonDurableCursorImpl - [pulsar/pulsarxx/10.130.0.150:8080/persistent/healthcheck] Created non-durable cursor read-position=83555506:59 mark-delete-position=83555506:58\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl - [pulsar/pulsarxx/10.130.0.150:8080/persistent/healthcheck] Opened new cursor: NonDurableCursorImpl{ledger=pulsar/pulsarxx/10.130.0.150:8080/persistent/healthcheck, cursor=healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423, ackPos=83555506:58, readPos=83555506:59}\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.pulsar.broker.service.persistent.DispatchRateLimiter - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] configured SUBSCRIPTION message-dispatch rate at broker DispatchRateImpl(dispatchThrottlingRateInMsg=0, dispatchThrottlingRateInByte=50000000, relativeToPublishRate=false, ratePeriodInSecond=1)\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.pulsar.broker.service.persistent.DispatchRateLimiter - setting message-dispatch-rate DispatchRateImpl(dispatchThrottlingRateInMsg=0, dispatchThrottlingRateInByte=50000000, relativeToPublishRate=false, ratePeriodInSecond=1)\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.bookkeeper.mledger.impl.ManagedCursorImpl - [pulsar/pulsarxx/10.130.0.150:8080/persistent/healthcheck-healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Rewind from 83555506:59 to 83555506:59\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.pulsar.broker.service.persistent.PersistentTopic - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] Disabled replicated subscriptions controller\r\n2024-05-20T20:41:14,229+0800 [BookKeeperClientWorker-OrderedExecutor-53-0] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.130.0.150:54620] Created subscription on topic persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck / healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423\r\n2024-05-20T20:41:14,229+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck][healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Subscribed to topic on 10.130.0.150/10.130.0.150:6650 -- consumer: 59\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.ServerCnx - [SystemTopic{topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck}][pulsarxx-3211-59] Closing producer on cnx /10.130.0.150:54620. producerId=59\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.ServerCnx - [SystemTopic{topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck}][pulsarxx-3211-59] Closed producer on cnx /10.130.0.150:54620. producerId=59\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ProducerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] [pulsarxx-3211-59] Closed Producer\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.130.0.150:54620] Closing consumer: consumerId=59\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.AbstractDispatcherSingleActiveConsumer - Removing consumer Consumer{subscription=PersistentSubscription{topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck, name=healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423}, consumerId=59, consumerName=3217b, address=[id: 0xa4af907c, L:/10.130.0.150:6650 - R:/10.130.0.150:54620] [SR:10.130.0.150, state:Connected]}\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.persistent.PersistentSubscription - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck][healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Successfully closed subscription [NonDurableCursorImpl{ledger=pulsar/pulsarxx/10.130.0.150:8080/persistent/healthcheck, cursor=healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423, ackPos=83555506:59, readPos=83555506:60}]\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.persistent.PersistentSubscription - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck][healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Successfully closed dispatcher for reader\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-105] INFO  org.apache.pulsar.broker.service.ServerCnx - [/10.130.0.150:54620] Closed consumer, consumerId=59\r\n2024-05-20T20:41:14,241+0800 [pulsar-io-4-104] INFO  org.apache.pulsar.client.impl.ConsumerImpl - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck] [healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423] Closed consumer\r\n2024-05-20T20:41:14,242+0800 [broker-client-shared-internal-executor-6-1] INFO  org.apache.pulsar.broker.admin.impl.BrokersBase - [broker-admin] Successfully run health check.\r\n2024-05-20T20:41:14,242+0800 [broker-client-shared-internal-executor-6-1] INFO  org.eclipse.jetty.server.RequestLog - 127.0.0.1 - - [20/May/2024:20:41:14 +0800] \"GET /admin/v2/brokers/health HTTP/1.1\" 200 2 \"-\" \"-\" 23\r\n2024-05-20T20:41:14,251+0800 [broker-topic-workers-OrderedExecutor-15-0] ERROR org.apache.pulsar.broker.service.persistent.PersistentDispatcherSingleActiveConsumer - [persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck / healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423-Consumer{subscription=PersistentSubscription{topic=persistent://pulsar/pulsarxx/10.130.0.150:8080/healthcheck, name=healthCheck-d57f97cc-1ca2-483c-8622-2e7bb0687423}, consumerId=59, consumerName=3217b, address=[id: 0xa4af907c, L:/10.130.0.150:6650 - R:/10.130.0.150:54620] [SR:10.130.0.150, state:Connected]}] Error reading entries at 83555506:60 : Cursor was already closed - Retrying to read in 15.0 seconds\r\n\r\n```\n\n### Anything else?\n\nmay be related to this pr since it raises the same exception CursorAlreadyClosedException.\r\nhttps://github.com/apache/pulsar/pull/22454/files#diff-fad355f91bd15cc041161f9a46fce62b7fee87fbfb8f0ff8a8b724a1bd1f29ee\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 1386,
    "test_files_count": 2,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumer.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumerTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumerTest.java"
    ],
    "base_commit": "67fc5b9f5342bd35d3fdacf37cf172a629ee15f9",
    "head_commit": "270b9578a22dfd4652e3836abf18999a58178cbc",
    "repo_url": "https://github.com/apache/pulsar/pull/22751",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22751",
    "dockerfile": "",
    "pr_merged_at": "2024-08-17T11:50:30.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\nindex 6eca58d070777..274bdd9947a07 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumers.java\n@@ -19,6 +19,7 @@\n package org.apache.pulsar.broker.service.persistent;\n \n import static org.apache.pulsar.broker.service.persistent.PersistentTopic.MESSAGE_RATE_BACKOFF_MS;\n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.Lists;\n import com.google.common.collect.Range;\n import java.util.ArrayList;\n@@ -299,6 +300,12 @@ public void readMoreEntriesAsync() {\n     }\n \n     public synchronized void readMoreEntries() {\n+        if (cursor.isClosed()) {\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"[{}] Cursor is already closed, skipping read more entries.\", cursor.getName());\n+            }\n+            return;\n+        }\n         if (isSendInProgress()) {\n             // we cannot read more entries while sending the previous batch\n             // otherwise we could re-read the same entries and send duplicates\n@@ -895,7 +902,14 @@ public synchronized void readEntriesFailed(ManagedLedgerException exception, Obj\n         ReadType readType = (ReadType) ctx;\n         long waitTimeMillis = readFailureBackoff.next();\n \n-        if (exception instanceof NoMoreEntriesToReadException) {\n+        // Do not keep reading more entries if the cursor is already closed.\n+        if (exception instanceof ManagedLedgerException.CursorAlreadyClosedException) {\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"[{}] Cursor is already closed, skipping read more entries\", cursor.getName());\n+            }\n+            // Set the wait time to -1 to avoid rescheduling the read.\n+            waitTimeMillis = -1;\n+        } else if (exception instanceof NoMoreEntriesToReadException) {\n             if (cursor.getNumberOfEntriesInBacklog(false) == 0) {\n                 // Topic has been terminated and there are no more entries to read\n                 // Notify the consumer only if all the messages were already acknowledged\n@@ -934,7 +948,14 @@ public synchronized void readEntriesFailed(ManagedLedgerException exception, Obj\n         }\n \n         readBatchSize = serviceConfig.getDispatcherMinReadBatchSize();\n+        // Skip read if the waitTimeMillis is a nagetive value.\n+        if (waitTimeMillis >= 0) {\n+            scheduleReadEntriesWithDelay(exception, readType, waitTimeMillis);\n+        }\n+    }\n \n+    @VisibleForTesting\n+    void scheduleReadEntriesWithDelay(Exception e, ReadType readType, long waitTimeMillis) {\n         topic.getBrokerService().executor().schedule(() -> {\n             synchronized (PersistentDispatcherMultipleConsumers.this) {\n                 // If it's a replay read we need to retry even if there's already\n@@ -944,11 +965,10 @@ public synchronized void readEntriesFailed(ManagedLedgerException exception, Obj\n                     log.info(\"[{}] Retrying read operation\", name);\n                     readMoreEntries();\n                 } else {\n-                    log.info(\"[{}] Skipping read retry: havePendingRead {}\", name, havePendingRead, exception);\n+                    log.info(\"[{}] Skipping read retry: havePendingRead {}\", name, havePendingRead, e);\n                 }\n             }\n         }, waitTimeMillis, TimeUnit.MILLISECONDS);\n-\n     }\n \n     private boolean needTrimAckedMessages() {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumer.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumer.java\nindex 600fbb26eb511..b451a8ad5dc0d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumer.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumer.java\n@@ -20,6 +20,7 @@\n \n import static org.apache.pulsar.broker.service.persistent.PersistentTopic.MESSAGE_RATE_BACKOFF_MS;\n import static org.apache.pulsar.common.protocol.Commands.DEFAULT_CONSUMER_EPOCH;\n+import com.google.common.annotations.VisibleForTesting;\n import io.netty.util.Recycler;\n import java.util.Iterator;\n import java.util.List;\n@@ -313,7 +314,14 @@ public void redeliverUnacknowledgedMessages(Consumer consumer, List<Position> po\n         redeliverUnacknowledgedMessages(consumer, DEFAULT_CONSUMER_EPOCH);\n     }\n \n-    private void readMoreEntries(Consumer consumer) {\n+    @VisibleForTesting\n+    void readMoreEntries(Consumer consumer) {\n+        if (cursor.isClosed()) {\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"[{}] Cursor is already closed, skipping read more entries\", cursor.getName());\n+            }\n+            return;\n+        }\n         // consumer can be null when all consumers are disconnected from broker.\n         // so skip reading more entries if currently there is no active consumer.\n         if (null == consumer) {\n@@ -499,6 +507,14 @@ private synchronized void internalReadEntriesFailed(ManagedLedgerException excep\n         Consumer c = readEntriesCtx.getConsumer();\n         readEntriesCtx.recycle();\n \n+        // Do not keep reading messages from a closed cursor.\n+        if (exception instanceof ManagedLedgerException.CursorAlreadyClosedException) {\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"[{}] Cursor was already closed, skipping read more entries\", cursor.getName());\n+            }\n+            return;\n+        }\n+\n         if (exception instanceof ConcurrentWaitCallbackException) {\n             // At most one pending read request is allowed when there are no more entries, we should not trigger more\n             // read operations in this case and just wait the existing read operation completes.\n@@ -535,6 +551,11 @@ private synchronized void internalReadEntriesFailed(ManagedLedgerException excep\n         // Reduce read batch size to avoid flooding bookies with retries\n         readBatchSize = serviceConfig.getDispatcherMinReadBatchSize();\n \n+        scheduleReadEntriesWithDelay(c, waitTimeMillis);\n+    }\n+\n+    @VisibleForTesting\n+    void scheduleReadEntriesWithDelay(Consumer c, long delay) {\n         topic.getBrokerService().executor().schedule(() -> {\n \n             // Jump again into dispatcher dedicated thread\n@@ -556,8 +577,7 @@ private synchronized void internalReadEntriesFailed(ManagedLedgerException excep\n                     }\n                 }\n             });\n-        }, waitTimeMillis, TimeUnit.MILLISECONDS);\n-\n+        }, delay, TimeUnit.MILLISECONDS);\n     }\n \n     @Override\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java\nindex f24c5c5933e5b..a03ed92b81590 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherMultipleConsumersTest.java\n@@ -20,15 +20,24 @@\n \n import com.carrotsearch.hppc.ObjectSet;\n import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.ManagedCursor;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException;\n+import org.apache.bookkeeper.mledger.impl.ManagedCursorImpl;\n import org.apache.pulsar.broker.BrokerTestUtil;\n import org.apache.pulsar.broker.service.Dispatcher;\n+import org.apache.pulsar.broker.service.Subscription;\n import org.apache.pulsar.client.api.Consumer;\n import org.apache.pulsar.client.api.MessageId;\n+import org.apache.pulsar.client.api.Producer;\n import org.apache.pulsar.client.api.ProducerConsumerBase;\n import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.client.api.SubscriptionType;\n import org.awaitility.reflect.WhiteboxImpl;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n import org.testng.annotations.BeforeClass;\n import org.testng.annotations.Test;\n@@ -98,4 +107,66 @@ public void testTopicDeleteIfConsumerSetMismatchConsumerList2() throws Exception\n         consumer.close();\n         admin.topics().delete(topicName, false);\n     }\n+\n+    @Test\n+    public void testSkipReadEntriesFromCloseCursor() throws Exception {\n+        final String topicName =\n+                BrokerTestUtil.newUniqueName(\"persistent://public/default/testSkipReadEntriesFromCloseCursor\");\n+        final String subscription = \"s1\";\n+        admin.topics().createNonPartitionedTopic(topicName);\n+\n+        @Cleanup\n+        Producer<String> producer = pulsarClient.newProducer(Schema.STRING).topic(topicName).create();\n+        for (int i = 0; i < 10; i++) {\n+            producer.send(\"message-\" + i);\n+        }\n+        producer.close();\n+\n+        // Get the dispatcher of the topic.\n+        PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService()\n+                .getTopic(topicName, false).join().get();\n+\n+        ManagedCursor cursor = Mockito.mock(ManagedCursorImpl.class);\n+        Mockito.doReturn(subscription).when(cursor).getName();\n+        Subscription sub = Mockito.mock(PersistentSubscription.class);\n+        Mockito.doReturn(topic).when(sub).getTopic();\n+        // Mock the dispatcher.\n+        PersistentDispatcherMultipleConsumers dispatcher =\n+                Mockito.spy(new PersistentDispatcherMultipleConsumers(topic, cursor, sub));\n+        // Return 10 permits to make the dispatcher can read more entries.\n+        Mockito.doReturn(10).when(dispatcher).getFirstAvailableConsumerPermits();\n+\n+        // Make the count + 1 when call the scheduleReadEntriesWithDelay(...).\n+        AtomicInteger callScheduleReadEntriesWithDelayCnt = new AtomicInteger(0);\n+        Mockito.doAnswer(inv -> {\n+            callScheduleReadEntriesWithDelayCnt.getAndIncrement();\n+            return inv.callRealMethod();\n+        }).when(dispatcher).scheduleReadEntriesWithDelay(Mockito.any(), Mockito.any(), Mockito.anyLong());\n+\n+        // Make the count + 1 when call the readEntriesFailed(...).\n+        AtomicInteger callReadEntriesFailed = new AtomicInteger(0);\n+        Mockito.doAnswer(inv -> {\n+            callReadEntriesFailed.getAndIncrement();\n+            return inv.callRealMethod();\n+        }).when(dispatcher).readEntriesFailed(Mockito.any(), Mockito.any());\n+\n+        Mockito.doReturn(false).when(cursor).isClosed();\n+\n+        // Mock the readEntriesOrWait(...) to simulate the cursor is closed.\n+        Mockito.doAnswer(inv -> {\n+            PersistentDispatcherMultipleConsumers dispatcher1 = inv.getArgument(2);\n+            dispatcher1.readEntriesFailed(new ManagedLedgerException.CursorAlreadyClosedException(\"cursor closed\"),\n+                    null);\n+            return null;\n+        }).when(cursor).asyncReadEntriesOrWait(Mockito.anyInt(), Mockito.anyLong(), Mockito.eq(dispatcher),\n+                Mockito.any(), Mockito.any());\n+\n+        dispatcher.readMoreEntries();\n+\n+        // Verify: the readEntriesFailed should be called once and the scheduleReadEntriesWithDelay should not be called.\n+        Assert.assertTrue(callReadEntriesFailed.get() == 1 && callScheduleReadEntriesWithDelayCnt.get() == 0);\n+\n+        // Verify: the topic can be deleted successfully.\n+        admin.topics().delete(topicName, false);\n+    }\n }\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumerTest.java\nnew file mode 100644\nindex 0000000000000..a4c9e26ffb853\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/persistent/PersistentDispatcherSingleActiveConsumerTest.java\n@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.service.persistent;\n+\n+import java.util.concurrent.atomic.AtomicInteger;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.ManagedCursor;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException;\n+import org.apache.bookkeeper.mledger.impl.ManagedCursorImpl;\n+import org.apache.pulsar.broker.BrokerTestUtil;\n+import org.apache.pulsar.broker.service.Consumer;\n+import org.apache.pulsar.broker.service.Subscription;\n+import org.apache.pulsar.client.api.Producer;\n+import org.apache.pulsar.client.api.ProducerConsumerBase;\n+import org.apache.pulsar.client.api.Schema;\n+import org.apache.pulsar.common.api.proto.CommandSubscribe;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+@Slf4j\n+@Test(groups = \"broker-api\")\n+public class PersistentDispatcherSingleActiveConsumerTest extends ProducerConsumerBase {\n+    @BeforeClass(alwaysRun = true)\n+    @Override\n+    protected void setup() throws Exception {\n+        super.internalSetup();\n+        super.producerBaseSetup();\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    @Override\n+    protected void cleanup() throws Exception {\n+        super.internalCleanup();\n+    }\n+\n+    @Test\n+    public void testSkipReadEntriesFromCloseCursor() throws Exception {\n+        final String topicName =\n+                BrokerTestUtil.newUniqueName(\"persistent://public/default/testSkipReadEntriesFromCloseCursor\");\n+        final String subscription = \"s1\";\n+        admin.topics().createNonPartitionedTopic(topicName);\n+\n+        @Cleanup\n+        Producer<String> producer = pulsarClient.newProducer(Schema.STRING).topic(topicName).create();\n+        for (int i = 0; i < 10; i++) {\n+            producer.send(\"message-\" + i);\n+        }\n+        producer.close();\n+\n+        // Get the dispatcher of the topic.\n+        PersistentTopic topic = (PersistentTopic) pulsar.getBrokerService()\n+                .getTopic(topicName, false).join().get();\n+\n+        ManagedCursor cursor = Mockito.mock(ManagedCursorImpl.class);\n+        Mockito.doReturn(subscription).when(cursor).getName();\n+        Subscription sub = Mockito.mock(PersistentSubscription.class);\n+        Mockito.doReturn(topic).when(sub).getTopic();\n+        // Mock the dispatcher.\n+        PersistentDispatcherSingleActiveConsumer dispatcher =\n+                Mockito.spy(new PersistentDispatcherSingleActiveConsumer(cursor, CommandSubscribe.SubType.Exclusive,0, topic, sub));\n+\n+        // Mock a consumer\n+        Consumer consumer = Mockito.mock(Consumer.class);\n+        consumer.getAvailablePermits();\n+        Mockito.doReturn(10).when(consumer).getAvailablePermits();\n+        Mockito.doReturn(10).when(consumer).getAvgMessagesPerEntry();\n+        Mockito.doReturn(\"test\").when(consumer).consumerName();\n+        Mockito.doReturn(true).when(consumer).isWritable();\n+        Mockito.doReturn(false).when(consumer).readCompacted();\n+\n+        // Make the consumer as the active consumer.\n+        Mockito.doReturn(consumer).when(dispatcher).getActiveConsumer();\n+\n+        // Make the count + 1 when call the scheduleReadEntriesWithDelay(...).\n+        AtomicInteger callScheduleReadEntriesWithDelayCnt = new AtomicInteger(0);\n+        Mockito.doAnswer(inv -> {\n+            callScheduleReadEntriesWithDelayCnt.getAndIncrement();\n+            return inv.callRealMethod();\n+        }).when(dispatcher).scheduleReadEntriesWithDelay(Mockito.eq(consumer), Mockito.anyLong());\n+\n+        // Make the count + 1 when call the readEntriesFailed(...).\n+        AtomicInteger callReadEntriesFailed = new AtomicInteger(0);\n+        Mockito.doAnswer(inv -> {\n+            callReadEntriesFailed.getAndIncrement();\n+            return inv.callRealMethod();\n+        }).when(dispatcher).readEntriesFailed(Mockito.any(), Mockito.any());\n+\n+        Mockito.doReturn(false).when(cursor).isClosed();\n+\n+        // Mock the readEntriesOrWait(...) to simulate the cursor is closed.\n+        Mockito.doAnswer(inv -> {\n+            PersistentDispatcherSingleActiveConsumer dispatcher1 = inv.getArgument(2);\n+            dispatcher1.readEntriesFailed(new ManagedLedgerException.CursorAlreadyClosedException(\"cursor closed\"),\n+                    null);\n+            return null;\n+        }).when(cursor).asyncReadEntriesOrWait(Mockito.anyInt(), Mockito.anyLong(), Mockito.eq(dispatcher),\n+                Mockito.any(), Mockito.any());\n+\n+        dispatcher.readMoreEntries(consumer);\n+\n+        // Verify: the readEntriesFailed should be called once and the scheduleReadEntriesWithDelay should not be called.\n+        Assert.assertTrue(callReadEntriesFailed.get() == 1 && callScheduleReadEntriesWithDelayCnt.get() == 0);\n+\n+        // Verify: the topic can be deleted successfully.\n+        admin.topics().delete(topicName, false);\n+    }\n+}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22745",
    "pr_id": 22745,
    "issue_id": 22345,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: ShadowManagedLedgerImplTest.testShadowWrites\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nhttps://github.com/apache/pulsar/actions/runs/8415552736/job/23056991961?pr=22335\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\nError:  org.apache.bookkeeper.mledger.impl.ShadowManagedLedgerImplTest.testShadowWrites  Time elapsed: 10.183 s  <<< FAILURE!\r\n  org.awaitility.core.ConditionTimeoutException: Assertion condition defined as a org.apache.bookkeeper.mledger.impl.ShadowManagedLedgerImplTest expected [5:1] but found [6:0] within 10 seconds.\r\n  \tat org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)\r\n  \tat org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)\r\n  \tat org.awaitility.core.ConditionFactory.until(ConditionFactory.java:985)\r\n  \tat org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:769)\r\n  \tat org.apache.bookkeeper.mledger.impl.ShadowManagedLedgerImplTest.testShadowWrites(ShadowManagedLedgerImplTest.java:88)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n  \tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n  \tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n  \tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n  \tat org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.runOne(InvokeMethodRunnable.java:47)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:76)\r\n  \tat org.testng.internal.invokers.InvokeMethodRunnable.call(InvokeMethodRunnable.java:11)\r\n  \tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n  \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n  \tat java.base/java.lang.Thread.run(Thread.java:840)\r\n  Caused by: java.lang.AssertionError: expected [5:1] but found [6:0]\r\n  \tat org.testng.Assert.fail(Assert.java:110)\r\n  \tat org.testng.Assert.failNotEquals(Assert.java:1577)\r\n  \tat org.testng.Assert.assertEqualsImpl(Assert.java:149)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:131)\r\n  \tat org.testng.Assert.assertEquals(Assert.java:643)\r\n  \tat org.apache.bookkeeper.mledger.impl.ShadowManagedLedgerImplTest.lambda$testShadowWrites$1(ShadowManagedLedgerImplTest.java:88)\r\n  \tat org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)\r\n  \tat org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)\r\n  \t... 4 more\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 383,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java"
    ],
    "base_commit": "9c60134f5af7c3eef11c764f06869bacab6f2344",
    "head_commit": "bc6c276e89141628b16ddfef6fa2a4d398b6b3bd",
    "repo_url": "https://github.com/apache/pulsar/pull/22745",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22745",
    "dockerfile": "",
    "pr_merged_at": "2024-05-23T03:22:58.000Z",
    "patch": "",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java\nindex 2aa04197ab91e..13dee4812b464 100644\n--- a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ShadowManagedLedgerImplTest.java\n@@ -51,7 +51,7 @@ private ShadowManagedLedgerImpl openShadowManagedLedger(String name, String sour\n         return (ShadowManagedLedgerImpl) shadowML;\n     }\n \n-    @Test(groups = \"flaky\")\n+    @Test\n     public void testShadowWrites() throws Exception {\n         ManagedLedgerImpl sourceML = (ManagedLedgerImpl) factory.open(\"source_ML\", new ManagedLedgerConfig()\n                 .setMaxEntriesPerLedger(2)\n@@ -76,16 +76,13 @@ public void testShadowWrites() throws Exception {\n         //Add new data to source ML\n         Position newPos = sourceML.addEntry(data);\n \n-        // The state should not be the same.\n-        log.info(\"Source.LCE={},Shadow.LCE={}\", sourceML.lastConfirmedEntry, shadowML.lastConfirmedEntry);\n-        assertNotEquals(sourceML.lastConfirmedEntry, shadowML.lastConfirmedEntry);\n-\n         //Add new data to source ML, and a new ledger rolled\n-        newPos = sourceML.addEntry(data);\n-        assertEquals(sourceML.ledgers.size(), 4);\n-        Awaitility.await().untilAsserted(()->assertEquals(shadowML.ledgers.size(), 4));\n+        Awaitility.await().untilAsserted(() -> {\n+            assertEquals(sourceML.ledgers.size(), 4);\n+            assertEquals(shadowML.ledgers.size(), 4);\n+            assertEquals(sourceML.lastConfirmedEntry, shadowML.lastConfirmedEntry);\n+        });\n         log.info(\"Source.LCE={},Shadow.LCE={}\", sourceML.lastConfirmedEntry, shadowML.lastConfirmedEntry);\n-        Awaitility.await().untilAsserted(()->assertEquals(sourceML.lastConfirmedEntry, shadowML.lastConfirmedEntry));\n \n         {// test write entry with ledgerId < currentLedger\n             CompletableFuture<Position> future = new CompletableFuture<>();\n@@ -146,10 +143,10 @@ public void addFailed(ManagedLedgerException exception, Object ctx) {\n             }, fakePos);\n             //This write will be queued unit new ledger is rolled in source.\n \n-            newPos = sourceML.addEntry(data); // new ledger rolled.\n-            newPos = sourceML.addEntry(data);\n+            sourceML.addEntry(data); // new ledger rolled.\n+            sourceML.addEntry(data);\n             Awaitility.await().untilAsserted(() -> {\n-                assertEquals(shadowML.ledgers.size(), 6);\n+                assertEquals(shadowML.ledgers.size(), 5);\n                 assertEquals(shadowML.currentLedgerEntries, 0);\n             });\n             assertEquals(future.get(), fakePos);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22713",
    "pr_id": 22713,
    "issue_id": 22712,
    "repo": "apache/pulsar",
    "problem_statement": "Flaky-test: AuthorizationTest.testGetListWithGetBundleOp\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Example failure\n\nn/a\n\n### Exception stacktrace\n\n<!-- copy-paste the stack trace in the code block below -->\r\n```\r\n[ERROR] Failures:\r\n[ERROR]   AuthorizationTest.testGetListWithGetBundleOp:326  ServerSideError\r\n --- An unexpected error occurred in the server ---\r\n\r\nMessage: class org.apache.pulsar.client.admin.internal.PulsarAdminImpl cannot be cast to class org.apache.pulsar.broker.ServiceConfiguration (org.apache.pulsar.client.admin.internal.PulsarAdminImpl and org.apache.pulsar.broker.ServiceConfiguration are in unnamed module of loader 'app')\r\n\r\nStacktrace:\r\n\r\njava.lang.ClassCastException: class org.apache.pulsar.client.admin.internal.PulsarAdminImpl cannot be cast to class org.apache.pulsar.broker.ServiceConfiguration (org.apache.pulsar.client.admin.internal.PulsarAdminImpl and org.apache.pulsar.broker.ServiceConfiguration are in unnamed module of loader 'app')\r\n\tat org.apache.pulsar.broker.PulsarService.getConfiguration(PulsarService.java:683)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.validateNamespaceOperationAsync(PulsarWebResource.java:1049)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.lambda$validateNamespaceOperation$37(PulsarWebResource.java:1043)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.sync(PulsarWebResource.java:1306)\r\n\tat org.apache.pulsar.broker.web.PulsarWebResource.validateNamespaceOperation(PulsarWebResource.java:1043)\r\n\tat org.apache.pulsar.broker.admin.v1.NonPersistentTopics.getList(NonPersistentTopics.java:185)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)\r\n\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)\r\n\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)\r\n\tat org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)\r\n\tat org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)\r\n\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)\r\n\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)\r\n\tat org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)\r\n\tat org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)\r\n\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)\r\n\tat org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:292)\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:274)\r\n\tat org.glassfish.jersey.internal.Errors.process(Errors.java:244)\r\n\tat org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)\r\n\tat org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)\r\n\tat org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)\r\n\tat org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)\r\n\tat org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)\r\n\tat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)\r\n\tat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)\r\n\tat org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)\r\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)\r\n\tat org.apache.pulsar.broker.web.AuthenticationFilter.doFilter(AuthenticationFilter.java:73)\r\n\tat org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)\r\n\tat org.eclipse.jetty.servlets.QoSFilter.doFilter(QoSFilter.java:202)\r\n\tat org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n\tat org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\r\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\r\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\r\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\r\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)\r\n\tat org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)\r\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\r\n\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\r\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\r\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\r\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\r\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```\r\n\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 947,
    "test_files_count": 1,
    "non_test_files_count": 0,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java"
    ],
    "base_commit": "3d260799e372138b95c573a105cab2d673076007",
    "head_commit": "0d0f99912bae7936f5bbc5bcd283967debe3ef64",
    "repo_url": "https://github.com/apache/pulsar/pull/22713",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22713",
    "dockerfile": "",
    "pr_merged_at": "2024-05-17T14:17:17.000Z",
    "patch": "",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java\nindex 6c913d4290897..6b0ff3333bbc7 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/auth/AuthorizationTest.java\n@@ -18,7 +18,6 @@\n  */\n package org.apache.pulsar.broker.auth;\n \n-import static org.mockito.Mockito.when;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n@@ -322,7 +321,6 @@ public void testGetListWithGetBundleOp() throws Exception {\n                         : brokerUrlTls.toString())\n                 .authentication(new MockAuthentication(\"pass.pass2\"))\n                 .build();\n-        when(pulsar.getAdminClient()).thenReturn(admin2);\n         Assert.assertEquals(admin2.topics().getList(namespaceV1, TopicDomain.non_persistent).size(), 0);\n         Assert.assertEquals(admin2.topics().getList(namespaceV2, TopicDomain.non_persistent).size(), 0);\n     }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22639",
    "pr_id": 22639,
    "issue_id": 22638,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] ReaderBuilder changes config state during reader creation failure due to server connection failure\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nany client version\n\n### Minimal reproduce step\n\n```\r\n@Test\r\npublic void createAsyncChangeStateIssue() throws Exception {\r\n\r\n ClientBuilder clientBuilder = PulsarClient.builder();\r\n clientBuilder.serviceUrl(\"pulsar://badUrl\");\r\n PulsarClient client = clientBuilder.build();\r\n ReaderBuilder<byte[]> readerBuilder = client.newReader()\r\n   .topic(\"persistent://tenant/ns1/t1\").startMessageFromRollbackDuration(100, TimeUnit.SECONDS);\r\n try {\r\n  readerBuilder.createAsync().get(1, TimeUnit.SECONDS);\r\n } catch (TimeoutException e) {\r\n  log.info(\"Got expected timeout exception exception, retrying\");\r\n  // The retry results in an IllegalArgumentException with message:\r\n  //   Start message id or start message from roll back must be specified\r\n  //   but they cannot be specified at the same time\r\n  readerBuilder.createAsync().get(1, TimeUnit.SECONDS);\r\n }\r\n}\r\n```\r\n\r\nOutput:\r\n```\r\njava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Start message id or start message from roll back must be specified but they cannot be specified at the same time\r\n\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)\r\n\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2096)\r\nCaused by: java.lang.IllegalArgumentException: Start message id or start message from roll back must be specified but they cannot be specified at the same time\r\n\tat org.apache.pulsar.client.impl.ReaderBuilderImpl.createAsync(ReaderBuilderImpl.java:93)\r\n```\n\n### What did you expect to see?\n\nBy any chance if ReaderBuilder fails to create Reader due to connection issue and if application retries then it should not receive `java.lang.IllegalArgumentException` because there is no such argument was given to ReaderImpl Builder. Instead Builder should not corrupt the arguments and create Reader to avoid creating lot of objects in memory and avoid memory pressure creation.\n\n### What did you see instead?\n\nClient gives `java.lang.IllegalArgumentException` even though there is no such illegal argument into the Reader Builder.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 350,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ReaderBuilderImpl.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java"
    ],
    "base_commit": "41f633f81e53bfc35ad37bb13e62def5c0dcb11d",
    "head_commit": "989c58f06b119560857dc9dcf0b0649e9d000cc1",
    "repo_url": "https://github.com/apache/pulsar/pull/22639",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22639",
    "dockerfile": "",
    "pr_merged_at": "2024-05-10T11:10:32.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ReaderBuilderImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ReaderBuilderImpl.java\nindex 2860cda0ceef1..ef230475be53b 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ReaderBuilderImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ReaderBuilderImpl.java\n@@ -86,8 +86,9 @@ public CompletableFuture<Reader<T>> createAsync() {\n                     .failedFuture(new IllegalArgumentException(\"Topic name must be set on the reader builder\"));\n         }\n \n-        if (conf.getStartMessageId() != null && conf.getStartMessageFromRollbackDurationInSec() > 0\n-                || conf.getStartMessageId() == null && conf.getStartMessageFromRollbackDurationInSec() <= 0) {\n+        boolean isStartMsgIdExist = conf.getStartMessageId() != null && conf.getStartMessageId() != MessageId.earliest;\n+        if ((isStartMsgIdExist && conf.getStartMessageFromRollbackDurationInSec() > 0)\n+                || (conf.getStartMessageId() == null && conf.getStartMessageFromRollbackDurationInSec() <= 0)) {\n             return FutureUtil\n                     .failedFuture(new IllegalArgumentException(\n                             \"Start message id or start message from roll back must be specified but they cannot be\"\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\nindex 2d3e8d4c6e978..12228220b18bd 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/impl/ReaderTest.java\n@@ -36,6 +36,8 @@\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.Future;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.pulsar.broker.auth.MockedPulsarServiceBaseTest;\n@@ -48,6 +50,7 @@\n import org.apache.pulsar.client.api.MessageRoutingMode;\n import org.apache.pulsar.client.api.Producer;\n import org.apache.pulsar.client.api.ProducerBuilder;\n+import org.apache.pulsar.client.api.PulsarClient;\n import org.apache.pulsar.client.api.PulsarClientException;\n import org.apache.pulsar.client.api.Range;\n import org.apache.pulsar.client.api.Reader;\n@@ -902,4 +905,28 @@ public void testHasMessageAvailableAfterSeekTimestamp(boolean initializeLastMess\n             assertTrue(reader.hasMessageAvailable());\n         }\n     }\n+\n+    @Test\n+    public void testReaderBuilderStateOnRetryFailure() throws Exception {\n+        String ns = \"my-property/my-ns\";\n+        String topic = \"persistent://\" + ns + \"/testRetryReader\";\n+        RetentionPolicies retention = new RetentionPolicies(-1, -1);\n+        admin.namespaces().setRetention(ns, retention);\n+        String badUrl = \"pulsar://bad-host:8080\";\n+\n+        PulsarClient client = PulsarClient.builder().serviceUrl(badUrl).build();\n+\n+        ReaderBuilder<byte[]> readerBuilder = client.newReader().topic(topic).startMessageFromRollbackDuration(100,\n+                TimeUnit.SECONDS);\n+\n+        for (int i = 0; i < 3; i++) {\n+            try {\n+                readerBuilder.createAsync().get(1, TimeUnit.SECONDS);\n+            } catch (TimeoutException e) {\n+                log.info(\"It should time out due to invalid url\");\n+            } catch (IllegalArgumentException e) {\n+                fail(\"It should not fail with corrupt reader state\");\n+            }\n+        }\n+    }\n }\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java\nindex 607689e0e2b3b..5f52f86d8b014 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/BuildersTest.java\n@@ -106,7 +106,7 @@ public void readerBuilderLoadConfTest() throws Exception {\n     @Test(expectedExceptions = {PulsarClientException.class}, expectedExceptionsMessageRegExp = \".* must be specified but they cannot be specified at the same time.*\")\n     public void shouldNotSetTwoOptAtTheSameTime() throws Exception {\n         PulsarClient client = PulsarClient.builder().serviceUrl(\"pulsar://localhost:6650\").build();\n-        try (Reader reader = client.newReader().topic(\"abc\").startMessageId(MessageId.earliest)\n+        try (Reader reader = client.newReader().topic(\"abc\").startMessageId(MessageId.latest)\n                 .startMessageFromRollbackDuration(10, TimeUnit.HOURS).create()) {\n             // no-op\n         } finally {\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22630",
    "pr_id": 22630,
    "issue_id": 22606,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] ReadonlyManagedLedger initialization does not fill in the properties\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nOS:MacOS 14.4.1 (23E224),JDK:jdk17, pulsar: branch-3.0\r\n\r\n### Minimal reproduce step\r\n\r\nSetting properties in managedLedger cannot be read using readOnlyManagedLedger\r\n\r\n### What did you expect to see?\r\n\r\nReadonlyManagedLedger initialization  fill in the properties\r\n\r\n### What did you see instead?\r\n\r\nSetting properties in managedLedger cannot be read using readOnlyManagedLedger\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 129,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImpl.java",
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImplTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImplTest.java"
    ],
    "base_commit": "084daf016294ee56496ae36e298d4e8758dc8906",
    "head_commit": "1dc0ca0d7c39776adbb63a353d0f18039e1c7048",
    "repo_url": "https://github.com/apache/pulsar/pull/22630",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22630",
    "dockerfile": "",
    "pr_merged_at": "2024-05-04T10:35:25.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImpl.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImpl.java\nindex 1fdf69395068f..707b71c9d9f09 100644\n--- a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImpl.java\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImpl.java\n@@ -32,6 +32,7 @@\n import org.apache.bookkeeper.mledger.ManagedLedgerException.MetadataNotFoundException;\n import org.apache.bookkeeper.mledger.ReadOnlyCursor;\n import org.apache.bookkeeper.mledger.impl.MetaStore.MetaStoreCallback;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo;\n import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n import org.apache.pulsar.metadata.api.Stat;\n@@ -58,6 +59,13 @@ public void operationComplete(ManagedLedgerInfo mlInfo, Stat stat) {\n                     ledgers.put(ls.getLedgerId(), ls);\n                 }\n \n+                if (mlInfo.getPropertiesCount() > 0) {\n+                    for (int i = 0; i < mlInfo.getPropertiesCount(); i++) {\n+                        MLDataFormats.KeyValue property = mlInfo.getProperties(i);\n+                        propertiesMap.put(property.getKey(), property.getValue());\n+                    }\n+                }\n+\n                 // Last ledger stat may be zeroed, we must update it\n                 if (ledgers.size() > 0 && ledgers.lastEntry().getValue().getEntries() == 0) {\n                     long lastLedgerId = ledgers.lastKey();\n",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImplTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImplTest.java\nnew file mode 100644\nindex 0000000000000..028ecad407276\n--- /dev/null\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/ReadOnlyManagedLedgerImplTest.java\n@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import static org.testng.Assert.assertEquals;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import org.apache.bookkeeper.mledger.AsyncCallbacks;\n+import org.apache.bookkeeper.mledger.ManagedLedger;\n+import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException;\n+import org.apache.bookkeeper.test.MockedBookKeeperTestCase;\n+import org.testng.annotations.Test;\n+\n+public class ReadOnlyManagedLedgerImplTest extends MockedBookKeeperTestCase {\n+    private static final String MANAGED_LEDGER_NAME_NON_PROPERTIES = \"ml-non-properties\";\n+    private static final String MANAGED_LEDGER_NAME_ATTACHED_PROPERTIES = \"ml-attached-properties\";\n+\n+\n+    @Test\n+    public void testReadOnlyManagedLedgerImplAttachProperties()\n+            throws ManagedLedgerException, InterruptedException, ExecutionException, TimeoutException {\n+        final ManagedLedger ledger = factory.open(MANAGED_LEDGER_NAME_ATTACHED_PROPERTIES,\n+                new ManagedLedgerConfig().setRetentionTime(1, TimeUnit.HOURS));\n+        final String propertiesKey = \"test-key\";\n+        final String propertiesValue = \"test-value\";\n+\n+        ledger.setConfig(new ManagedLedgerConfig());\n+        ledger.addEntry(\"entry-0\".getBytes());\n+        Map<String, String> properties = new HashMap<>();\n+        properties.put(propertiesKey, propertiesValue);\n+        ledger.setProperties(Collections.unmodifiableMap(properties));\n+        CompletableFuture<Void> future = new CompletableFuture<>();\n+        factory.asyncOpenReadOnlyManagedLedger(MANAGED_LEDGER_NAME_ATTACHED_PROPERTIES,\n+                new AsyncCallbacks.OpenReadOnlyManagedLedgerCallback() {\n+                    @Override\n+                    public void openReadOnlyManagedLedgerComplete(ReadOnlyManagedLedgerImpl managedLedger,\n+                                                                  Object ctx) {\n+                        managedLedger.getProperties().forEach((key, value) -> {\n+                            assertEquals(key, propertiesKey);\n+                            assertEquals(value, propertiesValue);\n+                        });\n+                        future.complete(null);\n+                    }\n+\n+                    @Override\n+                    public void openReadOnlyManagedLedgerFailed(ManagedLedgerException exception, Object ctx) {\n+                        future.completeExceptionally(exception);\n+                    }\n+                }, new ManagedLedgerConfig(), null);\n+\n+        future.get(60, TimeUnit.SECONDS);\n+    }\n+\n+    @Test\n+    public void testReadOnlyManagedLedgerImplNoProperties()\n+            throws ManagedLedgerException, InterruptedException, ExecutionException, TimeoutException {\n+        final ManagedLedger ledger = factory.open(MANAGED_LEDGER_NAME_NON_PROPERTIES,\n+                new ManagedLedgerConfig().setRetentionTime(1, TimeUnit.HOURS));\n+        ledger.setConfig(new ManagedLedgerConfig());\n+        ledger.addEntry(\"entry-0\".getBytes());\n+        CompletableFuture<Void> future = new CompletableFuture<>();\n+        factory.asyncOpenReadOnlyManagedLedger(MANAGED_LEDGER_NAME_NON_PROPERTIES,\n+                new AsyncCallbacks.OpenReadOnlyManagedLedgerCallback() {\n+                    @Override\n+                    public void openReadOnlyManagedLedgerComplete(ReadOnlyManagedLedgerImpl managedLedger,\n+                                                                  Object ctx) {\n+                        assertEquals(managedLedger.getProperties().size(), 0);\n+                        future.complete(null);\n+                    }\n+\n+                    @Override\n+                    public void openReadOnlyManagedLedgerFailed(ManagedLedgerException exception, Object ctx) {\n+                        future.completeExceptionally(exception);\n+                    }\n+                }, new ManagedLedgerConfig(), null);\n+\n+        future.get(60, TimeUnit.SECONDS);\n+    }\n+\n+}\n\\ No newline at end of file\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22619",
    "pr_id": 22619,
    "issue_id": 22618,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Consumer doesn't consider batch max number of messages configuration and return less number of messages\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\nany version\n\n### Minimal reproduce step\n\n1. Create consumer with `BatchReceivePolicy` with `maxNumMessages=2000` and higher `maxNumBytes` and `timeout` config values.\r\n2. Producer publishes > 2000 messages but still consumer `batchReceive`  always return 1000 messages even if consumer application wants to consume based on given configuration.\n\n### What did you expect to see?\n\nConsumer applications should expect a number of batch messages based on the batch-receive policy regardless of tuning other configurations as users are not aware of any internal implementation of the Pulsar client lib.\n\n### What did you see instead?\n\nConsumer application always sees less number of batch messages than the configured batch policy.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 190,
    "test_files_count": 2,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBuilderImpl.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java"
    ],
    "base_commit": "bc44280e88e98fdf0a815fa384a0f52508ca4b8e",
    "head_commit": "d537eac325770df12ede18581b8f7a3bd8745699",
    "repo_url": "https://github.com/apache/pulsar/pull/22619",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22619",
    "dockerfile": "",
    "pr_merged_at": "2024-05-02T23:57:49.000Z",
    "patch": "diff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBuilderImpl.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBuilderImpl.java\nindex f644c6a18398f..7686d0072cffb 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBuilderImpl.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConsumerBuilderImpl.java\n@@ -120,6 +120,10 @@ public CompletableFuture<Consumer<T>> subscribeAsync() {\n             return FutureUtil.failedFuture(\n                     new InvalidConfigurationException(\"KeySharedPolicy must set with KeyShared subscription\"));\n         }\n+        if (conf.getBatchReceivePolicy() != null) {\n+            conf.setReceiverQueueSize(\n+                    Math.max(conf.getBatchReceivePolicy().getMaxNumMessages(), conf.getReceiverQueueSize()));\n+        }\n         CompletableFuture<Void> applyDLQConfig;\n         if (conf.isRetryEnable() && conf.getTopicNames().size() > 0) {\n             TopicName topicFirst = TopicName.get(conf.getTopicNames().iterator().next());\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java\nindex d54b1c99e3e13..974d25aad64db 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/ConsumerBatchReceiveTest.java\n@@ -112,7 +112,7 @@ public Object[][] batchReceivePolicyProvider() {\n                 // Number of message limitation exceed receiverQueue size\n                 {\n                     BatchReceivePolicy.builder()\n-                        .maxNumMessages(70)\n+                        .maxNumMessages(50)\n                         .build(), true, 50, false\n                 },\n                 // Number of message limitation exceed receiverQueue size and timeout limitation\n@@ -147,7 +147,7 @@ public Object[][] batchReceivePolicyProvider() {\n                 // Number of message limitation exceed receiverQueue size\n                 {\n                     BatchReceivePolicy.builder()\n-                        .maxNumMessages(70)\n+                        .maxNumMessages(50)\n                         .build(), false, 50, false\n                 },\n                 // Number of message limitation exceed receiverQueue size and timeout limitation\n@@ -248,7 +248,7 @@ public Object[][] batchReceivePolicyProvider() {\n                 // Number of message limitation exceed receiverQueue size\n                 {\n                         BatchReceivePolicy.builder()\n-                                .maxNumMessages(70)\n+                                .maxNumMessages(50)\n                                 .build(), true, 50, true\n                 },\n                 // Number of message limitation exceed receiverQueue size and timeout limitation\n@@ -283,7 +283,7 @@ public Object[][] batchReceivePolicyProvider() {\n                 // Number of message limitation exceed receiverQueue size\n                 {\n                         BatchReceivePolicy.builder()\n-                                .maxNumMessages(70)\n+                                .maxNumMessages(50)\n                                 .build(), false, 50, true\n                 },\n                 // Number of message limitation exceed receiverQueue size and timeout limitation\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\nindex 70214fe6e3b87..d37bd484bfbfb 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java\n@@ -4821,6 +4821,35 @@ public void onSendAcknowledgement(Producer producer, Message message, MessageId\n         admin.topics().delete(topic, false);\n     }\n \n+    /**\n+     * It verifies that consumer receives configured number of messages into the batch.\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testBatchReceiveWithMaxBatchSize() throws Exception {\n+        int maxBatchSize = 100;\n+        final int internalQueueSize = 10;\n+        final int maxBytes = 2000000;\n+        final int timeOutInSeconds = 900;\n+        final String topic = \"persistent://my-property/my-ns/testBatchReceive\";\n+        BatchReceivePolicy batchReceivePolicy = BatchReceivePolicy.builder().maxNumBytes(maxBytes)\n+                .maxNumMessages(maxBatchSize).timeout(timeOutInSeconds, TimeUnit.SECONDS).build();\n+        @Cleanup\n+        Consumer<String> consumer = pulsarClient.newConsumer(Schema.STRING).topic(topic)\n+                .subscriptionName(\"my-subscriber-name\")\n+                .receiverQueueSize(internalQueueSize)\n+                .batchReceivePolicy(batchReceivePolicy).subscribe();\n+        @Cleanup\n+        Producer<byte[]> producer = pulsarClient.newProducer().topic(topic).enableBatching(false).create();\n+\n+        final int numMessages = 100;\n+        for (int i = 0; i < numMessages; i++) {\n+            producer.newMessage().value((\"value-\" + i).getBytes(UTF_8)).eventTime((i + 1) * 100L).send();\n+        }\n+\n+        assertEquals(consumer.batchReceive().size(), maxBatchSize);\n+    }\n+\n     private int compareMessageIds(MessageIdImpl messageId1, MessageIdImpl messageId2) {\n         if (messageId2.getLedgerId() < messageId1.getLedgerId()) {\n             return -1;\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22580",
    "pr_id": 22580,
    "issue_id": 20495,
    "repo": "apache/pulsar",
    "problem_statement": "Rewrite BrokerServiceTest#testBrokerStatsTopicLoadFailed\nThe BrokerServiceTest#testBrokerStatsTopicLoadFailed is disabled by #20494.\r\n\r\n> 2. Remove the test case and if the coverage is necessary, file a new ticket to add it back.\r\n\r\n_Originally posted by @tisonkun in https://github.com/apache/pulsar/pull/20494#pullrequestreview-1462643509_\r\n\r\nThe test BrokerServiceTest#testBrokerStatsTopicLoadFailed introduced in #19236 is invalid. \r\n* It modifies the current shared state and that causes other tests to fail. \r\n* The test uses Awaitility with a 2 minute timeout. That is too long for unit tests.\r\n\r\n            ",
    "issue_word_count": 81,
    "test_files_count": 1,
    "non_test_files_count": 1,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java"
    ],
    "base_commit": "a761b97b733142b1ade525e1d1c06785e98face1",
    "head_commit": "83e0dce176a9731f9875d927ef088d6e6db5861c",
    "repo_url": "https://github.com/apache/pulsar/pull/22580",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22580",
    "dockerfile": "",
    "pr_merged_at": "2024-04-29T12:46:43.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex 1f0cb12258e1d..b08b1a472ca20 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -1265,7 +1265,8 @@ private CompletableFuture<Optional<Topic>> createNonPersistentTopic(String topic\n             nonPersistentTopic = newTopic(topic, null, this, NonPersistentTopic.class);\n         } catch (Throwable e) {\n             log.warn(\"Failed to create topic {}\", topic, e);\n-            return FutureUtil.failedFuture(e);\n+            topicFuture.completeExceptionally(e);\n+            return topicFuture;\n         }\n         CompletableFuture<Void> isOwner = checkTopicNsOwnership(topic);\n         isOwner.thenRun(() -> {\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\nindex 8ebba5c9aeabd..5fbe147638026 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/BrokerServiceTest.java\n@@ -20,20 +20,23 @@\n \n import static org.apache.pulsar.common.naming.SystemTopicNames.TRANSACTION_COORDINATOR_ASSIGN;\n import static org.apache.pulsar.common.naming.SystemTopicNames.TRANSACTION_COORDINATOR_LOG;\n+import static org.mockito.ArgumentMatchers.anyString;\n import static org.mockito.Mockito.any;\n import static org.mockito.Mockito.doReturn;\n+import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.when;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertFalse;\n import static org.testng.Assert.assertNotNull;\n import static org.testng.Assert.assertNull;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n+import com.google.common.collect.Multimap;\n import com.google.common.collect.Sets;\n import com.google.gson.Gson;\n import com.google.gson.JsonArray;\n import com.google.gson.JsonObject;\n-import com.google.gson.JsonPrimitive;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.EventLoopGroup;\n import io.netty.util.concurrent.DefaultThreadFactory;\n@@ -79,6 +82,7 @@\n import org.apache.pulsar.broker.service.BrokerServiceException.PersistenceException;\n import org.apache.pulsar.broker.service.persistent.PersistentSubscription;\n import org.apache.pulsar.broker.service.persistent.PersistentTopic;\n+import org.apache.pulsar.broker.stats.prometheus.PrometheusMetricsClient;\n import org.apache.pulsar.broker.stats.prometheus.PrometheusRawMetricsProvider;\n import org.apache.pulsar.client.admin.BrokerStats;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n@@ -113,7 +117,11 @@\n import org.apache.pulsar.common.protocol.Commands;\n import org.apache.pulsar.common.util.netty.EventLoopUtil;\n import org.apache.pulsar.compaction.Compactor;\n+import org.apache.zookeeper.KeeperException;\n+import org.apache.zookeeper.MockZooKeeper;\n import org.awaitility.Awaitility;\n+import org.glassfish.jersey.client.JerseyClient;\n+import org.glassfish.jersey.client.JerseyClientBuilder;\n import org.mockito.Mockito;\n import org.testng.Assert;\n import org.testng.annotations.AfterClass;\n@@ -1589,82 +1597,93 @@ public void testDynamicConfigurationsForceDeleteTenantAllowed() throws Exception\n         });\n     }\n \n-    // this test is disabled since it is flaky\n-    @Test(enabled = false)\n-    public void testBrokerStatsTopicLoadFailed() throws Exception {\n-        admin.namespaces().createNamespace(\"prop/ns-test\");\n-\n-        String persistentTopic = \"persistent://prop/ns-test/topic1_\" + UUID.randomUUID();\n-        String nonPersistentTopic = \"non-persistent://prop/ns-test/topic2_\" + UUID.randomUUID();\n-\n-        BrokerService brokerService = pulsar.getBrokerService();\n-        brokerService = Mockito.spy(brokerService);\n-        // mock create persistent topic failed\n-        Mockito\n-                .doAnswer(invocation -> {\n-                    CompletableFuture<ManagedLedgerConfig> f = new CompletableFuture<>();\n-                    f.completeExceptionally(new RuntimeException(\"This is an exception\"));\n-                    return f;\n-                })\n-                .when(brokerService).getManagedLedgerConfig(Mockito.eq(TopicName.get(persistentTopic)));\n-\n-        // mock create non-persistent topic failed\n-        Mockito\n-                .doAnswer(inv -> {\n-                    CompletableFuture<Void> f = new CompletableFuture<>();\n-                    f.completeExceptionally(new RuntimeException(\"This is an exception\"));\n-                    return f;\n-                })\n-                .when(brokerService).checkTopicNsOwnership(Mockito.eq(nonPersistentTopic));\n-\n-\n-        PulsarService pulsarService = pulsar;\n-        Field field = PulsarService.class.getDeclaredField(\"brokerService\");\n-        field.setAccessible(true);\n-        field.set(pulsarService, brokerService);\n-\n-        CompletableFuture<Producer<String>> producer = pulsarClient.newProducer(Schema.STRING)\n-                .topic(persistentTopic)\n-                .createAsync();\n-        CompletableFuture<Producer<String>> producer1 = pulsarClient.newProducer(Schema.STRING)\n-                .topic(nonPersistentTopic)\n-                .createAsync();\n-\n-        producer.whenComplete((v, t) -> {\n-            if (t == null) {\n-                try {\n-                    v.close();\n-                } catch (PulsarClientException e) {\n-                    // ignore\n-                }\n+    @Test\n+    public void testMetricsPersistentTopicLoadFails() throws Exception {\n+        final String namespace = \"prop/\" + UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n+        String topic = \"persistent://\" + namespace + \"/topic1_\" + UUID.randomUUID();\n+        admin.namespaces().createNamespace(namespace);\n+        admin.topics().createNonPartitionedTopic(topic);\n+        admin.topics().unload(topic);\n+\n+        // Inject an error that makes the topic load fails.\n+        AtomicBoolean failMarker = new AtomicBoolean(true);\n+        mockZooKeeper.failConditional(KeeperException.Code.NODEEXISTS, (op, path) -> {\n+            if (failMarker.get() && op.equals(MockZooKeeper.Op.SET) &&\n+                    path.endsWith(TopicName.get(topic).getPersistenceNamingEncoding())) {\n+                return true;\n             }\n+            return false;\n         });\n-        producer1.whenComplete((v, t) -> {\n-            if (t == null) {\n-                try {\n-                    v.close();\n-                } catch (PulsarClientException e) {\n-                    // ignore\n-                }\n+\n+        // Do test\n+        CompletableFuture<Producer<byte[]>> producer = pulsarClient.newProducer().topic(topic).createAsync();\n+        JerseyClient httpClient = JerseyClientBuilder.createClient();\n+        Awaitility.await().until(() -> {\n+            String response = httpClient.target(pulsar.getWebServiceAddress()).path(\"/metrics/\")\n+                    .request().get(String.class);\n+            Multimap<String, PrometheusMetricsClient.Metric> metricMap = PrometheusMetricsClient.parseMetrics(response);\n+            if (!metricMap.containsKey(\"pulsar_topic_load_failed_count\")) {\n+                return false;\n+            }\n+            double topic_load_failed_count = 0;\n+            for (PrometheusMetricsClient.Metric metric : metricMap.get(\"pulsar_topic_load_failed_count\")) {\n+                topic_load_failed_count += metric.value;\n             }\n+            return topic_load_failed_count >= 1D;\n         });\n \n-        Awaitility.waitAtMost(2, TimeUnit.MINUTES).until(() -> {\n-            String json = admin.brokerStats().getMetrics();\n-            JsonArray metrics = new Gson().fromJson(json, JsonArray.class);\n-            AtomicBoolean flag = new AtomicBoolean(false);\n-\n-            metrics.forEach(ele -> {\n-                JsonObject obj = ((JsonObject) ele);\n-                JsonObject metrics0 = (JsonObject) obj.get(\"metrics\");\n-                JsonPrimitive v = (JsonPrimitive) metrics0.get(\"brk_topic_load_failed_count\");\n-                if (null != v && v.getAsDouble() >= 2D) {\n-                    flag.set(true);\n-                }\n-            });\n+        // Remove the injection.\n+        failMarker.set(false);\n+        // cleanup.\n+        httpClient.close();\n+        producer.join().close();\n+        admin.topics().delete(topic);\n+        admin.namespaces().deleteNamespace(namespace);\n+    }\n \n-            return flag.get();\n+    @Test\n+    public void testMetricsNonPersistentTopicLoadFails() throws Exception {\n+        final String namespace = \"prop/\" + UUID.randomUUID().toString().replaceAll(\"-\", \"\");\n+        String topic = \"non-persistent://\" + namespace + \"/topic1_\" + UUID.randomUUID();\n+        admin.namespaces().createNamespace(namespace);\n+\n+        // Inject an error that makes the topic load fails.\n+        // Since we did not set a topic factory name, the \"topicFactory\" variable is null, inject a mocked\n+        // \"topicFactory\".\n+        Field fieldTopicFactory = BrokerService.class.getDeclaredField(\"topicFactory\");\n+        fieldTopicFactory.setAccessible(true);\n+        TopicFactory originalTopicFactory = (TopicFactory) fieldTopicFactory.get(pulsar.getBrokerService());\n+        assertNull(originalTopicFactory);\n+        TopicFactory mockedTopicFactory = mock(TopicFactory.class);\n+        when(mockedTopicFactory.create(anyString(), any(), any(), any()))\n+                .thenThrow(new RuntimeException(\"mocked error\"));\n+        fieldTopicFactory.set(pulsar.getBrokerService(), mockedTopicFactory);\n+\n+        // Do test.\n+        CompletableFuture<Producer<byte[]>> producer = pulsarClient.newProducer().topic(topic).createAsync();\n+        JerseyClient httpClient = JerseyClientBuilder.createClient();\n+        Awaitility.await().until(() -> {\n+            String response = httpClient.target(pulsar.getWebServiceAddress()).path(\"/metrics/\")\n+                    .request().get(String.class);\n+            Multimap<String, PrometheusMetricsClient.Metric> metricMap = PrometheusMetricsClient.parseMetrics(response);\n+            if (!metricMap.containsKey(\"pulsar_topic_load_failed_count\")) {\n+                return false;\n+            }\n+            double topic_load_failed_count = 0;\n+            for (PrometheusMetricsClient.Metric metric : metricMap.get(\"pulsar_topic_load_failed_count\")) {\n+                topic_load_failed_count += metric.value;\n+            }\n+            return topic_load_failed_count >= 1D;\n         });\n+\n+        // Remove the injection.\n+        fieldTopicFactory.set(pulsar.getBrokerService(), null);\n+\n+        // cleanup.\n+        httpClient.close();\n+        producer.join().close();\n+        admin.topics().delete(topic);\n+        admin.namespaces().deleteNamespace(namespace);\n     }\n \n     @Test\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22573",
    "pr_id": 22573,
    "issue_id": 22569,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Broker could take 30+ seconds to close with extensible load manager\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Read release policy\r\n\r\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\r\n\r\n\r\n### Version\r\n\r\nmaster (89b201ed8a49877e0a7148b060af945b29074b02)\r\n\r\n### Minimal reproduce step\r\n\r\n```java\r\npublic class ExtensibleLoadManagerCloseTest extends MultiBrokerBaseTest {\r\n\r\n    @Override\r\n    protected void startBroker() throws Exception {\r\n        addCustomConfigs(conf);\r\n        super.startBroker();\r\n    }\r\n\r\n    @Override\r\n    protected ServiceConfiguration createConfForAdditionalBroker(int additionalBrokerIndex) {\r\n        return addCustomConfigs(getDefaultConf());\r\n    }\r\n\r\n    private static ServiceConfiguration addCustomConfigs(ServiceConfiguration config) {\r\n        config.setLoadManagerClassName(ExtensibleLoadManagerImpl.class.getName());\r\n        config.setDefaultNumberOfNamespaceBundles(16);\r\n        config.setLoadBalancerAutoBundleSplitEnabled(false);\r\n        config.setLoadBalancerDebugModeEnabled(true);\r\n        return config;\r\n    }\r\n\r\n    @Test\r\n    public void test() throws Exception {\r\n        final var topic = \"test\";\r\n        admin.topics().createPartitionedTopic(topic, 20);\r\n        admin.lookups().lookupPartitionedTopic(topic);\r\n        @Cleanup final var client = PulsarClient.builder().serviceUrl(pulsar.getBrokerServiceUrl()).build();\r\n        @Cleanup final var producer = (PartitionedProducerImpl<byte[]>) client.newProducer().topic(topic).create();\r\n    }\r\n}\r\n```\r\n\r\n### What did you expect to see?\r\n\r\nIt should not takes too long to complete.\r\n\r\n### What did you see instead?\r\n\r\nIt sometimes took about 54 seconds to complete and sometimes 22 seconds.\r\n\r\n### Anything else?\r\n\r\nWith the default load manager, it only takes about 15 seconds to complete.\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 216,
    "test_files_count": 1,
    "non_test_files_count": 3,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/store/TableViewLoadDataStoreImpl.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java"
    ],
    "base_commit": "d4756557bf4328019dd938a56c3135aecc3147e4",
    "head_commit": "cbab233302c0c1bada2bbaaec25cdf49928fc798",
    "repo_url": "https://github.com/apache/pulsar/pull/22573",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22573",
    "dockerfile": "",
    "pr_merged_at": "2024-04-26T13:30:16.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\nindex 7613a13db22de..c21c7dc771eae 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/PulsarService.java\n@@ -444,6 +444,9 @@ public CompletableFuture<Void> closeAsync() {\n                 return closeFuture;\n             }\n             LOG.info(\"Closing PulsarService\");\n+            if (brokerService != null) {\n+                brokerService.unloadNamespaceBundlesGracefully();\n+            }\n             state = State.Closing;\n \n             // close the service in reverse order v.s. in which they are started\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/store/TableViewLoadDataStoreImpl.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/store/TableViewLoadDataStoreImpl.java\nindex d916e91716223..81cf33b4a55d2 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/store/TableViewLoadDataStoreImpl.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/loadbalance/extensions/store/TableViewLoadDataStoreImpl.java\n@@ -161,12 +161,8 @@ public synchronized void init() throws IOException {\n     }\n \n     private void validateProducer() {\n-        if (producer == null || !producer.isConnected()) {\n+        if (producer == null) {\n             try {\n-                if (producer != null) {\n-                    producer.close();\n-                }\n-                producer = null;\n                 startProducer();\n                 log.info(\"Restarted producer on {}\", topic);\n             } catch (Exception e) {\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\nindex 295a9a2954126..1f0cb12258e1d 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/BrokerService.java\n@@ -309,6 +309,7 @@ public class BrokerService implements Closeable {\n     private Set<ManagedLedgerPayloadProcessor> brokerEntryPayloadProcessors;\n \n     private final TopicEventsDispatcher topicEventsDispatcher = new TopicEventsDispatcher();\n+    private volatile boolean unloaded = false;\n \n     public BrokerService(PulsarService pulsar, EventLoopGroup eventLoopGroup) throws Exception {\n         this.pulsar = pulsar;\n@@ -926,9 +927,13 @@ public void unloadNamespaceBundlesGracefully() {\n     }\n \n     public void unloadNamespaceBundlesGracefully(int maxConcurrentUnload, boolean closeWithoutWaitingClientDisconnect) {\n+        if (unloaded) {\n+            return;\n+        }\n         try {\n             log.info(\"Unloading namespace-bundles...\");\n             // make broker-node unavailable from the cluster\n+            long disableBrokerStartTime = System.nanoTime();\n             if (pulsar.getLoadManager() != null && pulsar.getLoadManager().get() != null) {\n                 try {\n                     pulsar.getLoadManager().get().disableBroker();\n@@ -937,6 +942,10 @@ public void unloadNamespaceBundlesGracefully(int maxConcurrentUnload, boolean cl\n                     // still continue and release bundle ownership as broker's registration node doesn't exist.\n                 }\n             }\n+            double disableBrokerTimeSeconds =\n+                    TimeUnit.NANOSECONDS.toMillis((System.nanoTime() - disableBrokerStartTime))\n+                            / 1000.0;\n+            log.info(\"Disable broker in load manager completed in {} seconds\", disableBrokerTimeSeconds);\n \n             // unload all namespace-bundles gracefully\n             long closeTopicsStartTime = System.nanoTime();\n@@ -966,6 +975,8 @@ public void unloadNamespaceBundlesGracefully(int maxConcurrentUnload, boolean cl\n             }\n         } catch (Exception e) {\n             log.error(\"Failed to disable broker from loadbalancer list {}\", e.getMessage(), e);\n+        } finally {\n+            unloaded = true;\n         }\n     }\n \n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java\nnew file mode 100644\nindex 0000000000000..41413f3e3a913\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/loadbalance/extensions/ExtensibleLoadManagerCloseTest.java\n@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.loadbalance.extensions;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Optional;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.pulsar.broker.PulsarService;\n+import org.apache.pulsar.broker.ServiceConfiguration;\n+import org.apache.pulsar.client.admin.PulsarAdmin;\n+import org.apache.pulsar.client.api.PulsarClient;\n+import org.apache.pulsar.common.policies.data.ClusterData;\n+import org.apache.pulsar.common.policies.data.TenantInfo;\n+import org.apache.pulsar.zookeeper.LocalBookkeeperEnsemble;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+@Slf4j\n+public class ExtensibleLoadManagerCloseTest {\n+\n+    private static final String clusterName = \"test\";\n+    private final LocalBookkeeperEnsemble bk = new LocalBookkeeperEnsemble(1, 0, () -> 0);\n+    private final List<PulsarService> brokers = new ArrayList<>();\n+    private PulsarAdmin admin;\n+\n+    @BeforeClass(alwaysRun = true)\n+    public void setup() throws Exception {\n+        bk.start();\n+        for (int i = 0; i < 3; i++) {\n+            final var broker = new PulsarService(brokerConfig());\n+            broker.start();\n+            brokers.add(broker);\n+        }\n+        admin = brokers.get(0).getAdminClient();\n+        admin.clusters().createCluster(clusterName, ClusterData.builder().build());\n+        admin.tenants().createTenant(\"public\", TenantInfo.builder()\n+                .allowedClusters(Collections.singleton(clusterName)).build());\n+        admin.namespaces().createNamespace(\"public/default\");\n+    }\n+\n+\n+    @AfterClass(alwaysRun = true, timeOut = 30000)\n+    public void cleanup() throws Exception {\n+        bk.stop();\n+    }\n+\n+    private ServiceConfiguration brokerConfig() {\n+        final var config = new ServiceConfiguration();\n+        config.setClusterName(clusterName);\n+        config.setAdvertisedAddress(\"localhost\");\n+        config.setBrokerServicePort(Optional.of(0));\n+        config.setWebServicePort(Optional.of(0));\n+        config.setMetadataStoreUrl(\"zk:127.0.0.1:\" + bk.getZookeeperPort());\n+        config.setManagedLedgerDefaultWriteQuorum(1);\n+        config.setManagedLedgerDefaultAckQuorum(1);\n+        config.setManagedLedgerDefaultEnsembleSize(1);\n+        config.setDefaultNumberOfNamespaceBundles(16);\n+        config.setLoadBalancerAutoBundleSplitEnabled(false);\n+        config.setLoadManagerClassName(ExtensibleLoadManagerImpl.class.getName());\n+        config.setLoadBalancerDebugModeEnabled(true);\n+        config.setBrokerShutdownTimeoutMs(100);\n+        return config;\n+    }\n+\n+\n+    @Test\n+    public void testCloseAfterLoadingBundles() throws Exception {\n+        final var topic = \"test\";\n+        admin.topics().createPartitionedTopic(topic, 20);\n+        admin.lookups().lookupPartitionedTopic(topic);\n+        final var client = PulsarClient.builder().serviceUrl(brokers.get(0).getBrokerServiceUrl()).build();\n+        final var producer = client.newProducer().topic(topic).create();\n+        producer.close();\n+        client.close();\n+\n+        final var closeTimeMsList = new ArrayList<Long>();\n+        for (var broker : brokers) {\n+            final var startTimeMs = System.currentTimeMillis();\n+            broker.close();\n+            closeTimeMsList.add(System.currentTimeMillis() - startTimeMs);\n+        }\n+        log.info(\"Brokers close time: {}\", closeTimeMsList);\n+        for (var closeTimeMs : closeTimeMsList) {\n+            Assert.assertTrue(closeTimeMs < 5000L);\n+        }\n+    }\n+}\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22572",
    "pr_id": 22572,
    "issue_id": 22571,
    "repo": "apache/pulsar",
    "problem_statement": "[Bug] Reader stuck after call hasMessageAvailable when enable replicateSubscriptionState\n### Search before asking\n\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\n\n\n### Read release policy\n\n- [X] I understand that unsupported versions don't get bug fixes. I will attempt to reproduce the issue on a supported version of Pulsar client and Pulsar broker.\n\n\n### Version\n\n- master\r\n- 3.2.x\r\n- 3.1.x\r\n- 3.0.x.\r\n- 2.11.x\n\n### Minimal reproduce step\n\n\r\nIn geo-replication case. Let's say there are two clusters: `r1`, `r2`, will replicator topic:`my-topic` from `r1` and `r2`.\r\n\r\nThe consumer1 subscribes to the topic `my-topic` of `r1` and enables `replicateSubscriptionState`.  After the subscription state sync to `r2`: `my-topic`, create a `reader` read the message from `r2`:`my-topic` will stuck on `readNext`.\r\n\r\nPlease copy this test to `ReplicatorSubscriptionTest` to run it. \r\n```java\r\n    @Test\r\n    public void testReplicatedSubscriptionAcrossTwoRegionsGetLastMessage() throws Exception {\r\n        String namespace = BrokerTestUtil.newUniqueName(\"pulsar/replicatedsubscriptionlastmessage\");\r\n        String topicName = \"persistent://\" + namespace + \"/mytopic\";\r\n        String subscriptionName = \"cluster-subscription\";\r\n        // this setting can be used to manually run the test with subscription replication disabled\r\n        // it shows that subscription replication has no impact in behavior for this test case\r\n        boolean replicateSubscriptionState = true;\r\n\r\n        admin1.namespaces().createNamespace(namespace);\r\n        admin1.namespaces().setNamespaceReplicationClusters(namespace, Sets.newHashSet(\"r1\", \"r2\"));\r\n\r\n        @Cleanup\r\n        PulsarClient client1 = PulsarClient.builder().serviceUrl(url1.toString())\r\n                .statsInterval(0, TimeUnit.SECONDS)\r\n                .build();\r\n\r\n        // create subscription in r1\r\n        createReplicatedSubscription(client1, topicName, subscriptionName, replicateSubscriptionState);\r\n\r\n        @Cleanup\r\n        PulsarClient client2 = PulsarClient.builder().serviceUrl(url2.toString())\r\n                .statsInterval(0, TimeUnit.SECONDS)\r\n                .build();\r\n\r\n        // create subscription in r2\r\n        createReplicatedSubscription(client2, topicName, subscriptionName, replicateSubscriptionState);\r\n\r\n        Set<String> sentMessages = new LinkedHashSet<>();\r\n\r\n        // send messages in r1\r\n        @Cleanup\r\n        Producer<byte[]> producer = client1.newProducer().topic(topicName)\r\n                .enableBatching(false)\r\n                .messageRoutingMode(MessageRoutingMode.SinglePartition)\r\n                .create();\r\n        int numMessages = 6;\r\n        for (int i = 0; i < numMessages; i++) {\r\n            String body = \"message\" + i;\r\n            producer.send(body.getBytes(StandardCharsets.UTF_8));\r\n            sentMessages.add(body);\r\n        }\r\n        producer.close();\r\n\r\n\r\n        // consume 3 messages in r1\r\n        Set<String> receivedMessages = new LinkedHashSet<>();\r\n        try (Consumer<byte[]> consumer1 = client1.newConsumer()\r\n                .topic(topicName)\r\n                .subscriptionName(subscriptionName)\r\n                .replicateSubscriptionState(replicateSubscriptionState)\r\n                .subscribe()) {\r\n            readMessages(consumer1, receivedMessages, 3, false);\r\n        }\r\n\r\n        // wait for subscription to be replicated\r\n        Thread.sleep(2 * config1.getReplicatedSubscriptionsSnapshotFrequencyMillis());\r\n\r\n        // create a reader in r2\r\n        Reader<byte[]> reader = client2.newReader().topic(topicName)\r\n                .subscriptionName(\"new-sub\")\r\n                .startMessageId(MessageId.earliest)\r\n                .create();\r\n        int readNum = 0;\r\n        while (reader.hasMessageAvailable()) {\r\n            Message<byte[]> message = reader.readNext(10, TimeUnit.SECONDS);\r\n            System.out.println(\"Receive message: \" + new String(message.getValue()) + \" msgId: \" + message.getMessageId());\r\n            assertNotNull(message);\r\n            readNum++;\r\n        }\r\n        assertEquals(readNum, numMessages);\r\n    }\r\n```\n\n### What did you expect to see?\n\nTest can passed. \r\n\n\n### What did you see instead?\n\nTest will stuck.\n\n### Anything else?\n\n_No response_\n\n### Are you willing to submit a PR?\n\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 426,
    "test_files_count": 4,
    "non_test_files_count": 4,
    "pr_changed_files": [
      "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtils.java",
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtilsTest.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionWithTransactionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java"
    ],
    "pr_changed_test_files": [
      "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtilsTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionWithTransactionTest.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java"
    ],
    "base_commit": "1bb9378b50aa891834b64cd39f55ae0e32a055bb",
    "head_commit": "f094e0449b2ebba77404d960ad3282e8f4151cea",
    "repo_url": "https://github.com/apache/pulsar/pull/22572",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22572",
    "dockerfile": "",
    "pr_merged_at": "2024-04-28T12:22:09.000Z",
    "patch": "diff --git a/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtils.java b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtils.java\nnew file mode 100644\nindex 0000000000000..cd8671b0e6289\n--- /dev/null\n+++ b/managed-ledger/src/main/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtils.java\n@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.util;\n+\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Predicate;\n+import org.apache.bookkeeper.mledger.AsyncCallbacks;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException;\n+import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.pulsar.common.classification.InterfaceStability;\n+\n+@InterfaceStability.Evolving\n+public class ManagedLedgerImplUtils {\n+\n+    /**\n+     * Reverse find last valid position one-entry by one-entry.\n+     */\n+    public static CompletableFuture<Position> asyncGetLastValidPosition(final ManagedLedgerImpl ledger,\n+                                                                        final Predicate<Entry> predicate,\n+                                                                        final PositionImpl startPosition) {\n+        CompletableFuture<Position> future = new CompletableFuture<>();\n+        if (!ledger.isValidPosition(startPosition)) {\n+            future.complete(startPosition);\n+        } else {\n+            internalAsyncReverseFindPositionOneByOne(ledger, predicate, startPosition, future);\n+        }\n+        return future;\n+    }\n+\n+    private static void internalAsyncReverseFindPositionOneByOne(final ManagedLedgerImpl ledger,\n+                                                                 final Predicate<Entry> predicate,\n+                                                                 final PositionImpl position,\n+                                                                 final CompletableFuture<Position> future) {\n+        ledger.asyncReadEntry(position, new AsyncCallbacks.ReadEntryCallback() {\n+            @Override\n+            public void readEntryComplete(Entry entry, Object ctx) {\n+                final Position position = entry.getPosition();\n+                try {\n+                    if (predicate.test(entry)) {\n+                        future.complete(position);\n+                        return;\n+                    }\n+                    PositionImpl previousPosition = ledger.getPreviousPosition((PositionImpl) position);\n+                    if (!ledger.isValidPosition(previousPosition)) {\n+                        future.complete(previousPosition);\n+                    } else {\n+                        internalAsyncReverseFindPositionOneByOne(ledger, predicate,\n+                                ledger.getPreviousPosition((PositionImpl) position), future);\n+                    }\n+                } catch (Exception e) {\n+                    future.completeExceptionally(e);\n+                } finally {\n+                    entry.release();\n+                }\n+            }\n+\n+            @Override\n+            public void readEntryFailed(ManagedLedgerException exception, Object ctx) {\n+                future.completeExceptionally(exception);\n+            }\n+        }, null);\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java\nindex a60f1d805ceb6..5ccdbfbe715c5 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/ServerCnx.java\n@@ -2174,29 +2174,31 @@ protected void handleGetLastMessageId(CommandGetLastMessageId getLastMessageId)\n             long requestId = getLastMessageId.getRequestId();\n \n             Topic topic = consumer.getSubscription().getTopic();\n-            topic.checkIfTransactionBufferRecoverCompletely(true).thenRun(() -> {\n-                Position lastPosition = ((PersistentTopic) topic).getMaxReadPosition();\n-                int partitionIndex = TopicName.getPartitionIndex(topic.getName());\n-\n-                Position markDeletePosition = null;\n-                if (consumer.getSubscription() instanceof PersistentSubscription) {\n-                    markDeletePosition = ((PersistentSubscription) consumer.getSubscription()).getCursor()\n-                            .getMarkDeletedPosition();\n-                }\n-\n-                getLargestBatchIndexWhenPossible(\n-                        topic,\n-                        (PositionImpl) lastPosition,\n-                        (PositionImpl) markDeletePosition,\n-                        partitionIndex,\n-                        requestId,\n-                        consumer.getSubscription().getName(),\n-                        consumer.readCompacted());\n-            }).exceptionally(e -> {\n-                writeAndFlush(Commands.newError(getLastMessageId.getRequestId(),\n-                        ServerError.UnknownError, \"Failed to recover Transaction Buffer.\"));\n-                return null;\n-            });\n+            topic.checkIfTransactionBufferRecoverCompletely(true)\n+                 .thenCompose(__ -> topic.getLastDispatchablePosition())\n+                 .thenApply(lastPosition -> {\n+                     int partitionIndex = TopicName.getPartitionIndex(topic.getName());\n+\n+                     Position markDeletePosition = null;\n+                     if (consumer.getSubscription() instanceof PersistentSubscription) {\n+                         markDeletePosition = ((PersistentSubscription) consumer.getSubscription()).getCursor()\n+                                 .getMarkDeletedPosition();\n+                     }\n+\n+                     getLargestBatchIndexWhenPossible(\n+                             topic,\n+                             (PositionImpl) lastPosition,\n+                             (PositionImpl) markDeletePosition,\n+                             partitionIndex,\n+                             requestId,\n+                             consumer.getSubscription().getName(),\n+                             consumer.readCompacted());\n+                    return null;\n+                 }).exceptionally(e -> {\n+                     writeAndFlush(Commands.newError(getLastMessageId.getRequestId(),\n+                             ServerError.UnknownError, \"Failed to recover Transaction Buffer.\"));\n+                     return null;\n+                 });\n         } else {\n             writeAndFlush(Commands.newError(getLastMessageId.getRequestId(),\n                     ServerError.MetadataError, \"Consumer not found\"));\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\nindex a296052a41191..37696d7a7c53c 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/Topic.java\n@@ -275,6 +275,13 @@ CompletableFuture<? extends TopicStatsImpl> asyncGetStats(boolean getPreciseBack\n \n     Position getLastPosition();\n \n+    /**\n+     * Get the last message position that can be dispatch.\n+     */\n+    default CompletableFuture<Position> getLastDispatchablePosition() {\n+        throw new UnsupportedOperationException(\"getLastDispatchablePosition is not supported by default\");\n+    }\n+\n     CompletableFuture<MessageId> getLastMessageId();\n \n     /**\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\nindex 155b67778820b..95a2b64908a73 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n@@ -83,6 +83,7 @@\n import org.apache.bookkeeper.mledger.impl.PositionImpl;\n import org.apache.bookkeeper.mledger.impl.ShadowManagedLedgerImpl;\n import org.apache.bookkeeper.mledger.util.Futures;\n+import org.apache.bookkeeper.mledger.util.ManagedLedgerImplUtils;\n import org.apache.bookkeeper.net.BookieId;\n import org.apache.commons.collections4.CollectionUtils;\n import org.apache.commons.lang3.StringUtils;\n@@ -174,6 +175,7 @@\n import org.apache.pulsar.common.policies.data.stats.TopicMetricBean;\n import org.apache.pulsar.common.policies.data.stats.TopicStatsImpl;\n import org.apache.pulsar.common.protocol.Commands;\n+import org.apache.pulsar.common.protocol.Markers;\n import org.apache.pulsar.common.protocol.schema.SchemaData;\n import org.apache.pulsar.common.protocol.schema.SchemaVersion;\n import org.apache.pulsar.common.schema.SchemaType;\n@@ -3634,6 +3636,22 @@ public Position getLastPosition() {\n         return ledger.getLastConfirmedEntry();\n     }\n \n+    @Override\n+    public CompletableFuture<Position> getLastDispatchablePosition() {\n+        PositionImpl maxReadPosition = getMaxReadPosition();\n+        // If `maxReadPosition` is not equal to `LastPosition`. It means that there are uncommitted transactions.\n+        // so return `maxRedPosition` directly.\n+        if (maxReadPosition.compareTo((PositionImpl) getLastPosition()) != 0) {\n+            return CompletableFuture.completedFuture(maxReadPosition);\n+        } else {\n+            return ManagedLedgerImplUtils.asyncGetLastValidPosition((ManagedLedgerImpl) ledger, entry -> {\n+                MessageMetadata md = Commands.parseMessageMetadata(entry.getDataBuffer());\n+                // If a messages has marker will filter by AbstractBaseDispatcher.filterEntriesForConsumer\n+                return !Markers.isServerOnlyMarker(md);\n+            }, maxReadPosition);\n+        }\n+    }\n+\n     @Override\n     public CompletableFuture<MessageId> getLastMessageId() {\n         CompletableFuture<MessageId> completableFuture = new CompletableFuture<>();\n",
    "test_patch": "diff --git a/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtilsTest.java b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtilsTest.java\nnew file mode 100644\nindex 0000000000000..f13d23c05296f\n--- /dev/null\n+++ b/managed-ledger/src/test/java/org/apache/bookkeeper/mledger/util/ManagedLedgerImplUtilsTest.java\n@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.util;\n+\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static org.testng.Assert.assertEquals;\n+import java.nio.charset.StandardCharsets;\n+import java.util.function.Predicate;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.ManagedLedger;\n+import org.apache.bookkeeper.mledger.ManagedLedgerConfig;\n+import org.apache.bookkeeper.mledger.Position;\n+import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.test.MockedBookKeeperTestCase;\n+import org.testng.annotations.Test;\n+\n+@Slf4j\n+public class ManagedLedgerImplUtilsTest extends MockedBookKeeperTestCase {\n+\n+    @Test\n+    public void testGetLastValidPosition() throws Exception {\n+        final int maxEntriesPerLedger = 5;\n+\n+        ManagedLedgerConfig managedLedgerConfig = new ManagedLedgerConfig();\n+        managedLedgerConfig.setMaxEntriesPerLedger(maxEntriesPerLedger);\n+        ManagedLedger ledger = factory.open(\"testReverseFindPositionOneByOne\", managedLedgerConfig);\n+\n+        String matchEntry = \"match-entry\";\n+        String noMatchEntry = \"nomatch-entry\";\n+        Predicate<Entry> predicate = entry -> {\n+            String entryValue = entry.getDataBuffer().toString(UTF_8);\n+            return matchEntry.equals(entryValue);\n+        };\n+\n+        // New ledger will return the last position, regardless of whether the conditions are met or not.\n+        Position position = ManagedLedgerImplUtils.asyncGetLastValidPosition((ManagedLedgerImpl) ledger, \n+                predicate, (PositionImpl) ledger.getLastConfirmedEntry()).get();\n+        assertEquals(ledger.getLastConfirmedEntry(), position);\n+\n+        for (int i = 0; i < maxEntriesPerLedger - 1; i++) {\n+            ledger.addEntry(matchEntry.getBytes(StandardCharsets.UTF_8));\n+        }\n+        Position lastMatchPosition = ledger.addEntry(matchEntry.getBytes(StandardCharsets.UTF_8));\n+        for (int i = 0; i < maxEntriesPerLedger; i++) {\n+            ledger.addEntry(noMatchEntry.getBytes(StandardCharsets.UTF_8));\n+        }\n+\n+        // Returns last position of entry is \"match-entry\"\n+        position = ManagedLedgerImplUtils.asyncGetLastValidPosition((ManagedLedgerImpl) ledger,\n+                predicate, (PositionImpl) ledger.getLastConfirmedEntry()).get();\n+        assertEquals(position, lastMatchPosition);\n+\n+        ledger.close();\n+    }\n+\n+}\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java\nindex 8aeb902211db2..25b09f965498d 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionTest.java\n@@ -51,6 +51,7 @@\n import org.apache.pulsar.client.api.Producer;\n import org.apache.pulsar.client.api.PulsarClient;\n import org.apache.pulsar.client.api.PulsarClientException;\n+import org.apache.pulsar.client.api.Reader;\n import org.apache.pulsar.client.api.Schema;\n import org.apache.pulsar.client.api.SubscriptionInitialPosition;\n import org.apache.pulsar.client.api.SubscriptionType;\n@@ -167,6 +168,82 @@ public void testReplicatedSubscriptionAcrossTwoRegions() throws Exception {\n                 \"messages don't match.\");\n     }\n \n+    /**\n+     * Tests replicated subscriptions across two regions and can read successful.\n+     */\n+    @Test\n+    public void testReplicatedSubscriptionAcrossTwoRegionsGetLastMessage() throws Exception {\n+        String namespace = BrokerTestUtil.newUniqueName(\"pulsar/replicatedsubscriptionlastmessage\");\n+        String topicName = \"persistent://\" + namespace + \"/mytopic\";\n+        String subscriptionName = \"cluster-subscription\";\n+        // this setting can be used to manually run the test with subscription replication disabled\n+        // it shows that subscription replication has no impact in behavior for this test case\n+        boolean replicateSubscriptionState = true;\n+\n+        admin1.namespaces().createNamespace(namespace);\n+        admin1.namespaces().setNamespaceReplicationClusters(namespace, Sets.newHashSet(\"r1\", \"r2\"));\n+\n+        @Cleanup\n+        PulsarClient client1 = PulsarClient.builder().serviceUrl(url1.toString())\n+                .statsInterval(0, TimeUnit.SECONDS)\n+                .build();\n+\n+        // create subscription in r1\n+        createReplicatedSubscription(client1, topicName, subscriptionName, replicateSubscriptionState);\n+\n+        @Cleanup\n+        PulsarClient client2 = PulsarClient.builder().serviceUrl(url2.toString())\n+                .statsInterval(0, TimeUnit.SECONDS)\n+                .build();\n+\n+        // create subscription in r2\n+        createReplicatedSubscription(client2, topicName, subscriptionName, replicateSubscriptionState);\n+\n+        Set<String> sentMessages = new LinkedHashSet<>();\n+\n+        // send messages in r1\n+        @Cleanup\n+        Producer<byte[]> producer = client1.newProducer().topic(topicName)\n+                .enableBatching(false)\n+                .messageRoutingMode(MessageRoutingMode.SinglePartition)\n+                .create();\n+        int numMessages = 6;\n+        for (int i = 0; i < numMessages; i++) {\n+            String body = \"message\" + i;\n+            producer.send(body.getBytes(StandardCharsets.UTF_8));\n+            sentMessages.add(body);\n+        }\n+        producer.close();\n+\n+\n+        // consume 3 messages in r1\n+        Set<String> receivedMessages = new LinkedHashSet<>();\n+        try (Consumer<byte[]> consumer1 = client1.newConsumer()\n+                .topic(topicName)\n+                .subscriptionName(subscriptionName)\n+                .replicateSubscriptionState(replicateSubscriptionState)\n+                .subscribe()) {\n+            readMessages(consumer1, receivedMessages, 3, false);\n+        }\n+\n+        // wait for subscription to be replicated\n+        Thread.sleep(2 * config1.getReplicatedSubscriptionsSnapshotFrequencyMillis());\n+\n+        // create a reader in r2\n+        Reader<byte[]> reader = client2.newReader().topic(topicName)\n+                .subscriptionName(\"new-sub\")\n+                .startMessageId(MessageId.earliest)\n+                .create();\n+        int readNum = 0;\n+        while (reader.hasMessageAvailable()) {\n+            Message<byte[]> message = reader.readNext(10, TimeUnit.SECONDS);\n+            assertNotNull(message);\n+            log.info(\"Receive message: \" + new String(message.getValue()) + \" msgId: \" + message.getMessageId());\n+            readNum++;\n+        }\n+        assertEquals(readNum, numMessages);\n+    }\n+\n     @Test\n     public void testReplicatedSubscribeAndSwitchToStandbyCluster() throws Exception {\n         final String namespace = BrokerTestUtil.newUniqueName(\"pulsar/ns_\");\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionWithTransactionTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionWithTransactionTest.java\nnew file mode 100644\nindex 0000000000000..93a22a851f160\n--- /dev/null\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/ReplicatorSubscriptionWithTransactionTest.java\n@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.broker.service;\n+\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+\n+/**\n+ * Tests replicated subscriptions with transaction (PIP-33)\n+ */\n+@Test(groups = \"broker\")\n+public class ReplicatorSubscriptionWithTransactionTest extends ReplicatorSubscriptionTest {\n+\n+    @Override\n+    @BeforeClass(timeOut = 300000)\n+    public void setup() throws Exception {\n+        config1.setTransactionCoordinatorEnabled(true);\n+        config2.setTransactionCoordinatorEnabled(true);\n+        config3.setTransactionCoordinatorEnabled(true);\n+        config4.setTransactionCoordinatorEnabled(true);\n+        super.setup();\n+    }\n+\n+    @Override\n+    @AfterClass(alwaysRun = true, timeOut = 300000)\n+    public void cleanup() throws Exception {\n+        super.cleanup();\n+    }\n+\n+    @DataProvider(name = \"isTopicPolicyEnabled\")\n+    private Object[][] isTopicPolicyEnabled() {\n+        // Todo: fix replication can not be enabled at topic level.\n+        return new Object[][] { { Boolean.FALSE } };\n+    }\n+}\n\ndiff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java\nindex fad785cc882ff..b0903b00be380 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/transaction/buffer/TopicTransactionBufferTest.java\n@@ -280,9 +280,9 @@ public void testGetLastMessageIdsWithOngoingTransactions() throws Exception {\n         for (int i = 0; i < 3; i++) {\n             expectedLastMessageID = (MessageIdImpl) producer.newMessage().send();\n         }\n-        assertMessageId(consumer, expectedLastMessageID, 0);\n+        assertMessageId(consumer, expectedLastMessageID);\n         // 2.2 Case2: send 2 ongoing transactional messages and 2 original messages.\n-        // |1:0|1:1|1:2|txn1->1:3|1:4|txn2->1:5|1:6|.\n+        // |1:0|1:1|1:2|txn1:start->1:3|1:4|txn2:start->1:5|1:6|.\n         Transaction txn1 = pulsarClient.newTransaction()\n                 .withTransactionTimeout(5, TimeUnit.HOURS)\n                 .build()\n@@ -292,18 +292,24 @@ public void testGetLastMessageIdsWithOngoingTransactions() throws Exception {\n                 .build()\n                 .get();\n         producer.newMessage(txn1).send();\n+        // expectedLastMessageID1 == 1:4\n         MessageIdImpl expectedLastMessageID1 = (MessageIdImpl) producer.newMessage().send();\n         producer.newMessage(txn2).send();\n+        // expectedLastMessageID2 == 1:6\n         MessageIdImpl expectedLastMessageID2 = (MessageIdImpl) producer.newMessage().send();\n+\n         // 2.2.1 Last message ID will not change when txn1 and txn2 do not end.\n-        assertMessageId(consumer, expectedLastMessageID, 0);\n+        assertMessageId(consumer, expectedLastMessageID);\n+\n         // 2.2.2 Last message ID will update to 1:4 when txn1 committed.\n+        // |1:0|1:1|1:2|txn1:start->1:3|1:4|txn2:start->1:5|1:6|tx1:commit->1:7|\n         txn1.commit().get(5, TimeUnit.SECONDS);\n-        assertMessageId(consumer, expectedLastMessageID1, 0);\n+        assertMessageId(consumer, expectedLastMessageID1);\n+\n         // 2.2.3 Last message ID will update to 1:6 when txn2 aborted.\n+        // |1:0|1:1|1:2|txn1:start->1:3|1:4|txn2:start->1:5|1:6|tx1:commit->1:7|tx2:abort->1:8|\n         txn2.abort().get(5, TimeUnit.SECONDS);\n-        // Todo: We can not ignore the marker's position in this fix.\n-        assertMessageId(consumer, expectedLastMessageID2, 2);\n+        assertMessageId(consumer, expectedLastMessageID2);\n     }\n \n     /**\n@@ -362,9 +368,9 @@ private void triggerLedgerSwitch(String topicName) throws Exception{\n         });\n     }\n \n-    private void assertMessageId(Consumer<?> consumer, MessageIdImpl expected, int entryOffset) throws Exception {\n+    private void assertMessageId(Consumer<?> consumer, MessageIdImpl expected) throws Exception {\n         TopicMessageIdImpl actual = (TopicMessageIdImpl) consumer.getLastMessageIds().get(0);\n-        assertEquals(expected.getEntryId(), actual.getEntryId() - entryOffset);\n+        assertEquals(expected.getEntryId(), actual.getEntryId());\n         assertEquals(expected.getLedgerId(), actual.getLedgerId());\n     }\n \n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22556",
    "pr_id": 22556,
    "issue_id": 22442,
    "repo": "apache/pulsar",
    "problem_statement": "Producers for geo-replication should be excluded from the `publishers` field of topic stats\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\nAfter upgrading the version of Pulsar used at our company, the `publishers` field of topic stats now includes producers whose names start with `pulsar.repl.`, which were not included before. These are producers created by brokers in other clusters for geo-replication.\r\n```json\r\n\"publishers\" : [ {\r\n  \"accessMode\" : \"Shared\",\r\n  \"msgRateIn\" : 0.0,\r\n  \"msgThroughputIn\" : 0.0,\r\n  \"averageMsgSize\" : 0.0,\r\n  \"chunkedMessageRate\" : 0.0,\r\n  \"producerId\" : 0,\r\n  \"supportsPartialProducer\" : false,\r\n  \"metadata\" : { },\r\n  \"address\" : \"/xxx.xxx.xxx.xxx:37102\",\r\n  \"connectedSince\" : \"2024-04-04T14:23:33.666865+09:00\",\r\n  \"clientVersion\" : \"2.10.5\",\r\n  \"producerName\" : \"pulsar.repl.dev\"\r\n} ],\r\n```\r\n\r\nProducers for geo-replication started to appear in `publishers` due to the following PR:\r\nhttps://github.com/apache/pulsar/pull/20229\r\n\r\nAlthough this PR is treated as a bug fix, it seems that the exclusion of geo-replication producers from `publishers` was intentional, so I think this is a specification change.\r\n\r\nI think geo-replication producers should be excluded from `publishers`. These are unknown producers to normal users, so they confuse users who look at topic stats. I think that the mechanism for achieving geo-replication should be hidden from users as much as possible.\r\n\r\n### Solution\r\n\r\nI would like to revert https://github.com/apache/pulsar/pull/20229. In addition to that, the `publishers` and `producerCount` fields in broker stats also include the number of geo-replication producers, so I'd like to exclude that from them too if possible.\r\n\r\n### Alternatives\r\n\r\nIf https://github.com/apache/pulsar/pull/20229 should not be completely reverted, there is an option to add a query parameter to the REST APIs for retrieving topic stats/broker stats to determine whether `publishers` should include geo-replication producers. Even in this case, I'd like to hide geo-replication producers by default. I suggest `showReplicatorProducers` as the name of the query parameter.\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [X] I'm willing to submit a PR!",
    "issue_word_count": 345,
    "test_files_count": 1,
    "non_test_files_count": 2,
    "pr_changed_files": [
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java",
      "pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java",
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java"
    ],
    "pr_changed_test_files": [
      "pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java"
    ],
    "base_commit": "b774666331db33ea6407174e0fe6e27a73160522",
    "head_commit": "14a4e8b9cd5434c4ba9d80ecb3228327f3f65ded",
    "repo_url": "https://github.com/apache/pulsar/pull/22556",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22556",
    "dockerfile": "",
    "pr_merged_at": "2024-05-07T05:02:52.000Z",
    "patch": "diff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\nindex 586fcd76151e4..962d93fb48f43 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/nonpersistent/NonPersistentTopic.java\n@@ -39,6 +39,7 @@\n import java.util.concurrent.atomic.AtomicLongFieldUpdater;\n import org.apache.bookkeeper.mledger.Entry;\n import org.apache.bookkeeper.mledger.Position;\n+import org.apache.commons.lang3.mutable.MutableInt;\n import org.apache.pulsar.broker.PulsarServerException;\n import org.apache.pulsar.broker.loadbalance.extensions.ExtensibleLoadManagerImpl;\n import org.apache.pulsar.broker.namespace.NamespaceService;\n@@ -745,8 +746,7 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n \n         replicators.forEach((region, replicator) -> replicator.updateRates());\n \n-        nsStats.producerCount += producers.size();\n-        bundleStats.producerCount += producers.size();\n+        final MutableInt producerCount = new MutableInt();\n         topicStatsStream.startObject(topic);\n \n         topicStatsStream.startList(\"publishers\");\n@@ -759,14 +759,19 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n \n             if (producer.isRemote()) {\n                 topicStats.remotePublishersStats.put(producer.getRemoteCluster(), publisherStats);\n-            }\n-\n-            if (hydratePublishers) {\n-                StreamingStats.writePublisherStats(topicStatsStream, publisherStats);\n+            } else {\n+                // Exclude producers for replication from \"publishers\" and \"producerCount\"\n+                producerCount.increment();\n+                if (hydratePublishers) {\n+                    StreamingStats.writePublisherStats(topicStatsStream, publisherStats);\n+                }\n             }\n         });\n         topicStatsStream.endList();\n \n+        nsStats.producerCount += producerCount.intValue();\n+        bundleStats.producerCount += producerCount.intValue();\n+\n         // Start replicator stats\n         topicStatsStream.startObject(\"replication\");\n         nsStats.replicatorCount += topicStats.remotePublishersStats.size();\n@@ -855,7 +860,7 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n         // Remaining dest stats.\n         topicStats.averageMsgSize = topicStats.aggMsgRateIn == 0.0 ? 0.0\n                 : (topicStats.aggMsgThroughputIn / topicStats.aggMsgRateIn);\n-        topicStatsStream.writePair(\"producerCount\", producers.size());\n+        topicStatsStream.writePair(\"producerCount\", producerCount.intValue());\n         topicStatsStream.writePair(\"averageMsgSize\", topicStats.averageMsgSize);\n         topicStatsStream.writePair(\"msgRateIn\", topicStats.aggMsgRateIn);\n         topicStatsStream.writePair(\"msgRateOut\", topicStats.aggMsgRateOut);\n@@ -929,6 +934,7 @@ public CompletableFuture<? extends TopicStatsImpl> asyncGetStats(GetStatsOptions\n             if (producer.isRemote()) {\n                 remotePublishersStats.put(producer.getRemoteCluster(), publisherStats);\n             } else if (!getStatsOptions.isExcludePublishers()) {\n+                // Exclude producers for replication from \"publishers\"\n                 stats.addPublisher(publisherStats);\n             }\n         });\n\ndiff --git a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\nindex c1a75d67e3c4e..8f87d054e2b2b 100644\n--- a/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n+++ b/pulsar-broker/src/main/java/org/apache/pulsar/broker/service/persistent/PersistentTopic.java\n@@ -85,6 +85,7 @@\n import org.apache.bookkeeper.net.BookieId;\n import org.apache.commons.collections4.CollectionUtils;\n import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.mutable.MutableInt;\n import org.apache.pulsar.broker.PulsarServerException;\n import org.apache.pulsar.broker.delayed.BucketDelayedDeliveryTrackerFactory;\n import org.apache.pulsar.broker.delayed.DelayedDeliveryTrackerFactory;\n@@ -2121,8 +2122,7 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n \n         replicators.forEach((region, replicator) -> replicator.updateRates());\n \n-        nsStats.producerCount += producers.size();\n-        bundleStats.producerCount += producers.size();\n+        final MutableInt producerCount = new MutableInt();\n         topicStatsStream.startObject(topic);\n \n         // start publisher stats\n@@ -2136,14 +2136,19 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n \n             if (producer.isRemote()) {\n                 topicStatsHelper.remotePublishersStats.put(producer.getRemoteCluster(), publisherStats);\n-            }\n-\n-            // Populate consumer specific stats here\n-            if (hydratePublishers) {\n-                StreamingStats.writePublisherStats(topicStatsStream, publisherStats);\n+            } else {\n+                // Exclude producers for replication from \"publishers\" and \"producerCount\"\n+                producerCount.increment();\n+                if (hydratePublishers) {\n+                    StreamingStats.writePublisherStats(topicStatsStream, publisherStats);\n+                }\n             }\n         });\n         topicStatsStream.endList();\n+\n+        nsStats.producerCount += producerCount.intValue();\n+        bundleStats.producerCount += producerCount.intValue();\n+\n         // if publish-rate increases (eg: 0 to 1K) then pick max publish-rate and if publish-rate decreases then keep\n         // average rate.\n         lastUpdatedAvgPublishRateInMsg = topicStatsHelper.aggMsgRateIn > lastUpdatedAvgPublishRateInMsg\n@@ -2311,7 +2316,7 @@ public void updateRates(NamespaceStats nsStats, NamespaceBundleStats bundleStats\n         // Remaining dest stats.\n         topicStatsHelper.averageMsgSize = topicStatsHelper.aggMsgRateIn == 0.0 ? 0.0\n                 : (topicStatsHelper.aggMsgThroughputIn / topicStatsHelper.aggMsgRateIn);\n-        topicStatsStream.writePair(\"producerCount\", producers.size());\n+        topicStatsStream.writePair(\"producerCount\", producerCount.intValue());\n         topicStatsStream.writePair(\"averageMsgSize\", topicStatsHelper.averageMsgSize);\n         topicStatsStream.writePair(\"msgRateIn\", topicStatsHelper.aggMsgRateIn);\n         topicStatsStream.writePair(\"msgRateOut\", topicStatsHelper.aggMsgRateOut);\n@@ -2399,8 +2404,8 @@ public CompletableFuture<? extends TopicStatsImpl> asyncGetStats(GetStatsOptions\n \n             if (producer.isRemote()) {\n                 remotePublishersStats.put(producer.getRemoteCluster(), publisherStats);\n-            }\n-            if (!getStatsOptions.isExcludePublishers()){\n+            } else if (!getStatsOptions.isExcludePublishers()) {\n+                // Exclude producers for replication from \"publishers\"\n                 stats.addPublisher(publisherStats);\n             }\n         });\n",
    "test_patch": "diff --git a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\nindex 9b8b567af081b..f281f394b3227 100644\n--- a/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n+++ b/pulsar-broker/src/test/java/org/apache/pulsar/broker/service/OneWayReplicatorTest.java\n@@ -27,12 +27,15 @@\n import static org.testng.Assert.assertNotEquals;\n import static org.testng.Assert.assertTrue;\n import static org.testng.Assert.fail;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n import com.google.common.collect.Sets;\n import io.netty.util.concurrent.FastThreadLocalThread;\n import java.lang.reflect.Field;\n import java.lang.reflect.Method;\n import java.time.Duration;\n import java.util.Arrays;\n+import java.util.Iterator;\n import java.util.Optional;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n@@ -137,17 +140,49 @@ public void testReplicatorProducerStatInTopic() throws Exception {\n \n         // Verify replicator works.\n         Producer<byte[]> producer1 = client1.newProducer().topic(topicName).create();\n+        Producer<byte[]> producer2 = client2.newProducer().topic(topicName).create(); // Do not publish messages\n         Consumer<byte[]> consumer2 = client2.newConsumer().topic(topicName).subscriptionName(subscribeName).subscribe();\n         producer1.newMessage().value(msgValue).send();\n         pulsar1.getBrokerService().checkReplicationPolicies();\n         assertEquals(consumer2.receive(10, TimeUnit.SECONDS).getValue(), msgValue);\n \n-        // Verify there has one item in the attribute \"publishers\" or \"replications\"\n+        // Verify that the \"publishers\" field does not include the producer for replication\n         TopicStats topicStats2 = admin2.topics().getStats(topicName);\n-        assertTrue(topicStats2.getPublishers().size() + topicStats2.getReplication().size() > 0);\n+        assertEquals(topicStats2.getPublishers().size(), 1);\n+        assertFalse(topicStats2.getPublishers().get(0).getProducerName().startsWith(config1.getReplicatorPrefix()));\n+\n+        // Update broker stats immediately (usually updated every minute)\n+        pulsar2.getBrokerService().updateRates();\n+        String brokerStats2 = admin2.brokerStats().getTopics();\n+\n+        boolean found = false;\n+        ObjectMapper mapper = new ObjectMapper();\n+        JsonNode rootNode = mapper.readTree(brokerStats2);\n+        if (rootNode.hasNonNull(replicatedNamespace)) {\n+            Iterator<JsonNode> bundleNodes = rootNode.get(replicatedNamespace).elements();\n+            while (bundleNodes.hasNext()) {\n+                JsonNode bundleNode = bundleNodes.next();\n+                if (bundleNode.hasNonNull(\"persistent\") && bundleNode.get(\"persistent\").hasNonNull(topicName)) {\n+                    found = true;\n+                    JsonNode topicNode = bundleNode.get(\"persistent\").get(topicName);\n+                    // Verify that the \"publishers\" field does not include the producer for replication\n+                    assertEquals(topicNode.get(\"publishers\").size(), 1);\n+                    assertEquals(topicNode.get(\"producerCount\").intValue(), 1);\n+                    Iterator<JsonNode> publisherNodes = topicNode.get(\"publishers\").elements();\n+                    while (publisherNodes.hasNext()) {\n+                        JsonNode publisherNode = publisherNodes.next();\n+                        assertFalse(publisherNode.get(\"producerName\").textValue()\n+                                .startsWith(config1.getReplicatorPrefix()));\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+        assertTrue(found);\n \n         // cleanup.\n-        consumer2.close();\n+        consumer2.unsubscribe();\n+        producer2.close();\n         producer1.close();\n         cleanupTopics(() -> {\n             admin1.topics().delete(topicName);\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  },
  {
    "instance_id": "apache__pulsar-22541",
    "pr_id": 22541,
    "issue_id": 22041,
    "repo": "apache/pulsar",
    "problem_statement": "Set limits for number of opened HTTP connections for Pulsar Admin client\n### Search before asking\r\n\r\n- [X] I searched in the [issues](https://github.com/apache/pulsar/issues) and found nothing similar.\r\n\r\n\r\n### Motivation\r\n\r\nThe Pulsar Admin client uses connection pooling (keep alive) without limiting the number of connections.\r\nWhen HTTP calls get queued up on the brokers for some reason, the client will keep on opening more connections.\r\n\r\n### Solution\r\n\r\nThe AsyncHttpClient used in pulsar-admin-client should be configured to limit the number of connections.\r\nThis could happen somewhere here:\r\nhttps://github.com/apache/pulsar/blob/e3debb9ad867cb9b977e8bb1b21aab66387b3c5d/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java#L99-L108\r\n`setMaxConnections` and `setMaxConnectionsPerHost` would have to be configured. \r\nIn addition, it would be useful to use `setPooledConnectionIdleTimeout` to set the timeout to 25 seconds so that pooled connections don't exceed timeouts in typical firewall configurations. The default of 60 seconds conflicts with many firewall idle connection defaults.\r\n\r\n### Alternatives\r\n\r\n_No response_\r\n\r\n### Anything else?\r\n\r\n_No response_\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] I'm willing to submit a PR!",
    "issue_word_count": 182,
    "test_files_count": 3,
    "non_test_files_count": 19,
    "pr_changed_files": [
      "distribution/server/src/assemble/LICENSE.bin.txt",
      "distribution/shell/src/assemble/LICENSE.bin.txt",
      "pom.xml",
      "pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/PulsarAdminBuilder.java",
      "pulsar-client-admin-shaded/pom.xml",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java",
      "pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpRequestExecutor.java",
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java",
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java",
      "pulsar-client-all/pom.xml",
      "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ClientBuilder.java",
      "pulsar-client-shaded/pom.xml",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConnectionPool.java",
      "pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ClientConfigurationData.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java",
      "pulsar-common/pom.xml"
    ],
    "pr_changed_test_files": [
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java",
      "pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java",
      "pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java"
    ],
    "base_commit": "8707fbe8351fb6ac4337fbd88d86eb32aff55b04",
    "head_commit": "fb374ebbdfedc7926e01da2128f2e8b01080d2b4",
    "repo_url": "https://github.com/apache/pulsar/pull/22541",
    "swe_url": "https://swe-bench-plus.turing.com/repos/apache__pulsar/22541",
    "dockerfile": "",
    "pr_merged_at": "2024-08-08T08:55:15.000Z",
    "patch": "diff --git a/distribution/server/src/assemble/LICENSE.bin.txt b/distribution/server/src/assemble/LICENSE.bin.txt\nindex af50d818c4e7a..4bbb86653add5 100644\n--- a/distribution/server/src/assemble/LICENSE.bin.txt\n+++ b/distribution/server/src/assemble/LICENSE.bin.txt\n@@ -536,6 +536,8 @@ The Apache Software License, Version 2.0\n     - io.opentelemetry.instrumentation-opentelemetry-runtime-telemetry-java17-1.33.3-alpha.jar\n     - io.opentelemetry.instrumentation-opentelemetry-runtime-telemetry-java8-1.33.3-alpha.jar\n     - io.opentelemetry.semconv-opentelemetry-semconv-1.25.0-alpha.jar\n+  * Spotify completable-futures\n+    - com.spotify-completable-futures-0.3.6.jar\n \n BSD 3-clause \"New\" or \"Revised\" License\n  * Google auth library\n@@ -580,15 +582,15 @@ CDDL-1.1 -- ../licenses/LICENSE-CDDL-1.1.txt\n     - org.glassfish.hk2-osgi-resource-locator-1.0.3.jar\n     - org.glassfish.hk2.external-aopalliance-repackaged-2.6.1.jar\n  * Jersey\n-    - org.glassfish.jersey.containers-jersey-container-servlet-2.41.jar\n-    - org.glassfish.jersey.containers-jersey-container-servlet-core-2.41.jar\n-    - org.glassfish.jersey.core-jersey-client-2.41.jar\n-    - org.glassfish.jersey.core-jersey-common-2.41.jar\n-    - org.glassfish.jersey.core-jersey-server-2.41.jar\n-    - org.glassfish.jersey.ext-jersey-entity-filtering-2.41.jar\n-    - org.glassfish.jersey.media-jersey-media-json-jackson-2.41.jar\n-    - org.glassfish.jersey.media-jersey-media-multipart-2.41.jar\n-    - org.glassfish.jersey.inject-jersey-hk2-2.41.jar\n+    - org.glassfish.jersey.containers-jersey-container-servlet-2.42.jar\n+    - org.glassfish.jersey.containers-jersey-container-servlet-core-2.42.jar\n+    - org.glassfish.jersey.core-jersey-client-2.42.jar\n+    - org.glassfish.jersey.core-jersey-common-2.42.jar\n+    - org.glassfish.jersey.core-jersey-server-2.42.jar\n+    - org.glassfish.jersey.ext-jersey-entity-filtering-2.42.jar\n+    - org.glassfish.jersey.media-jersey-media-json-jackson-2.42.jar\n+    - org.glassfish.jersey.media-jersey-media-multipart-2.42.jar\n+    - org.glassfish.jersey.inject-jersey-hk2-2.42.jar\n  * Mimepull -- org.jvnet.mimepull-mimepull-1.9.15.jar\n \n Eclipse Distribution License 1.0 -- ../licenses/LICENSE-EDL-1.0.txt\n\ndiff --git a/distribution/shell/src/assemble/LICENSE.bin.txt b/distribution/shell/src/assemble/LICENSE.bin.txt\nindex 0da56c6afa8fc..31acbd9ac161d 100644\n--- a/distribution/shell/src/assemble/LICENSE.bin.txt\n+++ b/distribution/shell/src/assemble/LICENSE.bin.txt\n@@ -417,6 +417,7 @@ The Apache Software License, Version 2.0\n     - avro-1.11.3.jar\n     - avro-protobuf-1.11.3.jar\n  * RE2j -- re2j-1.7.jar\n+ * Spotify completable-futures -- completable-futures-0.3.6.jar\n \n BSD 3-clause \"New\" or \"Revised\" License\n  * JSR305 -- jsr305-3.0.2.jar -- ../licenses/LICENSE-JSR305.txt\n@@ -446,12 +447,12 @@ CDDL-1.1 -- ../licenses/LICENSE-CDDL-1.1.txt\n     - aopalliance-repackaged-2.6.1.jar\n     - osgi-resource-locator-1.0.3.jar\n  * Jersey\n-    - jersey-client-2.41.jar\n-    - jersey-common-2.41.jar\n-    - jersey-entity-filtering-2.41.jar\n-    - jersey-media-json-jackson-2.41.jar\n-    - jersey-media-multipart-2.41.jar\n-    - jersey-hk2-2.41.jar\n+    - jersey-client-2.42.jar\n+    - jersey-common-2.42.jar\n+    - jersey-entity-filtering-2.42.jar\n+    - jersey-media-json-jackson-2.42.jar\n+    - jersey-media-multipart-2.42.jar\n+    - jersey-hk2-2.42.jar\n  * Mimepull -- mimepull-1.9.15.jar\n \n Eclipse Distribution License 1.0 -- ../licenses/LICENSE-EDL-1.0.txt\n\ndiff --git a/pom.xml b/pom.xml\nindex c0659e091d490..52843f5079f01 100644\n--- a/pom.xml\n+++ b/pom.xml\n@@ -152,7 +152,7 @@ flexible messaging model and an intuitive client API.</description>\n     <netty-iouring.version>0.0.24.Final</netty-iouring.version>\n     <jetty.version>9.4.54.v20240208</jetty.version>\n     <conscrypt.version>2.5.2</conscrypt.version>\n-    <jersey.version>2.41</jersey.version>\n+    <jersey.version>2.42</jersey.version>\n     <athenz.version>1.10.50</athenz.version>\n     <prometheus.version>0.16.0</prometheus.version>\n     <vertx.version>4.5.8</vertx.version>\n@@ -266,6 +266,7 @@ flexible messaging model and an intuitive client API.</description>\n     <opentelemetry.semconv.version>1.25.0-alpha</opentelemetry.semconv.version>\n     <picocli.version>4.7.5</picocli.version>\n     <re2j.version>1.7</re2j.version>\n+    <completable-futures.version>0.3.6</completable-futures.version>\n     <failsafe.version>3.3.2</failsafe.version>\n \n     <!-- test dependencies -->\n@@ -665,6 +666,12 @@ flexible messaging model and an intuitive client API.</description>\n         <version>${re2j.version}</version>\n       </dependency>\n \n+      <dependency>\n+        <groupId>com.spotify</groupId>\n+        <artifactId>completable-futures</artifactId>\n+        <version>${completable-futures.version}</version>\n+      </dependency>\n+\n       <dependency>\n         <groupId>org.rocksdb</groupId>\n         <artifactId>rocksdbjni</artifactId>\n\ndiff --git a/pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/PulsarAdminBuilder.java b/pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/PulsarAdminBuilder.java\nindex 1b025a752d9f3..b26e5b2cec802 100644\n--- a/pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/PulsarAdminBuilder.java\n+++ b/pulsar-client-admin-api/src/main/java/org/apache/pulsar/client/admin/PulsarAdminBuilder.java\n@@ -336,4 +336,30 @@ PulsarAdminBuilder authentication(String authPluginClassName, Map<String, String\n      *                              requests\n      */\n     PulsarAdminBuilder acceptGzipCompression(boolean acceptGzipCompression);\n+\n+    /**\n+     * Configures the maximum number of connections that the client library will establish with a single host.\n+     * <p>\n+     * By default, the connection pool maintains up to 16 connections to a single host. This method allows you to\n+     * modify this default behavior and limit the number of connections.\n+     * <p>\n+     * This setting can be useful in scenarios where you want to limit the resources used by the client library,\n+     * or control the level of parallelism for operations so that a single client does not overwhelm\n+     * the Pulsar cluster with too many concurrent connections.\n+     *\n+     * @param maxConnectionsPerHost the maximum number of connections to establish per host. Set to <= 0 to disable\n+     *                             the limit.\n+     * @return the PulsarAdminBuilder instance, allowing for method chaining\n+     */\n+    PulsarAdminBuilder maxConnectionsPerHost(int maxConnectionsPerHost);\n+\n+    /**\n+     * Sets the maximum idle time for a pooled connection. If a connection is idle for more than the specified\n+     * amount of seconds, it will be released back to the connection pool.\n+     * Defaults to 25 seconds.\n+     *\n+     * @param connectionMaxIdleSeconds the maximum idle time, in seconds, for a pooled connection\n+     * @return the PulsarAdminBuilder instance\n+     */\n+    PulsarAdminBuilder connectionMaxIdleSeconds(int connectionMaxIdleSeconds);\n }\n\\ No newline at end of file\n\ndiff --git a/pulsar-client-admin-shaded/pom.xml b/pulsar-client-admin-shaded/pom.xml\nindex 1376cefe80368..f2249b4c0ff6a 100644\n--- a/pulsar-client-admin-shaded/pom.xml\n+++ b/pulsar-client-admin-shaded/pom.xml\n@@ -123,6 +123,7 @@\n                   <include>com.google.guava:guava</include>\n                   <include>com.google.code.gson:gson</include>\n                   <include>com.google.re2j:re2j</include>\n+                  <include>com.spotify:completable-futures</include>\n                   <include>com.fasterxml.jackson.*:*</include>\n                   <include>io.netty:*</include>\n                   <include>io.netty.incubator:*</include>\n@@ -192,6 +193,10 @@\n                     <exclude>com.google.protobuf.*</exclude>\n                   </excludes>\n                 </relocation>\n+                <relocation>\n+                  <pattern>com.spotify.futures</pattern>\n+                  <shadedPattern>org.apache.pulsar.shade.com.spotify.futures</shadedPattern>\n+                </relocation>\n                 <relocation>\n                   <pattern>com.fasterxml.jackson</pattern>\n                   <shadedPattern>org.apache.pulsar.shade.com.fasterxml.jackson</shadedPattern>\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\nindex 97c42e5c1a95a..bfcc3fe39a444 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/FunctionsImpl.java\n@@ -22,7 +22,6 @@\n import static org.asynchttpclient.Dsl.post;\n import static org.asynchttpclient.Dsl.put;\n import com.google.gson.Gson;\n-import io.netty.handler.codec.http.HttpHeaders;\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.IOException;\n@@ -41,6 +40,7 @@\n import org.apache.commons.lang3.StringUtils;\n import org.apache.pulsar.client.admin.Functions;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n+import org.apache.pulsar.client.admin.internal.http.AsyncHttpRequestExecutor;\n import org.apache.pulsar.client.api.Authentication;\n import org.apache.pulsar.common.functions.FunctionConfig;\n import org.apache.pulsar.common.functions.FunctionDefinition;\n@@ -54,10 +54,8 @@\n import org.apache.pulsar.common.policies.data.FunctionStats;\n import org.apache.pulsar.common.policies.data.FunctionStatsImpl;\n import org.apache.pulsar.common.policies.data.FunctionStatus;\n-import org.asynchttpclient.AsyncHandler;\n-import org.asynchttpclient.AsyncHttpClient;\n+import org.asynchttpclient.AsyncCompletionHandlerBase;\n import org.asynchttpclient.HttpResponseBodyPart;\n-import org.asynchttpclient.HttpResponseStatus;\n import org.asynchttpclient.RequestBuilder;\n import org.asynchttpclient.request.body.multipart.ByteArrayPart;\n import org.asynchttpclient.request.body.multipart.FilePart;\n@@ -70,12 +68,14 @@\n public class FunctionsImpl extends ComponentResource implements Functions {\n \n     private final WebTarget functions;\n-    private final AsyncHttpClient asyncHttpClient;\n+    private final AsyncHttpRequestExecutor asyncHttpRequestExecutor;\n \n-    public FunctionsImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+    public FunctionsImpl(WebTarget web, Authentication auth,\n+                         AsyncHttpRequestExecutor asyncHttpRequestExecutor,\n+                         long requestTimeoutMs) {\n         super(auth, requestTimeoutMs);\n         this.functions = web.path(\"/admin/v3/functions\");\n-        this.asyncHttpClient = asyncHttpClient;\n+        this.asyncHttpRequestExecutor = asyncHttpRequestExecutor;\n     }\n \n     @Override\n@@ -171,8 +171,7 @@ public CompletableFuture<Void> createFunctionAsync(FunctionConfig functionConfig\n                 // If the function code is built in, we don't need to submit here\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n-            asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build())\n-                    .toCompletableFuture()\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build())\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n                             future.completeExceptionally(\n@@ -263,8 +262,7 @@ public CompletableFuture<Void> updateFunctionAsync(\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n \n-            asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build())\n-                    .toCompletableFuture()\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build())\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n                             future.completeExceptionally(\n@@ -464,7 +462,7 @@ public CompletableFuture<Void> uploadFunctionAsync(String sourceFile, String pat\n                     .addBodyPart(new FilePart(\"data\", new File(sourceFile), MediaType.APPLICATION_OCTET_STREAM))\n                     .addBodyPart(new StringPart(\"path\", path, MediaType.TEXT_PLAIN));\n \n-            asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build()).toCompletableFuture()\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build())\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n                             future.completeExceptionally(\n@@ -543,55 +541,31 @@ private CompletableFuture<Void> downloadFileAsync(String destinationPath, WebTar\n \n             RequestBuilder builder = get(target.getUri().toASCIIString());\n \n-            CompletableFuture<HttpResponseStatus> statusFuture =\n-                    asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build(),\n-                        new AsyncHandler<HttpResponseStatus>() {\n-                            private HttpResponseStatus status;\n-\n-                            @Override\n-                            public State onStatusReceived(HttpResponseStatus responseStatus) throws Exception {\n-                                status = responseStatus;\n-                                if (status.getStatusCode() != Response.Status.OK.getStatusCode()) {\n-                                    return State.ABORT;\n-                                }\n-                                return State.CONTINUE;\n-                            }\n-\n-                            @Override\n-                            public State onHeadersReceived(HttpHeaders headers) throws Exception {\n-                                return State.CONTINUE;\n-                            }\n+            CompletableFuture<org.asynchttpclient.Response> responseFuture =\n+                    asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build(),\n+                            () -> new AsyncCompletionHandlerBase() {\n \n                             @Override\n                             public State onBodyPartReceived(HttpResponseBodyPart bodyPart) throws Exception {\n                                 os.write(bodyPart.getBodyByteBuffer());\n                                 return State.CONTINUE;\n                             }\n+                        });\n \n-                            @Override\n-                            public HttpResponseStatus onCompleted() throws Exception {\n-                                return status;\n-                            }\n-\n-                            @Override\n-                            public void onThrowable(Throwable t) {\n-                            }\n-                        }).toCompletableFuture();\n-\n-            statusFuture\n-                    .whenComplete((status, throwable) -> {\n+            responseFuture\n+                    .whenComplete((response, throwable) -> {\n                         try {\n                             os.close();\n                         } catch (IOException e) {\n                             future.completeExceptionally(getApiException(e));\n                         }\n                     })\n-                    .thenAccept(status -> {\n-                        if (status.getStatusCode() < 200 || status.getStatusCode() >= 300) {\n+                    .thenAccept(response -> {\n+                        if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n                             future.completeExceptionally(\n                                     getApiException(Response\n-                                            .status(status.getStatusCode())\n-                                            .entity(status.getStatusText())\n+                                            .status(response.getStatusCode())\n+                                            .entity(response.getStatusText())\n                                             .build()));\n                         } else {\n                             future.complete(null);\n@@ -700,7 +674,7 @@ public CompletableFuture<Void> putFunctionStateAsync(\n                             .path(\"state\").path(state.getKey()).getUri().toASCIIString());\n             builder.addBodyPart(new StringPart(\"state\", objectWriter()\n                     .writeValueAsString(state), MediaType.APPLICATION_JSON));\n-            asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n@@ -740,7 +714,7 @@ public CompletableFuture<Void> updateOnWorkerLeaderAsync(String tenant, String n\n                             .addBodyPart(new ByteArrayPart(\"functionMetaData\", functionMetaData))\n                     .addBodyPart(new StringPart(\"delete\", Boolean.toString(delete)));\n \n-            asyncHttpClient.executeRequest(addAuthHeaders(functions, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(functions, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\nindex d69bef448c12e..2b8efc3b97c8c 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PackagesImpl.java\n@@ -20,7 +20,6 @@\n \n import static org.asynchttpclient.Dsl.get;\n import com.google.gson.Gson;\n-import io.netty.handler.codec.http.HttpHeaders;\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.IOException;\n@@ -36,15 +35,14 @@\n import javax.ws.rs.core.Response;\n import org.apache.pulsar.client.admin.Packages;\n import org.apache.pulsar.client.admin.PulsarAdminException;\n+import org.apache.pulsar.client.admin.internal.http.AsyncHttpRequestExecutor;\n import org.apache.pulsar.client.api.Authentication;\n import org.apache.pulsar.common.naming.NamespaceName;\n import org.apache.pulsar.packages.management.core.common.PackageMetadata;\n import org.apache.pulsar.packages.management.core.common.PackageName;\n-import org.asynchttpclient.AsyncHandler;\n-import org.asynchttpclient.AsyncHttpClient;\n+import org.asynchttpclient.AsyncCompletionHandlerBase;\n import org.asynchttpclient.Dsl;\n import org.asynchttpclient.HttpResponseBodyPart;\n-import org.asynchttpclient.HttpResponseStatus;\n import org.asynchttpclient.RequestBuilder;\n import org.asynchttpclient.request.body.multipart.FilePart;\n import org.asynchttpclient.request.body.multipart.StringPart;\n@@ -55,11 +53,12 @@\n public class PackagesImpl extends ComponentResource implements Packages {\n \n     private final WebTarget packages;\n-    private final AsyncHttpClient httpClient;\n+    private final AsyncHttpRequestExecutor asyncHttpRequestExecutor;\n \n-    public PackagesImpl(WebTarget webTarget, Authentication auth, AsyncHttpClient client, long requestTimeoutMs) {\n+    public PackagesImpl(WebTarget webTarget, Authentication auth, AsyncHttpRequestExecutor asyncHttpRequestExecutor,\n+                        long requestTimeoutMs) {\n         super(auth, requestTimeoutMs);\n-        this.httpClient = client;\n+        this.asyncHttpRequestExecutor = asyncHttpRequestExecutor;\n         this.packages = webTarget.path(\"/admin/v3/packages\");\n     }\n \n@@ -98,7 +97,7 @@ public CompletableFuture<Void> uploadAsync(PackageMetadata metadata, String pack\n                 .post(packages.path(PackageName.get(packageName).toRestPath()).getUri().toASCIIString())\n                 .addBodyPart(new FilePart(\"file\", new File(path), MediaType.APPLICATION_OCTET_STREAM))\n                 .addBodyPart(new StringPart(\"metadata\", new Gson().toJson(metadata), MediaType.APPLICATION_JSON));\n-            httpClient.executeRequest(addAuthHeaders(packages, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(packages, builder).build())\n                 .toCompletableFuture()\n                 .thenAccept(response -> {\n                     if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n@@ -138,55 +137,30 @@ public CompletableFuture<Void> downloadAsync(String packageName, String path) {\n             FileChannel os = new FileOutputStream(destinyPath.toFile()).getChannel();\n             RequestBuilder builder = get(webTarget.getUri().toASCIIString());\n \n-            CompletableFuture<HttpResponseStatus> statusFuture =\n-                httpClient.executeRequest(addAuthHeaders(webTarget, builder).build(),\n-                    new AsyncHandler<HttpResponseStatus>() {\n-                        private HttpResponseStatus status;\n+            CompletableFuture<org.asynchttpclient.Response> responseFuture =\n+                asyncHttpRequestExecutor.executeRequest(addAuthHeaders(webTarget, builder).build(),\n+                        () -> new AsyncCompletionHandlerBase() {\n \n-                        @Override\n-                        public State onStatusReceived(HttpResponseStatus httpResponseStatus) throws Exception {\n-                            status = httpResponseStatus;\n-                            if (status.getStatusCode() != Response.Status.OK.getStatusCode()) {\n-                                return State.ABORT;\n+                            @Override\n+                            public State onBodyPartReceived(HttpResponseBodyPart bodyPart) throws Exception {\n+                                os.write(bodyPart.getBodyByteBuffer());\n+                                return State.CONTINUE;\n                             }\n-                            return State.CONTINUE;\n-                        }\n-\n-                        @Override\n-                        public State onHeadersReceived(HttpHeaders httpHeaders) throws Exception {\n-                            return State.CONTINUE;\n-                        }\n-\n-                        @Override\n-                        public State onBodyPartReceived(HttpResponseBodyPart httpResponseBodyPart) throws Exception {\n-                            os.write(httpResponseBodyPart.getBodyByteBuffer());\n-                            return State.CONTINUE;\n-                        }\n-\n-                        @Override\n-                        public void onThrowable(Throwable throwable) {\n-                            // we don't need to handle that throwable and use the returned future to handle it.\n-                        }\n-\n-                        @Override\n-                        public HttpResponseStatus onCompleted() throws Exception {\n-                            return status;\n-                        }\n-                    }).toCompletableFuture();\n-            statusFuture\n-                .whenComplete((status, throwable) -> {\n+                    });\n+            responseFuture\n+                .whenComplete((response, throwable) -> {\n                     try {\n                         os.close();\n                     } catch (IOException e) {\n                         future.completeExceptionally(getApiException(throwable));\n                     }\n                 })\n-                .thenAccept(status -> {\n-                    if (status.getStatusCode() < 200 || status.getStatusCode() >= 300) {\n+                .thenAccept(response -> {\n+                    if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n                         future.completeExceptionally(\n                             getApiException(Response\n-                                .status(status.getStatusCode())\n-                                .entity(status.getStatusText())\n+                                .status(response.getStatusCode())\n+                                .entity(response.getStatusText())\n                                 .build()));\n                     } else {\n                         future.complete(null);\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImpl.java\nindex f7b1695f5f37b..9bfb4fc45f3b7 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImpl.java\n@@ -47,6 +47,7 @@ public PulsarAdmin build() throws PulsarClientException {\n \n     public PulsarAdminBuilderImpl() {\n         this.conf = new ClientConfigurationData();\n+        this.conf.setConnectionsPerBroker(16);\n     }\n \n     private PulsarAdminBuilderImpl(ClientConfigurationData conf) {\n@@ -73,6 +74,15 @@ public PulsarAdminBuilder loadConf(Map<String, Object> config) {\n                 acceptGzipCompression = Boolean.parseBoolean(acceptGzipCompressionObj.toString());\n             }\n         }\n+        // in ClientConfigurationData, the maxConnectionsPerHost maps to connectionsPerBroker\n+        if (config.containsKey(\"maxConnectionsPerHost\")) {\n+            Object maxConnectionsPerHostObj = config.get(\"maxConnectionsPerHost\");\n+            if (maxConnectionsPerHostObj instanceof Integer) {\n+                maxConnectionsPerHost((Integer) maxConnectionsPerHostObj);\n+            } else {\n+                maxConnectionsPerHost(Integer.parseInt(maxConnectionsPerHostObj.toString()));\n+            }\n+        }\n         return this;\n     }\n \n@@ -245,4 +255,18 @@ public PulsarAdminBuilder acceptGzipCompression(boolean acceptGzipCompression) {\n         this.acceptGzipCompression = acceptGzipCompression;\n         return this;\n     }\n+\n+    @Override\n+    public PulsarAdminBuilder maxConnectionsPerHost(int maxConnectionsPerHost) {\n+        // reuse the same configuration as the client, however for the admin client, the connection\n+        // is usually established to a cluster address and not to a broker address\n+        this.conf.setConnectionsPerBroker(maxConnectionsPerHost);\n+        return this;\n+    }\n+\n+    @Override\n+    public PulsarAdminBuilder connectionMaxIdleSeconds(int connectionMaxIdleSeconds) {\n+        this.conf.setConnectionMaxIdleSeconds(connectionMaxIdleSeconds);\n+        return this;\n+    }\n }\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\nindex e00caa6dbbca1..aaea8a89f8db5 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/PulsarAdminImpl.java\n@@ -174,13 +174,13 @@ public PulsarAdminImpl(String serviceUrl, ClientConfigurationData clientConfigDa\n         this.nonPersistentTopics = new NonPersistentTopicsImpl(root, auth, requestTimeoutMs);\n         this.resourceQuotas = new ResourceQuotasImpl(root, auth, requestTimeoutMs);\n         this.lookups = new LookupImpl(root, auth, useTls, requestTimeoutMs, topics);\n-        this.functions = new FunctionsImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n-        this.sources = new SourcesImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n-        this.sinks = new SinksImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.functions = new FunctionsImpl(root, auth, asyncHttpConnector, requestTimeoutMs);\n+        this.sources = new SourcesImpl(root, auth, asyncHttpConnector, requestTimeoutMs);\n+        this.sinks = new SinksImpl(root, auth, asyncHttpConnector, requestTimeoutMs);\n         this.worker = new WorkerImpl(root, auth, requestTimeoutMs);\n         this.schemas = new SchemasImpl(root, auth, requestTimeoutMs);\n         this.bookies = new BookiesImpl(root, auth, requestTimeoutMs);\n-        this.packages = new PackagesImpl(root, auth, asyncHttpConnector.getHttpClient(), requestTimeoutMs);\n+        this.packages = new PackagesImpl(root, auth, asyncHttpConnector, requestTimeoutMs);\n         this.transactions = new TransactionsImpl(root, auth, requestTimeoutMs);\n \n         if (originalCtxLoader != null) {\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\nindex a30f51264cc2e..bba0289d81254 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SinksImpl.java\n@@ -34,13 +34,13 @@\n import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.client.admin.Sink;\n import org.apache.pulsar.client.admin.Sinks;\n+import org.apache.pulsar.client.admin.internal.http.AsyncHttpRequestExecutor;\n import org.apache.pulsar.client.api.Authentication;\n import org.apache.pulsar.common.functions.UpdateOptions;\n import org.apache.pulsar.common.functions.UpdateOptionsImpl;\n import org.apache.pulsar.common.io.ConnectorDefinition;\n import org.apache.pulsar.common.io.SinkConfig;\n import org.apache.pulsar.common.policies.data.SinkStatus;\n-import org.asynchttpclient.AsyncHttpClient;\n import org.asynchttpclient.RequestBuilder;\n import org.asynchttpclient.request.body.multipart.FilePart;\n import org.asynchttpclient.request.body.multipart.StringPart;\n@@ -51,12 +51,13 @@\n public class SinksImpl extends ComponentResource implements Sinks, Sink {\n \n     private final WebTarget sink;\n-    private final AsyncHttpClient asyncHttpClient;\n+    private final AsyncHttpRequestExecutor asyncHttpRequestExecutor;\n \n-    public SinksImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+    public SinksImpl(WebTarget web, Authentication auth, AsyncHttpRequestExecutor asyncHttpRequestExecutor,\n+                     long requestTimeoutMs) {\n         super(auth, requestTimeoutMs);\n         this.sink = web.path(\"/admin/v3/sink\");\n-        this.asyncHttpClient = asyncHttpClient;\n+        this.asyncHttpRequestExecutor = asyncHttpRequestExecutor;\n     }\n \n     @Override\n@@ -145,7 +146,7 @@ public CompletableFuture<Void> createSinkAsync(SinkConfig sinkConfig, String fil\n                 // If the function code is built in, we don't need to submit here\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n-            asyncHttpClient.executeRequest(addAuthHeaders(sink, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(sink, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n@@ -233,7 +234,7 @@ public CompletableFuture<Void> updateSinkAsync(\n                 // If the function code is built in, we don't need to submit here\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n-            asyncHttpClient.executeRequest(addAuthHeaders(sink, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(sink, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\nindex 8821ed61ce5b8..56cf7db229b78 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/SourcesImpl.java\n@@ -33,13 +33,13 @@\n import org.apache.pulsar.client.admin.PulsarAdminException;\n import org.apache.pulsar.client.admin.Source;\n import org.apache.pulsar.client.admin.Sources;\n+import org.apache.pulsar.client.admin.internal.http.AsyncHttpRequestExecutor;\n import org.apache.pulsar.client.api.Authentication;\n import org.apache.pulsar.common.functions.UpdateOptions;\n import org.apache.pulsar.common.functions.UpdateOptionsImpl;\n import org.apache.pulsar.common.io.ConnectorDefinition;\n import org.apache.pulsar.common.io.SourceConfig;\n import org.apache.pulsar.common.policies.data.SourceStatus;\n-import org.asynchttpclient.AsyncHttpClient;\n import org.asynchttpclient.RequestBuilder;\n import org.asynchttpclient.request.body.multipart.FilePart;\n import org.asynchttpclient.request.body.multipart.StringPart;\n@@ -50,12 +50,13 @@\n public class SourcesImpl extends ComponentResource implements Sources, Source {\n \n     private final WebTarget source;\n-    private final AsyncHttpClient asyncHttpClient;\n+    private final AsyncHttpRequestExecutor asyncHttpRequestExecutor;\n \n-    public SourcesImpl(WebTarget web, Authentication auth, AsyncHttpClient asyncHttpClient, long requestTimeoutMs) {\n+    public SourcesImpl(WebTarget web, Authentication auth, AsyncHttpRequestExecutor asyncHttpRequestExecutor,\n+                       long requestTimeoutMs) {\n         super(auth, requestTimeoutMs);\n         this.source = web.path(\"/admin/v3/source\");\n-        this.asyncHttpClient = asyncHttpClient;\n+        this.asyncHttpRequestExecutor = asyncHttpRequestExecutor;\n     }\n \n     @Override\n@@ -124,7 +125,7 @@ public CompletableFuture<Void> createSourceAsync(SourceConfig sourceConfig, Stri\n                 // If the function code is built in, we don't need to submit here\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n-            asyncHttpClient.executeRequest(addAuthHeaders(source, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(source, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n@@ -202,7 +203,7 @@ public CompletableFuture<Void> updateSourceAsync(\n                 // If the function code is built in, we don't need to submit here\n                 builder.addBodyPart(new FilePart(\"data\", new File(fileName), MediaType.APPLICATION_OCTET_STREAM));\n             }\n-            asyncHttpClient.executeRequest(addAuthHeaders(source, builder).build())\n+            asyncHttpRequestExecutor.executeRequest(addAuthHeaders(source, builder).build())\n                     .toCompletableFuture()\n                     .thenAccept(response -> {\n                         if (response.getStatusCode() < 200 || response.getStatusCode() >= 300) {\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\nindex a0569c391ad50..1423d52642027 100644\n--- a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnector.java\n@@ -18,6 +18,17 @@\n  */\n package org.apache.pulsar.client.admin.internal.http;\n \n+import static org.asynchttpclient.util.HttpConstants.Methods.GET;\n+import static org.asynchttpclient.util.HttpConstants.Methods.HEAD;\n+import static org.asynchttpclient.util.HttpConstants.Methods.OPTIONS;\n+import static org.asynchttpclient.util.HttpConstants.ResponseStatusCodes.FOUND_302;\n+import static org.asynchttpclient.util.HttpConstants.ResponseStatusCodes.MOVED_PERMANENTLY_301;\n+import static org.asynchttpclient.util.HttpConstants.ResponseStatusCodes.PERMANENT_REDIRECT_308;\n+import static org.asynchttpclient.util.HttpConstants.ResponseStatusCodes.SEE_OTHER_303;\n+import static org.asynchttpclient.util.HttpConstants.ResponseStatusCodes.TEMPORARY_REDIRECT_307;\n+import static org.asynchttpclient.util.MiscUtils.isNonEmpty;\n+import com.spotify.futures.ConcurrencyReducer;\n+import io.netty.handler.codec.http.DefaultHttpHeaders;\n import io.netty.handler.codec.http.HttpRequest;\n import io.netty.handler.codec.http.HttpResponse;\n import io.netty.handler.ssl.SslContext;\n@@ -27,9 +38,12 @@\n import java.io.IOException;\n import java.net.InetSocketAddress;\n import java.net.URI;\n+import java.security.GeneralSecurityException;\n import java.time.Duration;\n+import java.util.Map;\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n@@ -37,32 +51,39 @@\n import java.util.concurrent.TimeoutException;\n import java.util.function.Supplier;\n import javax.net.ssl.SSLContext;\n+import javax.ws.rs.ProcessingException;\n import javax.ws.rs.client.Client;\n import javax.ws.rs.core.HttpHeaders;\n import javax.ws.rs.core.Response.Status;\n import lombok.Getter;\n import lombok.SneakyThrows;\n import lombok.extern.slf4j.Slf4j;\n-import org.apache.commons.lang3.StringUtils;\n+import org.apache.commons.lang3.Validate;\n import org.apache.pulsar.PulsarVersion;\n import org.apache.pulsar.client.admin.internal.PulsarAdminImpl;\n import org.apache.pulsar.client.api.AuthenticationDataProvider;\n import org.apache.pulsar.client.api.KeyStoreParams;\n import org.apache.pulsar.client.impl.PulsarServiceNameResolver;\n+import org.apache.pulsar.client.impl.ServiceNameResolver;\n import org.apache.pulsar.client.impl.conf.ClientConfigurationData;\n import org.apache.pulsar.client.util.WithSNISslEngineFactory;\n import org.apache.pulsar.common.util.FutureUtil;\n import org.apache.pulsar.common.util.SecurityUtility;\n import org.apache.pulsar.common.util.keystoretls.KeyStoreSSLContext;\n+import org.asynchttpclient.AsyncCompletionHandlerBase;\n+import org.asynchttpclient.AsyncHandler;\n import org.asynchttpclient.AsyncHttpClient;\n+import org.asynchttpclient.AsyncHttpClientConfig;\n import org.asynchttpclient.BoundRequestBuilder;\n import org.asynchttpclient.DefaultAsyncHttpClient;\n import org.asynchttpclient.DefaultAsyncHttpClientConfig;\n import org.asynchttpclient.ListenableFuture;\n import org.asynchttpclient.Request;\n import org.asynchttpclient.Response;\n+import org.asynchttpclient.SslEngineFactory;\n import org.asynchttpclient.channel.DefaultKeepAliveStrategy;\n import org.asynchttpclient.netty.ssl.JsseSslEngineFactory;\n+import org.asynchttpclient.uri.Uri;\n import org.glassfish.jersey.client.ClientProperties;\n import org.glassfish.jersey.client.ClientRequest;\n import org.glassfish.jersey.client.ClientResponse;\n@@ -73,17 +94,19 @@\n  * Customized Jersey client connector with multi-host support.\n  */\n @Slf4j\n-public class AsyncHttpConnector implements Connector {\n+public class AsyncHttpConnector implements Connector, AsyncHttpRequestExecutor {\n     private static final TimeoutException REQUEST_TIMEOUT_EXCEPTION =\n             FutureUtil.createTimeoutException(\"Request timeout\", AsyncHttpConnector.class, \"retryOrTimeout(...)\");\n+    private static final int DEFAULT_MAX_QUEUE_SIZE_PER_HOST = 10000;\n     @Getter\n     private final AsyncHttpClient httpClient;\n     private final Duration requestTimeout;\n     private final int maxRetries;\n-    private final PulsarServiceNameResolver serviceNameResolver;\n+    private final ServiceNameResolver serviceNameResolver;\n     private final ScheduledExecutorService delayer = Executors.newScheduledThreadPool(1,\n             new DefaultThreadFactory(\"delayer\"));\n     private final boolean acceptGzipCompression;\n+    private final Map<String, ConcurrencyReducer<Response>> concurrencyReducers = new ConcurrentHashMap<>();\n \n     public AsyncHttpConnector(Client client, ClientConfigurationData conf, int autoCertRefreshTimeSeconds,\n                               boolean acceptGzipCompression) {\n@@ -99,10 +122,47 @@ public AsyncHttpConnector(int connectTimeoutMs, int readTimeoutMs,\n                               int requestTimeoutMs,\n                               int autoCertRefreshTimeSeconds, ClientConfigurationData conf,\n                               boolean acceptGzipCompression) {\n+        Validate.notEmpty(conf.getServiceUrl(), \"Service URL is not provided\");\n+        serviceNameResolver = new PulsarServiceNameResolver();\n+        String serviceUrl = conf.getServiceUrl();\n+        serviceNameResolver.updateServiceUrl(serviceUrl);\n         this.acceptGzipCompression = acceptGzipCompression;\n+        AsyncHttpClientConfig asyncHttpClientConfig =\n+                createAsyncHttpClientConfig(conf, connectTimeoutMs, readTimeoutMs, requestTimeoutMs,\n+                        autoCertRefreshTimeSeconds);\n+        httpClient = createAsyncHttpClient(asyncHttpClientConfig);\n+        this.requestTimeout = requestTimeoutMs > 0 ? Duration.ofMillis(requestTimeoutMs) : null;\n+        this.maxRetries = httpClient.getConfig().getMaxRequestRetry();\n+    }\n+\n+    private AsyncHttpClientConfig createAsyncHttpClientConfig(ClientConfigurationData conf, int connectTimeoutMs,\n+                                                              int readTimeoutMs,\n+                                                              int requestTimeoutMs, int autoCertRefreshTimeSeconds)\n+            throws GeneralSecurityException, IOException {\n         DefaultAsyncHttpClientConfig.Builder confBuilder = new DefaultAsyncHttpClientConfig.Builder();\n+        configureAsyncHttpClientConfig(conf, connectTimeoutMs, readTimeoutMs, requestTimeoutMs, confBuilder);\n+        if (conf.getServiceUrl().startsWith(\"https://\")) {\n+            configureAsyncHttpClientSslEngineFactory(conf, autoCertRefreshTimeSeconds, confBuilder);\n+        }\n+        AsyncHttpClientConfig asyncHttpClientConfig = confBuilder.build();\n+        return asyncHttpClientConfig;\n+    }\n+\n+    private void configureAsyncHttpClientConfig(ClientConfigurationData conf, int connectTimeoutMs, int readTimeoutMs,\n+                                                int requestTimeoutMs,\n+                                                DefaultAsyncHttpClientConfig.Builder confBuilder) {\n+        if (conf.getConnectionsPerBroker() > 0) {\n+            confBuilder.setMaxConnectionsPerHost(conf.getConnectionsPerBroker());\n+            // Use the request timeout value for acquireFreeChannelTimeout so that we don't need to add\n+            // yet another configuration property. When the ConcurrencyReducer is in use, it shouldn't be necessary to\n+            // wait for a free channel since the ConcurrencyReducer will queue the requests.\n+            confBuilder.setAcquireFreeChannelTimeout(conf.getRequestTimeoutMs());\n+        }\n+        if (conf.getConnectionMaxIdleSeconds() > 0) {\n+            confBuilder.setPooledConnectionIdleTimeout(conf.getConnectionMaxIdleSeconds() * 1000);\n+        }\n         confBuilder.setUseProxyProperties(true);\n-        confBuilder.setFollowRedirect(true);\n+        confBuilder.setFollowRedirect(false);\n         confBuilder.setRequestTimeout(conf.getRequestTimeoutMs());\n         confBuilder.setConnectTimeout(connectTimeoutMs);\n         confBuilder.setReadTimeout(readTimeoutMs);\n@@ -118,75 +178,75 @@ public boolean keepAlive(InetSocketAddress remoteAddress, Request ahcRequest,\n                        && super.keepAlive(remoteAddress, ahcRequest, request, response);\n             }\n         });\n+        confBuilder.setDisableHttpsEndpointIdentificationAlgorithm(!conf.isTlsHostnameVerificationEnable());\n+    }\n \n-        serviceNameResolver = new PulsarServiceNameResolver();\n-        if (conf != null && StringUtils.isNotBlank(conf.getServiceUrl())) {\n-            serviceNameResolver.updateServiceUrl(conf.getServiceUrl());\n-            if (conf.getServiceUrl().startsWith(\"https://\")) {\n-                // Set client key and certificate if available\n-                AuthenticationDataProvider authData = conf.getAuthentication().getAuthData();\n-\n-                if (conf.isUseKeyStoreTls()) {\n-                    KeyStoreParams params = authData.hasDataForTls() ? authData.getTlsKeyStoreParams() :\n-                            new KeyStoreParams(conf.getTlsKeyStoreType(), conf.getTlsKeyStorePath(),\n-                                    conf.getTlsKeyStorePassword());\n-\n-                    final SSLContext sslCtx = KeyStoreSSLContext.createClientSslContext(\n-                            conf.getSslProvider(),\n-                            params.getKeyStoreType(),\n-                            params.getKeyStorePath(),\n-                            params.getKeyStorePassword(),\n-                            conf.isTlsAllowInsecureConnection(),\n-                            conf.getTlsTrustStoreType(),\n-                            conf.getTlsTrustStorePath(),\n-                            conf.getTlsTrustStorePassword(),\n-                            conf.getTlsCiphers(),\n-                            conf.getTlsProtocols());\n-\n-                    JsseSslEngineFactory sslEngineFactory = new JsseSslEngineFactory(sslCtx);\n-                    confBuilder.setSslEngineFactory(sslEngineFactory);\n-                } else {\n-                    SslProvider sslProvider = null;\n-                    if (conf.getSslProvider() != null) {\n-                        sslProvider = SslProvider.valueOf(conf.getSslProvider());\n-                    }\n-                    SslContext sslCtx = null;\n-                    if (authData.hasDataForTls()) {\n-                        sslCtx = authData.getTlsTrustStoreStream() == null\n-                                ? SecurityUtility.createAutoRefreshSslContextForClient(\n-                                sslProvider,\n-                                conf.isTlsAllowInsecureConnection(),\n-                                conf.getTlsTrustCertsFilePath(), authData.getTlsCertificateFilePath(),\n-                                authData.getTlsPrivateKeyFilePath(), null, autoCertRefreshTimeSeconds, delayer)\n-                                : SecurityUtility.createNettySslContextForClient(\n-                                sslProvider,\n-                                conf.isTlsAllowInsecureConnection(),\n-                                authData.getTlsTrustStoreStream(), authData.getTlsCertificates(),\n-                                authData.getTlsPrivateKey(),\n-                                conf.getTlsCiphers(),\n-                                conf.getTlsProtocols());\n-                    } else {\n-                        sslCtx = SecurityUtility.createNettySslContextForClient(\n-                                sslProvider,\n-                                conf.isTlsAllowInsecureConnection(),\n-                                conf.getTlsTrustCertsFilePath(),\n-                                conf.getTlsCertificateFilePath(),\n-                                conf.getTlsKeyFilePath(),\n-                                conf.getTlsCiphers(),\n-                                conf.getTlsProtocols());\n-                    }\n-                    confBuilder.setSslContext(sslCtx);\n-                    if (!conf.isTlsHostnameVerificationEnable()) {\n-                        confBuilder.setSslEngineFactory(new WithSNISslEngineFactory(serviceNameResolver\n-                                .resolveHostUri().getHost()));\n-                    }\n-                }\n+    protected AsyncHttpClient createAsyncHttpClient(AsyncHttpClientConfig asyncHttpClientConfig) {\n+        return new DefaultAsyncHttpClient(asyncHttpClientConfig);\n+    }\n+\n+    private void configureAsyncHttpClientSslEngineFactory(ClientConfigurationData conf, int autoCertRefreshTimeSeconds,\n+                                                          DefaultAsyncHttpClientConfig.Builder confBuilder)\n+            throws GeneralSecurityException, IOException {\n+        // Set client key and certificate if available\n+        AuthenticationDataProvider authData = conf.getAuthentication().getAuthData();\n+\n+        SslEngineFactory sslEngineFactory = null;\n+        if (conf.isUseKeyStoreTls()) {\n+            KeyStoreParams params = authData.hasDataForTls() ? authData.getTlsKeyStoreParams() :\n+                    new KeyStoreParams(conf.getTlsKeyStoreType(), conf.getTlsKeyStorePath(),\n+                            conf.getTlsKeyStorePassword());\n+\n+            final SSLContext sslCtx = KeyStoreSSLContext.createClientSslContext(\n+                    conf.getSslProvider(),\n+                    params.getKeyStoreType(),\n+                    params.getKeyStorePath(),\n+                    params.getKeyStorePassword(),\n+                    conf.isTlsAllowInsecureConnection(),\n+                    conf.getTlsTrustStoreType(),\n+                    conf.getTlsTrustStorePath(),\n+                    conf.getTlsTrustStorePassword(),\n+                    conf.getTlsCiphers(),\n+                    conf.getTlsProtocols());\n+\n+            sslEngineFactory = new JsseSslEngineFactory(sslCtx);\n+            confBuilder.setSslEngineFactory(sslEngineFactory);\n+        } else {\n+            SslProvider sslProvider = null;\n+            if (conf.getSslProvider() != null) {\n+                sslProvider = SslProvider.valueOf(conf.getSslProvider());\n+            }\n+            SslContext sslCtx = null;\n+            if (authData.hasDataForTls()) {\n+                sslCtx = authData.getTlsTrustStoreStream() == null\n+                        ? SecurityUtility.createAutoRefreshSslContextForClient(\n+                        sslProvider,\n+                        conf.isTlsAllowInsecureConnection(),\n+                        conf.getTlsTrustCertsFilePath(), authData.getTlsCertificateFilePath(),\n+                        authData.getTlsPrivateKeyFilePath(), null, autoCertRefreshTimeSeconds, delayer)\n+                        : SecurityUtility.createNettySslContextForClient(\n+                        sslProvider,\n+                        conf.isTlsAllowInsecureConnection(),\n+                        authData.getTlsTrustStoreStream(), authData.getTlsCertificates(),\n+                        authData.getTlsPrivateKey(),\n+                        conf.getTlsCiphers(),\n+                        conf.getTlsProtocols());\n+            } else {\n+                sslCtx = SecurityUtility.createNettySslContextForClient(\n+                        sslProvider,\n+                        conf.isTlsAllowInsecureConnection(),\n+                        conf.getTlsTrustCertsFilePath(),\n+                        conf.getTlsCertificateFilePath(),\n+                        conf.getTlsKeyFilePath(),\n+                        conf.getTlsCiphers(),\n+                        conf.getTlsProtocols());\n+            }\n+            confBuilder.setSslContext(sslCtx);\n+            if (!conf.isTlsHostnameVerificationEnable()) {\n+                confBuilder.setSslEngineFactory(new WithSNISslEngineFactory(serviceNameResolver\n+                        .resolveHostUri().getHost()));\n             }\n-            confBuilder.setDisableHttpsEndpointIdentificationAlgorithm(!conf.isTlsHostnameVerificationEnable());\n         }\n-        httpClient = new DefaultAsyncHttpClient(confBuilder.build());\n-        this.requestTimeout = requestTimeoutMs > 0 ? Duration.ofMillis(requestTimeoutMs) : null;\n-        this.maxRetries = httpClient.getConfig().getMaxRequestRetry();\n     }\n \n     @Override\n@@ -206,9 +266,8 @@ public void failure(Throwable failure) {\n         try {\n             return future.get();\n         } catch (InterruptedException | ExecutionException e) {\n-            log.error(e.getMessage());\n+            throw new ProcessingException(e.getCause());\n         }\n-        return null;\n     }\n \n     private URI replaceWithNew(InetSocketAddress address, URI uri) {\n@@ -270,6 +329,8 @@ private CompletableFuture<Response> retryOrTimeOut(ClientRequest request) {\n         return resultFuture;\n     }\n \n+    // TODO: There are problems with this solution since AsyncHttpClient already contains logic to retry requests.\n+    // This solution doesn't contain backoff handling.\n     private <T> void retryOperation(\n             final CompletableFuture<T> resultFuture,\n             final Supplier<CompletableFuture<T>> operation,\n@@ -281,9 +342,13 @@ private <T> void retryOperation(\n             operationFuture.whenComplete(\n                     (t, throwable) -> {\n                         if (throwable != null) {\n+                            throwable = FutureUtil.unwrapCompletionException(throwable);\n                             if (throwable instanceof CancellationException) {\n                                 resultFuture.completeExceptionally(\n                                         new RetryException(\"Operation future was cancelled.\", throwable));\n+                            } else if (throwable instanceof MaxRedirectException) {\n+                                // don't retry on max redirect\n+                                resultFuture.completeExceptionally(throwable);\n                             } else {\n                                 if (retries > 0) {\n                                     if (log.isDebugEnabled()) {\n@@ -323,7 +388,129 @@ public RetryException(String message, Throwable cause) {\n         }\n     }\n \n+    public static class MaxRedirectException extends Exception {\n+        public MaxRedirectException(String msg) {\n+            super(msg, null, true, false);\n+        }\n+    }\n+\n     protected CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequest request) {\n+        Request preparedRequest;\n+        try {\n+            preparedRequest = prepareRequest(host, request);\n+        } catch (IOException e) {\n+            return FutureUtil.failedFuture(e);\n+        }\n+        return executeRequest(preparedRequest);\n+    }\n+\n+    public CompletableFuture<Response> executeRequest(Request request) {\n+        return executeRequest(request, () -> new AsyncCompletionHandlerBase());\n+    }\n+\n+    public CompletableFuture<Response> executeRequest(Request request,\n+                                                       Supplier<AsyncHandler<Response>> handlerSupplier) {\n+        return executeRequest(request, handlerSupplier, 0);\n+    }\n+\n+    private CompletableFuture<Response> executeRequest(Request request,\n+                                                       Supplier<AsyncHandler<Response>> handlerSupplier,\n+                                                       int redirectCount) {\n+        int maxRedirects = httpClient.getConfig().getMaxRedirects();\n+        if (redirectCount > maxRedirects) {\n+            return FutureUtil.failedFuture(\n+                    new MaxRedirectException(\"Maximum redirect reached: \" + maxRedirects + \" uri:\" + request.getUri()));\n+        }\n+        CompletableFuture<Response> responseFuture;\n+        if (httpClient.getConfig().getMaxConnectionsPerHost() > 0) {\n+            String hostAndPort = request.getUri().getHost() + \":\" + request.getUri().getPort();\n+            ConcurrencyReducer<Response> responseConcurrencyReducer = concurrencyReducers.computeIfAbsent(hostAndPort,\n+                    h -> ConcurrencyReducer.create(httpClient.getConfig().getMaxConnectionsPerHost(),\n+                            DEFAULT_MAX_QUEUE_SIZE_PER_HOST));\n+            responseFuture = responseConcurrencyReducer.add(() -> doExecuteRequest(request, handlerSupplier));\n+        } else {\n+            responseFuture = doExecuteRequest(request, handlerSupplier);\n+        }\n+        CompletableFuture<Response> futureWithRedirect = responseFuture.thenCompose(response -> {\n+            if (isRedirectStatusCode(response.getStatusCode())) {\n+                return executeRedirect(request, response, handlerSupplier, redirectCount);\n+            }\n+            return CompletableFuture.completedFuture(response);\n+        });\n+        futureWithRedirect.whenComplete((response, throwable) -> {\n+            // propagate cancellation or timeout to the original response future\n+            responseFuture.cancel(false);\n+        });\n+        return futureWithRedirect;\n+    }\n+\n+    private CompletableFuture<Response> executeRedirect(Request request, Response response,\n+                                                        Supplier<AsyncHandler<Response>> handlerSupplier,\n+                                                        int redirectCount) {\n+        String originalMethod = request.getMethod();\n+        int statusCode = response.getStatusCode();\n+        boolean switchToGet = !originalMethod.equals(GET)\n+                && !originalMethod.equals(OPTIONS) && !originalMethod.equals(HEAD) && (\n+                statusCode == MOVED_PERMANENTLY_301 || statusCode == SEE_OTHER_303 || statusCode == FOUND_302);\n+        boolean keepBody = statusCode == TEMPORARY_REDIRECT_307 || statusCode == PERMANENT_REDIRECT_308;\n+        String location = response.getHeader(HttpHeaders.LOCATION);\n+        Uri newUri = Uri.create(request.getUri(), location);\n+        BoundRequestBuilder builder = httpClient.prepareRequest(request);\n+        if (switchToGet) {\n+            builder.setMethod(GET);\n+        }\n+        builder.setUri(newUri);\n+        if (keepBody) {\n+            builder.setCharset(request.getCharset());\n+            if (isNonEmpty(request.getFormParams())) {\n+                builder.setFormParams(request.getFormParams());\n+            } else if (request.getStringData() != null) {\n+                builder.setBody(request.getStringData());\n+            } else if (request.getByteData() != null){\n+                builder.setBody(request.getByteData());\n+            } else if (request.getByteBufferData() != null) {\n+                builder.setBody(request.getByteBufferData());\n+            } else if (request.getBodyGenerator() != null) {\n+                builder.setBody(request.getBodyGenerator());\n+            } else if (isNonEmpty(request.getBodyParts())) {\n+                builder.setBodyParts(request.getBodyParts());\n+            }\n+        } else {\n+            builder.resetFormParams();\n+            builder.resetNonMultipartData();\n+            builder.resetMultipartData();\n+            io.netty.handler.codec.http.HttpHeaders headers = new DefaultHttpHeaders();\n+            headers.add(request.getHeaders());\n+            headers.remove(HttpHeaders.CONTENT_LENGTH);\n+            headers.remove(HttpHeaders.CONTENT_TYPE);\n+            headers.remove(HttpHeaders.CONTENT_ENCODING);\n+            builder.setHeaders(headers);\n+        }\n+        return executeRequest(builder.build(), handlerSupplier, redirectCount + 1);\n+    }\n+\n+    private static boolean isRedirectStatusCode(int statusCode) {\n+        return statusCode == MOVED_PERMANENTLY_301 || statusCode == FOUND_302 || statusCode == SEE_OTHER_303\n+                || statusCode == TEMPORARY_REDIRECT_307 || statusCode == PERMANENT_REDIRECT_308;\n+    }\n+\n+    private CompletableFuture<Response> doExecuteRequest(Request request,\n+                                                         Supplier<AsyncHandler<Response>> handlerSupplier) {\n+        ListenableFuture<Response> responseFuture =\n+                httpClient.executeRequest(request, handlerSupplier.get());\n+        CompletableFuture<Response> completableFuture = responseFuture.toCompletableFuture();\n+        completableFuture.whenComplete((response, throwable) -> {\n+            throwable = FutureUtil.unwrapCompletionException(throwable);\n+            if (throwable != null && (throwable instanceof CancellationException\n+                    || throwable instanceof TimeoutException)) {\n+                // abort the request if the future is cancelled or timed out\n+                responseFuture.abort(throwable);\n+            }\n+        });\n+        return completableFuture;\n+    }\n+\n+    private Request prepareRequest(InetSocketAddress host, ClientRequest request) throws IOException {\n         ClientRequest currentRequest = new ClientRequest(request);\n         URI newUri = replaceWithNew(host, currentRequest.getUri());\n         currentRequest.setUri(newUri);\n@@ -334,14 +521,7 @@ protected CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequ\n         if (currentRequest.hasEntity()) {\n             ByteArrayOutputStream outStream = new ByteArrayOutputStream();\n             currentRequest.setStreamProvider(contentLength -> outStream);\n-            try {\n-                currentRequest.writeEntity();\n-            } catch (IOException e) {\n-                CompletableFuture<Response> r = new CompletableFuture<>();\n-                r.completeExceptionally(e);\n-                return r;\n-            }\n-\n+            currentRequest.writeEntity();\n             builder.setBody(outStream.toByteArray());\n         }\n \n@@ -355,16 +535,7 @@ protected CompletableFuture<Response> oneShot(InetSocketAddress host, ClientRequ\n             builder.setHeader(HttpHeaders.ACCEPT_ENCODING, \"gzip\");\n         }\n \n-        ListenableFuture<Response> responseFuture = builder.execute();\n-        CompletableFuture<Response> completableFuture = responseFuture.toCompletableFuture();\n-        completableFuture.whenComplete((response, throwable) -> {\n-            if (throwable != null && (throwable instanceof CancellationException\n-                    || throwable instanceof TimeoutException)) {\n-                // abort the request if the future is cancelled or timed out\n-                responseFuture.abort(throwable);\n-            }\n-        });\n-        return completableFuture;\n+        return builder.build();\n     }\n \n     @Override\n\ndiff --git a/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpRequestExecutor.java b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpRequestExecutor.java\nnew file mode 100644\nindex 0000000000000..d3c7a653b36b4\n--- /dev/null\n+++ b/pulsar-client-admin/src/main/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpRequestExecutor.java\n@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pulsar.client.admin.internal.http;\n+\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Supplier;\n+import org.asynchttpclient.AsyncHandler;\n+import org.asynchttpclient.Request;\n+import org.asynchttpclient.Response;\n+\n+/**\n+ * Interface for executing HTTP requests asynchronously.\n+ * This is used internally in the Pulsar Admin client for executing HTTP requests that by-pass the Jersey client\n+ * and use the AsyncHttpClient API directly.\n+ */\n+public interface AsyncHttpRequestExecutor {\n+    /**\n+     * Execute the given HTTP request asynchronously.\n+     *\n+     * @param request the HTTP request to execute\n+     * @return a future that will be completed with the HTTP response\n+     */\n+    CompletableFuture<Response> executeRequest(Request request);\n+    /**\n+     * Execute the given HTTP request asynchronously.\n+     *\n+     * @param request the HTTP request to execute\n+     * @param handlerSupplier a supplier for the async handler to use for the request\n+     * @return a future that will be completed with the HTTP response\n+     */\n+    CompletableFuture<Response> executeRequest(Request request, Supplier<AsyncHandler<Response>> handlerSupplier);\n+}\n\ndiff --git a/pulsar-client-all/pom.xml b/pulsar-client-all/pom.xml\nindex 65d24e3394d10..484869e35b604 100644\n--- a/pulsar-client-all/pom.xml\n+++ b/pulsar-client-all/pom.xml\n@@ -167,6 +167,7 @@\n                   <include>com.google.j2objc:*</include>\n                   <include>com.google.code.gson:gson</include>\n                   <include>com.google.re2j:re2j</include>\n+                  <include>com.spotify:completable-futures</include>\n                   <include>com.fasterxml.jackson.*:*</include>\n                   <include>io.netty:netty</include>\n                   <include>io.netty:netty-all</include>\n@@ -243,6 +244,10 @@\n                     <exclude>com.google.protobuf.*</exclude>\n                   </excludes>\n                 </relocation>\n+                <relocation>\n+                  <pattern>com.spotify.futures</pattern>\n+                  <shadedPattern>org.apache.pulsar.shade.com.spotify.futures</shadedPattern>\n+                </relocation>\n                 <relocation>\n                   <pattern>com.fasterxml.jackson</pattern>\n                   <shadedPattern>org.apache.pulsar.shade.com.fasterxml.jackson</shadedPattern>\n\ndiff --git a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ClientBuilder.java b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ClientBuilder.java\nindex 735aeeed55916..7b98fa57bf0de 100644\n--- a/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ClientBuilder.java\n+++ b/pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ClientBuilder.java\n@@ -130,6 +130,8 @@ public interface ClientBuilder extends Serializable, Cloneable {\n \n     /**\n      * Release the connection if it is not used for more than {@param connectionMaxIdleSeconds} seconds.\n+     * Defaults to 25 seconds.\n+     *\n      * @return the client builder instance\n      */\n     ClientBuilder connectionMaxIdleSeconds(int connectionMaxIdleSeconds);\n\ndiff --git a/pulsar-client-shaded/pom.xml b/pulsar-client-shaded/pom.xml\nindex c18d3123e66be..13f3d237d6e82 100644\n--- a/pulsar-client-shaded/pom.xml\n+++ b/pulsar-client-shaded/pom.xml\n@@ -145,6 +145,7 @@\n                   <include>com.google.j2objc:*</include>\n                   <include>com.google.code.gson:gson</include>\n                   <include>com.google.re2j:re2j</include>\n+                  <include>com.spotify:completable-futures</include>\n                   <include>com.fasterxml.jackson.*:*</include>\n                   <include>io.netty:*</include>\n                   <include>io.netty.incubator:*</include>\n@@ -204,6 +205,10 @@\n                     <exclude>com.google.protobuf.*</exclude>\n                   </excludes>\n                 </relocation>\n+                <relocation>\n+                  <pattern>com.spotify.futures</pattern>\n+                  <shadedPattern>org.apache.pulsar.shade.com.spotify.futures</shadedPattern>\n+                </relocation>\n                 <relocation>\n                   <pattern>com.fasterxml.jackson</pattern>\n                   <shadedPattern>org.apache.pulsar.shade.com.fasterxml.jackson</shadedPattern>\n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConnectionPool.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConnectionPool.java\nindex d5adbdd7098ed..21575578e76f2 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConnectionPool.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ConnectionPool.java\n@@ -67,7 +67,7 @@\n \n public class ConnectionPool implements AutoCloseable {\n \n-    public static final int IDLE_DETECTION_INTERVAL_SECONDS_MIN = 60;\n+    public static final int IDLE_DETECTION_INTERVAL_SECONDS_MIN = 15;\n \n     protected final ConcurrentMap<Key, CompletableFuture<ClientCnx>> pool;\n \n\ndiff --git a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ClientConfigurationData.java b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ClientConfigurationData.java\nindex 6dcea7dc46672..237c6b5aebc3c 100644\n--- a/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ClientConfigurationData.java\n+++ b/pulsar-client/src/main/java/org/apache/pulsar/client/impl/conf/ClientConfigurationData.java\n@@ -19,6 +19,7 @@\n package org.apache.pulsar.client.impl.conf;\n \n import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n import io.opentelemetry.api.OpenTelemetry;\n import io.swagger.annotations.ApiModelProperty;\n@@ -49,6 +50,7 @@\n @Data\n @NoArgsConstructor\n @AllArgsConstructor\n+@JsonIgnoreProperties(ignoreUnknown = true)\n public class ClientConfigurationData implements Serializable, Cloneable {\n     private static final long serialVersionUID = 1L;\n \n@@ -134,7 +136,7 @@ public class ClientConfigurationData implements Serializable, Cloneable {\n             value = \"Release the connection if it is not used for more than [connectionMaxIdleSeconds] seconds. \"\n                     + \"If  [connectionMaxIdleSeconds] < 0, disabled the feature that auto release the idle connections\"\n     )\n-    private int connectionMaxIdleSeconds = 180;\n+    private int connectionMaxIdleSeconds = 25;\n \n     @ApiModelProperty(\n             name = \"useTcpNoDelay\",\n\ndiff --git a/pulsar-common/pom.xml b/pulsar-common/pom.xml\nindex aa7e4998e5c3e..4b53954aab1df 100644\n--- a/pulsar-common/pom.xml\n+++ b/pulsar-common/pom.xml\n@@ -210,6 +210,11 @@\n       <artifactId>re2j</artifactId>\n     </dependency>\n \n+    <dependency>\n+      <groupId>com.spotify</groupId>\n+      <artifactId>completable-futures</artifactId>\n+    </dependency>\n+\n     <!-- test -->\n     <dependency>\n       <groupId>org.bouncycastle</groupId>\n",
    "test_patch": "diff --git a/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java\nindex 8f4162ca74b32..b61b8774b6e2e 100644\n--- a/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java\n+++ b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/PulsarAdminBuilderImplTest.java\n@@ -66,6 +66,7 @@ public void testGetPropertiesFromConf() throws Exception {\n         config.put(\"autoCertRefreshSeconds\", 20);\n         config.put(\"connectionTimeoutMs\", 30);\n         config.put(\"readTimeoutMs\", 40);\n+        config.put(\"maxConnectionsPerHost\", 50);\n         PulsarAdminBuilder adminBuilder = PulsarAdmin.builder().loadConf(config);\n         @Cleanup\n         PulsarAdminImpl admin = (PulsarAdminImpl) adminBuilder.build();\n@@ -74,6 +75,7 @@ public void testGetPropertiesFromConf() throws Exception {\n         Assert.assertEquals(clientConfigData.getAutoCertRefreshSeconds(), 20);\n         Assert.assertEquals(clientConfigData.getConnectionTimeoutMs(), 30);\n         Assert.assertEquals(clientConfigData.getReadTimeoutMs(), 40);\n+        Assert.assertEquals(clientConfigData.getConnectionsPerBroker(), 50);\n     }\n \n     @Test\n\ndiff --git a/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java\nindex dd3fb40ae9ab0..f8518b5931034 100644\n--- a/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java\n+++ b/pulsar-client-admin/src/test/java/org/apache/pulsar/client/admin/internal/http/AsyncHttpConnectorTest.java\n@@ -20,23 +20,34 @@\n \n import static com.github.tomakehurst.wiremock.client.WireMock.aResponse;\n import static com.github.tomakehurst.wiremock.client.WireMock.get;\n+import static com.github.tomakehurst.wiremock.client.WireMock.post;\n import static com.github.tomakehurst.wiremock.client.WireMock.urlEqualTo;\n import static org.testng.Assert.assertEquals;\n import static org.testng.Assert.assertTrue;\n+import static org.testng.Assert.fail;\n import com.github.tomakehurst.wiremock.WireMockServer;\n+import com.github.tomakehurst.wiremock.common.FileSource;\n import com.github.tomakehurst.wiremock.core.WireMockConfiguration;\n+import com.github.tomakehurst.wiremock.extension.Parameters;\n+import com.github.tomakehurst.wiremock.extension.ResponseTransformer;\n import com.github.tomakehurst.wiremock.stubbing.Scenario;\n import java.io.IOException;\n import java.net.InetSocketAddress;\n import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.List;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.Executor;\n import java.util.concurrent.Executors;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n import lombok.Cleanup;\n import org.apache.pulsar.client.impl.conf.ClientConfigurationData;\n+import org.apache.pulsar.common.util.FutureUtil;\n+import org.asynchttpclient.Request;\n+import org.asynchttpclient.RequestBuilder;\n import org.asynchttpclient.Response;\n import org.glassfish.jersey.client.ClientConfig;\n import org.glassfish.jersey.client.ClientRequest;\n@@ -52,10 +63,74 @@\n \n public class AsyncHttpConnectorTest {\n     WireMockServer server;\n+    ConcurrencyTestTransformer concurrencyTestTransformer = new ConcurrencyTestTransformer();\n+\n+    private static class CopyRequestBodyToResponseBodyTransformer extends ResponseTransformer {\n+        @Override\n+        public com.github.tomakehurst.wiremock.http.Response transform(\n+                com.github.tomakehurst.wiremock.http.Request request,\n+                com.github.tomakehurst.wiremock.http.Response response, FileSource fileSource, Parameters parameters) {\n+            return com.github.tomakehurst.wiremock.http.Response.Builder.like(response)\n+                    .body(request.getBodyAsString())\n+                    .build();\n+        }\n+\n+        @Override\n+        public String getName() {\n+            return \"copy-body\";\n+        }\n+\n+        @Override\n+        public boolean applyGlobally() {\n+            return false;\n+        }\n+    }\n+\n+    private static class ConcurrencyTestTransformer extends ResponseTransformer {\n+        private static final long DELAY_MS = 100;\n+        private final AtomicInteger concurrencyCounter = new AtomicInteger(0);\n+        private final AtomicInteger maxConcurrency = new AtomicInteger(0);\n+\n+        @Override\n+        public com.github.tomakehurst.wiremock.http.Response transform(\n+                com.github.tomakehurst.wiremock.http.Request request,\n+                com.github.tomakehurst.wiremock.http.Response response, FileSource fileSource, Parameters parameters) {\n+            int currentCounter = concurrencyCounter.incrementAndGet();\n+            maxConcurrency.updateAndGet(v -> Math.max(v, currentCounter));\n+            try {\n+                try {\n+                    Thread.sleep(DELAY_MS);\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+                return com.github.tomakehurst.wiremock.http.Response.Builder.like(response)\n+                        .body(String.valueOf(currentCounter))\n+                        .build();\n+            } finally {\n+                concurrencyCounter.decrementAndGet();\n+            }\n+        }\n+\n+        public int getMaxConcurrency() {\n+            return maxConcurrency.get();\n+        }\n+\n+        @Override\n+        public String getName() {\n+            return \"concurrency-test\";\n+        }\n+\n+        @Override\n+        public boolean applyGlobally() {\n+            return false;\n+        }\n+    }\n \n     @BeforeClass(alwaysRun = true)\n     void beforeClass() throws IOException {\n         server = new WireMockServer(WireMockConfiguration.wireMockConfig()\n+                .extensions(new CopyRequestBodyToResponseBodyTransformer(), concurrencyTestTransformer)\n+                .containerThreads(100)\n                 .port(0));\n         server.start();\n     }\n@@ -137,4 +212,129 @@ public void failure(Throwable failure) {\n         assertEquals(scenarioState, \"next\");\n         assertTrue(future.isCompletedExceptionally());\n     }\n+\n+    @Test\n+    void testMaxRedirects() {\n+        // Redirect to itself to test max redirects\n+        server.stubFor(get(urlEqualTo(\"/admin/v2/clusters\"))\n+                .willReturn(aResponse()\n+                        .withStatus(301)\n+                        .withHeader(\"Location\", \"http://localhost:\" + server.port() + \"/admin/v2/clusters\")));\n+\n+        ClientConfigurationData conf = new ClientConfigurationData();\n+        conf.setServiceUrl(\"http://localhost:\" + server.port());\n+\n+        @Cleanup\n+        AsyncHttpConnector connector = new AsyncHttpConnector(5000, 5000,\n+                5000, 0, conf, false);\n+\n+        Request request = new RequestBuilder(\"GET\")\n+                .setUrl(\"http://localhost:\" + server.port() + \"/admin/v2/clusters\")\n+                .build();\n+\n+        try {\n+            connector.executeRequest(request).get();\n+            fail();\n+        } catch (ExecutionException e) {\n+            assertTrue(e.getCause() instanceof AsyncHttpConnector.MaxRedirectException);\n+        } catch (InterruptedException e) {\n+            fail();\n+        }\n+    }\n+\n+    @Test\n+    void testRelativeRedirect() throws ExecutionException, InterruptedException {\n+        doTestRedirect(\"path2\");\n+    }\n+\n+    @Test\n+    void testAbsoluteRedirect() throws ExecutionException, InterruptedException {\n+        doTestRedirect(\"/path2\");\n+    }\n+\n+    @Test\n+    void testUrlRedirect() throws ExecutionException, InterruptedException {\n+        doTestRedirect(\"http://localhost:\" + server.port() + \"/path2\");\n+    }\n+\n+    private void doTestRedirect(String location) throws InterruptedException, ExecutionException {\n+        server.stubFor(get(urlEqualTo(\"/path1\"))\n+                .willReturn(aResponse()\n+                        .withStatus(301)\n+                        .withHeader(\"Location\", location)));\n+\n+        server.stubFor(get(urlEqualTo(\"/path2\"))\n+                .willReturn(aResponse()\n+                        .withBody(\"OK\")));\n+\n+        ClientConfigurationData conf = new ClientConfigurationData();\n+        conf.setServiceUrl(\"http://localhost:\" + server.port());\n+\n+        @Cleanup\n+        AsyncHttpConnector connector = new AsyncHttpConnector(5000, 5000,\n+                5000, 0, conf, false);\n+\n+        Request request = new RequestBuilder(\"GET\")\n+                .setUrl(\"http://localhost:\" + server.port() + \"/path1\")\n+                .build();\n+\n+        Response response = connector.executeRequest(request).get();\n+        assertEquals(response.getResponseBody(), \"OK\");\n+    }\n+\n+    @Test\n+    void testRedirectWithBody() throws ExecutionException, InterruptedException {\n+        server.stubFor(post(urlEqualTo(\"/path1\"))\n+                .willReturn(aResponse()\n+                        .withStatus(307)\n+                        .withHeader(\"Location\", \"/path2\")));\n+\n+        server.stubFor(post(urlEqualTo(\"/path2\"))\n+                .willReturn(aResponse()\n+                        .withTransformers(\"copy-body\")));\n+\n+        ClientConfigurationData conf = new ClientConfigurationData();\n+        conf.setServiceUrl(\"http://localhost:\" + server.port());\n+\n+        @Cleanup\n+        AsyncHttpConnector connector = new AsyncHttpConnector(5000, 5000,\n+                5000, 0, conf, false);\n+\n+        Request request = new RequestBuilder(\"POST\")\n+                .setUrl(\"http://localhost:\" + server.port() + \"/path1\")\n+                .setBody(\"Hello world!\")\n+                .build();\n+\n+        Response response = connector.executeRequest(request).get();\n+        assertEquals(response.getResponseBody(), \"Hello world!\");\n+    }\n+\n+    @Test\n+    void testMaxConnections() throws ExecutionException, InterruptedException {\n+        server.stubFor(post(urlEqualTo(\"/concurrency-test\"))\n+                .willReturn(aResponse()\n+                        .withTransformers(\"concurrency-test\")));\n+\n+        ClientConfigurationData conf = new ClientConfigurationData();\n+        int maxConnections = 10;\n+        conf.setConnectionsPerBroker(maxConnections);\n+        conf.setServiceUrl(\"http://localhost:\" + server.port());\n+\n+        @Cleanup\n+        AsyncHttpConnector connector = new AsyncHttpConnector(5000, 5000,\n+                5000, 0, conf, false);\n+\n+        Request request = new RequestBuilder(\"POST\")\n+                .setUrl(\"http://localhost:\" + server.port() + \"/concurrency-test\")\n+                .build();\n+\n+        List<CompletableFuture<Response>> futures = new ArrayList<>();\n+        for (int i = 0; i < 100; i++) {\n+            futures.add(connector.executeRequest(request));\n+        }\n+        FutureUtil.waitForAll(futures).get();\n+        int maxConcurrency = concurrencyTestTransformer.getMaxConcurrency();\n+        assertTrue(maxConcurrency > maxConnections / 2 && maxConcurrency <= maxConnections,\n+                \"concurrency didn't get limited as expected (max: \" + maxConcurrency + \")\");\n+    }\n }\n\\ No newline at end of file\n\ndiff --git a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java\nindex f56427b12038a..2f9c7536d753d 100644\n--- a/pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java\n+++ b/pulsar-client/src/test/java/org/apache/pulsar/client/impl/ClientBuilderImplTest.java\n@@ -123,7 +123,7 @@ public void testConnectionMaxIdleSeconds() throws Exception {\n         PulsarClient.builder().connectionMaxIdleSeconds(60);\n         // test config not correct.\n         try {\n-            PulsarClient.builder().connectionMaxIdleSeconds(30);\n+            PulsarClient.builder().connectionMaxIdleSeconds(14);\n             fail();\n         } catch (IllegalArgumentException e){\n         }\n",
    "agent_patch": null,
    "FAIL_TO_PASS": [],
    "PASS_TO_PASS": [],
    "test_output_before": null,
    "errors_before": [],
    "failed_before": [],
    "test_output_after": null,
    "errors_after": [],
    "failed_after": []
  }
]